{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebb61db",
   "metadata": {},
   "source": [
    "# Decoder-Only Exp 02: Length vs Content Decomposition\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 01 (Gemma 2 2B) found that **all surrogates beat the oracle** (recovery 115-146%),\n",
    "including a completely off-topic adversarial prefix (124%). This suggests the effect\n",
    "is primarily structural — any prefix text enriches document KV representations.\n",
    "\n",
    "This experiment disentangles **prefix length** from **prefix content** using a larger\n",
    "model (Gemma 3 4B-PT) with 10 conditions designed as a controlled factorial.\n",
    "\n",
    "## Conditions (10 total)\n",
    "\n",
    "### Baselines\n",
    "| # | Condition | Description |\n",
    "|---|-----------|-------------|\n",
    "| 1 | bare | No prefix — lower bound |\n",
    "| 2 | oracle | Real query as prefix — upper bound |\n",
    "\n",
    "### Content at surrogate length (~15 words)\n",
    "| # | Condition | Description |\n",
    "|---|-----------|-------------|\n",
    "| 3 | surr_reasonant | \"Evaluate the underlying arguments...\" (best from exp01) |\n",
    "| 4 | surr_universal | \"Analyze the following text...\" |\n",
    "| 5 | adversarial | Off-topic text (~15 words) |\n",
    "\n",
    "### Length sweep (random words, varying count)\n",
    "| # | Condition | Description |\n",
    "|---|-----------|-------------|\n",
    "| 6 | random_matched | Random words, same count as query (per-sample) |\n",
    "| 7 | random_15w | 15 random words |\n",
    "| 8 | random_30w | 30 random words |\n",
    "\n",
    "### Controls\n",
    "| # | Condition | Description |\n",
    "|---|-----------|-------------|\n",
    "| 9 | repeat_15w | \"the\" × 15 — minimal content, same length |\n",
    "| 10 | oracle_padded | Query + \"the\" padding to 15 words |\n",
    "\n",
    "## Key comparisons\n",
    "\n",
    "1. **Pure length**: random_matched → random_15w → random_30w\n",
    "2. **Content at oracle's length**: oracle vs random_matched\n",
    "3. **Content at surrogate length**: surr_reasonant vs random_15w vs adversarial\n",
    "4. **Token diversity**: repeat_15w vs random_15w (both 15 words)\n",
    "5. **Oracle + length boost**: oracle_padded vs oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a775cf7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:56:04.887959Z",
     "iopub.status.busy": "2026-02-20T14:56:04.887503Z",
     "iopub.status.idle": "2026-02-20T14:56:20.846364Z",
     "shell.execute_reply": "2026-02-20T14:56:20.845301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/gemma-3-4b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4874eb6264954602b84043f5eff2080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 02: Length vs Content Decomposition\n",
      "N: 400, Model: google/gemma-3-4b-it\n",
      "DEVICE: cuda:0, dtype: torch.bfloat16\n",
      "GPU memory: 8.60 GB\n",
      "Config: Gemma3Config\n",
      "Vocab size: 262208\n",
      "Num layers: 34\n",
      "Num KV heads: 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup and model loading\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, gc, re\n",
    "import random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 400\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "\n",
    "RESULTS_DIR = Path(\"../../../results/decoder_only/exp02\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", torch_dtype=torch.bfloat16, token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "\n",
    "print(f\"Exp 02: Length vs Content Decomposition\")\n",
    "print(f\"N: {N_SAMPLES}, Model: {MODEL_NAME}\")\n",
    "print(f\"DEVICE: {DEVICE}, dtype: {next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Config: {type(model.config).__name__}\")\n",
    "text_cfg = getattr(model.config, 'text_config', model.config)\n",
    "print(f\"Vocab size: {getattr(text_cfg, 'vocab_size', 'N/A')}\")\n",
    "print(f\"Num layers: {getattr(text_cfg, 'num_hidden_layers', 'N/A')}\")\n",
    "print(f\"Num KV heads: {getattr(text_cfg, 'num_key_value_heads', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2d5428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:56:20.850656Z",
     "iopub.status.busy": "2026-02-20T14:56:20.850003Z",
     "iopub.status.idle": "2026-02-20T14:56:20.876265Z",
     "shell.execute_reply": "2026-02-20T14:56:20.875190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring functions defined.\n",
      "\n",
      "Prefix token counts:\n",
      "  surr_reasonant        11w  14tok: Evaluate the underlying arguments, sentiment, and ...\n",
      "  surr_universal        13w  16tok: Analyze the following text for all key entities, f...\n",
      "  adversarial_15w       19w  23tok: The recipe calls for two cups of flour, one cup of...\n",
      "  repeat_15w            15w   ?tok: the the the the the ...\n",
      "                           -> 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: KV cache helpers and scoring function\n",
    "\n",
    "def slice_kv_cache(cache, start_idx):\n",
    "    # Remove first start_idx entries from KV cache.\n",
    "    from transformers import DynamicCache\n",
    "\n",
    "    if isinstance(cache, DynamicCache):\n",
    "        sliced = DynamicCache()\n",
    "        for i in range(len(cache.layers)):\n",
    "            k = cache.layers[i].keys[:, :, start_idx:, :]\n",
    "            v = cache.layers[i].values[:, :, start_idx:, :]\n",
    "            sliced.update(k, v, i)\n",
    "        return sliced\n",
    "    else:\n",
    "        return tuple(\n",
    "            (k[:, :, start_idx:, :], v[:, :, start_idx:, :])\n",
    "            for k, v in cache\n",
    "        )\n",
    "\n",
    "\n",
    "def score(doc_text, query_text, answer_text, prefix_text=None):\n",
    "    # Score NLL of answer tokens using two-phase KV cache approach.\n",
    "    #\n",
    "    # Phase A: Forward [prefix + doc] (or just [doc]) -> KV cache.\n",
    "    # Phase B: Forward [query + answer] using cached doc KV.\n",
    "    # If prefix_text is provided, prefix KV entries are sliced off.\n",
    "\n",
    "    # --- Phase A: Conditioning ---\n",
    "    if prefix_text:\n",
    "        prefix_ids = tokenizer(prefix_text + \"\\n\", add_special_tokens=True,\n",
    "                               truncation=True, max_length=512).input_ids\n",
    "        doc_ids = tokenizer(doc_text, add_special_tokens=False,\n",
    "                            truncation=True, max_length=1536).input_ids\n",
    "        cond_ids = prefix_ids + doc_ids\n",
    "        slice_start = len(prefix_ids)\n",
    "    else:\n",
    "        cond_ids = tokenizer(doc_text, add_special_tokens=True,\n",
    "                             truncation=True, max_length=2048).input_ids\n",
    "        slice_start = 0\n",
    "\n",
    "    cond_tensor = torch.tensor([cond_ids], dtype=torch.long, device=DEVICE)\n",
    "    total_cond_len = len(cond_ids)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        phase_a = model(input_ids=cond_tensor, use_cache=True)\n",
    "\n",
    "    cache = phase_a.past_key_values\n",
    "    del phase_a\n",
    "\n",
    "    if slice_start > 0:\n",
    "        cache = slice_kv_cache(cache, slice_start)\n",
    "\n",
    "    # --- Phase B: Inference with query + answer ---\n",
    "    query_part_ids = tokenizer(\"\\n\" + query_text + \"\\n\", add_special_tokens=False).input_ids\n",
    "    answer_ids = tokenizer(answer_text, add_special_tokens=False,\n",
    "                           truncation=True, max_length=256).input_ids\n",
    "\n",
    "    if not answer_ids:\n",
    "        del cache\n",
    "        return 0.0\n",
    "\n",
    "    phase_b_ids = query_part_ids + answer_ids\n",
    "    phase_b_tensor = torch.tensor([phase_b_ids], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    pos_ids = torch.arange(total_cond_len, total_cond_len + len(phase_b_ids),\n",
    "                           device=DEVICE).unsqueeze(0)\n",
    "\n",
    "    cache_position = torch.arange(total_cond_len, total_cond_len + len(phase_b_ids),\n",
    "                                  device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        phase_b = model(\n",
    "            input_ids=phase_b_tensor,\n",
    "            past_key_values=cache,\n",
    "            position_ids=pos_ids,\n",
    "            cache_position=cache_position,\n",
    "            use_cache=False,\n",
    "        )\n",
    "\n",
    "    logits = phase_b.logits\n",
    "    n_query_part = len(query_part_ids)\n",
    "    n_answer = len(answer_ids)\n",
    "\n",
    "    answer_logits = logits[0, n_query_part - 1 : n_query_part - 1 + n_answer, :]\n",
    "    answer_targets = torch.tensor(answer_ids, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    log_probs = F.log_softmax(answer_logits, dim=-1)\n",
    "    token_log_probs = log_probs.gather(1, answer_targets.unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "\n",
    "    del cache, phase_b, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "\n",
    "def score_full_sequence(doc_text, query_text, answer_text):\n",
    "    # Single-pass scoring for validation.\n",
    "    doc_ids = tokenizer(doc_text, add_special_tokens=True,\n",
    "                        truncation=True, max_length=2048).input_ids\n",
    "    query_part_ids = tokenizer(\"\\n\" + query_text + \"\\n\", add_special_tokens=False).input_ids\n",
    "    answer_ids = tokenizer(answer_text, add_special_tokens=False,\n",
    "                           truncation=True, max_length=256).input_ids\n",
    "\n",
    "    if not answer_ids:\n",
    "        return 0.0\n",
    "\n",
    "    all_ids = doc_ids + query_part_ids + answer_ids\n",
    "    input_tensor = torch.tensor([all_ids], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_tensor, use_cache=False)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    n_doc = len(doc_ids)\n",
    "    n_query = len(query_part_ids)\n",
    "    n_answer = len(answer_ids)\n",
    "\n",
    "    start = n_doc + n_query - 1\n",
    "    answer_logits = logits[0, start : start + n_answer, :]\n",
    "    answer_targets = torch.tensor(answer_ids, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    log_probs = F.log_softmax(answer_logits, dim=-1)\n",
    "    token_log_probs = log_probs.gather(1, answer_targets.unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "\n",
    "    del outputs, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "\n",
    "# === Surrogate definitions ===\n",
    "SURR_REASONANT = \"Evaluate the underlying arguments, sentiment, and intent of the following passage.\"\n",
    "SURR_UNIVERSAL = \"Analyze the following text for all key entities, factual claims, and logical relationships.\"\n",
    "ADVERSARIAL_15W = \"The recipe calls for two cups of flour, one cup of sugar, a pinch of salt, and some butter.\"\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "print(\"Scoring functions defined.\")\n",
    "print(f\"\\nPrefix token counts:\")\n",
    "for name, text in [('surr_reasonant', SURR_REASONANT),\n",
    "                    ('surr_universal', SURR_UNIVERSAL),\n",
    "                    ('adversarial_15w', ADVERSARIAL_15W)]:\n",
    "    n_tok = len(tokenizer(text, add_special_tokens=False).input_ids)\n",
    "    n_words = len(text.split())\n",
    "    print(f\"  {name:<20} {n_words:>3}w {n_tok:>3}tok: {text[:50]}...\")\n",
    "print(f\"  {'repeat_15w':<20} {'15':>3}w {'?':>3}tok: the the the the the ...\")\n",
    "the_15 = \" \".join([\"the\"] * 15)\n",
    "n_tok_the = len(tokenizer(the_15, add_special_tokens=False).input_ids)\n",
    "print(f\"  {'':>24} -> {n_tok_the} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e6d2bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:56:20.879740Z",
     "iopub.status.busy": "2026-02-20T14:56:20.879440Z",
     "iopub.status.idle": "2026-02-20T14:56:22.311392Z",
     "shell.execute_reply": "2026-02-20T14:56:22.310226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO v1.1 validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates: 1200\n",
      "Loaded 400 samples\n",
      "Mean passage words: 73\n",
      "Mean query words: 5.9\n",
      "\n",
      "Prefix word counts:\n",
      "  random_matched       mean=5.9, range=[2, 15]\n",
      "  random_15w           mean=15.0, range=[15, 15]\n",
      "  random_30w           mean=30.0, range=[30, 30]\n",
      "  repeat_15w           mean=15.0, range=[15, 15]\n",
      "  oracle_padded        mean=15.0, range=[15, 15]\n",
      "\n",
      "Sample 0:\n",
      "  Query (5w): average annual temperature of Uruguay\n",
      "  random_matched:     an Chronic value dermis. hide\n",
      "  random_15w:         separate kelpie to infected the be used them, eight Hindu ea...\n",
      "  random_30w:         Politics coal New rights copy) ratio the the say people earn...\n",
      "  repeat_15w:         the the the the the the the the the the the the the the the\n",
      "  oracle_padded:      average annual temperature of Uruguay the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load MS MARCO data and generate per-sample prefixes\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading MS MARCO v1.1 validation...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 3 * N_SAMPLES:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "print(f\"Total candidates: {len(all_candidates)}\")\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds, all_candidates\n",
    "gc.collect()\n",
    "\n",
    "# Build a pool of random English words from OTHER passages for random prefixes.\n",
    "# Use the second half of the shuffled data as the word pool (no overlap).\n",
    "word_pool = []\n",
    "for i in indices[N_SAMPLES:N_SAMPLES + 500]:\n",
    "    words = samples[0]['passage'].split() if i >= len(samples) else []\n",
    "    # Use all_candidates — but it's deleted. Rebuild from samples neighbors.\n",
    "    pass\n",
    "\n",
    "# Simpler: collect words from all passages, shuffle once\n",
    "all_words = []\n",
    "for s in samples:\n",
    "    all_words.extend(s['passage'].split())\n",
    "pyrandom.seed(SEED + 99)\n",
    "pyrandom.shuffle(all_words)\n",
    "word_pool = all_words  # ~30k words, plenty for random prefixes\n",
    "\n",
    "# Generate per-sample prefixes\n",
    "for i, s in enumerate(samples):\n",
    "    query_wc = len(s['query'].split())\n",
    "\n",
    "    # random_matched: same word count as query, from word pool\n",
    "    pool_offset = i * 50  # each sample gets a different slice\n",
    "    s['random_matched'] = \" \".join(word_pool[pool_offset:pool_offset + query_wc])\n",
    "\n",
    "    # random_15w: 15 words from pool\n",
    "    s['random_15w'] = \" \".join(word_pool[pool_offset + 50:pool_offset + 65])\n",
    "\n",
    "    # random_30w: 30 words from pool\n",
    "    s['random_30w'] = \" \".join(word_pool[pool_offset + 65:pool_offset + 95])\n",
    "\n",
    "    # repeat_15w: \"the\" x 15\n",
    "    s['repeat_15w'] = \" \".join([\"the\"] * 15)\n",
    "\n",
    "    # oracle_padded: query + \"the\" to reach 15 words\n",
    "    pad_count = max(0, 15 - query_wc)\n",
    "    s['oracle_padded'] = s['query'] + \" \" + \" \".join([\"the\"] * pad_count)\n",
    "\n",
    "print(f\"Loaded {len(samples)} samples\")\n",
    "print(f\"Mean passage words: {np.mean([s['word_count'] for s in samples]):.0f}\")\n",
    "print(f\"Mean query words: {np.mean([len(s['query'].split()) for s in samples]):.1f}\")\n",
    "\n",
    "# Show prefix word count stats\n",
    "print(f\"\\nPrefix word counts:\")\n",
    "for key in ['random_matched', 'random_15w', 'random_30w', 'repeat_15w', 'oracle_padded']:\n",
    "    wcs = [len(s[key].split()) for s in samples]\n",
    "    print(f\"  {key:<20} mean={np.mean(wcs):.1f}, range=[{min(wcs)}, {max(wcs)}]\")\n",
    "\n",
    "print(f\"\\nSample 0:\")\n",
    "print(f\"  Query ({len(samples[0]['query'].split())}w): {samples[0]['query']}\")\n",
    "print(f\"  random_matched:     {samples[0]['random_matched']}\")\n",
    "print(f\"  random_15w:         {samples[0]['random_15w'][:60]}...\")\n",
    "print(f\"  random_30w:         {samples[0]['random_30w'][:60]}...\")\n",
    "print(f\"  repeat_15w:         {samples[0]['repeat_15w']}\")\n",
    "print(f\"  oracle_padded:      {samples[0]['oracle_padded']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bc5a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:56:22.315392Z",
     "iopub.status.busy": "2026-02-20T14:56:22.314520Z",
     "iopub.status.idle": "2026-02-20T14:56:24.947498Z",
     "shell.execute_reply": "2026-02-20T14:56:24.946437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION: Two-phase caching vs single-pass\n",
      "======================================================================\n",
      "\n",
      "Comparing bare score (cached) vs full-sequence for 5 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 0: cached=0.738281, full=0.746094, diff=0.00781250 [OK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 1: cached=0.882812, full=0.878906, diff=0.00390625 [OK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2: cached=1.851562, full=1.859375, diff=0.00781250 [OK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3: cached=0.691406, full=0.699219, diff=0.00781250 [OK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4: cached=4.843750, full=4.781250, diff=0.06250000 [MISMATCH]\n",
      "\n",
      "WARNING: max diff = 0.06250000\n",
      "\n",
      "Quick sanity check (sample 0):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bare:      0.738281\n",
      "  oracle:    0.859375 (delta: -0.1211)\n",
      "  random_15w:0.894531 (delta: -0.1562)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Validate two-phase caching vs single-pass\n",
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION: Two-phase caching vs single-pass\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nComparing bare score (cached) vs full-sequence for 5 samples...\")\n",
    "max_diff = 0.0\n",
    "for i in range(5):\n",
    "    s = samples[i]\n",
    "    nll_cached = score(s['passage'], s['query'], s['answer'], prefix_text=None)\n",
    "    nll_full = score_full_sequence(s['passage'], s['query'], s['answer'])\n",
    "    diff = abs(nll_cached - nll_full)\n",
    "    max_diff = max(max_diff, diff)\n",
    "    status = \"OK\" if diff < 0.01 else \"MISMATCH\"\n",
    "    print(f\"  Sample {i}: cached={nll_cached:.6f}, full={nll_full:.6f}, \"\n",
    "          f\"diff={diff:.8f} [{status}]\")\n",
    "\n",
    "if max_diff < 0.01:\n",
    "    print(f\"\\nVALIDATION PASSED (max diff = {max_diff:.8f})\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: max diff = {max_diff:.8f}\")\n",
    "\n",
    "# Quick sanity: conditioned vs bare\n",
    "print(f\"\\nQuick sanity check (sample 0):\")\n",
    "nll_bare = score(samples[0]['passage'], samples[0]['query'], samples[0]['answer'])\n",
    "nll_oracle = score(samples[0]['passage'], samples[0]['query'], samples[0]['answer'],\n",
    "                   prefix_text=samples[0]['query'])\n",
    "nll_random = score(samples[0]['passage'], samples[0]['query'], samples[0]['answer'],\n",
    "                   prefix_text=samples[0]['random_15w'])\n",
    "print(f\"  bare:      {nll_bare:.6f}\")\n",
    "print(f\"  oracle:    {nll_oracle:.6f} (delta: {nll_bare - nll_oracle:+.4f})\")\n",
    "print(f\"  random_15w:{nll_random:.6f} (delta: {nll_bare - nll_random:+.4f})\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41dcf65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T14:56:24.951200Z",
     "iopub.status.busy": "2026-02-20T14:56:24.950918Z",
     "iopub.status.idle": "2026-02-20T15:09:29.351492Z",
     "shell.execute_reply": "2026-02-20T15:09:29.350530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCORING ALL CONDITIONS\n",
      "======================================================================\n",
      "Starting fresh: 10 conditions x 400 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aae1074fe014d0fb0633bff0f182bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 20/400 | 0.6m | ETA 12.3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 40/400 | 1.3m | ETA 11.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 60/400 | 1.9m | ETA 11.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 80/400 | 2.6m | ETA 10.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/400 | 3.2m | ETA 9.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 120/400 | 3.9m | ETA 9.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 140/400 | 4.5m | ETA 8.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 160/400 | 5.2m | ETA 7.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 180/400 | 5.8m | ETA 7.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/400 | 6.5m | ETA 6.5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 220/400 | 7.1m | ETA 5.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 240/400 | 7.8m | ETA 5.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 260/400 | 8.5m | ETA 4.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 280/400 | 9.1m | ETA 3.9m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/400 | 9.8m | ETA 3.3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 320/400 | 10.4m | ETA 2.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 340/400 | 11.1m | ETA 2.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 360/400 | 11.7m | ETA 1.3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 380/400 | 12.4m | ETA 0.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 400/400 | 13.1m | ETA 0.0m\n",
      "\n",
      "Scoring complete: 400 samples, 10 conditions in 13.1 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Scoring loop — 10 conditions x 400 samples\n",
    "print(\"=\" * 70)\n",
    "print(\"SCORING ALL CONDITIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "COND_NAMES = [\n",
    "    'bare', 'oracle',\n",
    "    'surr_reasonant', 'surr_universal', 'adversarial',\n",
    "    'random_matched', 'random_15w', 'random_30w',\n",
    "    'repeat_15w', 'oracle_padded',\n",
    "]\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    ckpt = json.loads(CHECKPOINT_PATH.read_text())\n",
    "    if ckpt.get('n_total') == N_SAMPLES and len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            results = ckpt['results']\n",
    "            start_idx = len(results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {len(COND_NAMES)} conditions x {N_SAMPLES} samples\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Scoring\"):\n",
    "    s = samples[i]\n",
    "    query = s['query']\n",
    "    passage = s['passage']\n",
    "    answer = s['answer']\n",
    "\n",
    "    result = {\n",
    "        'query': query,\n",
    "        'answer': answer,\n",
    "        'passage_words': s['word_count'],\n",
    "        'query_words': len(query.split()),\n",
    "    }\n",
    "\n",
    "    # 1. bare\n",
    "    result['nll_bare'] = score(passage, query, answer)\n",
    "\n",
    "    # 2. oracle\n",
    "    result['nll_oracle'] = score(passage, query, answer, prefix_text=query)\n",
    "\n",
    "    # 3. surr_reasonant\n",
    "    result['nll_surr_reasonant'] = score(passage, query, answer,\n",
    "                                         prefix_text=SURR_REASONANT)\n",
    "\n",
    "    # 4. surr_universal\n",
    "    result['nll_surr_universal'] = score(passage, query, answer,\n",
    "                                          prefix_text=SURR_UNIVERSAL)\n",
    "\n",
    "    # 5. adversarial\n",
    "    result['nll_adversarial'] = score(passage, query, answer,\n",
    "                                      prefix_text=ADVERSARIAL_15W)\n",
    "\n",
    "    # 6. random_matched (same word count as query)\n",
    "    result['nll_random_matched'] = score(passage, query, answer,\n",
    "                                          prefix_text=s['random_matched'])\n",
    "\n",
    "    # 7. random_15w\n",
    "    result['nll_random_15w'] = score(passage, query, answer,\n",
    "                                      prefix_text=s['random_15w'])\n",
    "\n",
    "    # 8. random_30w\n",
    "    result['nll_random_30w'] = score(passage, query, answer,\n",
    "                                      prefix_text=s['random_30w'])\n",
    "\n",
    "    # 9. repeat_15w (\"the\" x 15)\n",
    "    result['nll_repeat_15w'] = score(passage, query, answer,\n",
    "                                      prefix_text=s['repeat_15w'])\n",
    "\n",
    "    # 10. oracle_padded (query + \"the\" to 15 words)\n",
    "    result['nll_oracle_padded'] = score(passage, query, answer,\n",
    "                                         prefix_text=s['oracle_padded'])\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    if (i + 1) % 20 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'results': results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CHECKPOINT_PATH.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = i - start_idx + 1\n",
    "        eta = (N_SAMPLES - i - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {i+1}/{N_SAMPLES} | {elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nScoring complete: {len(results)} samples, \"\n",
    "      f\"{len(COND_NAMES)} conditions in {elapsed/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9194e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:09:29.355864Z",
     "iopub.status.busy": "2026-02-20T15:09:29.355547Z",
     "iopub.status.idle": "2026-02-20T15:09:29.379617Z",
     "shell.execute_reply": "2026-02-20T15:09:29.378717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESULTS (N=400)\n",
      "======================================================================\n",
      "\n",
      "  Condition            ~words      NLL    vs bare        d     Win%            p   sig   Recovery\n",
      "  --------------------------------------------------------------------------------------------------\n",
      "  bare                      0   1.6022         --       --       --           --    --         --\n",
      "  oracle                    6   0.9044    +0.6977   +0.428    73.8%     2.32e-16   ***     100.0%\n",
      "  surr_reasonant           11   0.8076    +0.7946   +0.435    64.5%     9.27e-17   ***     113.9%\n",
      "  surr_universal           13   0.8527    +0.7495   +0.400    65.5%     1.39e-14   ***     107.4%\n",
      "  adversarial              15   1.1259    +0.4762   +0.240    59.5%     2.19e-06   ***      68.3%\n",
      "  random_matched            6   0.7412    +0.8609   +0.518    77.8%     2.06e-22   ***     123.4%\n",
      "  random_15w               15   1.0135    +0.5887   +0.315    60.8%     7.46e-10   ***      84.4%\n",
      "  random_30w               30   1.1916    +0.4105   +0.199    56.5%     7.96e-05   ***      58.8%\n",
      "  repeat_15w               15   0.8911    +0.7110   +0.401    65.2%     1.22e-14   ***     101.9%\n",
      "  oracle_padded            15   0.9967    +0.6055   +0.358    63.0%     3.71e-12   ***      86.8%\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Results table\n",
    "print(\"=\" * 70)\n",
    "print(f\"RESULTS (N={len(results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract arrays\n",
    "arrays = {}\n",
    "for name in ['bare', 'oracle', 'surr_reasonant', 'surr_universal', 'adversarial',\n",
    "             'random_matched', 'random_15w', 'random_30w', 'repeat_15w', 'oracle_padded']:\n",
    "    arrays[name] = np.array([r[f'nll_{name}'] for r in results])\n",
    "\n",
    "bare = arrays['bare']\n",
    "oracle = arrays['oracle']\n",
    "oracle_delta_mean = (bare - oracle).mean()\n",
    "\n",
    "print(f\"\\n  {'Condition':<20} {'~words':>6} {'NLL':>8} {'vs bare':>10} {'d':>8} \"\n",
    "      f\"{'Win%':>8} {'p':>12} {'sig':>5} {'Recovery':>10}\")\n",
    "print(f\"  {'-'*98}\")\n",
    "\n",
    "# Approximate word counts for display\n",
    "approx_words = {\n",
    "    'bare': 0, 'oracle': 6, 'surr_reasonant': 11, 'surr_universal': 13,\n",
    "    'adversarial': 15, 'random_matched': 6, 'random_15w': 15, 'random_30w': 30,\n",
    "    'repeat_15w': 15, 'oracle_padded': 15,\n",
    "}\n",
    "\n",
    "analysis = {}\n",
    "for name in ['bare', 'oracle', 'surr_reasonant', 'surr_universal', 'adversarial',\n",
    "             'random_matched', 'random_15w', 'random_30w', 'repeat_15w', 'oracle_padded']:\n",
    "    nlls = arrays[name]\n",
    "    mean_nll = nlls.mean()\n",
    "    aw = approx_words[name]\n",
    "\n",
    "    if name == 'bare':\n",
    "        print(f\"  {name:<20} {aw:>6} {mean_nll:>8.4f} {'--':>10} {'--':>8} \"\n",
    "              f\"{'--':>8} {'--':>12} {'--':>5} {'--':>10}\")\n",
    "        analysis[name] = {'mean_nll': float(mean_nll)}\n",
    "    else:\n",
    "        diff = bare - nlls\n",
    "        d = cohens_d(diff)\n",
    "        win_pct = 100 * np.mean(diff > 0)\n",
    "        _, p_val = stats.ttest_1samp(diff, 0)\n",
    "        sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "\n",
    "        if oracle_delta_mean > 0:\n",
    "            recovery = diff.mean() / oracle_delta_mean * 100\n",
    "            rec_str = f\"{recovery:>9.1f}%\"\n",
    "        else:\n",
    "            recovery = float('nan')\n",
    "            rec_str = \"n/a\"\n",
    "\n",
    "        print(f\"  {name:<20} {aw:>6} {mean_nll:>8.4f} {diff.mean():>+10.4f} {d:>+8.3f} \"\n",
    "              f\"{win_pct:>7.1f}% {p_val:>12.2e} {sig:>5} {rec_str:>10}\")\n",
    "        analysis[name] = {\n",
    "            'mean_nll': float(mean_nll), 'delta': float(diff.mean()),\n",
    "            'd': float(d), 'win_pct': float(win_pct), 'p': float(p_val),\n",
    "            'recovery': float(recovery) if not np.isnan(recovery) else None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c6ad20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:09:29.382854Z",
     "iopub.status.busy": "2026-02-20T15:09:29.382551Z",
     "iopub.status.idle": "2026-02-20T15:09:29.406440Z",
     "shell.execute_reply": "2026-02-20T15:09:29.405559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DECOMPOSITION: LENGTH vs CONTENT\n",
      "======================================================================\n",
      "\n",
      "--- 1. PURE LENGTH EFFECT (random words, varying count) ---\n",
      "  Condition            ~words  d vs bare            p\n",
      "  -------------------------------------------------------\n",
      "  random_matched           ~6    +0.5177     2.06e-22 ***\n",
      "  random_15w               15    +0.3155     7.46e-10 ***\n",
      "  random_30w               30    +0.1993     7.96e-05 ***\n",
      "\n",
      "  Length scaling: 15w/matched = 0.61x, 30w/matched = 0.39x\n",
      "  -> Benefit DECREASES at 30w (diminishing returns)\n",
      "\n",
      "--- 2. CONTENT EFFECT at oracle's length (~6 words) ---\n",
      "  oracle        d vs bare = +0.4284\n",
      "  random_matched d vs bare = +0.5177\n",
      "  oracle vs random_matched: d = -0.1517 (**)\n",
      "  -> Content accounts for -21% of oracle benefit at this length\n",
      "  -> Structure accounts for 121%\n",
      "\n",
      "--- 3. CONTENT EFFECT at surrogate length (~15 words) ---\n",
      "  Condition                 Content  d vs bare\n",
      "  ------------------------------------------------\n",
      "  repeat_15w                   none    +0.4008\n",
      "  random_15w                 random    +0.3155\n",
      "  adversarial             off-topic    +0.2403\n",
      "  surr_universal            generic    +0.3999\n",
      "  surr_reasonant           targeted    +0.4346\n",
      "\n",
      "  surr_reasonant vs random_15w: d = +0.2276 (***)\n",
      "  -> Content matters at matched length\n",
      "  random_15w vs repeat_15w: d = -0.1535 (**)\n",
      "  -> Token diversity matters\n",
      "\n",
      "--- 4. ORACLE + LENGTH BOOST ---\n",
      "  oracle (natural):  d = +0.4284\n",
      "  oracle_padded(15w): d = +0.3584\n",
      "  padding boost: d = -0.1122 (*)\n",
      "  -> Padding oracle HURTS — the extra 'the' tokens add noise\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Length vs Content decomposition\n",
    "print(\"=\" * 70)\n",
    "print(\"DECOMPOSITION: LENGTH vs CONTENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --- 1. Pure length effect (random words at different counts) ---\n",
    "print(f\"\\n--- 1. PURE LENGTH EFFECT (random words, varying count) ---\")\n",
    "print(f\"  {'Condition':<20} {'~words':>6} {'d vs bare':>10} {'p':>12}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "for name, nw in [('random_matched', '~6'), ('random_15w', '15'), ('random_30w', '30')]:\n",
    "    diff = bare - arrays[name]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {name:<20} {nw:>6} {d:>+10.4f} {p:>12.2e} {sig}\")\n",
    "\n",
    "# Length gradient\n",
    "d_matched = cohens_d(bare - arrays['random_matched'])\n",
    "d_15 = cohens_d(bare - arrays['random_15w'])\n",
    "d_30 = cohens_d(bare - arrays['random_30w'])\n",
    "if d_matched > 0:\n",
    "    print(f\"\\n  Length scaling: 15w/matched = {d_15/d_matched:.2f}x, \"\n",
    "          f\"30w/matched = {d_30/d_matched:.2f}x\")\n",
    "    if d_30 > d_15 * 1.2:\n",
    "        print(f\"  -> Benefit INCREASES with length (not saturated)\")\n",
    "    elif d_30 > d_15 * 0.9:\n",
    "        print(f\"  -> Benefit roughly FLAT from 15w to 30w (saturated)\")\n",
    "    else:\n",
    "        print(f\"  -> Benefit DECREASES at 30w (diminishing returns)\")\n",
    "\n",
    "# --- 2. Content effect at oracle's length (~6 words) ---\n",
    "print(f\"\\n--- 2. CONTENT EFFECT at oracle's length (~6 words) ---\")\n",
    "diff_oracle_vs_random = arrays['random_matched'] - arrays['oracle']\n",
    "d_content_oracle = cohens_d(diff_oracle_vs_random)\n",
    "_, p_content_oracle = stats.ttest_1samp(diff_oracle_vs_random, 0)\n",
    "sig_co = '***' if p_content_oracle < 0.001 else '**' if p_content_oracle < 0.01 else '*' if p_content_oracle < 0.05 else 'ns'\n",
    "\n",
    "d_oracle = cohens_d(bare - arrays['oracle'])\n",
    "d_random_m = cohens_d(bare - arrays['random_matched'])\n",
    "\n",
    "print(f\"  oracle        d vs bare = {d_oracle:+.4f}\")\n",
    "print(f\"  random_matched d vs bare = {d_random_m:+.4f}\")\n",
    "print(f\"  oracle vs random_matched: d = {d_content_oracle:+.4f} ({sig_co})\")\n",
    "if d_oracle > 0 and d_random_m > 0:\n",
    "    content_pct_oracle = (d_oracle - d_random_m) / d_oracle * 100\n",
    "    print(f\"  -> Content accounts for {content_pct_oracle:.0f}% of oracle benefit at this length\")\n",
    "    print(f\"  -> Structure accounts for {100 - content_pct_oracle:.0f}%\")\n",
    "\n",
    "# --- 3. Content effect at surrogate length (~15 words) ---\n",
    "print(f\"\\n--- 3. CONTENT EFFECT at surrogate length (~15 words) ---\")\n",
    "print(f\"  {'Condition':<20} {'Content':>12} {'d vs bare':>10}\")\n",
    "print(f\"  {'-'*48}\")\n",
    "for name, content_type in [('repeat_15w', 'none'),\n",
    "                            ('random_15w', 'random'),\n",
    "                            ('adversarial', 'off-topic'),\n",
    "                            ('surr_universal', 'generic'),\n",
    "                            ('surr_reasonant', 'targeted')]:\n",
    "    d = cohens_d(bare - arrays[name])\n",
    "    print(f\"  {name:<20} {content_type:>12} {d:>+10.4f}\")\n",
    "\n",
    "# Pairwise: surr_reasonant vs random_15w\n",
    "diff_sr = arrays['random_15w'] - arrays['surr_reasonant']\n",
    "d_sr = cohens_d(diff_sr)\n",
    "_, p_sr = stats.ttest_1samp(diff_sr, 0)\n",
    "sig_sr = '***' if p_sr < 0.001 else '**' if p_sr < 0.01 else '*' if p_sr < 0.05 else 'ns'\n",
    "print(f\"\\n  surr_reasonant vs random_15w: d = {d_sr:+.4f} ({sig_sr})\")\n",
    "print(f\"  -> {'Content matters' if p_sr < 0.05 else 'No significant content effect'} \"\n",
    "      f\"at matched length\")\n",
    "\n",
    "# Pairwise: random_15w vs repeat_15w\n",
    "diff_rr = arrays['repeat_15w'] - arrays['random_15w']\n",
    "d_rr = cohens_d(diff_rr)\n",
    "_, p_rr = stats.ttest_1samp(diff_rr, 0)\n",
    "sig_rr = '***' if p_rr < 0.001 else '**' if p_rr < 0.01 else '*' if p_rr < 0.05 else 'ns'\n",
    "print(f\"  random_15w vs repeat_15w: d = {d_rr:+.4f} ({sig_rr})\")\n",
    "print(f\"  -> {'Token diversity matters' if p_rr < 0.05 else 'Token diversity does NOT matter'}\")\n",
    "\n",
    "# --- 4. Oracle + length boost ---\n",
    "print(f\"\\n--- 4. ORACLE + LENGTH BOOST ---\")\n",
    "d_oracle_plain = cohens_d(bare - arrays['oracle'])\n",
    "d_oracle_pad = cohens_d(bare - arrays['oracle_padded'])\n",
    "diff_pad = arrays['oracle'] - arrays['oracle_padded']\n",
    "d_pad_boost = cohens_d(diff_pad)\n",
    "_, p_pad = stats.ttest_1samp(diff_pad, 0)\n",
    "sig_pad = '***' if p_pad < 0.001 else '**' if p_pad < 0.01 else '*' if p_pad < 0.05 else 'ns'\n",
    "\n",
    "print(f\"  oracle (natural):  d = {d_oracle_plain:+.4f}\")\n",
    "print(f\"  oracle_padded(15w): d = {d_oracle_pad:+.4f}\")\n",
    "print(f\"  padding boost: d = {d_pad_boost:+.4f} ({sig_pad})\")\n",
    "if d_pad_boost > 0.05:\n",
    "    print(f\"  -> Padding oracle to 15w IMPROVES it — length matters even with real query\")\n",
    "elif d_pad_boost < -0.05:\n",
    "    print(f\"  -> Padding oracle HURTS — the extra 'the' tokens add noise\")\n",
    "else:\n",
    "    print(f\"  -> Padding has no significant effect on oracle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934fa18a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:09:29.410513Z",
     "iopub.status.busy": "2026-02-20T15:09:29.410028Z",
     "iopub.status.idle": "2026-02-20T15:09:29.422547Z",
     "shell.execute_reply": "2026-02-20T15:09:29.421599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY DECOMPOSITION\n",
      "======================================================================\n",
      "\n",
      "  Effect sizes (Cohen's d vs bare):\n",
      "                                        d\n",
      "  ------------------------------------------\n",
      "                bare (reference)  +0.0000\n",
      "                --- ~6 words ---\n",
      "            random_matched (~6w)  +0.5177\n",
      "                    oracle (~6w)  +0.4284\n",
      "               --- ~15 words ---\n",
      "                      repeat_15w  +0.4008\n",
      "                      random_15w  +0.3155\n",
      "              adversarial (~15w)  +0.2403\n",
      "             oracle_padded (15w)  +0.3584\n",
      "           surr_universal (~13w)  +0.3999\n",
      "           surr_reasonant (~11w)  +0.4346\n",
      "               --- ~30 words ---\n",
      "                      random_30w  +0.1993\n",
      "\n",
      "  Decomposition of surr_reasonant (d = +0.4346):\n",
      "    Length (~15 random words):  +0.3155 (73%)\n",
      "    Content (reasonant vs random): +0.1192 (27%)\n",
      "\n",
      "  Decomposition of oracle (d = +0.4284):\n",
      "    Length (~6 random words):   +0.5177 (121%)\n",
      "    Content (real query vs random): -0.0893 (-21%)\n",
      "\n",
      "  INTERPRETATION:\n",
      "  -> MIXED: length provides 73% of surrogate benefit,\n",
      "     but content contributes a meaningful additional 27%.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Summary — how much is length vs content?\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY DECOMPOSITION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "d_bare = 0  # reference\n",
    "d_oracle = cohens_d(bare - arrays['oracle'])\n",
    "d_random_m = cohens_d(bare - arrays['random_matched'])\n",
    "d_random_15 = cohens_d(bare - arrays['random_15w'])\n",
    "d_random_30 = cohens_d(bare - arrays['random_30w'])\n",
    "d_repeat_15 = cohens_d(bare - arrays['repeat_15w'])\n",
    "d_surr_r = cohens_d(bare - arrays['surr_reasonant'])\n",
    "d_surr_u = cohens_d(bare - arrays['surr_universal'])\n",
    "d_adv = cohens_d(bare - arrays['adversarial'])\n",
    "d_oracle_pad = cohens_d(bare - arrays['oracle_padded'])\n",
    "\n",
    "print(f\"\\n  Effect sizes (Cohen's d vs bare):\")\n",
    "print(f\"  {'':>30} {'d':>8}\")\n",
    "print(f\"  {'-'*42}\")\n",
    "print(f\"  {'bare (reference)':>30} {0:>+8.4f}\")\n",
    "print(f\"  {'--- ~6 words ---':>30}\")\n",
    "print(f\"  {'random_matched (~6w)':>30} {d_random_m:>+8.4f}\")\n",
    "print(f\"  {'oracle (~6w)':>30} {d_oracle:>+8.4f}\")\n",
    "print(f\"  {'--- ~15 words ---':>30}\")\n",
    "print(f\"  {'repeat_15w':>30} {d_repeat_15:>+8.4f}\")\n",
    "print(f\"  {'random_15w':>30} {d_random_15:>+8.4f}\")\n",
    "print(f\"  {'adversarial (~15w)':>30} {d_adv:>+8.4f}\")\n",
    "print(f\"  {'oracle_padded (15w)':>30} {d_oracle_pad:>+8.4f}\")\n",
    "print(f\"  {'surr_universal (~13w)':>30} {d_surr_u:>+8.4f}\")\n",
    "print(f\"  {'surr_reasonant (~11w)':>30} {d_surr_r:>+8.4f}\")\n",
    "print(f\"  {'--- ~30 words ---':>30}\")\n",
    "print(f\"  {'random_30w':>30} {d_random_30:>+8.4f}\")\n",
    "\n",
    "# Decompose the best surrogate's effect\n",
    "print(f\"\\n  Decomposition of surr_reasonant (d = {d_surr_r:+.4f}):\")\n",
    "length_component = d_random_15  # effect of having ~15 random words\n",
    "content_component = d_surr_r - d_random_15\n",
    "total = d_surr_r\n",
    "if total > 0:\n",
    "    print(f\"    Length (~15 random words):  {length_component:+.4f} ({length_component/total*100:.0f}%)\")\n",
    "    print(f\"    Content (reasonant vs random): {content_component:+.4f} ({content_component/total*100:.0f}%)\")\n",
    "\n",
    "# Decompose oracle's effect\n",
    "print(f\"\\n  Decomposition of oracle (d = {d_oracle:+.4f}):\")\n",
    "length_component_o = d_random_m  # effect of having ~6 random words\n",
    "content_component_o = d_oracle - d_random_m\n",
    "if d_oracle > 0:\n",
    "    print(f\"    Length (~6 random words):   {length_component_o:+.4f} ({length_component_o/d_oracle*100:.0f}%)\")\n",
    "    print(f\"    Content (real query vs random): {content_component_o:+.4f} ({content_component_o/d_oracle*100:.0f}%)\")\n",
    "\n",
    "# Interpret\n",
    "print(f\"\\n  INTERPRETATION:\")\n",
    "if d_random_15 > d_surr_r * 0.8:\n",
    "    print(f\"  -> STRUCTURAL DOMINANCE: random words at 15w achieve {d_random_15/d_surr_r*100:.0f}% of best surrogate\")\n",
    "    print(f\"     Content adds only marginal value. The effect is primarily about\")\n",
    "    print(f\"     giving doc tokens additional causal context to attend to.\")\n",
    "elif d_random_15 > d_surr_r * 0.5:\n",
    "    print(f\"  -> MIXED: length provides {d_random_15/d_surr_r*100:.0f}% of surrogate benefit,\")\n",
    "    print(f\"     but content contributes a meaningful additional {(d_surr_r - d_random_15)/d_surr_r*100:.0f}%.\")\n",
    "else:\n",
    "    print(f\"  -> CONTENT DOMINATES: random words at 15w only achieve {d_random_15/d_surr_r*100:.0f}%.\")\n",
    "    print(f\"     The semantic content of the prefix is the primary driver.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81519cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:09:29.425968Z",
     "iopub.status.busy": "2026-02-20T15:09:29.425673Z",
     "iopub.status.idle": "2026-02-20T15:09:30.034545Z",
     "shell.execute_reply": "2026-02-20T15:09:30.033660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERDICT — Decoder-Only Exp 02: Length vs Content\n",
      "======================================================================\n",
      "\n",
      "Model: google/gemma-3-4b-it\n",
      "N: 400 samples (MS MARCO v1.1)\n",
      "\n",
      "--- Key findings ---\n",
      "  1. Oracle (real query): d = +0.4284\n",
      "  2. Best surrogate:     d = +0.4346\n",
      "  3. Random 15w:         d = +0.3155\n",
      "  4. Random matched:     d = +0.5177\n",
      "\n",
      "--- Model comparison (vs exp01 Gemma 2 2B) ---\n",
      "  Exp01 oracle d = +0.440, surr_reasonant d = +0.647\n",
      "  Exp02 oracle d = +0.4284, surr_reasonant d = +0.4346\n",
      "  -> Effect REPLICATES on larger model\n",
      "\n",
      "--- All conditions ---\n",
      "  bare                 NLL = 1.6022\n",
      "  oracle               NLL = 0.9044  d = +0.4284 (***)\n",
      "  surr_reasonant       NLL = 0.8076  d = +0.4346 (***)\n",
      "  surr_universal       NLL = 0.8527  d = +0.3999 (***)\n",
      "  adversarial          NLL = 1.1259  d = +0.2403 (***)\n",
      "  random_matched       NLL = 0.7412  d = +0.5177 (***)\n",
      "  random_15w           NLL = 1.0135  d = +0.3155 (***)\n",
      "  random_30w           NLL = 1.1916  d = +0.1993 (***)\n",
      "  repeat_15w           NLL = 0.8911  d = +0.4008 (***)\n",
      "  oracle_padded        NLL = 0.9967  d = +0.3584 (***)\n",
      "\n",
      "Results saved to ../../../results/decoder_only/exp02/results.json\n",
      "\n",
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 8.61 GB -> 0.01 GB\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Verdict and save\n",
    "print(\"=\" * 70)\n",
    "print(\"VERDICT — Decoder-Only Exp 02: Length vs Content\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"N: {len(results)} samples (MS MARCO v1.1)\")\n",
    "\n",
    "d_oracle = cohens_d(bare - arrays['oracle'])\n",
    "d_surr_r = cohens_d(bare - arrays['surr_reasonant'])\n",
    "d_random_15 = cohens_d(bare - arrays['random_15w'])\n",
    "d_random_m = cohens_d(bare - arrays['random_matched'])\n",
    "\n",
    "print(f\"\\n--- Key findings ---\")\n",
    "print(f\"  1. Oracle (real query): d = {d_oracle:+.4f}\")\n",
    "print(f\"  2. Best surrogate:     d = {d_surr_r:+.4f}\")\n",
    "print(f\"  3. Random 15w:         d = {d_random_15:+.4f}\")\n",
    "print(f\"  4. Random matched:     d = {d_random_m:+.4f}\")\n",
    "\n",
    "# Compare to exp01 (Gemma 2 2B)\n",
    "print(f\"\\n--- Model comparison (vs exp01 Gemma 2 2B) ---\")\n",
    "print(f\"  Exp01 oracle d = +0.440, surr_reasonant d = +0.647\")\n",
    "print(f\"  Exp02 oracle d = {d_oracle:+.4f}, surr_reasonant d = {d_surr_r:+.4f}\")\n",
    "if d_oracle > 0.3:\n",
    "    print(f\"  -> Effect REPLICATES on larger model\")\n",
    "elif d_oracle > 0.1:\n",
    "    print(f\"  -> Weaker but present on larger model\")\n",
    "else:\n",
    "    print(f\"  -> Effect FAILS to replicate on larger model\")\n",
    "\n",
    "# All conditions summary\n",
    "print(f\"\\n--- All conditions ---\")\n",
    "for name in ['bare', 'oracle', 'surr_reasonant', 'surr_universal', 'adversarial',\n",
    "             'random_matched', 'random_15w', 'random_30w', 'repeat_15w', 'oracle_padded']:\n",
    "    if name == 'bare':\n",
    "        print(f\"  {name:<20} NLL = {arrays[name].mean():.4f}\")\n",
    "    else:\n",
    "        d = cohens_d(bare - arrays[name])\n",
    "        _, p = stats.ttest_1samp(bare - arrays[name], 0)\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        print(f\"  {name:<20} NLL = {arrays[name].mean():.4f}  d = {d:+.4f} ({sig})\")\n",
    "\n",
    "# Save\n",
    "final_results = {\n",
    "    'experiment': 'v4_decoder_only_exp02_length_vs_content',\n",
    "    'model': MODEL_NAME,\n",
    "    'dataset': 'ms_marco_v1.1',\n",
    "    'n_samples': len(results),\n",
    "    'seed': SEED,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'conditions': {k: v for k, v in analysis.items()},\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\nCleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "012f903844254b18b315055450d620e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1868b3af402a45ee85783bc34bafb364": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d70bc6b677e41968e9de47b08d43b11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3afc5bbc6c9c42bb9f1bee5ecc824695": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44f83927f71e4055ba57de4928a44d8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cedee088bc5c4f5b9e403eb8ce634c31",
       "placeholder": "​",
       "style": "IPY_MODEL_fbdc0fe00c7a40e08899f1fb29e56e01",
       "tabbable": null,
       "tooltip": null,
       "value": " 883/883 [00:03&lt;00:00, 538.52it/s, Materializing param=model.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "4874eb6264954602b84043f5eff2080b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ef6eae6f546e420ebc229f847670a377",
        "IPY_MODEL_8b46d41baa1248eb843b4d7b77a1a704",
        "IPY_MODEL_44f83927f71e4055ba57de4928a44d8b"
       ],
       "layout": "IPY_MODEL_1868b3af402a45ee85783bc34bafb364",
       "tabbable": null,
       "tooltip": null
      }
     },
     "68f9a97979ee42d3a366dd89cf25c178": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76e0da5fddeb4f909f3775b98f14f394": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e1628b9eaa44e6e9f67844d435944da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8003c75b58ac4624bffa22df01ab816e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d70bc6b677e41968e9de47b08d43b11",
       "placeholder": "​",
       "style": "IPY_MODEL_914101fdc23b44f9b785391005a0f5c2",
       "tabbable": null,
       "tooltip": null,
       "value": " 400/400 [13:04&lt;00:00,  2.08s/it]"
      }
     },
     "8b46d41baa1248eb843b4d7b77a1a704": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68f9a97979ee42d3a366dd89cf25c178",
       "max": 883.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_012f903844254b18b315055450d620e6",
       "tabbable": null,
       "tooltip": null,
       "value": 883.0
      }
     },
     "8c627a8b279642beab497de33051b780": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "914101fdc23b44f9b785391005a0f5c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "97fdbe5e96cc4bb7b842440d6f87efa9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9aae1074fe014d0fb0633bff0f182bba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4882021b6c444a3b79059ca242978c0",
        "IPY_MODEL_f19c7081cdbc4ff3b2519d4ecc4aa3b6",
        "IPY_MODEL_8003c75b58ac4624bffa22df01ab816e"
       ],
       "layout": "IPY_MODEL_97fdbe5e96cc4bb7b842440d6f87efa9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a35b5b4f52bf43e1a63b0cf6c69b4f0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a4882021b6c444a3b79059ca242978c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7e1628b9eaa44e6e9f67844d435944da",
       "placeholder": "​",
       "style": "IPY_MODEL_a35b5b4f52bf43e1a63b0cf6c69b4f0b",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring: 100%"
      }
     },
     "b361efd60d964cf79f9c10cc4dd7e8d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cedee088bc5c4f5b9e403eb8ce634c31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef6eae6f546e420ebc229f847670a377": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3afc5bbc6c9c42bb9f1bee5ecc824695",
       "placeholder": "​",
       "style": "IPY_MODEL_8c627a8b279642beab497de33051b780",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "f19c7081cdbc4ff3b2519d4ecc4aa3b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b361efd60d964cf79f9c10cc4dd7e8d1",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76e0da5fddeb4f909f3775b98f14f394",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "fbdc0fe00c7a40e08899f1fb29e56e01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
