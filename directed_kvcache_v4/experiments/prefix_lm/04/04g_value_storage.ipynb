{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b265e6fa",
   "metadata": {},
   "source": [
    "# Prefix LM Exp 04g: Value Storage Enhancement\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 04f confirmed: oracle DOES create measurably different attention patterns than\n",
    "random during Phase A (d up to +1.34 at peak layers, significant in all 13/13 probed\n",
    "layers), but the semantic signal doesn't survive truncation -- the oracle-vs-random\n",
    "attention difference doesn't predict oracle-vs-random NLL benefit (r=+0.031, ns).\n",
    "\n",
    "**Root cause**: doc tokens attend only ~2-5% to the prime, so little prime information\n",
    "gets stored in doc VALUE vectors. After truncation cuts prime KV positions from Phase B,\n",
    "only what's baked into doc KVs persists.\n",
    "\n",
    "**Goal**: Force more prime information into document value vectors during Phase A so\n",
    "it survives truncation into Phase B.\n",
    "\n",
    "## Five Mechanistic Approaches\n",
    "\n",
    "| # | Approach | Mechanism | Key question |\n",
    "|---|----------|-----------|-------------|\n",
    "| 1 | Attention logit boost | Positive mask values at doc->prime positions | Does forcing more attention store more info in doc Vs? |\n",
    "| 2 | Bidirectional bridge | Prime tokens can see doc tokens (upper triangle unmasked) | Does multi-layer cross-information help? |\n",
    "| 3 | Chat format | IT turn markers activate instruction-following circuits | Does the model process content more deeply in chat mode? |\n",
    "| 4 | Interspersed repetition | Prime copies between doc chunks | Does proximity to fresh prime copies help? |\n",
    "| 5 | Value injection | Directly add prime V content to doc V vectors post-Phase-A | Is V content the actual bottleneck? |\n",
    "\n",
    "## Conditions (17)\n",
    "\n",
    "| # | Name | Category | Description |\n",
    "|---|------|----------|-------------|\n",
    "| 1 | `bare` | control | No prime |\n",
    "| 2 | `random` | control | 8 random words |\n",
    "| 3 | `oracle` | control | Real query |\n",
    "| 4 | `oracle_boost2` | boost | Oracle, Phase A mask doc->prime = +2.0 |\n",
    "| 5 | `oracle_boost4` | boost | Oracle, Phase A mask doc->prime = +4.0 |\n",
    "| 6 | `oracle_boost8` | boost | Oracle, Phase A mask doc->prime = +8.0 |\n",
    "| 7 | `random_boost4` | boost | Random, Phase A mask doc->prime = +4.0 |\n",
    "| 8 | `oracle_bidir` | bidir | Oracle, prime->doc bidirectional in Phase A |\n",
    "| 9 | `oracle_chat` | chat | Oracle in chat turn markers |\n",
    "| 10 | `instr_chat` | chat | Instruction in chat turn markers |\n",
    "| 11 | `oracle_inter` | interspersed | [BOS, oracle, doc1, oracle, doc2, oracle, doc3] |\n",
    "| 12 | `random_inter` | interspersed | [BOS, random, doc1, random, doc2, random, doc3] |\n",
    "| 13 | `oracle_vinj01` | vinject | Oracle + post-Phase-A value inject beta=0.1 |\n",
    "| 14 | `oracle_vinj05` | vinject | Oracle + post-Phase-A value inject beta=0.5 |\n",
    "| 15 | `oracle_vinj10` | vinject | Oracle + post-Phase-A value inject beta=1.0 |\n",
    "| 16 | `pointer` | reference | \"the answer is about [keywords]\" (04e best vs random) |\n",
    "| 17 | `oracle_plus_vocab` | reference | Query + answer-doc overlap words (04e overall best) |\n",
    "\n",
    "## Key Analyses\n",
    "\n",
    "- **A**: Full ranking (all 17 by mean NLL, d vs bare/random/oracle)\n",
    "- **B**: Per-approach comparison (dose-response for boost and vinj; paired for bidir, chat, inter)\n",
    "- **C**: Best-of-each approach vs oracle\n",
    "- **D**: Attention verification (frac_prime monotonic with boost; correlation with NLL)\n",
    "- **E**: Structural fraction per approach\n",
    "- **F**: Per-sample heterogeneity (correlation with answer_wc, doc_wc, overlap)\n",
    "- **G**: 04e replication check (pointer, oracle_plus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c404fd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:04:55.314247Z",
     "iopub.status.busy": "2026-02-22T18:04:55.313984Z",
     "iopub.status.idle": "2026-02-22T18:04:59.824559Z",
     "shell.execute_reply": "2026-02-22T18:04:59.823595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix LM Exp 04g: Value Storage Enhancement\n",
      "N: 500, Conditions: 17\n",
      "Attention probing: 7 conditions x 4 layers\n",
      "DEVICE: cuda\n",
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "GPU memory: 42.3 GB\n",
      "\n",
      "Conditions: ['bare', 'random', 'oracle', 'oracle_boost2', 'oracle_boost4', 'oracle_boost8', 'random_boost4', 'oracle_bidir', 'oracle_chat', 'instr_chat', 'oracle_inter', 'random_inter', 'oracle_vinj01', 'oracle_vinj05', 'oracle_vinj10', 'pointer', 'oracle_plus_vocab']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, gc, re\n",
    "import random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 500\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "\n",
    "RESULTS_DIR = Path(\"../../../results/prefix_lm_exp04g\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONDITIONS = [\n",
    "    \"bare\",\n",
    "    \"random\",\n",
    "    \"oracle\",\n",
    "    \"oracle_boost2\",\n",
    "    \"oracle_boost4\",\n",
    "    \"oracle_boost8\",\n",
    "    \"random_boost4\",\n",
    "    \"oracle_bidir\",\n",
    "    \"oracle_chat\",\n",
    "    \"instr_chat\",\n",
    "    \"oracle_inter\",\n",
    "    \"random_inter\",\n",
    "    \"oracle_vinj01\",\n",
    "    \"oracle_vinj05\",\n",
    "    \"oracle_vinj10\",\n",
    "    \"pointer\",\n",
    "    \"oracle_plus_vocab\",\n",
    "]\n",
    "\n",
    "CONDITION_CONFIG = {\n",
    "    \"bare\":             {\"prime\": \"bare\",             \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"random\":           {\"prime\": \"random\",           \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle\":           {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_boost2\":    {\"prime\": \"oracle\",           \"boost\": 2, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_boost4\":    {\"prime\": \"oracle\",           \"boost\": 4, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_boost8\":    {\"prime\": \"oracle\",           \"boost\": 8, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"random_boost4\":    {\"prime\": \"random\",           \"boost\": 4, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_bidir\":     {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": True,  \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_chat\":      {\"prime\": \"oracle_chat\",      \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"instr_chat\":       {\"prime\": \"instr_chat\",       \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_inter\":     {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": False, \"inter\": True,  \"vinj\": 0},\n",
    "    \"random_inter\":     {\"prime\": \"random\",           \"boost\": 0, \"bidir\": False, \"inter\": True,  \"vinj\": 0},\n",
    "    \"oracle_vinj01\":    {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0.1},\n",
    "    \"oracle_vinj05\":    {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0.5},\n",
    "    \"oracle_vinj10\":    {\"prime\": \"oracle\",           \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 1.0},\n",
    "    \"pointer\":          {\"prime\": \"pointer\",          \"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "    \"oracle_plus_vocab\":{\"prime\": \"oracle_plus_vocab\",\"boost\": 0, \"bidir\": False, \"inter\": False, \"vinj\": 0},\n",
    "}\n",
    "\n",
    "# Attention probing: control + boost conditions at 4 late layers\n",
    "ATTN_CONDITIONS = {\"bare\", \"random\", \"oracle\",\n",
    "                   \"oracle_boost2\", \"oracle_boost4\", \"oracle_boost8\",\n",
    "                   \"random_boost4\"}\n",
    "PROBE_LAYERS = [36, 40, 44, 47]\n",
    "\n",
    "# Chat token IDs (set after tokenizer loads in Cell 2)\n",
    "CHAT_PREFIX_IDS = None\n",
    "CHAT_SUFFIX_IDS = None\n",
    "INSTR_CHAT_IDS = None\n",
    "\n",
    "print(f\"Prefix LM Exp 04g: Value Storage Enhancement\")\n",
    "print(f\"N: {N_SAMPLES}, Conditions: {len(CONDITIONS)}\")\n",
    "print(f\"Attention probing: {len(ATTN_CONDITIONS)} conditions x {len(PROBE_LAYERS)} layers\")\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"\\nConditions: {CONDITIONS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528eea11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:04:59.828444Z",
     "iopub.status.busy": "2026-02-22T18:04:59.827976Z",
     "iopub.status.idle": "2026-02-22T18:05:15.971737Z",
     "shell.execute_reply": "2026-02-22T18:05:15.970829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 5.1.0\n",
      "Loading google/gemma-3-12b-it...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7fa377b7704d599320e7aa1bb6cc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 12.2B params, 24.4 GB GPU, 13s\n",
      "Model has 48 layers\n",
      "BOS token id: 2\n",
      "Probe layers: [36, 40, 44, 47]\n",
      "\n",
      "--- DynamicCache verification ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cache type: DynamicCache\n",
      "  n_layers in cache: 48\n",
      "  Key shape [0]: torch.Size([1, 8, 6, 256])\n",
      "  Value shape [0]: torch.Size([1, 8, 6, 256])\n",
      "\n",
      "--- Chat token verification ---\n",
      "  <start_of_turn> ID: 105\n",
      "  <end_of_turn> ID: 106\n",
      "  Chat prefix IDs: [105, 2364, 107]\n",
      "  Chat suffix IDs: [106, 107]\n",
      "  Instr chat IDs (13 tokens): [105, 2364, 107, 137938, 506]...[236787, 106, 107]\n",
      "  Chat tokenization verified.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load model + tokenizer, verify DynamicCache API + chat tokens\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "t0 = time.time()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters()) / 1e9\n",
    "gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"Loaded: {n_params:.1f}B params, {gpu_mem:.1f} GB GPU, {time.time()-t0:.0f}s\")\n",
    "\n",
    "n_layers = model.config.text_config.num_hidden_layers\n",
    "print(f\"Model has {n_layers} layers\")\n",
    "print(f\"BOS token id: {tokenizer.bos_token_id}\")\n",
    "\n",
    "# Verify PROBE_LAYERS are valid\n",
    "PROBE_LAYERS = [l for l in PROBE_LAYERS if l < n_layers]\n",
    "if (n_layers - 1) not in PROBE_LAYERS:\n",
    "    PROBE_LAYERS.append(n_layers - 1)\n",
    "PROBE_LAYERS = sorted(set(PROBE_LAYERS))\n",
    "print(f\"Probe layers: {PROBE_LAYERS}\")\n",
    "\n",
    "# --- Verify DynamicCache API ---\n",
    "print(f\"\\n--- DynamicCache verification ---\")\n",
    "test_text = \"The quick brown fox.\"\n",
    "test_ids = tokenizer(test_text, return_tensors=\"pt\",\n",
    "                     add_special_tokens=True).input_ids.to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(input_ids=test_ids, use_cache=True)\n",
    "past_kv = out.past_key_values\n",
    "print(f\"  Cache type: {type(past_kv).__name__}\")\n",
    "print(f\"  n_layers in cache: {len(past_kv.layers)}\")\n",
    "print(f\"  Key shape [0]: {past_kv.layers[0].keys.shape}\")\n",
    "print(f\"  Value shape [0]: {past_kv.layers[0].values.shape}\")\n",
    "del out, past_kv\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Verify chat token handling ---\n",
    "print(f\"\\n--- Chat token verification ---\")\n",
    "sot_id = tokenizer.convert_tokens_to_ids(\"<start_of_turn>\")\n",
    "eot_id = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "print(f\"  <start_of_turn> ID: {sot_id}\")\n",
    "print(f\"  <end_of_turn> ID: {eot_id}\")\n",
    "\n",
    "CHAT_PREFIX_IDS = tokenizer(\"<start_of_turn>user\\n\", add_special_tokens=False).input_ids\n",
    "CHAT_SUFFIX_IDS = tokenizer(\"<end_of_turn>\\n\", add_special_tokens=False).input_ids\n",
    "print(f\"  Chat prefix IDs: {CHAT_PREFIX_IDS}\")\n",
    "print(f\"  Chat suffix IDs: {CHAT_SUFFIX_IDS}\")\n",
    "\n",
    "instr_text = \"Identify the key facts in this passage:\"\n",
    "instr_raw_ids = tokenizer(instr_text, add_special_tokens=False).input_ids\n",
    "INSTR_CHAT_IDS = CHAT_PREFIX_IDS + instr_raw_ids + CHAT_SUFFIX_IDS\n",
    "print(f\"  Instr chat IDs ({len(INSTR_CHAT_IDS)} tokens): {INSTR_CHAT_IDS[:5]}...{INSTR_CHAT_IDS[-3:]}\")\n",
    "\n",
    "# Round-trip verify\n",
    "test_chat = \"<start_of_turn>user\\nhello world<end_of_turn>\\n\"\n",
    "test_chat_ids = tokenizer(test_chat, add_special_tokens=False).input_ids\n",
    "assert test_chat_ids[0] == sot_id, f\"Expected SOT at pos 0, got {test_chat_ids[0]}\"\n",
    "assert test_chat_ids[-2] == eot_id, f\"Expected EOT at pos -2, got {test_chat_ids[-2]}\"\n",
    "print(f\"  Chat tokenization verified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e516bf1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:05:15.975302Z",
     "iopub.status.busy": "2026-02-22T18:05:15.974882Z",
     "iopub.status.idle": "2026-02-22T18:05:16.422464Z",
     "shell.execute_reply": "2026-02-22T18:05:16.421547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask sanity check: custom causal mask vs default forward...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Max logit diff: 0.000000\n",
      "  PASS: Dict-based mask API verified.\n",
      "\n",
      "  Interspersed test: seq=[2, 10, 11, 12, 20, 21, 10, 11, 12, 22, 23, 10, 11, 12, 24, 25]\n",
      "    prime_positions=[1, 2, 3, 6, 7, 8, 11, 12, 13]\n",
      "    doc_positions=[4, 5, 9, 10, 14, 15]\n",
      "  PASS: Interspersed sequence verified.\n",
      "All helpers verified.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Mask functions + helpers + sanity check\n",
    "\n",
    "# --- Base masks ---\n",
    "\n",
    "def make_causal_mask(n, dtype=torch.bfloat16):\n",
    "    # Standard causal mask: lower triangle = 0, upper triangle = min_val\n",
    "    min_val = torch.finfo(dtype).min\n",
    "    mask = torch.triu(torch.full((n, n), min_val, dtype=dtype), diagonal=1)\n",
    "    return mask.unsqueeze(0).unsqueeze(0)  # (1, 1, n, n)\n",
    "\n",
    "\n",
    "def make_phase_b_mask_general(n_prefix, prime_positions, n_q, n_a,\n",
    "                              dtype=torch.bfloat16):\n",
    "    # Phase B mask: continuation tokens see all prefix EXCEPT prime positions\n",
    "    n_cont = n_q + n_a\n",
    "    min_val = torch.finfo(dtype).min\n",
    "    mask = torch.full((n_cont, n_prefix + n_cont), min_val, dtype=dtype)\n",
    "    # Allow attending to all prefix positions\n",
    "    mask[:, :n_prefix] = 0.0\n",
    "    # Mask out prime positions (truncation)\n",
    "    for p in prime_positions:\n",
    "        mask[:, p] = min_val\n",
    "    # Causal mask for continuation tokens among themselves\n",
    "    mask[:, n_prefix:] = torch.triu(\n",
    "        torch.full((n_cont, n_cont), min_val, dtype=dtype), diagonal=1\n",
    "    )\n",
    "    return mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def make_mask_dict(mask_4d):\n",
    "    return {\"full_attention\": mask_4d, \"sliding_attention\": mask_4d}\n",
    "\n",
    "\n",
    "# --- Approach helpers ---\n",
    "\n",
    "def apply_boost(mask, doc_positions, prime_positions, boost):\n",
    "    # Set doc->prime attention positions to +boost (positive boosts pre-softmax logits)\n",
    "    # Works for standard layout where prime and doc are contiguous blocks\n",
    "    dp_start = doc_positions[0]\n",
    "    dp_end = doc_positions[-1] + 1\n",
    "    pp_start = prime_positions[0]\n",
    "    pp_end = prime_positions[-1] + 1\n",
    "    mask[0, 0, dp_start:dp_end, pp_start:pp_end] = boost\n",
    "\n",
    "\n",
    "def apply_bidir(mask, prime_positions, doc_positions):\n",
    "    # Allow prime tokens to attend to doc tokens (breaks causal for prime->doc only)\n",
    "    pp_start = prime_positions[0]\n",
    "    pp_end = prime_positions[-1] + 1\n",
    "    dp_start = doc_positions[0]\n",
    "    dp_end = doc_positions[-1] + 1\n",
    "    mask[0, 0, pp_start:pp_end, dp_start:dp_end] = 0.0\n",
    "\n",
    "\n",
    "def make_interspersed_sequence(bos_id, prime_ids, doc_ids, n_chunks=3):\n",
    "    # Split doc into n_chunks, insert prime copy before each chunk\n",
    "    # Returns: (sequence, prime_positions, doc_positions)\n",
    "    if not prime_ids:\n",
    "        return ([bos_id] + doc_ids, [], list(range(1, 1 + len(doc_ids))))\n",
    "\n",
    "    chunk_size = max(1, len(doc_ids) // n_chunks)\n",
    "    chunks = []\n",
    "    for i in range(n_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = start + chunk_size if i < n_chunks - 1 else len(doc_ids)\n",
    "        chunks.append(doc_ids[start:end])\n",
    "\n",
    "    seq = [bos_id]\n",
    "    prime_positions = []\n",
    "    doc_positions = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Add prime copy\n",
    "        p_start = len(seq)\n",
    "        seq.extend(prime_ids)\n",
    "        prime_positions.extend(range(p_start, p_start + len(prime_ids)))\n",
    "        # Add doc chunk\n",
    "        d_start = len(seq)\n",
    "        seq.extend(chunk)\n",
    "        doc_positions.extend(range(d_start, d_start + len(chunk)))\n",
    "\n",
    "    return seq, prime_positions, doc_positions\n",
    "\n",
    "\n",
    "def inject_values(past_kv, prime_positions, doc_positions, beta):\n",
    "    # Add scaled mean of prime V vectors to doc V vectors (in-place)\n",
    "    n_layers = len(past_kv.layers)\n",
    "    dp_start = doc_positions[0]\n",
    "    dp_end = doc_positions[-1] + 1\n",
    "    for layer_idx in range(n_layers):\n",
    "        v = past_kv.layers[layer_idx].values  # (1, n_heads, seq_len, head_dim)\n",
    "        prime_v = v[:, :, prime_positions, :]  # (1, n_heads, n_prime, head_dim)\n",
    "        mean_v = prime_v.mean(dim=2, keepdim=True)  # (1, n_heads, 1, head_dim)\n",
    "        v[:, :, dp_start:dp_end, :] += beta * mean_v\n",
    "\n",
    "\n",
    "# --- Sanity check: custom causal mask vs default forward ---\n",
    "print(\"Mask sanity check: custom causal mask vs default forward...\")\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "test_ids = tokenizer(test_text, return_tensors=\"pt\",\n",
    "                     add_special_tokens=True).input_ids.to(DEVICE)\n",
    "Lt = test_ids.shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_default = model(input_ids=test_ids)\n",
    "\n",
    "causal_mask = make_causal_mask(Lt)\n",
    "causal_dict = make_mask_dict(causal_mask.to(DEVICE))\n",
    "causal_pos = torch.arange(Lt, device=DEVICE).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_custom = model(input_ids=test_ids, attention_mask=causal_dict,\n",
    "                       position_ids=causal_pos)\n",
    "\n",
    "max_diff = (out_default.logits - out_custom.logits).abs().max().item()\n",
    "print(f\"  Max logit diff: {max_diff:.6f}\")\n",
    "assert max_diff < 0.1, f\"FAIL: max_diff={max_diff:.4f}\"\n",
    "print(f\"  PASS: Dict-based mask API verified.\")\n",
    "\n",
    "# Quick test of interspersed helper\n",
    "seq, pp, dp = make_interspersed_sequence(2, [10, 11, 12], [20, 21, 22, 23, 24, 25], 3)\n",
    "print(f\"\\n  Interspersed test: seq={seq}\")\n",
    "print(f\"    prime_positions={pp}\")\n",
    "print(f\"    doc_positions={dp}\")\n",
    "assert len(seq) == 1 + 3*3 + 6, f\"Wrong length: {len(seq)}\"\n",
    "print(f\"  PASS: Interspersed sequence verified.\")\n",
    "\n",
    "del out_default, out_custom\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "print(\"All helpers verified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13c8230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:05:16.425971Z",
     "iopub.status.busy": "2026-02-22T18:05:16.425661Z",
     "iopub.status.idle": "2026-02-22T18:05:17.858467Z",
     "shell.execute_reply": "2026-02-22T18:05:17.857521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO v1.1 validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates: 1500\n",
      "\n",
      "Loaded 500 samples\n",
      "Mean passage words: 74\n",
      "Mean query words: 6\n",
      "Mean answer words: 14\n",
      "\n",
      "--- Examples ---\n",
      "\n",
      "  Sample 0:\n",
      "    Q: what is the link between alveoli and capillaries\n",
      "    A: Diffusion\n",
      "    pointer: the answer is about diffusion\n",
      "    oracle_plus_vocab: what is the link between alveoli and capillaries diffusion\n",
      "\n",
      "  Sample 1:\n",
      "    Q: how thick does concrete need to be garden wall\n",
      "    A: For walls up to 3ft, 5.5 inches thick.\n",
      "    pointer: the answer is about 3ft inches thick walls\n",
      "    oracle_plus_vocab: how thick does concrete need to be garden wall 3ft inches thick walls\n",
      "\n",
      "  Sample 2:\n",
      "    Q: average nurse salary singapore\n",
      "    A: S$34,924 per year\n",
      "    pointer: the answer is about per s34924 year\n",
      "    oracle_plus_vocab: average nurse salary singapore per s34924 year\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load MS MARCO + prepare per-sample fields\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "WORD_POOL = [\n",
    "    \"computer\", \"mountain\", \"hospital\", \"children\", \"building\", \"national\",\n",
    "    \"business\", \"research\", \"students\", \"american\", \"possible\", \"economic\",\n",
    "    \"personal\", \"together\", \"products\", \"services\", \"actually\", \"remember\",\n",
    "    \"practice\", \"training\", \"industry\", \"complete\", \"critical\", \"function\",\n",
    "    \"language\", \"standard\", \"material\", \"original\", \"physical\", \"security\",\n",
    "    \"interest\", \"problems\", \"consider\", \"response\", \"pressure\", \"politics\",\n",
    "    \"movement\", \"evidence\", \"southern\", \"northern\", \"exchange\", \"decision\",\n",
    "    \"position\", \"increase\", \"describe\", \"military\", \"required\", \"approach\",\n",
    "    \"strategy\", \"customer\", \"resource\", \"employee\", \"audience\", \"location\",\n",
    "    \"property\", \"cultural\", \"activity\", \"strength\", \"analysis\", \"powerful\",\n",
    "    \"election\", \"argument\", \"campaign\", \"maintain\", \"question\", \"behavior\",\n",
    "    \"majority\", \"solution\", \"software\", \"consumer\", \"creative\", \"reaction\",\n",
    "    \"european\", \"delivery\", \"organize\", \"involved\", \"relative\", \"learning\",\n",
    "    \"positive\", \"numerous\", \"familiar\", \"engineer\", \"platform\", \"indicate\",\n",
    "    \"previous\", \"pleasure\", \"opposite\", \"magazine\", \"document\", \"religion\",\n",
    "    \"scenario\", \"workshop\", \"minority\", \"guidance\", \"estimate\", \"recently\",\n",
    "    \"surprise\", \"champion\", \"pleasant\", \"grateful\", \"moderate\", \"boundary\",\n",
    "]\n",
    "\n",
    "def content_words(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "def jaccard(set_a, set_b):\n",
    "    union = set_a | set_b\n",
    "    return len(set_a & set_b) / len(union) if union else 0.0\n",
    "\n",
    "print(\"Loading MS MARCO v1.1 validation...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 3 * N_SAMPLES:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "print(f\"Total candidates: {len(all_candidates)}\")\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds, all_candidates\n",
    "gc.collect()\n",
    "\n",
    "# --- Prepare per-sample fields ---\n",
    "for i, s in enumerate(samples):\n",
    "    # Random prefix (8 words, same seed as all prior experiments)\n",
    "    rng = np.random.RandomState(SEED + i + 20000)\n",
    "    words = rng.choice(WORD_POOL, size=8, replace=False)\n",
    "    s['random_prefix'] = \" \".join(words)\n",
    "\n",
    "    # Query-doc overlap\n",
    "    q_words = set(content_words(s['query']))\n",
    "    d_words = set(content_words(s['passage']))\n",
    "    a_words = set(content_words(s['answer']))\n",
    "    s['query_doc_overlap'] = jaccard(q_words, d_words)\n",
    "\n",
    "    # Answer-doc overlap words (for pointer + oracle_plus_vocab)\n",
    "    overlap_words = sorted(a_words & d_words)\n",
    "    if not overlap_words:\n",
    "        overlap_words = content_words(s['answer'])[:5]\n",
    "\n",
    "    # Pointer instruction\n",
    "    kw = overlap_words[:5] if overlap_words else content_words(s['query'])[:3]\n",
    "    s['pointer'] = \"the answer is about \" + \" \".join(kw)\n",
    "\n",
    "    # Oracle + vocabulary\n",
    "    s['answer_vocab'] = \" \".join(overlap_words[:10])\n",
    "    s['oracle_plus_vocab'] = s['query'] + \" \" + s['answer_vocab']\n",
    "\n",
    "    s['answer_wc'] = count_words(s['answer'])\n",
    "\n",
    "print(f\"\\nLoaded {len(samples)} samples\")\n",
    "print(f\"Mean passage words: {np.mean([s['word_count'] for s in samples]):.0f}\")\n",
    "print(f\"Mean query words: {np.mean([count_words(s['query']) for s in samples]):.0f}\")\n",
    "print(f\"Mean answer words: {np.mean([s['answer_wc'] for s in samples]):.0f}\")\n",
    "\n",
    "print(f\"\\n--- Examples ---\")\n",
    "for j in range(3):\n",
    "    print(f\"\\n  Sample {j}:\")\n",
    "    print(f\"    Q: {samples[j]['query'][:70]}\")\n",
    "    print(f\"    A: {samples[j]['answer'][:70]}\")\n",
    "    print(f\"    pointer: {samples[j]['pointer']}\")\n",
    "    print(f\"    oracle_plus_vocab: {samples[j]['oracle_plus_vocab'][:70]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cdb353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:05:17.862053Z",
     "iopub.status.busy": "2026-02-22T18:05:17.861544Z",
     "iopub.status.idle": "2026-02-22T18:05:17.881140Z",
     "shell.execute_reply": "2026-02-22T18:05:17.880318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function defined (17 conditions per sample).\n",
      "Attention probing on: ['bare', 'oracle', 'oracle_boost2', 'oracle_boost4', 'oracle_boost8', 'random', 'random_boost4']\n",
      "Probe layers: [36, 40, 44, 47]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: score_sample() -- 17 conditions, 5 approaches, selective attention probing\n",
    "\n",
    "def score_sample(model, tokenizer, sample, device, probe_layers):\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "\n",
    "    bos_id = tokenizer.bos_token_id\n",
    "\n",
    "    doc_ids = tokenizer(passage, add_special_tokens=False, truncation=True,\n",
    "                        max_length=1024).input_ids\n",
    "    query_ids = tokenizer(query, add_special_tokens=False, truncation=True,\n",
    "                          max_length=512).input_ids\n",
    "    answer_ids = tokenizer(answer, add_special_tokens=False, truncation=True,\n",
    "                           max_length=256).input_ids\n",
    "\n",
    "    if len(answer_ids) == 0:\n",
    "        return None\n",
    "\n",
    "    # Tokenize all prime variants\n",
    "    oracle_ids = tokenizer(query, add_special_tokens=False, truncation=True,\n",
    "                           max_length=256).input_ids\n",
    "    random_ids = tokenizer(sample['random_prefix'], add_special_tokens=False).input_ids\n",
    "    pointer_ids = tokenizer(sample['pointer'], add_special_tokens=False).input_ids\n",
    "    oracle_plus_vocab_ids = tokenizer(sample['oracle_plus_vocab'],\n",
    "                                      add_special_tokens=False,\n",
    "                                      truncation=True, max_length=256).input_ids\n",
    "\n",
    "    # Chat-formatted primes\n",
    "    oracle_chat_ids = CHAT_PREFIX_IDS + oracle_ids + CHAT_SUFFIX_IDS\n",
    "    # INSTR_CHAT_IDS is a global constant (same for all samples)\n",
    "\n",
    "    prime_map = {\n",
    "        \"bare\": [],\n",
    "        \"random\": random_ids,\n",
    "        \"oracle\": oracle_ids,\n",
    "        \"oracle_chat\": oracle_chat_ids,\n",
    "        \"instr_chat\": INSTR_CHAT_IDS,\n",
    "        \"pointer\": pointer_ids,\n",
    "        \"oracle_plus_vocab\": oracle_plus_vocab_ids,\n",
    "    }\n",
    "\n",
    "    n_q = len(query_ids)\n",
    "    n_a = len(answer_ids)\n",
    "    n_d = len(doc_ids)\n",
    "\n",
    "    targets = torch.tensor(answer_ids, dtype=torch.long, device=device)\n",
    "    result = {'n_doc': n_d, 'n_query': n_q}\n",
    "\n",
    "    for cond_name in CONDITIONS:\n",
    "        cfg = CONDITION_CONFIG[cond_name]\n",
    "        surr_ids = prime_map[cfg[\"prime\"]]\n",
    "\n",
    "        # --- Build Phase A sequence ---\n",
    "        if cfg[\"inter\"]:\n",
    "            seq, prime_positions, doc_positions = make_interspersed_sequence(\n",
    "                bos_id, surr_ids, doc_ids, n_chunks=3)\n",
    "        else:\n",
    "            seq = [bos_id] + surr_ids + doc_ids\n",
    "            prime_positions = list(range(1, 1 + len(surr_ids)))\n",
    "            doc_positions = list(range(1 + len(surr_ids), len(seq)))\n",
    "\n",
    "        n_prefix = len(seq)\n",
    "        prefix_input = torch.tensor([seq], dtype=torch.long, device=device)\n",
    "\n",
    "        # Record prime token count\n",
    "        result[f'n_prime_{cond_name}'] = len(prime_positions)\n",
    "\n",
    "        # --- Build Phase A mask ---\n",
    "        phase_a_mask = make_causal_mask(n_prefix)\n",
    "\n",
    "        if cfg[\"boost\"] > 0 and len(prime_positions) > 0:\n",
    "            apply_boost(phase_a_mask, doc_positions, prime_positions, cfg[\"boost\"])\n",
    "        if cfg[\"bidir\"] and len(prime_positions) > 0:\n",
    "            apply_bidir(phase_a_mask, prime_positions, doc_positions)\n",
    "\n",
    "        phase_a_dict = make_mask_dict(phase_a_mask.to(device))\n",
    "        phase_a_pos = torch.arange(n_prefix, device=device).unsqueeze(0)\n",
    "\n",
    "        # --- Phase A forward ---\n",
    "        extract_attn = (cond_name in ATTN_CONDITIONS)\n",
    "        with torch.no_grad():\n",
    "            out_a = model(input_ids=prefix_input,\n",
    "                          attention_mask=phase_a_dict,\n",
    "                          position_ids=phase_a_pos,\n",
    "                          use_cache=True,\n",
    "                          output_attentions=extract_attn)\n",
    "        past_kv = out_a.past_key_values\n",
    "\n",
    "        # --- Extract attention stats if probing ---\n",
    "        if extract_attn and out_a.attentions is not None:\n",
    "            attentions = out_a.attentions\n",
    "            for layer_idx in probe_layers:\n",
    "                if layer_idx >= len(attentions):\n",
    "                    continue\n",
    "                attn = attentions[layer_idx][0]  # (n_heads, n_prefix, n_prefix)\n",
    "\n",
    "                if n_d == 0:\n",
    "                    continue\n",
    "\n",
    "                # Doc-token attention patterns\n",
    "                doc_attn = attn[:, doc_positions, :]  # (n_heads, n_d, n_prefix)\n",
    "\n",
    "                frac_bos = doc_attn[:, :, 0].mean().item()\n",
    "\n",
    "                if len(prime_positions) > 0:\n",
    "                    frac_prime = doc_attn[:, :, prime_positions].sum(dim=-1).mean().item()\n",
    "                else:\n",
    "                    frac_prime = 0.0\n",
    "\n",
    "                frac_doc = doc_attn[:, :, doc_positions].sum(dim=-1).mean().item()\n",
    "\n",
    "                # Attention entropy\n",
    "                eps = 1e-10\n",
    "                ent = -(doc_attn * (doc_attn + eps).log()).sum(dim=-1).mean().item()\n",
    "\n",
    "                result[f'{cond_name}_L{layer_idx}_frac_bos'] = frac_bos\n",
    "                result[f'{cond_name}_L{layer_idx}_frac_prime'] = frac_prime\n",
    "                result[f'{cond_name}_L{layer_idx}_frac_doc'] = frac_doc\n",
    "                result[f'{cond_name}_L{layer_idx}_entropy'] = ent\n",
    "\n",
    "            del attentions\n",
    "\n",
    "        # --- Value injection (post Phase A, pre Phase B) ---\n",
    "        if cfg[\"vinj\"] > 0 and len(prime_positions) > 0:\n",
    "            inject_values(past_kv, prime_positions, doc_positions, cfg[\"vinj\"])\n",
    "\n",
    "        # --- Phase B (truncation: mask prime positions) ---\n",
    "        cont_tokens = query_ids + answer_ids\n",
    "        n_cont = len(cont_tokens)\n",
    "        cont_input = torch.tensor([cont_tokens], dtype=torch.long, device=device)\n",
    "\n",
    "        phase_b_mask = make_phase_b_mask_general(n_prefix, prime_positions, n_q, n_a)\n",
    "        phase_b_dict = make_mask_dict(phase_b_mask.to(device))\n",
    "        phase_b_pos = torch.arange(n_prefix, n_prefix + n_cont,\n",
    "                                    device=device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_b = model(input_ids=cont_input,\n",
    "                          attention_mask=phase_b_dict,\n",
    "                          position_ids=phase_b_pos,\n",
    "                          past_key_values=past_kv)\n",
    "\n",
    "        # Compute answer NLL\n",
    "        answer_logits = out_b.logits[0, n_q - 1 : n_q + n_a - 1, :]\n",
    "        log_probs = F.log_softmax(answer_logits, dim=-1)\n",
    "        token_nlls = -log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        result[f'nll_{cond_name}'] = token_nlls.mean().item()\n",
    "\n",
    "        # Cleanup\n",
    "        del out_a, out_b, past_kv, prefix_input, cont_input\n",
    "        del phase_a_mask, phase_a_dict, phase_b_mask, phase_b_dict\n",
    "        del answer_logits, log_probs, token_nlls\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print(f\"Scoring function defined ({len(CONDITIONS)} conditions per sample).\")\n",
    "print(f\"Attention probing on: {sorted(ATTN_CONDITIONS)}\")\n",
    "print(f\"Probe layers: {PROBE_LAYERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b5ebef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:05:17.884242Z",
     "iopub.status.busy": "2026-02-22T18:05:17.883626Z",
     "iopub.status.idle": "2026-02-22T18:39:40.611354Z",
     "shell.execute_reply": "2026-02-22T18:39:40.610439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MAIN SCORING LOOP\n",
      "======================================================================\n",
      "Starting fresh: 500 samples x 17 conditions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff287867dd36485f9955491d670a1015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 500 samples in 34.4 min\n",
      "\n",
      "Quick summary:\n",
      "  bare                 NLL=2.9572\n",
      "  random               NLL=2.2979\n",
      "  oracle               NLL=1.9678\n",
      "  oracle_boost2        NLL=2.0500\n",
      "  oracle_boost4        NLL=2.6634\n",
      "  oracle_boost8        NLL=4.1395\n",
      "  random_boost4        NLL=3.5542\n",
      "  oracle_bidir         NLL=2.1911\n",
      "  oracle_chat          NLL=2.7652\n",
      "  instr_chat           NLL=3.1430\n",
      "  oracle_inter         NLL=2.1419\n",
      "  random_inter         NLL=2.3557\n",
      "  oracle_vinj01        NLL=2.1978\n",
      "  oracle_vinj05        NLL=4.1142\n",
      "  oracle_vinj10        NLL=5.2826\n",
      "  pointer              NLL=2.0587\n",
      "  oracle_plus_vocab    NLL=1.8939\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main scoring loop\n",
    "from lib.data import count_words as _cw\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MAIN SCORING LOOP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "CKPT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "all_results = []\n",
    "start_idx = 0\n",
    "if CKPT_PATH.exists():\n",
    "    ckpt = json.loads(CKPT_PATH.read_text())\n",
    "    if len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            all_results = ckpt['results']\n",
    "            start_idx = len(all_results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {N_SAMPLES} samples x {len(CONDITIONS)} conditions\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Scoring\"):\n",
    "    s = samples[i]\n",
    "    try:\n",
    "        result = score_sample(model, tokenizer, s, DEVICE, PROBE_LAYERS)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at sample {i}: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        result = None\n",
    "\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    result['query'] = s['query'][:50]\n",
    "    result['query_doc_overlap'] = s['query_doc_overlap']\n",
    "    result['answer_wc'] = s['answer_wc']\n",
    "    result['query_wc'] = _cw(s['query'])\n",
    "    result['doc_wc'] = s['word_count']\n",
    "    all_results.append(result)\n",
    "\n",
    "    if (i + 1) % 25 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'model': MODEL_NAME,\n",
    "            'n_total': N_SAMPLES,\n",
    "            'n_conditions': len(CONDITIONS),\n",
    "            'condition_names': CONDITIONS,\n",
    "            'probe_layers': PROBE_LAYERS,\n",
    "            'results': all_results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CKPT_PATH.write_text(json.dumps(ckpt))\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nDone: {len(all_results)} samples in {elapsed/60:.1f} min\")\n",
    "print(f\"\\nQuick summary:\")\n",
    "for cn in CONDITIONS:\n",
    "    vals = [r[f'nll_{cn}'] for r in all_results]\n",
    "    print(f\"  {cn:<20} NLL={np.mean(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44221a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:39:40.614806Z",
     "iopub.status.busy": "2026-02-22T18:39:40.614527Z",
     "iopub.status.idle": "2026-02-22T18:39:40.705246Z",
     "shell.execute_reply": "2026-02-22T18:39:40.704334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESULTS: VALUE STORAGE ENHANCEMENT\n",
      "======================================================================\n",
      "\n",
      "--- A. Full Ranking (500 samples) ---\n",
      "\n",
      "  Condition              Mean NLL  d vs bare  d vs rand  d vs orac    p vs rand   sig\n",
      "  ----------------------------------------------------------------------------------\n",
      "  oracle_plus_vocab        1.8939     +0.474     +0.311     +0.089     1.15e-11   ***\n",
      "  oracle                   1.9678     +0.452     +0.266     +0.000     4.94e-09   ***\n",
      "  oracle_boost2            2.0500     +0.443     +0.223     -0.154     8.74e-07   ***\n",
      "  pointer                  2.0587     +0.524     +0.250     -0.079     3.87e-08   ***\n",
      "  oracle_inter             2.1419     +0.409     +0.128     -0.244     4.51e-03    **\n",
      "  oracle_bidir             2.1911     +0.435     +0.110     -0.228     1.39e-02     *\n",
      "  oracle_vinj01            2.1978     +0.369     +0.088     -0.329     4.87e-02     *\n",
      "  random                   2.2979     +0.475     +0.000     -0.266     1.00e+00    ns\n",
      "  random_inter             2.3557     +0.439     -0.112     -0.301     1.22e-02     *\n",
      "  oracle_boost4            2.6634     +0.183     -0.365     -0.589     2.64e-15   ***\n",
      "  oracle_chat              2.7652     +0.183     -0.417     -0.478     3.82e-19   ***\n",
      "  bare                     2.9572     +0.000     -0.475     -0.452     1.00e+00    ns\n",
      "  instr_chat               3.1430     -0.203     -0.546     -0.500     3.59e-30   ***\n",
      "  random_boost4            3.5542     -0.459     -0.749     -0.707     2.91e-50   ***\n",
      "  oracle_vinj05            4.1142     -0.727     -0.950     -0.873     7.43e-72   ***\n",
      "  oracle_boost8            4.1395     -0.622     -1.085     -1.130     1.81e-86   ***\n",
      "  oracle_vinj10            5.2826     -1.235     -1.178     -1.033     1.88e-96   ***\n",
      "\n",
      "--- B1. Boost Dose-Response ---\n",
      "\n",
      "  Condition              Mean NLL  d vs bare  d vs oracle  p vs oracle   sig\n",
      "  ------------------------------------------------------------------------\n",
      "  oracle                   1.9678     +0.452       +0.000     1.00e+00    ns\n",
      "  oracle_boost2            2.0500     +0.443       -0.154     5.98e-04   ***\n",
      "  oracle_boost4            2.6634     +0.183       -0.589     3.02e-34   ***\n",
      "  oracle_boost8            4.1395     -0.622       -1.130     2.48e-91   ***\n",
      "\n",
      "  random_boost4 vs random: d=-0.749, p=2.91e-50 ***\n",
      "  (Does boosting help structural primes too?)\n",
      "\n",
      "--- B2. Bidirectional Bridge ---\n",
      "\n",
      "  oracle_bidir vs oracle: d=-0.228, p=5.10e-07 ***, win%=44.2%\n",
      "\n",
      "--- B3. Chat Format ---\n",
      "\n",
      "  Comparison                                      d            p   sig    win%\n",
      "  ---------------------------------------------------------------------------\n",
      "  oracle_chat vs oracle                      -0.478     3.70e-24   ***   13.6%\n",
      "  instr_chat vs oracle                       -0.500     5.00e-26   ***   13.8%\n",
      "\n",
      "--- B4. Interspersed Repetition ---\n",
      "\n",
      "  Comparison                                      d            p   sig    win%\n",
      "  ---------------------------------------------------------------------------\n",
      "  oracle_inter vs oracle                     -0.244     8.00e-08   ***   33.0%\n",
      "  random_inter vs random                     -0.112     1.22e-02     *   41.0%\n",
      "\n",
      "--- B5. Value Injection Dose-Response ---\n",
      "\n",
      "  Condition              Mean NLL  d vs bare  d vs oracle  p vs oracle   sig\n",
      "  ------------------------------------------------------------------------\n",
      "  oracle                   1.9678     +0.452       +0.000     1.00e+00    ns\n",
      "  oracle_vinj01            2.1978     +0.369       -0.329     7.77e-13   ***\n",
      "  oracle_vinj05            4.1142     -0.727       -0.873     1.62e-63   ***\n",
      "  oracle_vinj10            5.2826     -1.235       -1.033     8.18e-81   ***\n",
      "\n",
      "--- C. Best-of-Each Approach vs Oracle ---\n",
      "\n",
      "  Approach        Best cond              Mean NLL  d vs oracle  p vs oracle   sig\n",
      "  ------------------------------------------------------------------------------\n",
      "  boost           oracle_boost2            2.0500       -0.154     5.98e-04   ***\n",
      "  bidir           oracle_bidir             2.1911       -0.228     5.10e-07   ***\n",
      "  chat            oracle_chat              2.7652       -0.478     3.70e-24   ***\n",
      "  interspersed    oracle_inter             2.1419       -0.244     8.00e-08   ***\n",
      "  vinject         oracle_vinj01            2.1978       -0.329     7.77e-13   ***\n",
      "  reference       oracle_plus_vocab        1.8939       +0.089     4.61e-02     *\n",
      "\n",
      "--- D. Attention Verification ---\n",
      "\n",
      "  Doc-to-prime attention fraction (frac_prime):\n",
      "\n",
      "   Layer       bare     random     oracle   o_boost2   o_boost4   o_boost8   r_boost4\n",
      "  -------------------------------------------------------------------------------------\n",
      "  L  36     0.0000     0.0184     0.0281     0.0810     0.1858     0.6495     0.2038\n",
      "  L  40     0.0000     0.0095     0.0078     0.0306     0.0863     0.3741     0.1077\n",
      "  L  44     0.0000     0.0174     0.0194     0.0830     0.2486     0.7151     0.2586\n",
      "  L  47     0.0000     0.0478     0.0494     0.2146     0.5188     0.9298     0.5393\n",
      "\n",
      "  Attention entropy:\n",
      "\n",
      "   Layer       bare     random     oracle   o_boost2   o_boost4   o_boost8   r_boost4\n",
      "  -------------------------------------------------------------------------------------\n",
      "  L  36      0.833      0.906      0.894      1.000      1.211      1.631      1.564\n",
      "  L  40      0.580      0.629      0.615      0.600      0.633      0.993      0.790\n",
      "  L  44      1.053      1.130      1.122      1.184      1.177      1.387      1.348\n",
      "  L  47      1.083      1.303      1.241      1.624      1.834      1.453      2.105\n",
      "\n",
      "  Monotonicity check (last probed layer L47):\n",
      "    boost=0: frac_prime=0.0494\n",
      "    boost=2: frac_prime=0.2146\n",
      "    boost=4: frac_prime=0.5188\n",
      "    boost=8: frac_prime=0.9298\n",
      "\n",
      "  Correlation: frac_prime x NLL benefit (vs bare):\n",
      "\n",
      "  Condition                   r            p   sig\n",
      "  --------------------------------------------------\n",
      "  random                 +0.167     1.69e-04   ***\n",
      "  oracle                 +0.134     2.65e-03    **\n",
      "  oracle_boost2          +0.104     2.03e-02     *\n",
      "  oracle_boost4          +0.088     4.88e-02     *\n",
      "  oracle_boost8          -0.004     9.32e-01    ns\n",
      "  random_boost4          +0.002     9.72e-01    ns\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Analysis A-D\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS: VALUE STORAGE ENHANCEMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "nll = {}\n",
    "for cn in CONDITIONS:\n",
    "    nll[cn] = np.array([r[f'nll_{cn}'] for r in all_results])\n",
    "\n",
    "N = len(all_results)\n",
    "\n",
    "# ============================================================\n",
    "# A. Full ranking\n",
    "# ============================================================\n",
    "print(f\"\\n--- A. Full Ranking ({N} samples) ---\\n\")\n",
    "print(f\"  {'Condition':<20} {'Mean NLL':>10} {'d vs bare':>10} {'d vs rand':>10}\"\n",
    "      f\" {'d vs orac':>10} {'p vs rand':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*82}\")\n",
    "\n",
    "ranked = sorted(CONDITIONS, key=lambda cn: nll[cn].mean())\n",
    "for cn in ranked:\n",
    "    d_base = cohens_d(nll['bare'] - nll[cn]) if cn != \"bare\" else 0.0\n",
    "    diff_rand = nll['random'] - nll[cn]\n",
    "    d_rand = cohens_d(diff_rand) if cn != \"random\" else 0.0\n",
    "    diff_orac = nll['oracle'] - nll[cn]\n",
    "    d_orac = cohens_d(diff_orac) if cn != \"oracle\" else 0.0\n",
    "\n",
    "    if cn == \"bare\":\n",
    "        p_rand = 1.0\n",
    "    elif cn == \"random\":\n",
    "        p_rand = 1.0\n",
    "    else:\n",
    "        _, p_rand = stats.ttest_1samp(diff_rand, 0)\n",
    "\n",
    "    sig = '***' if p_rand < 0.001 else '**' if p_rand < 0.01 else '*' if p_rand < 0.05 else 'ns'\n",
    "    print(f\"  {cn:<20} {nll[cn].mean():>10.4f} {d_base:>+10.3f} {d_rand:>+10.3f}\"\n",
    "          f\" {d_orac:>+10.3f} {p_rand:>12.2e} {sig:>5}\")\n",
    "\n",
    "# ============================================================\n",
    "# B. Per-approach analysis\n",
    "# ============================================================\n",
    "\n",
    "# --- B1. Boost dose-response ---\n",
    "print(f\"\\n--- B1. Boost Dose-Response ---\\n\")\n",
    "print(f\"  {'Condition':<20} {'Mean NLL':>10} {'d vs bare':>10} {'d vs oracle':>12}\"\n",
    "      f\" {'p vs oracle':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*72}\")\n",
    "\n",
    "boost_conds = [\"oracle\", \"oracle_boost2\", \"oracle_boost4\", \"oracle_boost8\"]\n",
    "for cn in boost_conds:\n",
    "    d_base = cohens_d(nll['bare'] - nll[cn])\n",
    "    diff_orac = nll['oracle'] - nll[cn]\n",
    "    d_orac = cohens_d(diff_orac) if cn != \"oracle\" else 0.0\n",
    "    _, p_orac = stats.ttest_1samp(diff_orac, 0) if cn != \"oracle\" else (None, 1.0)\n",
    "    sig = '***' if p_orac < 0.001 else '**' if p_orac < 0.01 else '*' if p_orac < 0.05 else 'ns'\n",
    "    boost_val = CONDITION_CONFIG[cn][\"boost\"]\n",
    "    print(f\"  {cn:<20} {nll[cn].mean():>10.4f} {d_base:>+10.3f} {d_orac:>+12.3f}\"\n",
    "          f\" {p_orac:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Random boost comparison\n",
    "diff_rb = nll['random'] - nll['random_boost4']\n",
    "d_rb = cohens_d(diff_rb)\n",
    "_, p_rb = stats.ttest_1samp(diff_rb, 0)\n",
    "sig_rb = '***' if p_rb < 0.001 else '**' if p_rb < 0.01 else '*' if p_rb < 0.05 else 'ns'\n",
    "print(f\"\\n  random_boost4 vs random: d={d_rb:+.3f}, p={p_rb:.2e} {sig_rb}\")\n",
    "print(f\"  (Does boosting help structural primes too?)\")\n",
    "\n",
    "# --- B2. Bidirectional bridge ---\n",
    "print(f\"\\n--- B2. Bidirectional Bridge ---\\n\")\n",
    "diff_bd = nll['oracle'] - nll['oracle_bidir']\n",
    "d_bd = cohens_d(diff_bd)\n",
    "_, p_bd = stats.ttest_1samp(diff_bd, 0)\n",
    "sig_bd = '***' if p_bd < 0.001 else '**' if p_bd < 0.01 else '*' if p_bd < 0.05 else 'ns'\n",
    "win_bd = (diff_bd > 0).mean() * 100\n",
    "print(f\"  oracle_bidir vs oracle: d={d_bd:+.3f}, p={p_bd:.2e} {sig_bd}, win%={win_bd:.1f}%\")\n",
    "\n",
    "# --- B3. Chat format ---\n",
    "print(f\"\\n--- B3. Chat Format ---\\n\")\n",
    "print(f\"  {'Comparison':<40} {'d':>8} {'p':>12} {'sig':>5} {'win%':>7}\")\n",
    "print(f\"  {'-'*75}\")\n",
    "\n",
    "for cn in [\"oracle_chat\", \"instr_chat\"]:\n",
    "    diff = nll['oracle'] - nll[cn]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    win = (diff > 0).mean() * 100\n",
    "    print(f\"  {cn + ' vs oracle':<40} {d:>+8.3f} {p:>12.2e} {sig:>5} {win:>6.1f}%\")\n",
    "\n",
    "# --- B4. Interspersed repetition ---\n",
    "print(f\"\\n--- B4. Interspersed Repetition ---\\n\")\n",
    "print(f\"  {'Comparison':<40} {'d':>8} {'p':>12} {'sig':>5} {'win%':>7}\")\n",
    "print(f\"  {'-'*75}\")\n",
    "\n",
    "for base, inter in [(\"oracle\", \"oracle_inter\"), (\"random\", \"random_inter\")]:\n",
    "    diff = nll[base] - nll[inter]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    win = (diff > 0).mean() * 100\n",
    "    print(f\"  {inter + ' vs ' + base:<40} {d:>+8.3f} {p:>12.2e} {sig:>5} {win:>6.1f}%\")\n",
    "\n",
    "# --- B5. Value injection dose-response ---\n",
    "print(f\"\\n--- B5. Value Injection Dose-Response ---\\n\")\n",
    "print(f\"  {'Condition':<20} {'Mean NLL':>10} {'d vs bare':>10} {'d vs oracle':>12}\"\n",
    "      f\" {'p vs oracle':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*72}\")\n",
    "\n",
    "vinj_conds = [\"oracle\", \"oracle_vinj01\", \"oracle_vinj05\", \"oracle_vinj10\"]\n",
    "for cn in vinj_conds:\n",
    "    d_base = cohens_d(nll['bare'] - nll[cn])\n",
    "    diff_orac = nll['oracle'] - nll[cn]\n",
    "    d_orac = cohens_d(diff_orac) if cn != \"oracle\" else 0.0\n",
    "    _, p_orac = stats.ttest_1samp(diff_orac, 0) if cn != \"oracle\" else (None, 1.0)\n",
    "    sig = '***' if p_orac < 0.001 else '**' if p_orac < 0.01 else '*' if p_orac < 0.05 else 'ns'\n",
    "    print(f\"  {cn:<20} {nll[cn].mean():>10.4f} {d_base:>+10.3f} {d_orac:>+12.3f}\"\n",
    "          f\" {p_orac:>12.2e} {sig:>5}\")\n",
    "\n",
    "# ============================================================\n",
    "# C. Best-of-each approach vs oracle\n",
    "# ============================================================\n",
    "print(f\"\\n--- C. Best-of-Each Approach vs Oracle ---\\n\")\n",
    "\n",
    "APPROACH_GROUPS = {\n",
    "    \"boost\": [\"oracle_boost2\", \"oracle_boost4\", \"oracle_boost8\"],\n",
    "    \"bidir\": [\"oracle_bidir\"],\n",
    "    \"chat\": [\"oracle_chat\", \"instr_chat\"],\n",
    "    \"interspersed\": [\"oracle_inter\", \"random_inter\"],\n",
    "    \"vinject\": [\"oracle_vinj01\", \"oracle_vinj05\", \"oracle_vinj10\"],\n",
    "    \"reference\": [\"pointer\", \"oracle_plus_vocab\"],\n",
    "}\n",
    "\n",
    "print(f\"  {'Approach':<15} {'Best cond':<20} {'Mean NLL':>10} {'d vs oracle':>12}\"\n",
    "      f\" {'p vs oracle':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*78}\")\n",
    "\n",
    "for approach, conds in APPROACH_GROUPS.items():\n",
    "    best_cn = min(conds, key=lambda cn: nll[cn].mean())\n",
    "    d_base = cohens_d(nll['bare'] - nll[best_cn])\n",
    "    diff_orac = nll['oracle'] - nll[best_cn]\n",
    "    d_orac = cohens_d(diff_orac)\n",
    "    _, p_orac = stats.ttest_1samp(diff_orac, 0)\n",
    "    sig = '***' if p_orac < 0.001 else '**' if p_orac < 0.01 else '*' if p_orac < 0.05 else 'ns'\n",
    "    print(f\"  {approach:<15} {best_cn:<20} {nll[best_cn].mean():>10.4f} {d_orac:>+12.3f}\"\n",
    "          f\" {p_orac:>12.2e} {sig:>5}\")\n",
    "\n",
    "# ============================================================\n",
    "# D. Attention verification (boost conditions only)\n",
    "# ============================================================\n",
    "print(f\"\\n--- D. Attention Verification ---\\n\")\n",
    "\n",
    "# D1: frac_prime by condition and layer\n",
    "attn_conds_ordered = [\"bare\", \"random\", \"oracle\", \"oracle_boost2\",\n",
    "                      \"oracle_boost4\", \"oracle_boost8\", \"random_boost4\"]\n",
    "print(f\"  Doc-to-prime attention fraction (frac_prime):\\n\")\n",
    "header = f\"  {'Layer':>6}\"\n",
    "for cn in attn_conds_ordered:\n",
    "    short = cn.replace(\"oracle_\", \"o_\").replace(\"random_\", \"r_\")\n",
    "    header += f\" {short:>10}\"\n",
    "print(header)\n",
    "print(f\"  {'-'*(8 + 11*len(attn_conds_ordered))}\")\n",
    "\n",
    "layer_attn_data = {}\n",
    "for layer_idx in PROBE_LAYERS:\n",
    "    row = f\"  L{layer_idx:>4}\"\n",
    "    layer_attn_data[layer_idx] = {}\n",
    "    for cn in attn_conds_ordered:\n",
    "        key = f'{cn}_L{layer_idx}_frac_prime'\n",
    "        if key in all_results[0]:\n",
    "            vals = np.array([r[key] for r in all_results])\n",
    "            layer_attn_data[layer_idx][cn] = vals\n",
    "            row += f\" {vals.mean():>10.4f}\"\n",
    "        else:\n",
    "            row += f\" {'N/A':>10}\"\n",
    "    print(row)\n",
    "\n",
    "# D2: Entropy by condition and layer\n",
    "print(f\"\\n  Attention entropy:\\n\")\n",
    "header = f\"  {'Layer':>6}\"\n",
    "for cn in attn_conds_ordered:\n",
    "    short = cn.replace(\"oracle_\", \"o_\").replace(\"random_\", \"r_\")\n",
    "    header += f\" {short:>10}\"\n",
    "print(header)\n",
    "print(f\"  {'-'*(8 + 11*len(attn_conds_ordered))}\")\n",
    "\n",
    "for layer_idx in PROBE_LAYERS:\n",
    "    row = f\"  L{layer_idx:>4}\"\n",
    "    for cn in attn_conds_ordered:\n",
    "        key = f'{cn}_L{layer_idx}_entropy'\n",
    "        if key in all_results[0]:\n",
    "            vals = np.array([r[key] for r in all_results])\n",
    "            row += f\" {vals.mean():>10.3f}\"\n",
    "        else:\n",
    "            row += f\" {'N/A':>10}\"\n",
    "    print(row)\n",
    "\n",
    "# D3: Is frac_prime monotonic with boost?\n",
    "print(f\"\\n  Monotonicity check (last probed layer L{PROBE_LAYERS[-1]}):\")\n",
    "last_l = PROBE_LAYERS[-1]\n",
    "for cn in [\"oracle\", \"oracle_boost2\", \"oracle_boost4\", \"oracle_boost8\"]:\n",
    "    key = f'{cn}_L{last_l}_frac_prime'\n",
    "    if key in all_results[0]:\n",
    "        vals = np.array([r[key] for r in all_results])\n",
    "        boost_val = CONDITION_CONFIG[cn][\"boost\"]\n",
    "        print(f\"    boost={boost_val}: frac_prime={vals.mean():.4f}\")\n",
    "\n",
    "# D4: Correlation between boost-induced prime attention and NLL benefit\n",
    "print(f\"\\n  Correlation: frac_prime x NLL benefit (vs bare):\\n\")\n",
    "print(f\"  {'Condition':<20} {'r':>8} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for cn in attn_conds_ordered:\n",
    "    if cn == \"bare\":\n",
    "        continue\n",
    "    key = f'{cn}_L{last_l}_frac_prime'\n",
    "    if key not in all_results[0]:\n",
    "        continue\n",
    "    frac = np.array([r[key] for r in all_results])\n",
    "    benefit = nll['bare'] - nll[cn]\n",
    "    r_val, p_val = stats.pearsonr(frac, benefit)\n",
    "    sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "    print(f\"  {cn:<20} {r_val:>+8.3f} {p_val:>12.2e} {sig:>5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9e98fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:39:40.708631Z",
     "iopub.status.busy": "2026-02-22T18:39:40.708364Z",
     "iopub.status.idle": "2026-02-22T18:39:40.762073Z",
     "shell.execute_reply": "2026-02-22T18:39:40.761042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- E. Structural Fraction ---\n",
      "\n",
      "  Baseline: d_oracle=+0.452, d_random=+0.475, structural=105%\n",
      "\n",
      "  Approach         d_oracle_var  d_random_var  struct%\n",
      "  -------------------------------------------------------\n",
      "  standard               +0.452        +0.475    105%\n",
      "  boost4                 +0.183        -0.459   -250%\n",
      "  interspersed           +0.409        +0.439    107%\n",
      "\n",
      "  All conditions d vs bare:\n",
      "  Condition             d vs bare\n",
      "  ---------------------------------\n",
      "  oracle_plus_vocab        +0.474\n",
      "  oracle                   +0.452\n",
      "  oracle_boost2            +0.443\n",
      "  pointer                  +0.524\n",
      "  oracle_inter             +0.409\n",
      "  oracle_bidir             +0.435\n",
      "  oracle_vinj01            +0.369\n",
      "  random                   +0.475\n",
      "  random_inter             +0.439\n",
      "  oracle_boost4            +0.183\n",
      "  oracle_chat              +0.183\n",
      "  bare                     +0.000\n",
      "  instr_chat               -0.203\n",
      "  random_boost4            -0.459\n",
      "  oracle_vinj05            -0.727\n",
      "  oracle_boost8            -0.622\n",
      "  oracle_vinj10            -1.235\n",
      "\n",
      "--- F. Per-Sample Heterogeneity ---\n",
      "\n",
      "  Correlation of NLL benefit (vs bare) with sample features:\n",
      "\n",
      "  Condition             r(ans_wc)  r(doc_wc) r(overlap)\n",
      "  -------------------------------------------------------\n",
      "  oracle                   -0.333     +0.009     +0.054\n",
      "  random                   -0.334     -0.058     +0.097\n",
      "  oracle_boost2            -0.329     +0.001     +0.064\n",
      "  oracle_bidir             -0.309     -0.002     +0.012\n",
      "  oracle_chat              -0.178     -0.036     +0.092\n",
      "  oracle_inter             -0.310     +0.017     +0.019\n",
      "  oracle_vinj01            -0.317     -0.010     +0.052\n",
      "  oracle_plus_vocab        -0.347     +0.012     +0.081\n",
      "\n",
      "  Split by answer length:\n",
      "  Condition               Short d     Long d\n",
      "  -------------------------------------------\n",
      "  oracle_plus_vocab        +0.734     +0.798\n",
      "  oracle                   +0.698     +0.690\n",
      "  oracle_boost2            +0.689     +0.557\n",
      "  pointer                  +0.772     +0.931\n",
      "  oracle_inter             +0.635     +0.475\n",
      "  oracle_bidir             +0.639     +0.762\n",
      "  oracle_vinj01            +0.636     +0.008\n",
      "  random                   +0.699     +0.816\n",
      "  random_inter             +0.660     +0.598\n",
      "  oracle_boost4            +0.513     -0.648\n",
      "  oracle_chat              +0.311     -0.095\n",
      "  instr_chat               -0.251     -0.274\n",
      "  random_boost4            -0.181     -1.388\n",
      "  oracle_vinj05            -0.372     -1.784\n",
      "  oracle_boost8            -0.221     -1.931\n",
      "  oracle_vinj10            -0.875     -2.497\n",
      "\n",
      "--- G. 04e Replication Check ---\n",
      "\n",
      "  Expected from 04e: pointer d~+0.250 vs random, oracle_plus_vocab d~+0.311 vs random\n",
      "\n",
      "  pointer              d vs random = +0.250 (p=3.87e-08) ***\n",
      "  oracle_plus_vocab    d vs random = +0.311 (p=1.15e-11) ***\n",
      "\n",
      "  Prime token counts (mean):\n",
      "    random                  8.1 tokens\n",
      "    oracle                  6.5 tokens\n",
      "    oracle_boost2           6.5 tokens\n",
      "    oracle_boost4           6.5 tokens\n",
      "    oracle_boost8           6.5 tokens\n",
      "    random_boost4           8.1 tokens\n",
      "    oracle_bidir            6.5 tokens\n",
      "    oracle_chat            11.5 tokens\n",
      "    instr_chat             13.0 tokens\n",
      "    oracle_inter           19.6 tokens\n",
      "    random_inter           24.2 tokens\n",
      "    oracle_vinj01           6.5 tokens\n",
      "    oracle_vinj05           6.5 tokens\n",
      "    oracle_vinj10           6.5 tokens\n",
      "    pointer                 9.2 tokens\n",
      "    oracle_plus_vocab      13.9 tokens\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Analysis E-G\n",
    "\n",
    "# ============================================================\n",
    "# E. Structural fraction per approach\n",
    "# ============================================================\n",
    "print(f\"\\n--- E. Structural Fraction ---\\n\")\n",
    "\n",
    "d_oracle_base = cohens_d(nll['bare'] - nll['oracle'])\n",
    "d_random_base = cohens_d(nll['bare'] - nll['random'])\n",
    "struct_base = d_random_base / d_oracle_base if d_oracle_base != 0 else float('nan')\n",
    "\n",
    "print(f\"  Baseline: d_oracle={d_oracle_base:+.3f}, d_random={d_random_base:+.3f},\"\n",
    "      f\" structural={struct_base:.0%}\")\n",
    "\n",
    "# Approaches with both oracle and random variants\n",
    "print(f\"\\n  {'Approach':<15} {'d_oracle_var':>13} {'d_random_var':>13} {'struct%':>8}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "struct_pairs = [\n",
    "    (\"standard\", \"oracle\", \"random\"),\n",
    "    (\"boost4\", \"oracle_boost4\", \"random_boost4\"),\n",
    "    (\"interspersed\", \"oracle_inter\", \"random_inter\"),\n",
    "]\n",
    "for label, orc_cn, rnd_cn in struct_pairs:\n",
    "    d_orc = cohens_d(nll['bare'] - nll[orc_cn])\n",
    "    d_rnd = cohens_d(nll['bare'] - nll[rnd_cn])\n",
    "    sf = d_rnd / d_orc if d_orc != 0 else float('nan')\n",
    "    print(f\"  {label:<15} {d_orc:>+13.3f} {d_rnd:>+13.3f} {sf:>7.0%}\")\n",
    "\n",
    "# All conditions: d vs bare\n",
    "print(f\"\\n  All conditions d vs bare:\")\n",
    "print(f\"  {'Condition':<20} {'d vs bare':>10}\")\n",
    "print(f\"  {'-'*33}\")\n",
    "for cn in ranked:\n",
    "    d = cohens_d(nll['bare'] - nll[cn]) if cn != \"bare\" else 0.0\n",
    "    print(f\"  {cn:<20} {d:>+10.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# F. Per-sample heterogeneity\n",
    "# ============================================================\n",
    "print(f\"\\n--- F. Per-Sample Heterogeneity ---\\n\")\n",
    "\n",
    "answer_wc = np.array([r['answer_wc'] for r in all_results])\n",
    "doc_wc = np.array([r['doc_wc'] for r in all_results])\n",
    "qd_overlap = np.array([r['query_doc_overlap'] for r in all_results])\n",
    "\n",
    "# For each approach category, pick the best non-control condition\n",
    "# and correlate its benefit (vs bare) with sample features\n",
    "approach_best = {}\n",
    "for approach, conds in APPROACH_GROUPS.items():\n",
    "    best_cn = min(conds, key=lambda cn: nll[cn].mean())\n",
    "    approach_best[approach] = best_cn\n",
    "\n",
    "print(f\"  Correlation of NLL benefit (vs bare) with sample features:\\n\")\n",
    "print(f\"  {'Condition':<20} {'r(ans_wc)':>10} {'r(doc_wc)':>10} {'r(overlap)':>10}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "for label in [\"oracle\", \"random\"] + list(approach_best.values()):\n",
    "    if label in (\"oracle\", \"random\"):\n",
    "        cn = label\n",
    "    else:\n",
    "        cn = label\n",
    "    benefit = nll['bare'] - nll[cn]\n",
    "    r_awc, _ = stats.pearsonr(benefit, answer_wc)\n",
    "    r_dwc, _ = stats.pearsonr(benefit, doc_wc)\n",
    "    r_ov, _ = stats.pearsonr(benefit, qd_overlap)\n",
    "    print(f\"  {cn:<20} {r_awc:>+10.3f} {r_dwc:>+10.3f} {r_ov:>+10.3f}\")\n",
    "\n",
    "# Difficulty split: short vs long answers\n",
    "print(f\"\\n  Split by answer length:\")\n",
    "short = answer_wc <= 5\n",
    "long_a = answer_wc > 5\n",
    "\n",
    "print(f\"  {'Condition':<20} {'Short d':>10} {'Long d':>10}\")\n",
    "print(f\"  {'-'*43}\")\n",
    "for cn in ranked:\n",
    "    if cn == \"bare\":\n",
    "        continue\n",
    "    ds = cohens_d((nll['bare'] - nll[cn])[short])\n",
    "    dl = cohens_d((nll['bare'] - nll[cn])[long_a])\n",
    "    print(f\"  {cn:<20} {ds:>+10.3f} {dl:>+10.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# G. 04e Replication Check\n",
    "# ============================================================\n",
    "print(f\"\\n--- G. 04e Replication Check ---\\n\")\n",
    "print(f\"  Expected from 04e: pointer d~+0.250 vs random, oracle_plus_vocab d~+0.311 vs random\\n\")\n",
    "\n",
    "for cn in [\"pointer\", \"oracle_plus_vocab\"]:\n",
    "    diff = nll['random'] - nll[cn]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {cn:<20} d vs random = {d:+.3f} (p={p:.2e}) {sig}\")\n",
    "\n",
    "# Prime token counts\n",
    "print(f\"\\n  Prime token counts (mean):\")\n",
    "for cn in CONDITIONS:\n",
    "    if cn == \"bare\":\n",
    "        continue\n",
    "    vals = [r[f'n_prime_{cn}'] for r in all_results]\n",
    "    print(f\"    {cn:<20} {np.mean(vals):>6.1f} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222b36ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T18:39:40.765787Z",
     "iopub.status.busy": "2026-02-22T18:39:40.765471Z",
     "iopub.status.idle": "2026-02-22T18:39:40.806772Z",
     "shell.execute_reply": "2026-02-22T18:39:40.805861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERDICT -- Prefix LM Exp 04g: Value Storage Enhancement\n",
      "======================================================================\n",
      "\n",
      "  Baseline replication:\n",
      "    d_oracle=+0.452, d_random=+0.475, structural=105%\n",
      "\n",
      "  Per-approach verdicts:\n",
      "\n",
      "  BOOST: HURTS. Best=oracle_boost2, d vs oracle=-0.154 (p=5.98e-04)\n",
      "  RANDOM BOOST: No effect on structural. d=-0.749 (p=2.91e-50)\n",
      "  BIDIR: HURTS. d vs oracle=-0.228 (p=5.10e-07)\n",
      "  CHAT: HURTS. Best=oracle_chat, d vs oracle=-0.478 (p=3.70e-24)\n",
      "  INTERSPERSED: HURTS. oracle_inter vs oracle d=-0.244 (p=8.00e-08)\n",
      "    random_inter vs random: d=-0.112 (p=1.22e-02)\n",
      "  VINJECT: HURTS. Best=oracle_vinj01, d vs oracle=-0.329 (p=7.77e-13)\n",
      "\n",
      "  --- OVERALL ---\n",
      "  YES: At least one approach significantly beats oracle.\n",
      "  Best overall: oracle_plus_vocab (d vs oracle = +0.089)\n",
      "  Some conditions beat random (semantic signal can be amplified).\n",
      "\n",
      "Results saved to ../../../results/prefix_lm_exp04g/results.json\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save results + verdict\n",
    "print(\"=\" * 70)\n",
    "print(\"VERDICT -- Prefix LM Exp 04g: Value Storage Enhancement\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "d_oracle_v_bare = cohens_d(nll['bare'] - nll['oracle'])\n",
    "d_random_v_bare = cohens_d(nll['bare'] - nll['random'])\n",
    "struct_frac = d_random_v_bare / d_oracle_v_bare if d_oracle_v_bare != 0 else float('nan')\n",
    "\n",
    "print(f\"\\n  Baseline replication:\")\n",
    "print(f\"    d_oracle={d_oracle_v_bare:+.3f}, d_random={d_random_v_bare:+.3f}, structural={struct_frac:.0%}\")\n",
    "\n",
    "# --- Per-approach verdicts ---\n",
    "print(f\"\\n  Per-approach verdicts:\\n\")\n",
    "\n",
    "# Boost\n",
    "best_boost = min([\"oracle_boost2\", \"oracle_boost4\", \"oracle_boost8\"],\n",
    "                 key=lambda cn: nll[cn].mean())\n",
    "diff_bb = nll['oracle'] - nll[best_boost]\n",
    "d_bb = cohens_d(diff_bb)\n",
    "_, p_bb = stats.ttest_1samp(diff_bb, 0)\n",
    "if p_bb < 0.05 and d_bb > 0:\n",
    "    print(f\"  BOOST: HELPS. Best={best_boost}, d vs oracle={d_bb:+.3f} (p={p_bb:.2e})\")\n",
    "elif p_bb < 0.05 and d_bb < 0:\n",
    "    print(f\"  BOOST: HURTS. Best={best_boost}, d vs oracle={d_bb:+.3f} (p={p_bb:.2e})\")\n",
    "else:\n",
    "    print(f\"  BOOST: NO EFFECT. Best={best_boost}, d vs oracle={d_bb:+.3f} (p={p_bb:.2e})\")\n",
    "\n",
    "# Random boost\n",
    "diff_rb = nll['random'] - nll['random_boost4']\n",
    "d_rb = cohens_d(diff_rb)\n",
    "_, p_rb = stats.ttest_1samp(diff_rb, 0)\n",
    "if p_rb < 0.05 and d_rb > 0:\n",
    "    print(f\"  RANDOM BOOST: HELPS structural too. d={d_rb:+.3f} (p={p_rb:.2e})\")\n",
    "else:\n",
    "    print(f\"  RANDOM BOOST: No effect on structural. d={d_rb:+.3f} (p={p_rb:.2e})\")\n",
    "\n",
    "# Bidir\n",
    "diff_bd = nll['oracle'] - nll['oracle_bidir']\n",
    "d_bd = cohens_d(diff_bd)\n",
    "_, p_bd = stats.ttest_1samp(diff_bd, 0)\n",
    "if p_bd < 0.05 and d_bd > 0:\n",
    "    print(f\"  BIDIR: HELPS. d vs oracle={d_bd:+.3f} (p={p_bd:.2e})\")\n",
    "elif p_bd < 0.05 and d_bd < 0:\n",
    "    print(f\"  BIDIR: HURTS. d vs oracle={d_bd:+.3f} (p={p_bd:.2e})\")\n",
    "else:\n",
    "    print(f\"  BIDIR: NO EFFECT. d vs oracle={d_bd:+.3f} (p={p_bd:.2e})\")\n",
    "\n",
    "# Chat\n",
    "best_chat = min([\"oracle_chat\", \"instr_chat\"], key=lambda cn: nll[cn].mean())\n",
    "diff_ch = nll['oracle'] - nll[best_chat]\n",
    "d_ch = cohens_d(diff_ch)\n",
    "_, p_ch = stats.ttest_1samp(diff_ch, 0)\n",
    "if p_ch < 0.05 and d_ch > 0:\n",
    "    print(f\"  CHAT: HELPS. Best={best_chat}, d vs oracle={d_ch:+.3f} (p={p_ch:.2e})\")\n",
    "elif p_ch < 0.05 and d_ch < 0:\n",
    "    print(f\"  CHAT: HURTS. Best={best_chat}, d vs oracle={d_ch:+.3f} (p={p_ch:.2e})\")\n",
    "else:\n",
    "    print(f\"  CHAT: NO EFFECT. Best={best_chat}, d vs oracle={d_ch:+.3f} (p={p_ch:.2e})\")\n",
    "\n",
    "# Interspersed\n",
    "diff_io = nll['oracle'] - nll['oracle_inter']\n",
    "d_io = cohens_d(diff_io)\n",
    "_, p_io = stats.ttest_1samp(diff_io, 0)\n",
    "if p_io < 0.05 and d_io > 0:\n",
    "    print(f\"  INTERSPERSED: HELPS. oracle_inter vs oracle d={d_io:+.3f} (p={p_io:.2e})\")\n",
    "elif p_io < 0.05 and d_io < 0:\n",
    "    print(f\"  INTERSPERSED: HURTS. oracle_inter vs oracle d={d_io:+.3f} (p={p_io:.2e})\")\n",
    "else:\n",
    "    print(f\"  INTERSPERSED: NO EFFECT. oracle_inter vs oracle d={d_io:+.3f} (p={p_io:.2e})\")\n",
    "\n",
    "diff_ir = nll['random'] - nll['random_inter']\n",
    "d_ir = cohens_d(diff_ir)\n",
    "_, p_ir = stats.ttest_1samp(diff_ir, 0)\n",
    "print(f\"    random_inter vs random: d={d_ir:+.3f} (p={p_ir:.2e})\")\n",
    "\n",
    "# Value injection\n",
    "best_vinj = min([\"oracle_vinj01\", \"oracle_vinj05\", \"oracle_vinj10\"],\n",
    "                key=lambda cn: nll[cn].mean())\n",
    "diff_vj = nll['oracle'] - nll[best_vinj]\n",
    "d_vj = cohens_d(diff_vj)\n",
    "_, p_vj = stats.ttest_1samp(diff_vj, 0)\n",
    "if p_vj < 0.05 and d_vj > 0:\n",
    "    print(f\"  VINJECT: HELPS. Best={best_vinj}, d vs oracle={d_vj:+.3f} (p={p_vj:.2e})\")\n",
    "elif p_vj < 0.05 and d_vj < 0:\n",
    "    print(f\"  VINJECT: HURTS. Best={best_vinj}, d vs oracle={d_vj:+.3f} (p={p_vj:.2e})\")\n",
    "else:\n",
    "    print(f\"  VINJECT: NO EFFECT. Best={best_vinj}, d vs oracle={d_vj:+.3f} (p={p_vj:.2e})\")\n",
    "\n",
    "# --- Overall verdict ---\n",
    "print(f\"\\n  --- OVERALL ---\")\n",
    "\n",
    "# Does ANY approach beat oracle?\n",
    "any_beats_oracle = False\n",
    "best_overall = None\n",
    "best_d_vs_oracle = -999\n",
    "for approach, conds in APPROACH_GROUPS.items():\n",
    "    for cn in conds:\n",
    "        diff = nll['oracle'] - nll[cn]\n",
    "        d = cohens_d(diff)\n",
    "        _, p = stats.ttest_1samp(diff, 0)\n",
    "        if d > 0 and p < 0.05:\n",
    "            any_beats_oracle = True\n",
    "        if d > best_d_vs_oracle:\n",
    "            best_d_vs_oracle = d\n",
    "            best_overall = cn\n",
    "\n",
    "if any_beats_oracle:\n",
    "    print(f\"  YES: At least one approach significantly beats oracle.\")\n",
    "    print(f\"  Best overall: {best_overall} (d vs oracle = {best_d_vs_oracle:+.3f})\")\n",
    "else:\n",
    "    print(f\"  NO: No approach significantly beats oracle.\")\n",
    "    print(f\"  Closest: {best_overall} (d vs oracle = {best_d_vs_oracle:+.3f})\")\n",
    "\n",
    "# Does anything beat random?\n",
    "any_beats_random = False\n",
    "for cn in CONDITIONS:\n",
    "    if cn in (\"bare\", \"random\"):\n",
    "        continue\n",
    "    diff = nll['random'] - nll[cn]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    if d > 0 and p < 0.05:\n",
    "        any_beats_random = True\n",
    "        break\n",
    "\n",
    "if not any_beats_random:\n",
    "    print(f\"  NOTHING beats random  mechanism is purely structural even with forced value storage.\")\n",
    "else:\n",
    "    print(f\"  Some conditions beat random (semantic signal can be amplified).\")\n",
    "\n",
    "# --- Save results ---\n",
    "summary = {'n_samples': N, 'model': MODEL_NAME}\n",
    "for cn in CONDITIONS:\n",
    "    summary[f'nll_{cn}'] = float(nll[cn].mean())\n",
    "    summary[f'd_vs_bare_{cn}'] = float(cohens_d(nll['bare'] - nll[cn])) if cn != \"bare\" else 0.0\n",
    "summary['d_structural'] = float(d_random_v_bare)\n",
    "summary['d_oracle'] = float(d_oracle_v_bare)\n",
    "summary['structural_fraction'] = float(struct_frac)\n",
    "\n",
    "final_results = {\n",
    "    'experiment': 'prefix_lm_exp04g',\n",
    "    'dataset': 'ms_marco_v1.1',\n",
    "    'model': MODEL_NAME,\n",
    "    'n_samples': N,\n",
    "    'seed': SEED,\n",
    "    'conditions': CONDITIONS,\n",
    "    'condition_config': {k: {kk: vv for kk, vv in v.items()}\n",
    "                        for k, v in CONDITION_CONFIG.items()},\n",
    "    'probe_layers': PROBE_LAYERS,\n",
    "    'attn_conditions': sorted(ATTN_CONDITIONS),\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'summary': summary,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a7fa377b7704d599320e7aa1bb6cc67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_643856a1dedf4119a2bc447f406212af",
        "IPY_MODEL_5b61983a2e8b4d1ea1b0aecd66b15579",
        "IPY_MODEL_98e411e621dc478cac2bbb3aefcde050"
       ],
       "layout": "IPY_MODEL_7d5c29f839f74f56bd3987041161a3ed",
       "tabbable": null,
       "tooltip": null
      }
     },
     "14f824b8aa134147b1eb37f7755787ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f6417d413b247ee84101ff44862ef7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d93f550f89f423290df0de199a66d74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e6120eeb7f049afbc55688bb86ea5a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5883d448288547f990628dd3f66d3c3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5a49a7a2636d41ecb638a4632dc373a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5b61983a2e8b4d1ea1b0aecd66b15579": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_14f824b8aa134147b1eb37f7755787ec",
       "max": 1065.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a64ae1391a28439599bc8d14f9dce58c",
       "tabbable": null,
       "tooltip": null,
       "value": 1065.0
      }
     },
     "5cd73112d5ef4c05ae3a5d2ad650bf56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "643856a1dedf4119a2bc447f406212af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e19fe1b814d049e9a7ce90258529e68e",
       "placeholder": "",
       "style": "IPY_MODEL_b5803aa96346446d8f813fa89177e969",
       "tabbable": null,
       "tooltip": null,
       "value": "Loadingweights:100%"
      }
     },
     "74a148ee778047de8f89882ebd2841b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7799a1e8bf754f358a5bfce710843c8f",
       "placeholder": "",
       "style": "IPY_MODEL_5a49a7a2636d41ecb638a4632dc373a9",
       "tabbable": null,
       "tooltip": null,
       "value": "500/500[34:22&lt;00:00,4.23s/it]"
      }
     },
     "7799a1e8bf754f358a5bfce710843c8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d5c29f839f74f56bd3987041161a3ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "805dcb5f1424476593fdd61bb777e728": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5cd73112d5ef4c05ae3a5d2ad650bf56",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5883d448288547f990628dd3f66d3c3f",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "91226735f9f54f0ab7dc906bedc7cda6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f6417d413b247ee84101ff44862ef7d",
       "placeholder": "",
       "style": "IPY_MODEL_e8cd6b6832bc41b598944bb47dc6229f",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring:100%"
      }
     },
     "98e411e621dc478cac2bbb3aefcde050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bbd8a57c006b4f2498151bf429a6b44f",
       "placeholder": "",
       "style": "IPY_MODEL_4e6120eeb7f049afbc55688bb86ea5a5",
       "tabbable": null,
       "tooltip": null,
       "value": "1065/1065[00:06&lt;00:00,654.23it/s,Materializingparam=model.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "a64ae1391a28439599bc8d14f9dce58c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b5803aa96346446d8f813fa89177e969": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bbd8a57c006b4f2498151bf429a6b44f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e19fe1b814d049e9a7ce90258529e68e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8cd6b6832bc41b598944bb47dc6229f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff287867dd36485f9955491d670a1015": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91226735f9f54f0ab7dc906bedc7cda6",
        "IPY_MODEL_805dcb5f1424476593fdd61bb777e728",
        "IPY_MODEL_74a148ee778047de8f89882ebd2841b4"
       ],
       "layout": "IPY_MODEL_2d93f550f89f423290df0de199a66d74",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
