{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c7e9b3",
   "metadata": {},
   "source": [
    "# Prefix LM Exp 04e: Semantic Amplification & Relevance Hints\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 04d showed under two-pass truncation (no copy shortcut), ALL content conditions\n",
    "hurt vs random. The structural mechanism dominates completely.\n",
    "\n",
    "**Why isn't the semantic effect stronger?** Four hypotheses:\n",
    "\n",
    "| # | Hypothesis | Test |\n",
    "|---|-----------|------|\n",
    "| H1 | Questions too easy | Stratify by difficulty |\n",
    "| H2 | Prime too short | Repeat query 3x, 5x |\n",
    "| H3 | Model can't anticipate relevance | Give explicit relevance hints |\n",
    "| H4 | Mechanism purely structural | If NOTHING beats random |\n",
    "\n",
    "## Conditions (11)\n",
    "\n",
    "All two-pass truncation: Phase A caches `[BOS, prime, doc]`, Phase B evaluates\n",
    "`[query, answer]` with prime positions masked.\n",
    "\n",
    "| # | Condition | Content | Hypothesis | Tokens (est) |\n",
    "|---|-----------|---------|-----------|-------------|\n",
    "| 1 | `bare` | (none) | baseline | 0 |\n",
    "| 2 | `random` | 8 random words | structural control | ~9 |\n",
    "| 3 | `oracle` | real query | standard semantic | ~9 |\n",
    "| 4 | `oracle_3x` | query x 3 | H2: more signal | ~27 |\n",
    "| 5 | `oracle_5x` | query x 5 | H2: max signal | ~45 |\n",
    "| 6 | `random_long` | 40 random words | H2: length control | ~45 |\n",
    "| 7 | `relevant_sent` | doc sentence with highest answer overlap | H3: relevance | ~15-30 |\n",
    "| 8 | `irrelevant_sent` | doc sentence with lowest answer overlap | H3: control | ~15-30 |\n",
    "| 9 | `answer_vocab` | answer words that appear in doc | H3: vocabulary bridge | ~5-12 |\n",
    "| 10 | `pointer` | \"the answer is about [overlap words]\" | H3: instructed hint | ~10-18 |\n",
    "| 11 | `oracle_plus_vocab` | query + answer-doc overlap words | H3: max semantic info | ~15-22 |\n",
    "\n",
    "## Key Analyses\n",
    "\n",
    "- **A**: Full ranking (does ANYTHING beat random?)\n",
    "- **B**: Repetition scaling (oracle_1x vs 3x vs 5x) + length control (random_long)\n",
    "- **C**: Relevance hints (relevant_sent, answer_vocab, pointer vs random)\n",
    "- **D**: Maximum semantic info (oracle_plus_vocab vs oracle vs random)\n",
    "- **E**: Difficulty stratification (split by query-doc overlap, answer length, query length)\n",
    "- **F**: Structural fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d16bbec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:46:48.916414Z",
     "iopub.status.busy": "2026-02-22T15:46:48.915957Z",
     "iopub.status.idle": "2026-02-22T15:46:53.496912Z",
     "shell.execute_reply": "2026-02-22T15:46:53.495804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix LM Exp 04e: Semantic Amplification & Relevance Hints\n",
      "N: 500, Conditions: 11\n",
      "DEVICE: cuda\n",
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "GPU memory: 42.3 GB\n",
      "\n",
      "Conditions: ['bare', 'random', 'oracle', 'oracle_3x', 'oracle_5x', 'random_long', 'relevant_sent', 'irrelevant_sent', 'answer_vocab', 'pointer', 'oracle_plus_vocab']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, gc, re\n",
    "import random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 500\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "\n",
    "RESULTS_DIR = Path(\"../../../results/prefix_lm_exp04e\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONDITIONS = [\n",
    "    \"bare\",\n",
    "    \"random\",\n",
    "    \"oracle\",\n",
    "    \"oracle_3x\",\n",
    "    \"oracle_5x\",\n",
    "    \"random_long\",\n",
    "    \"relevant_sent\",\n",
    "    \"irrelevant_sent\",\n",
    "    \"answer_vocab\",\n",
    "    \"pointer\",\n",
    "    \"oracle_plus_vocab\",\n",
    "]\n",
    "\n",
    "print(f\"Prefix LM Exp 04e: Semantic Amplification & Relevance Hints\")\n",
    "print(f\"N: {N_SAMPLES}, Conditions: {len(CONDITIONS)}\")\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"\\nConditions: {CONDITIONS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674bf813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:46:53.500902Z",
     "iopub.status.busy": "2026-02-22T15:46:53.500089Z",
     "iopub.status.idle": "2026-02-22T15:47:09.303855Z",
     "shell.execute_reply": "2026-02-22T15:47:09.302963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 5.1.0\n",
      "Loading google/gemma-3-12b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed42046792749a689f77f1418fbbff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 12.2B params, 24.4 GB GPU, 13s\n",
      "BOS token id: 2\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load model + tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "t0 = time.time()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters()) / 1e9\n",
    "gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"Loaded: {n_params:.1f}B params, {gpu_mem:.1f} GB GPU, {time.time()-t0:.0f}s\")\n",
    "print(f\"BOS token id: {tokenizer.bos_token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d992830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:47:09.307483Z",
     "iopub.status.busy": "2026-02-22T15:47:09.306755Z",
     "iopub.status.idle": "2026-02-22T15:47:10.210220Z",
     "shell.execute_reply": "2026-02-22T15:47:10.209277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask sanity check: custom causal mask vs default forward...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Max logit diff: 0.000000\n",
      "  PASS: Dict-based mask API verified.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Phase A/B attention masks + sanity check\n",
    "\n",
    "def make_phase_a_mask(n_s, n_d, dtype=torch.bfloat16):\n",
    "    n_prefix = 1 + n_s + n_d\n",
    "    min_val = torch.finfo(dtype).min\n",
    "    mask = torch.triu(torch.full((n_prefix, n_prefix), min_val, dtype=dtype),\n",
    "                      diagonal=1)\n",
    "    return mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def make_phase_b_mask(n_s, n_d, n_q, n_a, dtype=torch.bfloat16):\n",
    "    n_prefix = 1 + n_s + n_d\n",
    "    n_cont = n_q + n_a\n",
    "    min_val = torch.finfo(dtype).min\n",
    "    mask = torch.full((n_cont, n_prefix + n_cont), min_val, dtype=dtype)\n",
    "    mask[:, :n_prefix] = 0.0\n",
    "    if n_s > 0:\n",
    "        mask[:, 1:1 + n_s] = min_val\n",
    "    mask[:, n_prefix:] = torch.triu(\n",
    "        torch.full((n_cont, n_cont), min_val, dtype=dtype), diagonal=1\n",
    "    )\n",
    "    return mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def make_mask_dict(mask_4d):\n",
    "    return {\"full_attention\": mask_4d, \"sliding_attention\": mask_4d}\n",
    "\n",
    "\n",
    "# --- Sanity check ---\n",
    "print(\"Mask sanity check: custom causal mask vs default forward...\")\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "test_ids = tokenizer(test_text, return_tensors=\"pt\",\n",
    "                     add_special_tokens=True).input_ids.to(DEVICE)\n",
    "Lt = test_ids.shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_default = model(input_ids=test_ids)\n",
    "\n",
    "causal_mask = make_phase_a_mask(0, Lt - 1)\n",
    "causal_dict = make_mask_dict(causal_mask.to(DEVICE))\n",
    "causal_pos = torch.arange(Lt, device=DEVICE).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_custom = model(input_ids=test_ids, attention_mask=causal_dict,\n",
    "                       position_ids=causal_pos)\n",
    "\n",
    "max_diff = (out_default.logits - out_custom.logits).abs().max().item()\n",
    "print(f\"  Max logit diff: {max_diff:.6f}\")\n",
    "assert max_diff < 0.1, f\"FAIL: max_diff={max_diff:.4f}\"\n",
    "print(f\"  PASS: Dict-based mask API verified.\")\n",
    "\n",
    "del out_default, out_custom\n",
    "gc.collect(); torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba59f711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:47:10.213657Z",
     "iopub.status.busy": "2026-02-22T15:47:10.213321Z",
     "iopub.status.idle": "2026-02-22T15:47:11.882025Z",
     "shell.execute_reply": "2026-02-22T15:47:11.881280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO v1.1 validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates: 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 500 samples\n",
      "Mean passage words: 74\n",
      "Mean query words: 6\n",
      "Mean answer words: 14\n",
      "\n",
      "--- Per-sample field stats ---\n",
      "  relevant_sent overlap:   mean=0.455\n",
      "  irrelevant_sent overlap: mean=0.035\n",
      "  n_sentences per doc:     mean=4.5\n",
      "  answer_vocab words:      mean=5.3\n",
      "\n",
      "--- Examples ---\n",
      "\n",
      "  Sample 0:\n",
      "    Q: what is the link between alveoli and capillaries\n",
      "    A: Diffusion\n",
      "    relevant_sent: Gas exchange between the air within the alveoli and the pulmonary capi...\n",
      "    irrelevant_sent: Gas exchange in the lungs takes place between the blood in the capilla...\n",
      "    answer_vocab: diffusion\n",
      "    pointer: the answer is about diffusion\n",
      "\n",
      "  Sample 1:\n",
      "    Q: how thick does concrete need to be garden wall\n",
      "    A: For walls up to 3ft, 5.5 inches thick.\n",
      "    relevant_sent: For walls up to 3ft, 5.5 inches thick works fine....\n",
      "    irrelevant_sent: Another consideration is whether a concrete truck can get to the wall ...\n",
      "    answer_vocab: 3ft inches thick walls\n",
      "    pointer: the answer is about 3ft inches thick walls\n",
      "\n",
      "  Sample 2:\n",
      "    Q: average nurse salary singapore\n",
      "    A: S$34,924 per year\n",
      "    relevant_sent: A Registered Nurse (RN) earns an average salary of S$34,924 per year....\n",
      "    irrelevant_sent: Registered Nurse (RN) Salary....\n",
      "    answer_vocab: per s34924 year\n",
      "    pointer: the answer is about per s34924 year\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load MS MARCO + prepare per-sample fields\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "WORD_POOL = [\n",
    "    \"computer\", \"mountain\", \"hospital\", \"children\", \"building\", \"national\",\n",
    "    \"business\", \"research\", \"students\", \"american\", \"possible\", \"economic\",\n",
    "    \"personal\", \"together\", \"products\", \"services\", \"actually\", \"remember\",\n",
    "    \"practice\", \"training\", \"industry\", \"complete\", \"critical\", \"function\",\n",
    "    \"language\", \"standard\", \"material\", \"original\", \"physical\", \"security\",\n",
    "    \"interest\", \"problems\", \"consider\", \"response\", \"pressure\", \"politics\",\n",
    "    \"movement\", \"evidence\", \"southern\", \"northern\", \"exchange\", \"decision\",\n",
    "    \"position\", \"increase\", \"describe\", \"military\", \"required\", \"approach\",\n",
    "    \"strategy\", \"customer\", \"resource\", \"employee\", \"audience\", \"location\",\n",
    "    \"property\", \"cultural\", \"activity\", \"strength\", \"analysis\", \"powerful\",\n",
    "    \"election\", \"argument\", \"campaign\", \"maintain\", \"question\", \"behavior\",\n",
    "    \"majority\", \"solution\", \"software\", \"consumer\", \"creative\", \"reaction\",\n",
    "    \"european\", \"delivery\", \"organize\", \"involved\", \"relative\", \"learning\",\n",
    "    \"positive\", \"numerous\", \"familiar\", \"engineer\", \"platform\", \"indicate\",\n",
    "    \"previous\", \"pleasure\", \"opposite\", \"magazine\", \"document\", \"religion\",\n",
    "    \"scenario\", \"workshop\", \"minority\", \"guidance\", \"estimate\", \"recently\",\n",
    "    \"surprise\", \"champion\", \"pleasant\", \"grateful\", \"moderate\", \"boundary\",\n",
    "]\n",
    "\n",
    "def content_words(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "def jaccard(set_a, set_b):\n",
    "    union = set_a | set_b\n",
    "    return len(set_a & set_b) / len(union) if union else 0.0\n",
    "\n",
    "print(\"Loading MS MARCO v1.1 validation...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 3 * N_SAMPLES:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "print(f\"Total candidates: {len(all_candidates)}\")\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds, all_candidates\n",
    "gc.collect()\n",
    "\n",
    "# --- Prepare per-sample fields ---\n",
    "for i, s in enumerate(samples):\n",
    "    # Random prefix (8 words, same seed as all prior experiments)\n",
    "    rng = np.random.RandomState(SEED + i + 20000)\n",
    "    words = rng.choice(WORD_POOL, size=8, replace=False)\n",
    "    s['random_prefix'] = \" \".join(words)\n",
    "\n",
    "    # Random long prefix (40 words, different seed)\n",
    "    rng_long = np.random.RandomState(SEED + i + 40000)\n",
    "    words_long = rng_long.choice(WORD_POOL, size=40, replace=True)\n",
    "    s['random_long'] = \" \".join(words_long)\n",
    "\n",
    "    # Query-doc overlap\n",
    "    q_words = set(content_words(s['query']))\n",
    "    d_words = set(content_words(s['passage']))\n",
    "    s['query_doc_overlap'] = jaccard(q_words, d_words)\n",
    "\n",
    "    # --- Sentence extraction for relevant_sent / irrelevant_sent ---\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', s['passage'].strip())\n",
    "    sents = [sent.strip() for sent in sents if len(sent.strip().split()) >= 3]\n",
    "    if not sents:\n",
    "        sents = [s['passage']]\n",
    "\n",
    "    a_words = set(content_words(s['answer']))\n",
    "\n",
    "    sent_overlaps = []\n",
    "    for sent in sents:\n",
    "        s_words = set(content_words(sent))\n",
    "        sent_overlaps.append(jaccard(s_words, a_words))\n",
    "\n",
    "    best_idx = max(range(len(sent_overlaps)), key=lambda j: sent_overlaps[j])\n",
    "    worst_idx = min(range(len(sent_overlaps)), key=lambda j: sent_overlaps[j])\n",
    "\n",
    "    s['relevant_sent'] = sents[best_idx]\n",
    "    s['irrelevant_sent'] = sents[worst_idx]\n",
    "    s['relevant_sent_overlap'] = sent_overlaps[best_idx]\n",
    "    s['irrelevant_sent_overlap'] = sent_overlaps[worst_idx]\n",
    "    s['n_sentences'] = len(sents)\n",
    "\n",
    "    # --- Answer vocabulary bridge ---\n",
    "    # Words appearing in BOTH the answer and the document\n",
    "    overlap_words = sorted(a_words & d_words)\n",
    "    if not overlap_words:\n",
    "        # Fall back to top answer content words\n",
    "        overlap_words = content_words(s['answer'])[:5]\n",
    "    s['answer_vocab'] = \" \".join(overlap_words[:10])\n",
    "    s['n_answer_vocab_words'] = len(overlap_words[:10])\n",
    "\n",
    "    # --- Pointer instruction ---\n",
    "    kw = overlap_words[:5] if overlap_words else content_words(s['query'])[:3]\n",
    "    s['pointer'] = \"the answer is about \" + \" \".join(kw)\n",
    "\n",
    "    # --- Oracle + vocabulary ---\n",
    "    s['oracle_plus_vocab'] = s['query'] + \" \" + s['answer_vocab']\n",
    "\n",
    "print(f\"\\nLoaded {len(samples)} samples\")\n",
    "print(f\"Mean passage words: {np.mean([s['word_count'] for s in samples]):.0f}\")\n",
    "print(f\"Mean query words: {np.mean([count_words(s['query']) for s in samples]):.0f}\")\n",
    "print(f\"Mean answer words: {np.mean([count_words(s['answer']) for s in samples]):.0f}\")\n",
    "\n",
    "print(f\"\\n--- Per-sample field stats ---\")\n",
    "print(f\"  relevant_sent overlap:   mean={np.mean([s['relevant_sent_overlap'] for s in samples]):.3f}\")\n",
    "print(f\"  irrelevant_sent overlap: mean={np.mean([s['irrelevant_sent_overlap'] for s in samples]):.3f}\")\n",
    "print(f\"  n_sentences per doc:     mean={np.mean([s['n_sentences'] for s in samples]):.1f}\")\n",
    "print(f\"  answer_vocab words:      mean={np.mean([s['n_answer_vocab_words'] for s in samples]):.1f}\")\n",
    "\n",
    "print(f\"\\n--- Examples ---\")\n",
    "for j in range(3):\n",
    "    print(f\"\\n  Sample {j}:\")\n",
    "    print(f\"    Q: {samples[j]['query'][:70]}\")\n",
    "    print(f\"    A: {samples[j]['answer'][:70]}\")\n",
    "    print(f\"    relevant_sent: {samples[j]['relevant_sent'][:70]}...\")\n",
    "    print(f\"    irrelevant_sent: {samples[j]['irrelevant_sent'][:70]}...\")\n",
    "    print(f\"    answer_vocab: {samples[j]['answer_vocab']}\")\n",
    "    print(f\"    pointer: {samples[j]['pointer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345459f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:47:11.885532Z",
     "iopub.status.busy": "2026-02-22T15:47:11.885067Z",
     "iopub.status.idle": "2026-02-22T15:47:11.899196Z",
     "shell.execute_reply": "2026-02-22T15:47:11.898546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring function defined (two-pass, 11 conditions per sample).\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: score_sample() -- two-pass, all truncate=True, 11 conditions\n",
    "\n",
    "def score_sample(model, tokenizer, sample, device):\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "\n",
    "    bos_id = tokenizer.bos_token_id\n",
    "\n",
    "    doc_ids = tokenizer(passage, add_special_tokens=False, truncation=True,\n",
    "                        max_length=1024).input_ids\n",
    "    query_ids = tokenizer(query, add_special_tokens=False, truncation=True,\n",
    "                          max_length=512).input_ids\n",
    "    answer_ids = tokenizer(answer, add_special_tokens=False, truncation=True,\n",
    "                           max_length=256).input_ids\n",
    "\n",
    "    if len(answer_ids) == 0:\n",
    "        return None\n",
    "\n",
    "    # Tokenize all prime variants\n",
    "    oracle_ids = tokenizer(query, add_special_tokens=False, truncation=True,\n",
    "                           max_length=256).input_ids\n",
    "    random_ids = tokenizer(sample['random_prefix'], add_special_tokens=False).input_ids\n",
    "    random_long_ids = tokenizer(sample['random_long'], add_special_tokens=False).input_ids\n",
    "    relevant_sent_ids = tokenizer(sample['relevant_sent'], add_special_tokens=False,\n",
    "                                  truncation=True, max_length=128).input_ids\n",
    "    irrelevant_sent_ids = tokenizer(sample['irrelevant_sent'], add_special_tokens=False,\n",
    "                                    truncation=True, max_length=128).input_ids\n",
    "    answer_vocab_ids = tokenizer(sample['answer_vocab'], add_special_tokens=False).input_ids\n",
    "    pointer_ids = tokenizer(sample['pointer'], add_special_tokens=False).input_ids\n",
    "    oracle_plus_vocab_ids = tokenizer(sample['oracle_plus_vocab'], add_special_tokens=False,\n",
    "                                      truncation=True, max_length=256).input_ids\n",
    "\n",
    "    prefix_map = {\n",
    "        \"bare\": [],\n",
    "        \"random\": random_ids,\n",
    "        \"oracle\": oracle_ids,\n",
    "        \"oracle_3x\": oracle_ids * 3,\n",
    "        \"oracle_5x\": oracle_ids * 5,\n",
    "        \"random_long\": random_long_ids,\n",
    "        \"relevant_sent\": relevant_sent_ids,\n",
    "        \"irrelevant_sent\": irrelevant_sent_ids,\n",
    "        \"answer_vocab\": answer_vocab_ids,\n",
    "        \"pointer\": pointer_ids,\n",
    "        \"oracle_plus_vocab\": oracle_plus_vocab_ids,\n",
    "    }\n",
    "\n",
    "    n_q = len(query_ids)\n",
    "    n_a = len(answer_ids)\n",
    "    n_d = len(doc_ids)\n",
    "\n",
    "    targets = torch.tensor(answer_ids, dtype=torch.long, device=device)\n",
    "    result = {\n",
    "        'n_doc': n_d,\n",
    "        'n_query': n_q,\n",
    "    }\n",
    "\n",
    "    # Record prime token counts for length analysis\n",
    "    for cname in CONDITIONS:\n",
    "        result[f'n_prime_{cname}'] = len(prefix_map[cname])\n",
    "\n",
    "    for cond_name in CONDITIONS:\n",
    "        surr_ids = prefix_map[cond_name]\n",
    "        n_s = len(surr_ids)\n",
    "        n_prefix = 1 + n_s + n_d\n",
    "\n",
    "        # === Phase A: Cache [BOS, surrogate, doc] ===\n",
    "        prefix_tokens = [bos_id] + surr_ids + doc_ids\n",
    "        prefix_input = torch.tensor([prefix_tokens], dtype=torch.long, device=device)\n",
    "\n",
    "        phase_a_mask = make_phase_a_mask(n_s, n_d)\n",
    "        phase_a_dict = make_mask_dict(phase_a_mask.to(device))\n",
    "        phase_a_pos = torch.arange(n_prefix, device=device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_a = model(input_ids=prefix_input, attention_mask=phase_a_dict,\n",
    "                          position_ids=phase_a_pos, use_cache=True)\n",
    "        past_kv = out_a.past_key_values\n",
    "\n",
    "        # === Phase B: Evaluate [query, answer] ===\n",
    "        cont_tokens = query_ids + answer_ids\n",
    "        n_cont = len(cont_tokens)\n",
    "        cont_input = torch.tensor([cont_tokens], dtype=torch.long, device=device)\n",
    "\n",
    "        phase_b_mask = make_phase_b_mask(n_s, n_d, n_q, n_a)\n",
    "        phase_b_dict = make_mask_dict(phase_b_mask.to(device))\n",
    "        phase_b_pos = torch.arange(n_prefix, n_prefix + n_cont,\n",
    "                                    device=device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_b = model(input_ids=cont_input, attention_mask=phase_b_dict,\n",
    "                          position_ids=phase_b_pos, past_key_values=past_kv)\n",
    "\n",
    "        answer_logits = out_b.logits[0, n_q - 1 : n_q + n_a - 1, :]\n",
    "        log_probs = F.log_softmax(answer_logits, dim=-1)\n",
    "        token_nlls = -log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        result[f'nll_{cond_name}'] = token_nlls.mean().item()\n",
    "\n",
    "        del out_a, out_b, past_kv, prefix_input, cont_input\n",
    "        del phase_a_mask, phase_b_mask, phase_a_dict, phase_b_dict\n",
    "        del answer_logits, log_probs, token_nlls\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print(f\"Scoring function defined (two-pass, {len(CONDITIONS)} conditions per sample).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c01e6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:47:11.902249Z",
     "iopub.status.busy": "2026-02-22T15:47:11.901742Z",
     "iopub.status.idle": "2026-02-22T16:09:42.718316Z",
     "shell.execute_reply": "2026-02-22T16:09:42.717547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MAIN SCORING LOOP\n",
      "======================================================================\n",
      "Starting fresh: 500 samples x 11 conditions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179d64bd908a49cdad1cc9da33205568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 500 samples in 22.5 min\n",
      "\n",
      "Quick summary:\n",
      "  bare                 NLL=2.9572\n",
      "  random               NLL=2.2979\n",
      "  oracle               NLL=1.9678\n",
      "  oracle_3x            NLL=2.0991\n",
      "  oracle_5x            NLL=2.1525\n",
      "  random_long          NLL=2.4107\n",
      "  relevant_sent        NLL=2.7129\n",
      "  irrelevant_sent      NLL=2.5809\n",
      "  answer_vocab         NLL=2.3423\n",
      "  pointer              NLL=2.0587\n",
      "  oracle_plus_vocab    NLL=1.8939\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main scoring loop\n",
    "from lib.data import count_words as _cw\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MAIN SCORING LOOP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "CKPT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "all_results = []\n",
    "start_idx = 0\n",
    "if CKPT_PATH.exists():\n",
    "    ckpt = json.loads(CKPT_PATH.read_text())\n",
    "    if len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            all_results = ckpt['results']\n",
    "            start_idx = len(all_results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {N_SAMPLES} samples x {len(CONDITIONS)} conditions\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Scoring\"):\n",
    "    s = samples[i]\n",
    "    try:\n",
    "        result = score_sample(model, tokenizer, s, DEVICE)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at sample {i}: {e}\")\n",
    "        result = None\n",
    "\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    result['query'] = s['query'][:50]\n",
    "    result['query_doc_overlap'] = s['query_doc_overlap']\n",
    "    result['relevant_sent_overlap'] = s['relevant_sent_overlap']\n",
    "    result['irrelevant_sent_overlap'] = s['irrelevant_sent_overlap']\n",
    "    result['n_answer_vocab_words'] = s['n_answer_vocab_words']\n",
    "    result['answer_wc'] = _cw(s['answer'])\n",
    "    result['query_wc'] = _cw(s['query'])\n",
    "    result['doc_wc'] = s['word_count']\n",
    "    all_results.append(result)\n",
    "\n",
    "    if (i + 1) % 25 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'model': MODEL_NAME,\n",
    "            'n_total': N_SAMPLES,\n",
    "            'n_conditions': len(CONDITIONS),\n",
    "            'condition_names': CONDITIONS,\n",
    "            'results': all_results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CKPT_PATH.write_text(json.dumps(ckpt))\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nDone: {len(all_results)} samples in {elapsed/60:.1f} min\")\n",
    "print(f\"\\nQuick summary:\")\n",
    "for cn in CONDITIONS:\n",
    "    vals = [r[f'nll_{cn}'] for r in all_results]\n",
    "    print(f\"  {cn:<20} NLL={np.mean(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facda576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T16:09:42.722117Z",
     "iopub.status.busy": "2026-02-22T16:09:42.721814Z",
     "iopub.status.idle": "2026-02-22T16:09:42.797101Z",
     "shell.execute_reply": "2026-02-22T16:09:42.796362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESULTS: SEMANTIC AMPLIFICATION & RELEVANCE HINTS\n",
      "======================================================================\n",
      "\n",
      "--- A. Full Ranking (500 samples) ---\n",
      "\n",
      "  Condition              Mean NLL  d vs bare  d vs random    p vs rand   sig\n",
      "  ------------------------------------------------------------------------------\n",
      "  oracle_plus_vocab        1.8939     +0.474       +0.311     1.15e-11   ***\n",
      "  oracle                   1.9678     +0.452       +0.266     4.94e-09   ***\n",
      "  pointer                  2.0587     +0.524       +0.250     3.87e-08   ***\n",
      "  oracle_3x                2.0991     +0.441       +0.197     1.30e-05   ***\n",
      "  oracle_5x                2.1525     +0.436       +0.153     6.61e-04   ***\n",
      "  random                   2.2979     +0.475       +0.000          nan    ns\n",
      "  answer_vocab             2.3423     +0.553       -0.048     2.81e-01    ns\n",
      "  random_long              2.4107     +0.443       -0.190     2.62e-05   ***\n",
      "  irrelevant_sent          2.5809     +0.439       -0.286     3.88e-10   ***\n",
      "  relevant_sent            2.7129     +0.262       -0.416     4.53e-19   ***\n",
      "  bare                     2.9572     +0.000       -0.475     1.00e+00    ns\n",
      "\n",
      "  ANY condition beats random? YES\n",
      "\n",
      "--- B. H2: Repetition Scaling (does more query signal help?) ---\n",
      "\n",
      "  Comparison                                                d    win%            p   sig\n",
      "  ----------------------------------------------------------------------------------\n",
      "  oracle_3x vs oracle (3x repetition helps?)           -0.188   40.6%     2.97e-05   ***\n",
      "  oracle_5x vs oracle (5x repetition helps?)           -0.239   36.2%     1.43e-07   ***\n",
      "  oracle_5x vs oracle_3x (diminishing returns?)        -0.193   36.8%     1.97e-05   ***\n",
      "  random_long vs random (length alone helps?)          -0.190   41.8%     2.62e-05   ***\n",
      "  oracle_5x vs random_long (content at matched length?)   +0.244   57.6%     7.30e-08   ***\n",
      "  oracle_5x vs random (max repetition vs structural?)   +0.153   50.2%     6.61e-04   ***\n",
      "\n",
      "  Prime token counts (mean):\n",
      "    oracle               6.5 tokens\n",
      "    oracle_3x            19.6 tokens\n",
      "    oracle_5x            32.7 tokens\n",
      "    random               8.1 tokens\n",
      "    random_long          40.1 tokens\n",
      "\n",
      "--- C. H3: Relevance Hints (does explicit relevance help?) ---\n",
      "\n",
      "  Comparison                                                d    win%            p   sig\n",
      "  ----------------------------------------------------------------------------------\n",
      "  relevant_sent vs random                              -0.416   23.0%     4.53e-19   ***\n",
      "  irrelevant_sent vs random                            -0.286   36.6%     3.88e-10   ***\n",
      "  relevant_sent vs irrelevant_sent (relevance?)        -0.302   20.8%     3.97e-11   ***\n",
      "  answer_vocab vs random (vocabulary bridge?)          -0.048   57.4%     2.81e-01    ns\n",
      "  pointer vs random (instructed hint?)                 +0.250   69.6%     3.87e-08   ***\n",
      "  oracle_plus_vocab vs random (max semantic?)          +0.311   66.6%     1.15e-11   ***\n",
      "  oracle_plus_vocab vs oracle (vocab adds value?)      +0.089   56.2%     4.61e-02     *\n",
      "\n",
      "--- D. H1: Question Difficulty Stratification ---\n",
      "\n",
      "  Correlation of semantic signal (d_oracle_vs_random) with difficulty proxies:\n",
      "  Proxy                            r            p   sig\n",
      "  -------------------------------------------------------\n",
      "  answer_wc                   -0.215     1.27e-06   ***\n",
      "  query_wc                    +0.043     3.38e-01    ns\n",
      "  query_doc_overlap           -0.014     7.52e-01    ns\n",
      "\n",
      "  Split by answer length:\n",
      "  Group               N   d_oracle   d_random   d_orc-rand            p   sig\n",
      "  ---------------------------------------------------------------------------\n",
      "  Short (<=5w)      210     +0.698     +0.699       +0.423     4.18e-09   ***\n",
      "  Long (>5w)        290     +0.690     +0.816       +0.065     2.70e-01    ns\n",
      "\n",
      "  Split by query-doc overlap (median=0.067):\n",
      "  Group                    N   d_oracle   d_random   d_orc-rand            p   sig\n",
      "  --------------------------------------------------------------------------------\n",
      "  High overlap           259     +0.476     +0.509       +0.245     1.05e-04   ***\n",
      "  Low overlap            241     +0.427     +0.437       +0.288     1.23e-05   ***\n",
      "\n",
      "  All conditions by difficulty stratum (d vs bare):\n",
      "  Condition               Short d     Long d     HiOv d     LoOv d\n",
      "  -----------------------------------------------------------------\n",
      "  oracle_plus_vocab        +0.734     +0.798     +0.495     +0.451\n",
      "  oracle                   +0.698     +0.690     +0.476     +0.427\n",
      "  pointer                  +0.772     +0.931     +0.524     +0.530\n",
      "  oracle_3x                +0.670     +0.682     +0.457     +0.423\n",
      "  oracle_5x                +0.665     +0.656     +0.450     +0.421\n",
      "  random                   +0.699     +0.816     +0.509     +0.437\n",
      "  answer_vocab             +0.773     +0.827     +0.571     +0.536\n",
      "  random_long              +0.632     +0.703     +0.485     +0.397\n",
      "  irrelevant_sent          +0.588     +0.713     +0.443     +0.436\n",
      "  relevant_sent            +0.457     -0.093     +0.267     +0.259\n",
      "  bare                     +0.000     +0.000     +0.000     +0.000\n",
      "\n",
      "--- E. Length-Controlled Analysis ---\n",
      "\n",
      "  Prime length stats (mean tokens):\n",
      "    random                  8.1 +/-   0.2\n",
      "    oracle                  6.5 +/-   2.3\n",
      "    oracle_3x              19.6 +/-   6.9\n",
      "    oracle_5x              32.7 +/-  11.4\n",
      "    random_long            40.1 +/-   0.2\n",
      "    relevant_sent          27.8 +/-  14.8\n",
      "    irrelevant_sent        21.2 +/-  14.7\n",
      "    answer_vocab            7.2 +/-   4.9\n",
      "    pointer                 9.2 +/-   3.3\n",
      "    oracle_plus_vocab      13.9 +/-   5.2\n",
      "\n",
      "  OLS: NLL ~ n_tokens + condition_dummies (pooled, content conds only)\n",
      "    n_tokens: slope=-0.00468, r2=0.0005, p=1.05e-01\n",
      "\n",
      "--- F. Structural Fraction ---\n",
      "\n",
      "  d_oracle=+0.452, d_random=+0.475\n",
      "  Structural fraction: 105%\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS: SEMANTIC AMPLIFICATION & RELEVANCE HINTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "nll = {}\n",
    "for cn in CONDITIONS:\n",
    "    nll[cn] = np.array([r[f'nll_{cn}'] for r in all_results])\n",
    "\n",
    "N = len(all_results)\n",
    "\n",
    "# --- A. Full ranking ---\n",
    "print(f\"\\n--- A. Full Ranking ({N} samples) ---\\n\")\n",
    "print(f\"  {'Condition':<20} {'Mean NLL':>10} {'d vs bare':>10} {'d vs random':>12} {'p vs rand':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*78}\")\n",
    "\n",
    "ranked = sorted(CONDITIONS, key=lambda cn: nll[cn].mean())\n",
    "for cn in ranked:\n",
    "    if cn == \"bare\":\n",
    "        d_base = 0.0\n",
    "        d_rand = cohens_d(nll['random'] - nll[cn])\n",
    "        p_rand = 1.0\n",
    "    else:\n",
    "        diff_base = nll['bare'] - nll[cn]\n",
    "        d_base = cohens_d(diff_base)\n",
    "        diff_rand = nll['random'] - nll[cn]\n",
    "        d_rand = cohens_d(diff_rand)\n",
    "        _, p_rand = stats.ttest_1samp(diff_rand, 0)\n",
    "    sig = '***' if p_rand < 0.001 else '**' if p_rand < 0.01 else '*' if p_rand < 0.05 else 'ns'\n",
    "    print(f\"  {cn:<20} {nll[cn].mean():>10.4f} {d_base:>+10.3f} {d_rand:>+12.3f} {p_rand:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Does ANYTHING beat random?\n",
    "any_beats_random = False\n",
    "for cn in CONDITIONS:\n",
    "    if cn in (\"bare\", \"random\"):\n",
    "        continue\n",
    "    diff = nll['random'] - nll[cn]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    if d > 0 and p < 0.05:\n",
    "        any_beats_random = True\n",
    "        break\n",
    "\n",
    "print(f\"\\n  ANY condition beats random? {'YES' if any_beats_random else 'NO'}\")\n",
    "\n",
    "# --- B. Hypothesis H2: Repetition scaling ---\n",
    "print(f\"\\n--- B. H2: Repetition Scaling (does more query signal help?) ---\\n\")\n",
    "print(f\"  {'Comparison':<50} {'d':>8} {'win%':>7} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*82}\")\n",
    "\n",
    "h2_tests = [\n",
    "    (\"oracle_3x vs oracle (3x repetition helps?)\",\n",
    "     nll['oracle'] - nll['oracle_3x']),\n",
    "    (\"oracle_5x vs oracle (5x repetition helps?)\",\n",
    "     nll['oracle'] - nll['oracle_5x']),\n",
    "    (\"oracle_5x vs oracle_3x (diminishing returns?)\",\n",
    "     nll['oracle_3x'] - nll['oracle_5x']),\n",
    "    (\"random_long vs random (length alone helps?)\",\n",
    "     nll['random'] - nll['random_long']),\n",
    "    (\"oracle_5x vs random_long (content at matched length?)\",\n",
    "     nll['random_long'] - nll['oracle_5x']),\n",
    "    (\"oracle_5x vs random (max repetition vs structural?)\",\n",
    "     nll['random'] - nll['oracle_5x']),\n",
    "]\n",
    "\n",
    "for label, diff in h2_tests:\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    win = (diff > 0).mean() * 100\n",
    "    print(f\"  {label:<50} {d:>+8.3f} {win:>6.1f}% {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Mean token counts\n",
    "print(f\"\\n  Prime token counts (mean):\")\n",
    "for cn in ['oracle', 'oracle_3x', 'oracle_5x', 'random', 'random_long']:\n",
    "    vals = [r[f'n_prime_{cn}'] for r in all_results]\n",
    "    print(f\"    {cn:<20} {np.mean(vals):.1f} tokens\")\n",
    "\n",
    "# --- C. Hypothesis H3: Relevance hints ---\n",
    "print(f\"\\n--- C. H3: Relevance Hints (does explicit relevance help?) ---\\n\")\n",
    "print(f\"  {'Comparison':<50} {'d':>8} {'win%':>7} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*82}\")\n",
    "\n",
    "h3_tests = [\n",
    "    (\"relevant_sent vs random\",\n",
    "     nll['random'] - nll['relevant_sent']),\n",
    "    (\"irrelevant_sent vs random\",\n",
    "     nll['random'] - nll['irrelevant_sent']),\n",
    "    (\"relevant_sent vs irrelevant_sent (relevance?)\",\n",
    "     nll['irrelevant_sent'] - nll['relevant_sent']),\n",
    "    (\"answer_vocab vs random (vocabulary bridge?)\",\n",
    "     nll['random'] - nll['answer_vocab']),\n",
    "    (\"pointer vs random (instructed hint?)\",\n",
    "     nll['random'] - nll['pointer']),\n",
    "    (\"oracle_plus_vocab vs random (max semantic?)\",\n",
    "     nll['random'] - nll['oracle_plus_vocab']),\n",
    "    (\"oracle_plus_vocab vs oracle (vocab adds value?)\",\n",
    "     nll['oracle'] - nll['oracle_plus_vocab']),\n",
    "]\n",
    "\n",
    "for label, diff in h3_tests:\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    win = (diff > 0).mean() * 100\n",
    "    print(f\"  {label:<50} {d:>+8.3f} {win:>6.1f}% {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# --- D. Hypothesis H1: Question difficulty stratification ---\n",
    "print(f\"\\n--- D. H1: Question Difficulty Stratification ---\\n\")\n",
    "\n",
    "answer_wc = np.array([r['answer_wc'] for r in all_results])\n",
    "query_wc = np.array([r['query_wc'] for r in all_results])\n",
    "qd_overlap = np.array([r['query_doc_overlap'] for r in all_results])\n",
    "\n",
    "# Semantic signal = oracle - random (positive means oracle beats random)\n",
    "semantic = nll['random'] - nll['oracle']\n",
    "\n",
    "print(f\"  Correlation of semantic signal (d_oracle_vs_random) with difficulty proxies:\")\n",
    "print(f\"  {'Proxy':<25} {'r':>8} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "for proxy_name, proxy_vals in [(\"answer_wc\", answer_wc),\n",
    "                                (\"query_wc\", query_wc),\n",
    "                                (\"query_doc_overlap\", qd_overlap)]:\n",
    "    r, p = stats.pearsonr(semantic, proxy_vals)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {proxy_name:<25} {r:>+8.3f} {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Split by answer length\n",
    "short = answer_wc <= 5\n",
    "long = answer_wc > 5\n",
    "\n",
    "print(f\"\\n  Split by answer length:\")\n",
    "print(f\"  {'Group':<15} {'N':>5} {'d_oracle':>10} {'d_random':>10} {'d_orc-rand':>12} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*75}\")\n",
    "for label, mask in [(\"Short (<=5w)\", short), (\"Long (>5w)\", long)]:\n",
    "    d_orc = cohens_d((nll['bare'] - nll['oracle'])[mask])\n",
    "    d_rnd = cohens_d((nll['bare'] - nll['random'])[mask])\n",
    "    diff = (nll['random'] - nll['oracle'])[mask]\n",
    "    d_sem = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {label:<15} {mask.sum():>5} {d_orc:>+10.3f} {d_rnd:>+10.3f} {d_sem:>+12.3f} {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Split by query-doc overlap\n",
    "med_ov = np.median(qd_overlap)\n",
    "hi_ov = qd_overlap >= med_ov\n",
    "lo_ov = ~hi_ov\n",
    "\n",
    "print(f\"\\n  Split by query-doc overlap (median={med_ov:.3f}):\")\n",
    "print(f\"  {'Group':<20} {'N':>5} {'d_oracle':>10} {'d_random':>10} {'d_orc-rand':>12} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*80}\")\n",
    "for label, mask in [(\"High overlap\", hi_ov), (\"Low overlap\", lo_ov)]:\n",
    "    d_orc = cohens_d((nll['bare'] - nll['oracle'])[mask])\n",
    "    d_rnd = cohens_d((nll['bare'] - nll['random'])[mask])\n",
    "    diff = (nll['random'] - nll['oracle'])[mask]\n",
    "    d_sem = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {label:<20} {mask.sum():>5} {d_orc:>+10.3f} {d_rnd:>+10.3f} {d_sem:>+12.3f} {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Full condition breakdown by difficulty\n",
    "print(f\"\\n  All conditions by difficulty stratum (d vs bare):\")\n",
    "print(f\"  {'Condition':<20} {'Short d':>10} {'Long d':>10} {'HiOv d':>10} {'LoOv d':>10}\")\n",
    "print(f\"  {'-'*65}\")\n",
    "for cn in ranked:\n",
    "    ds = cohens_d((nll['bare'] - nll[cn])[short])\n",
    "    dl = cohens_d((nll['bare'] - nll[cn])[long])\n",
    "    dh = cohens_d((nll['bare'] - nll[cn])[hi_ov])\n",
    "    dlo = cohens_d((nll['bare'] - nll[cn])[lo_ov])\n",
    "    print(f\"  {cn:<20} {ds:>+10.3f} {dl:>+10.3f} {dh:>+10.3f} {dlo:>+10.3f}\")\n",
    "\n",
    "# --- E. Length-controlled regression ---\n",
    "print(f\"\\n--- E. Length-Controlled Analysis ---\\n\")\n",
    "# For each content condition, compute d vs random AFTER controlling for length\n",
    "# Simple approach: compute d for conditions with similar token counts\n",
    "\n",
    "print(f\"  Prime length stats (mean tokens):\")\n",
    "for cn in CONDITIONS:\n",
    "    if cn == \"bare\":\n",
    "        continue\n",
    "    vals = [r[f'n_prime_{cn}'] for r in all_results]\n",
    "    print(f\"    {cn:<20} {np.mean(vals):>6.1f} +/- {np.std(vals):>5.1f}\")\n",
    "\n",
    "# Regression: NLL on n_prime_tokens for all non-bare conditions\n",
    "# Pool all conditions, regress NLL on (n_tokens, condition_dummies)\n",
    "from itertools import chain\n",
    "print(f\"\\n  OLS: NLL ~ n_tokens + condition_dummies (pooled, content conds only)\")\n",
    "content_conds = [cn for cn in CONDITIONS if cn != \"bare\"]\n",
    "ys, xs_len, xs_dummies = [], [], []\n",
    "for cn in content_conds:\n",
    "    for r in all_results:\n",
    "        ys.append(r[f'nll_{cn}'])\n",
    "        xs_len.append(r[f'n_prime_{cn}'])\n",
    "y = np.array(ys)\n",
    "x_len = np.array(xs_len)\n",
    "\n",
    "# Just test: does n_tokens predict NLL?\n",
    "slope, intercept, r_val, p_val, se = stats.linregress(x_len, y)\n",
    "print(f\"    n_tokens: slope={slope:+.5f}, r2={r_val**2:.4f}, p={p_val:.2e}\")\n",
    "\n",
    "# --- F. Structural fraction ---\n",
    "print(f\"\\n--- F. Structural Fraction ---\\n\")\n",
    "d_oracle = cohens_d(nll['bare'] - nll['oracle'])\n",
    "d_random = cohens_d(nll['bare'] - nll['random'])\n",
    "struct_frac = d_random / d_oracle if d_oracle != 0 else float('nan')\n",
    "print(f\"  d_oracle={d_oracle:+.3f}, d_random={d_random:+.3f}\")\n",
    "print(f\"  Structural fraction: {struct_frac:.0%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4555520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T16:09:42.800727Z",
     "iopub.status.busy": "2026-02-22T16:09:42.800308Z",
     "iopub.status.idle": "2026-02-22T16:09:42.824521Z",
     "shell.execute_reply": "2026-02-22T16:09:42.823813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY -- Prefix LM Exp 04e\n",
      "======================================================================\n",
      "\n",
      "  H2: Prime too short?\n",
      "    oracle_5x vs oracle:      d=-0.239 (p=1.43e-07)\n",
      "    oracle_5x vs random_long: d=+0.244 (p=7.30e-08)\n",
      "    random_long vs random:    d=-0.190 (p=2.62e-05)\n",
      "\n",
      "  H3: Model can't anticipate relevance?\n",
      "    relevant_sent vs random:    d=-0.416 (p=4.53e-19)\n",
      "    answer_vocab vs random:     d=-0.048 (p=2.81e-01)\n",
      "    pointer vs random:          d=+0.250 (p=3.87e-08)\n",
      "    oracle+vocab vs random:     d=+0.311 (p=1.15e-11)\n",
      "\n",
      "  VERDICT:\n",
      "  H2 REJECTED: Repeating query 5x doesn't help (d=-0.239). Not a length issue.\n",
      "  H3 SUPPORTED: pointer beats random (d=+0.250). Relevance helps!\n",
      "  H3 SUPPORTED: oracle+vocab beats random (d=+0.311). Relevance helps!\n",
      "\n",
      "Results saved to ../../../results/prefix_lm_exp04e/results.json\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save results + verdict\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY -- Prefix LM Exp 04e\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "d_struct = cohens_d(nll['bare'] - nll['random'])\n",
    "d_oracle_base = cohens_d(nll['bare'] - nll['oracle'])\n",
    "\n",
    "# Key H2 tests\n",
    "d_5x_vs_1x = cohens_d(nll['oracle'] - nll['oracle_5x'])\n",
    "_, p_5x_vs_1x = stats.ttest_1samp(nll['oracle'] - nll['oracle_5x'], 0)\n",
    "\n",
    "d_5x_vs_randlong = cohens_d(nll['random_long'] - nll['oracle_5x'])\n",
    "_, p_5x_vs_randlong = stats.ttest_1samp(nll['random_long'] - nll['oracle_5x'], 0)\n",
    "\n",
    "d_randlong_vs_rand = cohens_d(nll['random'] - nll['random_long'])\n",
    "_, p_randlong_vs_rand = stats.ttest_1samp(nll['random'] - nll['random_long'], 0)\n",
    "\n",
    "# Key H3 tests\n",
    "d_relsent_vs_rand = cohens_d(nll['random'] - nll['relevant_sent'])\n",
    "_, p_relsent_vs_rand = stats.ttest_1samp(nll['random'] - nll['relevant_sent'], 0)\n",
    "\n",
    "d_vocab_vs_rand = cohens_d(nll['random'] - nll['answer_vocab'])\n",
    "_, p_vocab_vs_rand = stats.ttest_1samp(nll['random'] - nll['answer_vocab'], 0)\n",
    "\n",
    "d_pointer_vs_rand = cohens_d(nll['random'] - nll['pointer'])\n",
    "_, p_pointer_vs_rand = stats.ttest_1samp(nll['random'] - nll['pointer'], 0)\n",
    "\n",
    "d_opv_vs_rand = cohens_d(nll['random'] - nll['oracle_plus_vocab'])\n",
    "_, p_opv_vs_rand = stats.ttest_1samp(nll['random'] - nll['oracle_plus_vocab'], 0)\n",
    "\n",
    "print(f\"\\n  H2: Prime too short?\")\n",
    "print(f\"    oracle_5x vs oracle:      d={d_5x_vs_1x:+.3f} (p={p_5x_vs_1x:.2e})\")\n",
    "print(f\"    oracle_5x vs random_long: d={d_5x_vs_randlong:+.3f} (p={p_5x_vs_randlong:.2e})\")\n",
    "print(f\"    random_long vs random:    d={d_randlong_vs_rand:+.3f} (p={p_randlong_vs_rand:.2e})\")\n",
    "\n",
    "print(f\"\\n  H3: Model can't anticipate relevance?\")\n",
    "print(f\"    relevant_sent vs random:    d={d_relsent_vs_rand:+.3f} (p={p_relsent_vs_rand:.2e})\")\n",
    "print(f\"    answer_vocab vs random:     d={d_vocab_vs_rand:+.3f} (p={p_vocab_vs_rand:.2e})\")\n",
    "print(f\"    pointer vs random:          d={d_pointer_vs_rand:+.3f} (p={p_pointer_vs_rand:.2e})\")\n",
    "print(f\"    oracle+vocab vs random:     d={d_opv_vs_rand:+.3f} (p={p_opv_vs_rand:.2e})\")\n",
    "\n",
    "print(f\"\\n  VERDICT:\")\n",
    "\n",
    "# H2\n",
    "if p_5x_vs_1x < 0.05 and d_5x_vs_1x > 0:\n",
    "    print(f\"  H2 SUPPORTED: Repeating query 5x helps (d={d_5x_vs_1x:+.3f}). Prime was too short.\")\n",
    "    if p_5x_vs_randlong < 0.05 and d_5x_vs_randlong > 0:\n",
    "        print(f\"    AND content matters at matched length (d={d_5x_vs_randlong:+.3f}).\")\n",
    "    else:\n",
    "        print(f\"    BUT oracle_5x ~ random_long -- still just length/structural.\")\n",
    "else:\n",
    "    print(f\"  H2 REJECTED: Repeating query 5x doesn't help (d={d_5x_vs_1x:+.3f}). Not a length issue.\")\n",
    "\n",
    "# H3\n",
    "any_h3_works = False\n",
    "for name, d_val, p_val in [(\"relevant_sent\", d_relsent_vs_rand, p_relsent_vs_rand),\n",
    "                             (\"answer_vocab\", d_vocab_vs_rand, p_vocab_vs_rand),\n",
    "                             (\"pointer\", d_pointer_vs_rand, p_pointer_vs_rand),\n",
    "                             (\"oracle+vocab\", d_opv_vs_rand, p_opv_vs_rand)]:\n",
    "    if p_val < 0.05 and d_val > 0:\n",
    "        any_h3_works = True\n",
    "        print(f\"  H3 SUPPORTED: {name} beats random (d={d_val:+.3f}). Relevance helps!\")\n",
    "\n",
    "if not any_h3_works:\n",
    "    print(f\"  H3 REJECTED: No relevance hint beats random. Model doesn't use content.\")\n",
    "\n",
    "# H4\n",
    "any_beats_random = False\n",
    "for cn in CONDITIONS:\n",
    "    if cn in (\"bare\", \"random\"):\n",
    "        continue\n",
    "    diff = nll['random'] - nll[cn]\n",
    "    d = cohens_d(diff)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    if d > 0 and p < 0.05:\n",
    "        any_beats_random = True\n",
    "        break\n",
    "\n",
    "if not any_beats_random:\n",
    "    print(f\"  H4 CONFIRMED: NOTHING beats random under truncation.\")\n",
    "    print(f\"  The mechanism is purely structural. Content is irrelevant for enrichment.\")\n",
    "    print(f\"  Structural fraction: {struct_frac:.0%}\")\n",
    "\n",
    "# Save\n",
    "summary = {'n_samples': N, 'model': MODEL_NAME}\n",
    "for cn in CONDITIONS:\n",
    "    summary[f'nll_{cn}'] = float(nll[cn].mean())\n",
    "summary['d_structural'] = float(d_struct)\n",
    "summary['d_oracle'] = float(d_oracle_base)\n",
    "summary['structural_fraction'] = float(struct_frac)\n",
    "\n",
    "final_results = {\n",
    "    'experiment': 'prefix_lm_exp04e',\n",
    "    'dataset': 'ms_marco_v1.1',\n",
    "    'model': MODEL_NAME,\n",
    "    'n_samples': N,\n",
    "    'seed': SEED,\n",
    "    'conditions': CONDITIONS,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'summary': summary,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "179d64bd908a49cdad1cc9da33205568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3c9b6e58cece418d987df4d99666143e",
        "IPY_MODEL_1c70e24355474f2cbd219946e60ed12c",
        "IPY_MODEL_394550755a30411a905a9db8533f21a3"
       ],
       "layout": "IPY_MODEL_474db3aa74714a7eb8db28393dd350b7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1a46003cd3e64d12ab8c5d7a5180c011": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c70e24355474f2cbd219946e60ed12c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d85ff3d83753423fb64817179e44e8b9",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a6f654dd95f04c54aab478eeff2d39df",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "20c4f44ad761415da451ede1cc305df0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9553a95c59cc4de08fd5b52fbc0bf2bb",
       "placeholder": "",
       "style": "IPY_MODEL_f3af986937ae4c63af5d3689711c8af7",
       "tabbable": null,
       "tooltip": null,
       "value": "1065/1065[00:07&lt;00:00,646.03it/s,Materializingparam=model.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "394550755a30411a905a9db8533f21a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ffa6be00e94d47f1b95e6758f7df2ae4",
       "placeholder": "",
       "style": "IPY_MODEL_b53ed0081232410ba0cda68471a82ffa",
       "tabbable": null,
       "tooltip": null,
       "value": "500/500[22:30&lt;00:00,2.77s/it]"
      }
     },
     "3a079d0e07284c31b1593f2e9d665f6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c9b6e58cece418d987df4d99666143e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fa71cd054d454fd6bb9ccdb693697585",
       "placeholder": "",
       "style": "IPY_MODEL_d37297732a084c66987958ed523343e4",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring:100%"
      }
     },
     "474db3aa74714a7eb8db28393dd350b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ed42046792749a689f77f1418fbbff9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_615860d1fe3a402fa6992fd2f32ea4e4",
        "IPY_MODEL_5e8b13c0956f47799e6299dfb17cb352",
        "IPY_MODEL_20c4f44ad761415da451ede1cc305df0"
       ],
       "layout": "IPY_MODEL_1a46003cd3e64d12ab8c5d7a5180c011",
       "tabbable": null,
       "tooltip": null
      }
     },
     "53ff9976ce604cd7a6b2c092a41ecaf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5e8b13c0956f47799e6299dfb17cb352": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3a079d0e07284c31b1593f2e9d665f6c",
       "max": 1065.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_53ff9976ce604cd7a6b2c092a41ecaf8",
       "tabbable": null,
       "tooltip": null,
       "value": 1065.0
      }
     },
     "615860d1fe3a402fa6992fd2f32ea4e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75a1d34968be4e1b894dddad7da5e153",
       "placeholder": "",
       "style": "IPY_MODEL_cf44290d2a5f4501872e3a12c6255d49",
       "tabbable": null,
       "tooltip": null,
       "value": "Loadingweights:100%"
      }
     },
     "75a1d34968be4e1b894dddad7da5e153": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9553a95c59cc4de08fd5b52fbc0bf2bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f654dd95f04c54aab478eeff2d39df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b53ed0081232410ba0cda68471a82ffa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cf44290d2a5f4501872e3a12c6255d49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d37297732a084c66987958ed523343e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d85ff3d83753423fb64817179e44e8b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3af986937ae4c63af5d3689711c8af7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fa71cd054d454fd6bb9ccdb693697585": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffa6be00e94d47f1b95e6758f7df2ae4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
