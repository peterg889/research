{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00488412",
   "metadata": {},
   "source": [
    "# Experiment 01: Production-Realistic KV Cache â€” Condition Examples\n",
    "\n",
    "This notebook shows the actual text for each experimental condition using real data from the dataset. No GPU needed.\n",
    "\n",
    "**Key difference from v3**: The decoder now receives the query as a prefix before the answer tokens, modeling a production encoder-decoder system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62022f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from lib.data import count_words\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# ---- Load MS MARCO (same reconstruction as all SEED=42 experiments) ----\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 1500:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:500]]\n",
    "del ds, all_candidates\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "def make_surrogate_template(passage):\n",
    "    content_words = extract_keywords(passage)\n",
    "    if not content_words:\n",
    "        return \"What is this about?\"\n",
    "    counts = Counter(content_words)\n",
    "    top_word = counts.most_common(1)[0][0]\n",
    "    return f\"What is {top_word}?\"\n",
    "\n",
    "def make_surrogate_from_doc(passage):\n",
    "    content_words = extract_keywords(passage)\n",
    "    if not content_words:\n",
    "        return \"information\"\n",
    "    counts = Counter(content_words)\n",
    "    return \" \".join(w for w, _ in counts.most_common(5))\n",
    "\n",
    "# Verify against checkpoint\n",
    "ckpt_path = Path(\"../../../results/exp01/checkpoint.json\")\n",
    "if ckpt_path.exists():\n",
    "    ckpt = json.loads(ckpt_path.read_text())\n",
    "    results = ckpt.get('results', [])\n",
    "    if results and results[0].get('query', '')[:50] == samples[0]['query'][:50]:\n",
    "        print(f\"Checkpoint verification: MATCH\")\n",
    "    elif results:\n",
    "        print(f\"Checkpoint verification: MISMATCH\")\n",
    "else:\n",
    "    print(\"No checkpoint found yet\")\n",
    "\n",
    "print(f\"Loaded {len(samples)} MS MARCO samples (SEED={SEED})\")\n",
    "\n",
    "# ---- Generate surrogates for sample 0 ----\n",
    "ex = samples[0]\n",
    "surr_template = make_surrogate_template(ex['passage'])\n",
    "surr_doc_kw = make_surrogate_from_doc(ex['passage'])\n",
    "other_idx = (0 + 250) % len(samples)\n",
    "other_words = samples[other_idx]['passage'].split()\n",
    "query_word_count = len(ex['query'].split())\n",
    "random_prefix = \" \".join(other_words[:query_word_count])\n",
    "doc_short = ex['passage'][:80]\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Query:      {ex['query']}\")\n",
    "print(f\"  Answer:     {ex['answer']}\")\n",
    "print(f\"  Document:   {doc_short}...\")\n",
    "print(f\"  Doc words:  {ex['word_count']}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"HOW THIS EXPERIMENT WORKS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"  The T5Gemma encoder-decoder has two stages:\")\n",
    "print()\n",
    "print(\"    1. ENCODER: reads text with bidirectional attention (sees everything)\")\n",
    "print(\"    2. DECODER: generates text, cross-attending to encoder output\")\n",
    "print()\n",
    "print(\"  v3 setup (decoder has NO query):\")\n",
    "print(\"    - Decoder input: [BOS] + answer tokens\")\n",
    "print(\"    - Measured how well the model predicts the answer from encoder states alone\")\n",
    "print(\"    - Found d=+0.408 benefit from co-encoding query with document\")\n",
    "print()\n",
    "print(\"  v4 setup (decoder HAS the query -- PRODUCTION REALISTIC):\")\n",
    "print(\"    - Decoder input: [BOS] + query tokens + answer tokens\")\n",
    "print(\"    - NLL computed only on answer token positions\")\n",
    "print(\"    - Models real production: query arrives at inference, decoder sees it\")\n",
    "print()\n",
    "print(\"  KEY QUESTION: Does co-encoding still help when the decoder already\")\n",
    "print(\"  has the query? If not, the v3 benefit was just the decoder reading\")\n",
    "print(\"  the query from encoder output (trivial).\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"CONDITIONS (8 total)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print()\n",
    "print(\"  === WITH QUERY IN DECODER (production-realistic) ===\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 1: bare ---\")\n",
    "print()\n",
    "print(f\"  Encoder input:      [document]\")\n",
    "print(f\"  Decoder cross-attn: all encoder tokens (= document)\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "print(f\"  NLL measured on:    answer tokens only\")\n",
    "print()\n",
    "print(f\"  Baseline. The decoder has the query but encoder only has the document.\")\n",
    "print()\n",
    "print(f\"  Encoder sees: \\\"{doc_short}...\\\"\")\n",
    "print(f\"  Decoder sees: \\\"{ex['query']}\\\" -> \\\"{ex['answer']}\\\"\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 2: oracle_trunc  *** THE KEY CONDITION ***\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{ex['query']}\\\"\")\n",
    "print(f\"  Encoder input:      [query + document]  (full bidirectional attention)\")\n",
    "print(f\"  Decoder cross-attn: document tokens ONLY  (query tokens MASKED)\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "print(f\"  NLL measured on:    answer tokens only\")\n",
    "print()\n",
    "print(f\"  The encoder co-encodes query + document, but the decoder cannot read\")\n",
    "print(f\"  the query from encoder output. If this beats bare, the document\")\n",
    "print(f\"  representations are genuinely improved -- and it still matters even\")\n",
    "print(f\"  though the decoder already knows the query!\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 3: oracle_full ---\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{ex['query']}\\\"\")\n",
    "print(f\"  Encoder input:      [query + document]\")\n",
    "print(f\"  Decoder cross-attn: ALL encoder tokens  (query visible)\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "print()\n",
    "print(f\"  Decoder can read the query from BOTH its own input AND the encoder.\")\n",
    "print(f\"  Comparison with oracle_trunc shows if reading query from encoder adds\")\n",
    "print(f\"  anything beyond having it in the decoder input.\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 4: surr_template_trunc ---\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{surr_template}\\\"  ('What is [top keyword]?')\")\n",
    "print(f\"  Encoder input:      [template + document]\")\n",
    "print(f\"  Decoder cross-attn: document tokens ONLY\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "print()\n",
    "print(f\"  Production-realistic surrogate: cheap to generate offline, no query needed.\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 5: surr_doc_trunc ---\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{surr_doc_kw}\\\"  (top-5 TF keywords from document)\")\n",
    "print(f\"  Encoder input:      [keywords + document]\")\n",
    "print(f\"  Decoder cross-attn: document tokens ONLY\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 6: random_trunc ---\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{random_prefix[:60]}...\\\"\")\n",
    "print(f\"                      ({query_word_count} words from unrelated passage)\")\n",
    "print(f\"  Encoder input:      [random + document]\")\n",
    "print(f\"  Decoder cross-attn: document tokens ONLY\")\n",
    "print(f\"  Decoder input:      [BOS] + query + answer\")\n",
    "print()\n",
    "print(f\"  Structural control: tests if ANY prefix helps via attention redistribution,\")\n",
    "print(f\"  even when the decoder already has the query.\")\n",
    "\n",
    "print()\n",
    "print(\"  === WITHOUT QUERY IN DECODER (v3 replication) ===\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 7: bare_nq ---\")\n",
    "print()\n",
    "print(f\"  Encoder input:      [document]\")\n",
    "print(f\"  Decoder cross-attn: all encoder tokens\")\n",
    "print(f\"  Decoder input:      [BOS] + answer  (NO query)\")\n",
    "print(f\"  NLL measured on:    answer tokens\")\n",
    "print()\n",
    "print(f\"  v3 baseline. Decoder does NOT see the query at all.\")\n",
    "\n",
    "print()\n",
    "print(\"--- CONDITION 8: oracle_trunc_nq ---\")\n",
    "print()\n",
    "print(f\"  Encoder prefix:     \\\"{ex['query']}\\\"\")\n",
    "print(f\"  Encoder input:      [query + document]\")\n",
    "print(f\"  Decoder cross-attn: document tokens ONLY\")\n",
    "print(f\"  Decoder input:      [BOS] + answer  (NO query)\")\n",
    "print()\n",
    "print(f\"  Replicates v3 Exp 01 (expected d~+0.4). Provides the reference:\")\n",
    "print(f\"  how much does enrichment help when the decoder does NOT have the query?\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"  {'#':<3} {'Condition':<25} {'Enc prefix':<22} {'Trunc':>6} {'Dec query':>10}\")\n",
    "print(f\"  {'-'*70}\")\n",
    "print(f\"  {'1':<3} {'bare':<25} {'(none)':<22} {'no':>6} {'yes':>10}\")\n",
    "print(f\"  {'2':<3} {'oracle_trunc':<25} {'real query':<22} {'yes':>6} {'yes':>10}\")\n",
    "print(f\"  {'3':<3} {'oracle_full':<25} {'real query':<22} {'no':>6} {'yes':>10}\")\n",
    "print(f\"  {'4':<3} {'surr_template_trunc':<25} {surr_template:<22} {'yes':>6} {'yes':>10}\")\n",
    "print(f\"  {'5':<3} {'surr_doc_trunc':<25} {surr_doc_kw[:20]:<22} {'yes':>6} {'yes':>10}\")\n",
    "print(f\"  {'6':<3} {'random_trunc':<25} {'(unrelated words)':<22} {'yes':>6} {'yes':>10}\")\n",
    "print(f\"  {'7':<3} {'bare_nq':<25} {'(none)':<22} {'no':>6} {'no':>10}\")\n",
    "print(f\"  {'8':<3} {'oracle_trunc_nq':<25} {'real query':<22} {'yes':>6} {'no':>10}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"WHAT TO LOOK FOR IN RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"  1. oracle_trunc vs bare (both with query in decoder):\")\n",
    "print(\"     THE key question. If d > 0: enrichment helps even in production.\")\n",
    "print()\n",
    "print(\"  2. oracle_trunc_nq vs bare_nq (without query in decoder):\")\n",
    "print(\"     Should replicate v3 Exp 01 (d ~ +0.4). Reference for comparison.\")\n",
    "print()\n",
    "print(\"  3. Ratio: (oracle_trunc vs bare) / (oracle_trunc_nq vs bare_nq):\")\n",
    "print(\"     What fraction of enrichment survives when decoder has the query?\")\n",
    "print(\"     >80%: almost fully preserved. <30%: mostly redundant.\")\n",
    "print()\n",
    "print(\"  4. oracle_full vs oracle_trunc (with query in decoder):\")\n",
    "print(\"     Does full cross-attention add anything beyond enriched doc reps\")\n",
    "print(\"     when the decoder already has the query in its own input?\")\n",
    "print()\n",
    "print(\"  5. surr_doc_trunc vs bare:\")\n",
    "print(\"     Can a cheap doc-keyword surrogate provide production value?\")\n",
    "print()\n",
    "print(\"  6. random_trunc vs bare:\")\n",
    "print(\"     Does structural attention redistribution still help when\")\n",
    "print(\"     the decoder has the query? (In v3 it explained 85% of benefit.)\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
