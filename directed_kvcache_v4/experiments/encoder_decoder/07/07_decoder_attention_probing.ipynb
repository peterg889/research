{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d256461",
   "metadata": {},
   "source": [
    "# Experiment 07: Decoder Attention Probing\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "The v3-to-v4 structural collapse (85% → 35%) occurred when we gave the decoder\n",
    "the query as input. **Hypothesis: the query tokens act as attention buffers in the\n",
    "decoder's self-attention** — the same mechanism that the encoder prefix provides\n",
    "in the encoder's bidirectional attention.\n",
    "\n",
    "In the decoder, `[BOS, query_tokens, answer_tokens]` is processed with causal\n",
    "self-attention + merged cross-attention to encoder representations. The decoder's\n",
    "BOS token likely acts as an attention sink (like the encoder's BOS). The query\n",
    "tokens may absorb attention from answer tokens, redistributing the answer-token\n",
    "self-attention budget — exactly the \"attention buffer\" mechanism we identified\n",
    "in the encoder (v3 Exp 3E).\n",
    "\n",
    "If this is correct:\n",
    "1. The decoder's BOS should be a massive attention sink (like encoder BOS)\n",
    "2. Query tokens should absorb significant attention from answer tokens\n",
    "3. This absorption should come at the expense of answer-answer self-attention\n",
    "4. The encoder prefix's contribution to cross-attention redistribution should\n",
    "   shrink when the decoder already has query buffers (the interaction effect)\n",
    "\n",
    "## Design: 2×2 Factorial\n",
    "\n",
    "| # | Condition | Encoder input | Cross-attn mask | Decoder input |\n",
    "|---|-----------|--------------|-----------------|---------------|\n",
    "| 1 | bare_nq | [document] | all visible | [BOS, answer] |\n",
    "| 2 | bare_q | [document] | all visible | [BOS, query, answer] |\n",
    "| 3 | oracle_trunc_nq | [query + document] | doc only | [BOS, answer] |\n",
    "| 4 | oracle_trunc_q | [query + document] | doc only | [BOS, query, answer] |\n",
    "\n",
    "**Key comparisons:**\n",
    "- **(2) vs (1)**: Decoder query buffer effect (no encoder prefix)\n",
    "- **(4) vs (3)**: Decoder query buffer effect (with encoder prefix)\n",
    "- **(3) vs (1)**: Encoder prefix effect (no decoder query)\n",
    "- **(4) vs (2)**: Encoder prefix effect (with decoder query)\n",
    "- **Interaction**: Does having a decoder query reduce the encoder prefix's effect?\n",
    "\n",
    "## Probes (per decoder layer, per condition)\n",
    "\n",
    "**Self-attention budget** (from `decoder_attentions`):\n",
    "- `self_to_bos`: Answer tokens' attention to decoder BOS\n",
    "- `self_to_query`: Answer tokens' attention to query positions (0 for _nq)\n",
    "- `self_to_answer`: Answer tokens' attention to other answer positions\n",
    "- `self_entropy`: Entropy of answer-token self-attention distribution\n",
    "\n",
    "**Cross-attention budget** (from `cross_attentions`):\n",
    "- `cross_total`: Total cross-attention mass per answer token\n",
    "- `cross_entropy`: Entropy of cross-attention distribution over encoder positions\n",
    "\n",
    "**Budget check**: `self_total + cross_total = 1.0` (merged softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a74cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Setup and model loading (EAGER attention for weight extraction)\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, gc, re\n",
    "import random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 500\n",
    "MODEL_NAME = \"google/t5gemma-2-4b-4b\"\n",
    "\n",
    "RESULTS_DIR = Path(\"../../../results/exp07\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} with attn_implementation='eager'...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", torch_dtype=torch.bfloat16, token=HF_TOKEN,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "BOS_ID = getattr(model.config, 'decoder_start_token_id', None) or tokenizer.bos_token_id\n",
    "\n",
    "# Discover decoder layer count\n",
    "N_DEC_LAYERS = len(model.model.decoder.layers)\n",
    "# Probe 6 representative layers (evenly spaced)\n",
    "PROBE_LAYERS = [0, N_DEC_LAYERS // 6, N_DEC_LAYERS // 3,\n",
    "                N_DEC_LAYERS // 2, 2 * N_DEC_LAYERS // 3, N_DEC_LAYERS - 1]\n",
    "\n",
    "print(f\"Exp 07: Decoder Attention Probing\")\n",
    "print(f\"N: {N_SAMPLES}, Model: {MODEL_NAME}\")\n",
    "print(f\"DEVICE: {DEVICE}, dtype: {next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Decoder layers: {N_DEC_LAYERS}\")\n",
    "print(f\"Probe layers: {PROBE_LAYERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ae121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load MS MARCO data (same pipeline as Exp 01-06)\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading MS MARCO v1.1 validation...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 3 * N_SAMPLES:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "print(f\"Total candidates: {len(all_candidates)}\")\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds, all_candidates\n",
    "gc.collect()\n",
    "\n",
    "# Count prefix tokens for oracle conditions\n",
    "def count_prefix_tokens(prefix_text, document_text):\n",
    "    full_text = prefix_text + \"\\n\" + document_text\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True, truncation=True,\n",
    "                         max_length=2048).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids\n",
    "    return len(full_ids) - len(doc_ids)\n",
    "\n",
    "for s in samples:\n",
    "    s['n_pfx_oracle'] = count_prefix_tokens(s['query'], s['passage'])\n",
    "\n",
    "print(f\"Loaded {len(samples)} samples\")\n",
    "print(f\"Mean passage words: {np.mean([s['word_count'] for s in samples]):.0f}\")\n",
    "print(f\"Mean query words: {np.mean([count_words(s['query']) for s in samples]):.0f}\")\n",
    "print(f\"Mean answer words: {np.mean([count_words(s['answer']) for s in samples]):.0f}\")\n",
    "print(f\"Mean oracle prefix tokens: {np.mean([s['n_pfx_oracle'] for s in samples]):.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94418e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Verify attention output structure and define probing function\n",
    "\n",
    "# Test forward pass to verify shapes\n",
    "print(\"Verifying attention output structure...\")\n",
    "s0 = samples[0]\n",
    "\n",
    "# Encode bare document\n",
    "enc_ids = tokenizer(s0['passage'], return_tensors=\"pt\",\n",
    "                    add_special_tokens=True, truncation=True,\n",
    "                    max_length=2048).input_ids.to(DEVICE)\n",
    "enc_mask = torch.ones(1, enc_ids.shape[1], device=DEVICE, dtype=torch.long)\n",
    "with torch.no_grad():\n",
    "    encoder_outputs = model.get_encoder()(input_ids=enc_ids, attention_mask=enc_mask)\n",
    "\n",
    "# Decoder with query prefix\n",
    "query_ids = tokenizer(s0['query'], add_special_tokens=False, truncation=True,\n",
    "                      max_length=512).input_ids\n",
    "answer_ids = tokenizer(s0['answer'], add_special_tokens=False, truncation=True,\n",
    "                       max_length=256).input_ids\n",
    "dec_ids = [BOS_ID] + query_ids + answer_ids\n",
    "dec_tensor = torch.tensor([dec_ids], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        encoder_outputs=encoder_outputs,\n",
    "        attention_mask=enc_mask,\n",
    "        decoder_input_ids=dec_tensor,\n",
    "        output_attentions=True,\n",
    "    )\n",
    "\n",
    "# Check what we got\n",
    "dec_len = len(dec_ids)\n",
    "enc_len = enc_ids.shape[1]\n",
    "print(f\"  Decoder seq len: {dec_len} (1 BOS + {len(query_ids)} query + {len(answer_ids)} answer)\")\n",
    "print(f\"  Encoder seq len: {enc_len}\")\n",
    "\n",
    "if outputs.decoder_attentions is not None:\n",
    "    print(f\"  decoder_attentions: {len(outputs.decoder_attentions)} layers\")\n",
    "    print(f\"    Shape per layer: {outputs.decoder_attentions[0].shape}\")\n",
    "    # Expected: [1, heads, dec_len, dec_len]\n",
    "else:\n",
    "    print(\"  WARNING: decoder_attentions is None!\")\n",
    "\n",
    "if outputs.cross_attentions is not None:\n",
    "    print(f\"  cross_attentions: {len(outputs.cross_attentions)} layers\")\n",
    "    print(f\"    Shape per layer: {outputs.cross_attentions[0].shape}\")\n",
    "    # Expected: [1, heads, dec_len, enc_len]\n",
    "else:\n",
    "    print(\"  WARNING: cross_attentions is None!\")\n",
    "\n",
    "# Verify merged softmax: self + cross should sum to 1.0\n",
    "sa = outputs.decoder_attentions[0][0].float().mean(dim=0)  # [dec_len, dec_len]\n",
    "ca = outputs.cross_attentions[0][0].float().mean(dim=0)    # [dec_len, enc_len]\n",
    "budget_sum = sa.sum(dim=1) + ca.sum(dim=1)  # [dec_len]\n",
    "print(f\"\\n  Budget check (self + cross per position):\")\n",
    "print(f\"    Min: {budget_sum.min().item():.6f}\")\n",
    "print(f\"    Max: {budget_sum.max().item():.6f}\")\n",
    "print(f\"    Mean: {budget_sum.mean().item():.6f}\")\n",
    "print(f\"    (Should be ~1.0)\")\n",
    "\n",
    "del outputs, encoder_outputs\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# === Probing function ===\n",
    "def forward_with_probes(encoder_outputs, cross_attn_mask, decoder_input_ids,\n",
    "                        answer_start, answer_len, answer_ids_list):\n",
    "    # Forward pass with attention extraction.\n",
    "    # Returns (nll, probes_dict) where probes_dict is keyed by layer index.\n",
    "    dec_len = decoder_input_ids.shape[1]\n",
    "    n_query = answer_start - 1  # 0 for _nq, len(query_ids) for _q\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            attention_mask=cross_attn_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            output_attentions=True,\n",
    "        )\n",
    "\n",
    "    # --- NLL ---\n",
    "    logits = outputs.logits\n",
    "    answer_logits = logits[0, n_query:n_query + answer_len, :]\n",
    "    targets = torch.tensor(answer_ids_list, dtype=torch.long, device=DEVICE)\n",
    "    log_probs = F.log_softmax(answer_logits, dim=-1)\n",
    "    token_log_probs = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "    nll = -token_log_probs.mean().item()\n",
    "\n",
    "    # --- Probes ---\n",
    "    probes = {}\n",
    "    for layer_idx in PROBE_LAYERS:\n",
    "        # Self-attention: [1, heads, dec_len, dec_len]\n",
    "        sa = outputs.decoder_attentions[layer_idx][0].float().mean(dim=0)  # [dec_len, dec_len]\n",
    "        # Cross-attention: [1, heads, dec_len, enc_len]\n",
    "        ca = outputs.cross_attentions[layer_idx][0].float().mean(dim=0)  # [dec_len, enc_len]\n",
    "\n",
    "        # Extract answer-token rows\n",
    "        ans_sa = sa[answer_start:answer_start + answer_len]  # [M, dec_len]\n",
    "        ans_ca = ca[answer_start:answer_start + answer_len]  # [M, enc_len]\n",
    "\n",
    "        # Self-attention budget decomposition for answer tokens\n",
    "        self_to_bos = ans_sa[:, 0].mean().item()\n",
    "\n",
    "        if n_query > 0:\n",
    "            self_to_query = ans_sa[:, 1:1 + n_query].sum(dim=1).mean().item()\n",
    "        else:\n",
    "            self_to_query = 0.0\n",
    "\n",
    "        # Self-attention to answer positions (including self)\n",
    "        # For answer token t at absolute position p=answer_start+t,\n",
    "        # attend to positions answer_start..p (causal)\n",
    "        answer_mask = torch.zeros(answer_len, dec_len, device=DEVICE)\n",
    "        for t in range(answer_len):\n",
    "            p = answer_start + t\n",
    "            answer_mask[t, answer_start:p + 1] = 1.0\n",
    "        self_to_answer = (ans_sa * answer_mask).sum(dim=1).mean().item()\n",
    "\n",
    "        # Totals\n",
    "        self_total = ans_sa.sum(dim=1).mean().item()\n",
    "        cross_total = ans_ca.sum(dim=1).mean().item()\n",
    "\n",
    "        # Self-attention entropy (over causal positions 0..p for each answer token)\n",
    "        eps = 1e-10\n",
    "        # Build per-token causal mask\n",
    "        positions = torch.arange(dec_len, device=DEVICE)\n",
    "        abs_positions = torch.arange(answer_start, answer_start + answer_len, device=DEVICE)\n",
    "        causal = (positions.unsqueeze(0) <= abs_positions.unsqueeze(1)).float()  # [M, dec_len]\n",
    "        masked_sa = ans_sa * causal  # zero out non-causal\n",
    "        sa_clamped = masked_sa.clamp(min=eps)\n",
    "        self_entropy = -(masked_sa * sa_clamped.log()).sum(dim=1).mean().item()\n",
    "\n",
    "        # Cross-attention entropy (over all encoder positions)\n",
    "        ca_clamped = ans_ca.clamp(min=eps)\n",
    "        cross_entropy = -(ans_ca * ca_clamped.log()).sum(dim=1).mean().item()\n",
    "\n",
    "        probes[layer_idx] = {\n",
    "            'sb': round(self_to_bos, 6),\n",
    "            'sq': round(self_to_query, 6),\n",
    "            'sa': round(self_to_answer, 6),\n",
    "            'st': round(self_total, 6),\n",
    "            'ct': round(cross_total, 6),\n",
    "            'se': round(self_entropy, 4),\n",
    "            'ce': round(cross_entropy, 4),\n",
    "        }\n",
    "\n",
    "    del outputs, logits, log_probs\n",
    "    return nll, probes\n",
    "\n",
    "\n",
    "print(\"Probing function defined. Ready for scoring loop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Probing loop — 4 conditions x 500 samples\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBING ALL CONDITIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "COND_NAMES = ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    ckpt = json.loads(CHECKPOINT_PATH.read_text())\n",
    "    if ckpt.get('n_total') == N_SAMPLES and len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            results = ckpt['results']\n",
    "            # JSON converts int dict keys to strings — convert back\n",
    "            for r in results:\n",
    "                for cond in COND_NAMES:\n",
    "                    key = f'probes_{cond}'\n",
    "                    if key in r and isinstance(r[key], dict):\n",
    "                        r[key] = {int(k): v for k, v in r[key].items()}\n",
    "            start_idx = len(results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {len(COND_NAMES)} conditions x {N_SAMPLES} samples\")\n",
    "    print(f\"Probe layers: {PROBE_LAYERS}\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Probing\"):\n",
    "    s = samples[i]\n",
    "    query = s['query']\n",
    "    passage = s['passage']\n",
    "    answer = s['answer']\n",
    "\n",
    "    query_ids = tokenizer(query, add_special_tokens=False, truncation=True,\n",
    "                          max_length=512).input_ids\n",
    "    answer_ids = tokenizer(answer, add_special_tokens=False, truncation=True,\n",
    "                           max_length=256).input_ids\n",
    "\n",
    "    if len(answer_ids) == 0:\n",
    "        continue\n",
    "\n",
    "    result = {\n",
    "        'query': query[:50],\n",
    "        'n_query_toks': len(query_ids),\n",
    "        'n_answer_toks': len(answer_ids),\n",
    "    }\n",
    "\n",
    "    # --- Encoder pass 1: bare document ---\n",
    "    enc_ids_bare = tokenizer(passage, return_tensors=\"pt\",\n",
    "                             add_special_tokens=True, truncation=True,\n",
    "                             max_length=2048).input_ids.to(DEVICE)\n",
    "    enc_len_bare = enc_ids_bare.shape[1]\n",
    "    enc_mask_bare = torch.ones(1, enc_len_bare, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_out_bare = model.get_encoder()(\n",
    "            input_ids=enc_ids_bare, attention_mask=enc_mask_bare\n",
    "        )\n",
    "\n",
    "    # Condition 1: bare_nq — decoder=[BOS, answer]\n",
    "    dec_nq = torch.tensor([[BOS_ID] + answer_ids], dtype=torch.long, device=DEVICE)\n",
    "    nll, probes = forward_with_probes(\n",
    "        enc_out_bare, enc_mask_bare, dec_nq,\n",
    "        answer_start=1, answer_len=len(answer_ids), answer_ids_list=answer_ids)\n",
    "    result['nll_bare_nq'] = nll\n",
    "    result['probes_bare_nq'] = probes\n",
    "\n",
    "    # Condition 2: bare_q — decoder=[BOS, query, answer]\n",
    "    dec_q = torch.tensor([[BOS_ID] + query_ids + answer_ids],\n",
    "                         dtype=torch.long, device=DEVICE)\n",
    "    nll, probes = forward_with_probes(\n",
    "        enc_out_bare, enc_mask_bare, dec_q,\n",
    "        answer_start=1 + len(query_ids), answer_len=len(answer_ids),\n",
    "        answer_ids_list=answer_ids)\n",
    "    result['nll_bare_q'] = nll\n",
    "    result['probes_bare_q'] = probes\n",
    "\n",
    "    del enc_out_bare\n",
    "\n",
    "    # --- Encoder pass 2: oracle (query + document) ---\n",
    "    enc_text_oracle = query + \"\\n\" + passage\n",
    "    enc_ids_oracle = tokenizer(enc_text_oracle, return_tensors=\"pt\",\n",
    "                               add_special_tokens=True, truncation=True,\n",
    "                               max_length=2048).input_ids.to(DEVICE)\n",
    "    enc_len_oracle = enc_ids_oracle.shape[1]\n",
    "    enc_mask_oracle = torch.ones(1, enc_len_oracle, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_out_oracle = model.get_encoder()(\n",
    "            input_ids=enc_ids_oracle, attention_mask=enc_mask_oracle\n",
    "        )\n",
    "\n",
    "    # Cross-attention mask: hide prefix (query + BOS)\n",
    "    pfx_count = s['n_pfx_oracle']\n",
    "    cross_mask_trunc = torch.ones(1, enc_len_oracle, device=DEVICE, dtype=torch.long)\n",
    "    cross_mask_trunc[:, :pfx_count] = 0\n",
    "\n",
    "    # Condition 3: oracle_trunc_nq — decoder=[BOS, answer]\n",
    "    nll, probes = forward_with_probes(\n",
    "        enc_out_oracle, cross_mask_trunc, dec_nq,\n",
    "        answer_start=1, answer_len=len(answer_ids), answer_ids_list=answer_ids)\n",
    "    result['nll_oracle_trunc_nq'] = nll\n",
    "    result['probes_oracle_trunc_nq'] = probes\n",
    "\n",
    "    # Condition 4: oracle_trunc_q — decoder=[BOS, query, answer]\n",
    "    nll, probes = forward_with_probes(\n",
    "        enc_out_oracle, cross_mask_trunc, dec_q,\n",
    "        answer_start=1 + len(query_ids), answer_len=len(answer_ids),\n",
    "        answer_ids_list=answer_ids)\n",
    "    result['nll_oracle_trunc_q'] = nll\n",
    "    result['probes_oracle_trunc_q'] = probes\n",
    "\n",
    "    del enc_out_oracle\n",
    "    results.append(result)\n",
    "\n",
    "    if (i + 1) % 20 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'probe_layers': PROBE_LAYERS,\n",
    "            'results': results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CHECKPOINT_PATH.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = i - start_idx + 1\n",
    "        eta = (N_SAMPLES - i - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {i+1}/{N_SAMPLES} | {elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nProbing complete: {len(results)} samples, \"\n",
    "      f\"{len(COND_NAMES)} conditions in {elapsed/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64839a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: NLL calibration and attention budget overview\n",
    "print(\"=\" * 70)\n",
    "print(\"NLL CALIBRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "nll_bare_nq = np.array([r['nll_bare_nq'] for r in results])\n",
    "nll_bare_q = np.array([r['nll_bare_q'] for r in results])\n",
    "nll_oracle_nq = np.array([r['nll_oracle_trunc_nq'] for r in results])\n",
    "nll_oracle_q = np.array([r['nll_oracle_trunc_q'] for r in results])\n",
    "\n",
    "# Expected from Exp 01: oracle_trunc_q vs bare_q: d~+0.228, oracle_trunc_nq vs bare_nq: d~+0.376\n",
    "print(f\"\\n  {'Condition':<25} {'Mean NLL':>10} {'d vs bare':>10} {'sig':>5}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "for name, nlls, baseline, bl_name in [\n",
    "    ('bare_nq', nll_bare_nq, None, None),\n",
    "    ('oracle_trunc_nq', nll_oracle_nq, nll_bare_nq, 'bare_nq'),\n",
    "    ('bare_q', nll_bare_q, None, None),\n",
    "    ('oracle_trunc_q', nll_oracle_q, nll_bare_q, 'bare_q'),\n",
    "]:\n",
    "    if baseline is None:\n",
    "        print(f\"  {name:<25} {nlls.mean():>10.4f} {'--':>10} {'--':>5}\")\n",
    "    else:\n",
    "        diff = baseline - nlls\n",
    "        d = cohens_d(diff)\n",
    "        _, p = stats.ttest_1samp(diff, 0)\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        print(f\"  {name:<25} {nlls.mean():>10.4f} {d:>+10.3f} {sig:>5}\")\n",
    "\n",
    "# Query-in-decoder effect on bare NLL\n",
    "diff_q = nll_bare_nq - nll_bare_q\n",
    "d_q = cohens_d(diff_q)\n",
    "_, p_q = stats.ttest_1samp(diff_q, 0)\n",
    "print(f\"\\n  Query in decoder effect (bare_nq → bare_q): d={d_q:+.3f} (p={p_q:.2e})\")\n",
    "print(f\"  (Expected: large positive — query helps predict answer)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ATTENTION BUDGET OVERVIEW (last probe layer)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "last_layer = PROBE_LAYERS[-1]\n",
    "print(f\"Layer {last_layer} — mean over {len(results)} samples, averaged over heads and answer tokens\")\n",
    "print(f\"\\n  {'Condition':<25} {'self_bos':>10} {'self_query':>10} {'self_ans':>10} \"\n",
    "      f\"{'self_tot':>10} {'cross_tot':>10} {'check':>8}\")\n",
    "print(f\"  {'-'*83}\")\n",
    "\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    sb = np.mean([r[f'probes_{cond}'][last_layer]['sb'] for r in results])\n",
    "    sq = np.mean([r[f'probes_{cond}'][last_layer]['sq'] for r in results])\n",
    "    sa = np.mean([r[f'probes_{cond}'][last_layer]['sa'] for r in results])\n",
    "    st = np.mean([r[f'probes_{cond}'][last_layer]['st'] for r in results])\n",
    "    ct = np.mean([r[f'probes_{cond}'][last_layer]['ct'] for r in results])\n",
    "    check = st + ct\n",
    "    print(f\"  {cond:<25} {sb:>10.4f} {sq:>10.4f} {sa:>10.4f} \"\n",
    "          f\"{st:>10.4f} {ct:>10.4f} {check:>8.4f}\")\n",
    "\n",
    "print(f\"\\n  Budget check: self_total + cross_total should = 1.0000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Probe A — Decoder BOS sink and query as attention buffer\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE A: DECODER BOS SINK AND QUERY BUFFER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Layer-by-layer trajectory of BOS sink mass\n",
    "print(f\"\\n--- BOS attention sink (answer tokens → decoder BOS) ---\")\n",
    "print(f\"\\n  {'Layer':>6} {'bare_nq':>10} {'bare_q':>10} {'orc_nq':>10} {'orc_q':>10}  \"\n",
    "      f\"{'q effect':>10} {'p':>10}\")\n",
    "print(f\"  {'-'*73}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    vals = {}\n",
    "    for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "        vals[cond] = np.array([r[f'probes_{cond}'][layer]['sb'] for r in results])\n",
    "\n",
    "    # Query buffer effect on BOS: does adding query reduce BOS attention?\n",
    "    diff_bos = vals['bare_nq'] - vals['bare_q']\n",
    "    d_bos = cohens_d(diff_bos)\n",
    "    _, p_bos = stats.ttest_1samp(diff_bos, 0)\n",
    "    sig = '***' if p_bos < 0.001 else '**' if p_bos < 0.01 else '*' if p_bos < 0.05 else 'ns'\n",
    "\n",
    "    print(f\"  {layer:>6} {vals['bare_nq'].mean():>10.4f} {vals['bare_q'].mean():>10.4f} \"\n",
    "          f\"{vals['oracle_trunc_nq'].mean():>10.4f} {vals['oracle_trunc_q'].mean():>10.4f}  \"\n",
    "          f\"{d_bos:>+10.3f} {p_bos:>10.2e} {sig}\")\n",
    "\n",
    "# Query buffer mass: how much attention do answer tokens give to query positions?\n",
    "print(f\"\\n--- Query as attention buffer (answer tokens → query positions) ---\")\n",
    "print(f\"  (Only nonzero for _q conditions)\")\n",
    "print(f\"\\n  {'Layer':>6} {'bare_q':>10} {'orc_q':>10} {'diff':>10}\")\n",
    "print(f\"  {'-'*40}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    sq_bare = np.array([r['probes_bare_q'][layer]['sq'] for r in results])\n",
    "    sq_orc = np.array([r['probes_oracle_trunc_q'][layer]['sq'] for r in results])\n",
    "    print(f\"  {layer:>6} {sq_bare.mean():>10.4f} {sq_orc.mean():>10.4f} \"\n",
    "          f\"{sq_orc.mean() - sq_bare.mean():>+10.4f}\")\n",
    "\n",
    "# Where does the query buffer steal attention FROM?\n",
    "print(f\"\\n--- Where does query attention come from? ---\")\n",
    "print(f\"  Compare bare_nq vs bare_q (no encoder prefix)\")\n",
    "print(f\"\\n  {'Layer':>6} {'BOS change':>12} {'Answer chg':>12} {'Cross chg':>12}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    sb_nq = np.mean([r['probes_bare_nq'][layer]['sb'] for r in results])\n",
    "    sb_q = np.mean([r['probes_bare_q'][layer]['sb'] for r in results])\n",
    "    sa_nq = np.mean([r['probes_bare_nq'][layer]['sa'] for r in results])\n",
    "    sa_q = np.mean([r['probes_bare_q'][layer]['sa'] for r in results])\n",
    "    ct_nq = np.mean([r['probes_bare_nq'][layer]['ct'] for r in results])\n",
    "    ct_q = np.mean([r['probes_bare_q'][layer]['ct'] for r in results])\n",
    "\n",
    "    print(f\"  {layer:>6} {sb_q - sb_nq:>+12.4f} {sa_q - sa_nq:>+12.4f} {ct_q - ct_nq:>+12.4f}\")\n",
    "\n",
    "print(f\"\\n  (Negative = query steals FROM that budget. Positive = that budget grows.)\")\n",
    "print(f\"  Query buffer mass at last layer:\")\n",
    "sq_last = np.mean([r['probes_bare_q'][PROBE_LAYERS[-1]]['sq'] for r in results])\n",
    "print(f\"  = {sq_last:.4f} ({sq_last*100:.1f}% of total attention budget)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37379840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Probe B — Self vs cross allocation and cross-attention redistribution\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE B: SELF VS CROSS ALLOCATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# How does the self/cross split change across conditions?\n",
    "print(f\"\\n--- Cross-attention total mass (answer tokens → encoder) ---\")\n",
    "print(f\"\\n  {'Layer':>6} {'bare_nq':>10} {'bare_q':>10} {'orc_nq':>10} {'orc_q':>10}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    ct = {}\n",
    "    for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "        ct[cond] = np.mean([r[f'probes_{cond}'][layer]['ct'] for r in results])\n",
    "    print(f\"  {layer:>6} {ct['bare_nq']:>10.4f} {ct['bare_q']:>10.4f} \"\n",
    "          f\"{ct['oracle_trunc_nq']:>10.4f} {ct['oracle_trunc_q']:>10.4f}\")\n",
    "\n",
    "# Does encoder prefix change cross-attention mass?\n",
    "print(f\"\\n--- Encoder prefix effect on cross-attention mass ---\")\n",
    "print(f\"  (oracle_trunc vs bare, for each decoder condition)\")\n",
    "print(f\"\\n  {'Layer':>6} {'nq: orc-bare':>14} {'q: orc-bare':>14}\")\n",
    "print(f\"  {'-'*38}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    ct_bare_nq = np.array([r['probes_bare_nq'][layer]['ct'] for r in results])\n",
    "    ct_orc_nq = np.array([r['probes_oracle_trunc_nq'][layer]['ct'] for r in results])\n",
    "    ct_bare_q = np.array([r['probes_bare_q'][layer]['ct'] for r in results])\n",
    "    ct_orc_q = np.array([r['probes_oracle_trunc_q'][layer]['ct'] for r in results])\n",
    "    print(f\"  {layer:>6} {(ct_orc_nq - ct_bare_nq).mean():>+14.4f} \"\n",
    "          f\"{(ct_orc_q - ct_bare_q).mean():>+14.4f}\")\n",
    "\n",
    "print(f\"\\n  (Positive = encoder prefix increases cross-attention mass)\")\n",
    "\n",
    "# Cross-attention entropy\n",
    "print(f\"\\n--- Cross-attention entropy (answer → encoder) ---\")\n",
    "print(f\"\\n  {'Layer':>6} {'bare_nq':>10} {'bare_q':>10} {'orc_nq':>10} {'orc_q':>10}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    ce = {}\n",
    "    for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "        ce[cond] = np.mean([r[f'probes_{cond}'][layer]['ce'] for r in results])\n",
    "    print(f\"  {layer:>6} {ce['bare_nq']:>10.4f} {ce['bare_q']:>10.4f} \"\n",
    "          f\"{ce['oracle_trunc_nq']:>10.4f} {ce['oracle_trunc_q']:>10.4f}\")\n",
    "\n",
    "# Self-attention entropy\n",
    "print(f\"\\n--- Self-attention entropy (answer → self positions) ---\")\n",
    "print(f\"\\n  {'Layer':>6} {'bare_nq':>10} {'bare_q':>10} {'orc_nq':>10} {'orc_q':>10}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for layer in PROBE_LAYERS:\n",
    "    se = {}\n",
    "    for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "        se[cond] = np.mean([r[f'probes_{cond}'][layer]['se'] for r in results])\n",
    "    print(f\"  {layer:>6} {se['bare_nq']:>10.4f} {se['bare_q']:>10.4f} \"\n",
    "          f\"{se['oracle_trunc_nq']:>10.4f} {se['oracle_trunc_q']:>10.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fa7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: The 2x2 interaction test — does decoder query reduce encoder prefix effect?\n",
    "print(\"=\" * 70)\n",
    "print(\"THE 2x2 INTERACTION TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# For each probe metric at the last layer, compute the 2x2 decomposition\n",
    "last_layer = PROBE_LAYERS[-1]\n",
    "\n",
    "print(f\"\\nLayer {last_layer} — 2x2 factorial decomposition\")\n",
    "print(f\"  Factors: Encoder prefix (bare vs oracle_trunc) x Decoder query (nq vs q)\")\n",
    "\n",
    "# NLL interaction\n",
    "print(f\"\\n--- NLL ---\")\n",
    "nll = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    nll[cond] = np.array([r[f'nll_{cond}'] for r in results])\n",
    "\n",
    "enc_effect_nq = nll['bare_nq'] - nll['oracle_trunc_nq']  # positive = prefix helps\n",
    "enc_effect_q = nll['bare_q'] - nll['oracle_trunc_q']\n",
    "dec_effect_bare = nll['bare_nq'] - nll['bare_q']  # positive = query helps\n",
    "dec_effect_oracle = nll['oracle_trunc_nq'] - nll['oracle_trunc_q']\n",
    "\n",
    "d_enc_nq = cohens_d(enc_effect_nq)\n",
    "d_enc_q = cohens_d(enc_effect_q)\n",
    "d_dec_bare = cohens_d(dec_effect_bare)\n",
    "d_dec_oracle = cohens_d(dec_effect_oracle)\n",
    "\n",
    "print(f\"\\n  {'':>24} {'No query':>12} {'With query':>12} {'Difference':>12}\")\n",
    "print(f\"  {'Bare encoder':<24} {nll['bare_nq'].mean():>12.4f} {nll['bare_q'].mean():>12.4f} \"\n",
    "      f\"{dec_effect_bare.mean():>+12.4f}\")\n",
    "print(f\"  {'Oracle encoder':<24} {nll['oracle_trunc_nq'].mean():>12.4f} {nll['oracle_trunc_q'].mean():>12.4f} \"\n",
    "      f\"{dec_effect_oracle.mean():>+12.4f}\")\n",
    "print(f\"  {'Enc prefix effect':<24} {enc_effect_nq.mean():>+12.4f} {enc_effect_q.mean():>+12.4f}\")\n",
    "\n",
    "print(f\"\\n  Encoder prefix effect:\")\n",
    "print(f\"    Without decoder query: d={d_enc_nq:+.3f}\")\n",
    "print(f\"    With decoder query:    d={d_enc_q:+.3f}\")\n",
    "print(f\"    Reduction: {(1 - d_enc_q/d_enc_nq)*100:.0f}% (from {d_enc_nq:.3f} to {d_enc_q:.3f})\")\n",
    "\n",
    "print(f\"\\n  Decoder query effect:\")\n",
    "print(f\"    Without encoder prefix: d={d_dec_bare:+.3f}\")\n",
    "print(f\"    With encoder prefix:    d={d_dec_oracle:+.3f}\")\n",
    "\n",
    "# Interaction test\n",
    "interaction = enc_effect_nq - enc_effect_q  # positive = query reduces prefix benefit\n",
    "d_interaction = cohens_d(interaction)\n",
    "_, p_interaction = stats.ttest_1samp(interaction, 0)\n",
    "sig_int = '***' if p_interaction < 0.001 else '**' if p_interaction < 0.01 else '*' if p_interaction < 0.05 else 'ns'\n",
    "print(f\"\\n  NLL INTERACTION (enc_prefix_benefit_nq - enc_prefix_benefit_q):\")\n",
    "print(f\"    d={d_interaction:+.3f} ({sig_int})\")\n",
    "print(f\"    Positive = decoder query makes encoder prefix benefit SMALLER\")\n",
    "\n",
    "# Attention budget interaction\n",
    "print(f\"\\n--- Cross-attention mass: 2x2 ---\")\n",
    "ct = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    ct[cond] = np.array([r[f'probes_{cond}'][last_layer]['ct'] for r in results])\n",
    "\n",
    "enc_ct_nq = ct['oracle_trunc_nq'] - ct['bare_nq']\n",
    "enc_ct_q = ct['oracle_trunc_q'] - ct['bare_q']\n",
    "dec_ct_bare = ct['bare_q'] - ct['bare_nq']\n",
    "dec_ct_oracle = ct['oracle_trunc_q'] - ct['oracle_trunc_nq']\n",
    "ct_interaction = enc_ct_nq - enc_ct_q\n",
    "\n",
    "print(f\"\\n  {'':>24} {'No query':>12} {'With query':>12}\")\n",
    "print(f\"  {'Bare encoder':<24} {ct['bare_nq'].mean():>12.4f} {ct['bare_q'].mean():>12.4f}\")\n",
    "print(f\"  {'Oracle encoder':<24} {ct['oracle_trunc_nq'].mean():>12.4f} {ct['oracle_trunc_q'].mean():>12.4f}\")\n",
    "print(f\"\\n  Encoder prefix changes cross-attn mass:\")\n",
    "print(f\"    Without query: {enc_ct_nq.mean():>+.4f}\")\n",
    "print(f\"    With query:    {enc_ct_q.mean():>+.4f}\")\n",
    "print(f\"  Interaction: {ct_interaction.mean():>+.4f}\")\n",
    "_, p_ct_int = stats.ttest_1samp(ct_interaction, 0)\n",
    "sig_ct = '***' if p_ct_int < 0.001 else '**' if p_ct_int < 0.01 else '*' if p_ct_int < 0.05 else 'ns'\n",
    "print(f\"    ({sig_ct}, p={p_ct_int:.2e})\")\n",
    "\n",
    "# Self-attention entropy interaction\n",
    "print(f\"\\n--- Self-attention entropy: 2x2 ---\")\n",
    "se = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    se[cond] = np.array([r[f'probes_{cond}'][last_layer]['se'] for r in results])\n",
    "\n",
    "enc_se_nq = se['oracle_trunc_nq'] - se['bare_nq']\n",
    "enc_se_q = se['oracle_trunc_q'] - se['bare_q']\n",
    "dec_se_bare = se['bare_q'] - se['bare_nq']\n",
    "se_interaction = enc_se_nq - enc_se_q\n",
    "\n",
    "print(f\"  Encoder prefix changes self-attn entropy:\")\n",
    "print(f\"    Without query: {enc_se_nq.mean():>+.4f}\")\n",
    "print(f\"    With query:    {enc_se_q.mean():>+.4f}\")\n",
    "print(f\"  Decoder query changes self-attn entropy:\")\n",
    "print(f\"    Without prefix: {dec_se_bare.mean():>+.4f}\")\n",
    "print(f\"  Interaction: {se_interaction.mean():>+.4f}\")\n",
    "_, p_se_int = stats.ttest_1samp(se_interaction, 0)\n",
    "sig_se = '***' if p_se_int < 0.001 else '**' if p_se_int < 0.01 else '*' if p_se_int < 0.05 else 'ns'\n",
    "print(f\"    ({sig_se}, p={p_se_int:.2e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22de6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Summary and save\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY — Exp 07: Decoder Attention Probing\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "last_layer = PROBE_LAYERS[-1]\n",
    "\n",
    "# Gather key metrics\n",
    "nll = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    nll[cond] = np.array([r[f'nll_{cond}'] for r in results])\n",
    "\n",
    "d_enc_nq = cohens_d(nll['bare_nq'] - nll['oracle_trunc_nq'])\n",
    "d_enc_q = cohens_d(nll['bare_q'] - nll['oracle_trunc_q'])\n",
    "d_dec_bare = cohens_d(nll['bare_nq'] - nll['bare_q'])\n",
    "d_dec_oracle = cohens_d(nll['oracle_trunc_nq'] - nll['oracle_trunc_q'])\n",
    "\n",
    "interaction = (nll['bare_nq'] - nll['oracle_trunc_nq']) - (nll['bare_q'] - nll['oracle_trunc_q'])\n",
    "d_interaction = cohens_d(interaction)\n",
    "_, p_interaction = stats.ttest_1samp(interaction, 0)\n",
    "\n",
    "# Query buffer mass at last layer\n",
    "sq_bare = np.mean([r['probes_bare_q'][last_layer]['sq'] for r in results])\n",
    "sq_oracle = np.mean([r['probes_oracle_trunc_q'][last_layer]['sq'] for r in results])\n",
    "\n",
    "# Cross-attention totals at last layer\n",
    "ct = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    ct[cond] = np.mean([r[f'probes_{cond}'][last_layer]['ct'] for r in results])\n",
    "\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"N: {len(results)}, Decoder layers: {N_DEC_LAYERS}\")\n",
    "print(f\"Probe layers: {PROBE_LAYERS}\")\n",
    "\n",
    "print(f\"\\n--- NLL 2x2 ---\")\n",
    "print(f\"  Encoder prefix effect without query: d={d_enc_nq:+.3f}\")\n",
    "print(f\"  Encoder prefix effect WITH query:    d={d_enc_q:+.3f}\")\n",
    "print(f\"  Decoder query effect without prefix: d={d_dec_bare:+.3f}\")\n",
    "print(f\"  Decoder query effect WITH prefix:    d={d_dec_oracle:+.3f}\")\n",
    "sig_int = '***' if p_interaction < 0.001 else 'ns'\n",
    "print(f\"  Interaction: d={d_interaction:+.3f} ({sig_int})\")\n",
    "\n",
    "print(f\"\\n--- Decoder query as attention buffer (layer {last_layer}) ---\")\n",
    "print(f\"  Query buffer absorbs {sq_bare*100:.1f}% of answer-token attention (bare encoder)\")\n",
    "print(f\"  Query buffer absorbs {sq_oracle*100:.1f}% of answer-token attention (oracle encoder)\")\n",
    "\n",
    "print(f\"\\n--- Cross-attention budget (layer {last_layer}) ---\")\n",
    "print(f\"  bare_nq:         {ct['bare_nq']*100:.1f}%\")\n",
    "print(f\"  bare_q:          {ct['bare_q']*100:.1f}%\")\n",
    "print(f\"  oracle_trunc_nq: {ct['oracle_trunc_nq']*100:.1f}%\")\n",
    "print(f\"  oracle_trunc_q:  {ct['oracle_trunc_q']*100:.1f}%\")\n",
    "\n",
    "# Hypothesis verdict\n",
    "print(f\"\\n--- Hypothesis verdict ---\")\n",
    "if sq_bare > 0.05:\n",
    "    print(f\"  CONFIRMED: Query tokens absorb {sq_bare*100:.1f}% of answer attention budget.\")\n",
    "    print(f\"  This is the decoder-side attention buffer mechanism.\")\n",
    "else:\n",
    "    print(f\"  NOT CONFIRMED: Query tokens absorb only {sq_bare*100:.1f}% of attention.\")\n",
    "\n",
    "if d_interaction > 0.05 and p_interaction < 0.05:\n",
    "    redundancy = (1 - d_enc_q / d_enc_nq) * 100 if d_enc_nq > 0 else 0\n",
    "    print(f\"  Encoder prefix benefit reduced by {redundancy:.0f}% when decoder has query.\")\n",
    "    print(f\"  The two buffer mechanisms are PARTIALLY REDUNDANT.\")\n",
    "elif d_interaction < -0.05:\n",
    "    print(f\"  Encoder prefix benefit INCREASES when decoder has query.\")\n",
    "    print(f\"  The mechanisms are SYNERGISTIC, not redundant.\")\n",
    "else:\n",
    "    print(f\"  No significant interaction. The mechanisms appear INDEPENDENT.\")\n",
    "\n",
    "# Save results\n",
    "# Aggregate probe data per (condition, layer, metric)\n",
    "probe_summary = {}\n",
    "for cond in ['bare_nq', 'bare_q', 'oracle_trunc_nq', 'oracle_trunc_q']:\n",
    "    probe_summary[cond] = {}\n",
    "    for layer in PROBE_LAYERS:\n",
    "        layer_data = {}\n",
    "        for metric in ['sb', 'sq', 'sa', 'st', 'ct', 'se', 'ce']:\n",
    "            vals = [r[f'probes_{cond}'][layer][metric] for r in results]\n",
    "            layer_data[metric] = {\n",
    "                'mean': float(np.mean(vals)),\n",
    "                'std': float(np.std(vals)),\n",
    "            }\n",
    "        probe_summary[cond][str(layer)] = layer_data\n",
    "\n",
    "final_results = {\n",
    "    'experiment': 'v4_exp07_decoder_attention_probing',\n",
    "    'model': MODEL_NAME,\n",
    "    'dataset': 'ms_marco_v1.1',\n",
    "    'n_samples': len(results),\n",
    "    'seed': SEED,\n",
    "    'n_decoder_layers': N_DEC_LAYERS,\n",
    "    'probe_layers': PROBE_LAYERS,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'nll': {\n",
    "        'bare_nq': float(nll['bare_nq'].mean()),\n",
    "        'bare_q': float(nll['bare_q'].mean()),\n",
    "        'oracle_trunc_nq': float(nll['oracle_trunc_nq'].mean()),\n",
    "        'oracle_trunc_q': float(nll['oracle_trunc_q'].mean()),\n",
    "    },\n",
    "    'nll_effects': {\n",
    "        'd_enc_nq': float(d_enc_nq),\n",
    "        'd_enc_q': float(d_enc_q),\n",
    "        'd_dec_bare': float(d_dec_bare),\n",
    "        'd_dec_oracle': float(d_dec_oracle),\n",
    "        'd_interaction': float(d_interaction),\n",
    "        'p_interaction': float(p_interaction),\n",
    "    },\n",
    "    'query_buffer_mass': {\n",
    "        'bare_q': float(sq_bare),\n",
    "        'oracle_q': float(sq_oracle),\n",
    "    },\n",
    "    'probe_summary': probe_summary,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\nCleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, processor, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
