{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe92e9d",
   "metadata": {},
   "source": [
    "# Experiment 04b: ESCI Ranking â€” Condition Examples\n",
    "\n",
    "This notebook shows the actual text for each experimental condition using real data from the dataset. No GPU needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "SEED = 42\n",
    "N_QUERIES = 400\n",
    "\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"tasksource/esci\", split=\"train\")\n",
    "\n",
    "# Reconstruct ESCI samples\n",
    "queries = {}\n",
    "for row in ds:\n",
    "    q = row.get('query', '')\n",
    "    label = row.get('esci_label', '')\n",
    "    product_title = row.get('product_title', '')\n",
    "    product_desc = row.get('product_description', '')\n",
    "    if not q or not product_title:\n",
    "        continue\n",
    "    text = product_title\n",
    "    if product_desc and len(product_desc) > 20:\n",
    "        text = product_title + \" \" + product_desc\n",
    "    if len(text.split()) < 10:\n",
    "        continue\n",
    "    if q not in queries:\n",
    "        queries[q] = {'products': [], 'labels': []}\n",
    "    queries[q]['products'].append(text)\n",
    "    queries[q]['labels'].append(label)\n",
    "\n",
    "# Filter: need at least 1 exact + 1 irrelevant\n",
    "usable = []\n",
    "for q, data in queries.items():\n",
    "    has_exact = 'E' in data['labels'] or 'Exact' in data['labels']\n",
    "    has_irrel = 'I' in data['labels'] or 'Irrelevant' in data['labels']\n",
    "    if has_exact and has_irrel and len(data['products']) >= 3:\n",
    "        usable.append({'query': q, **data})\n",
    "\n",
    "if not usable:\n",
    "    # Debug: show what labels look like\n",
    "    all_labels = set()\n",
    "    for data in queries.values():\n",
    "        all_labels.update(data['labels'])\n",
    "    print(f\"WARNING: No usable queries found! Unique labels in dataset: {all_labels}\")\n",
    "    print(f\"Total queries collected: {len(queries)}\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(usable)\n",
    "usable = usable[:N_QUERIES]\n",
    "\n",
    "print(f\"Loaded {len(usable)} ESCI queries with products\")\n",
    "del ds\n",
    "\n",
    "ex = usable[0]\n",
    "exact_idx = ex['labels'].index('Exact') if 'Exact' in ex['labels'] else ex['labels'].index('E')\n",
    "irrel_idx = ex['labels'].index('Irrelevant') if 'Irrelevant' in ex['labels'] else ex['labels'].index('I')\n",
    "rel_product = ex['products'][exact_idx]\n",
    "irrel_product = ex['products'][irrel_idx]\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "import re\n",
    "def extract_keywords(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "from collections import Counter\n",
    "def make_surrogate_from_doc(passage):\n",
    "    content_words = extract_keywords(passage)\n",
    "    if not content_words:\n",
    "        return \"information\"\n",
    "    counts = Counter(content_words)\n",
    "    return \" \".join(w for w, _ in counts.most_common(5))\n",
    "def make_surrogate_template(passage):\n",
    "    content_words = extract_keywords(passage)\n",
    "    if not content_words:\n",
    "        return \"What is this about?\"\n",
    "    counts = Counter(content_words)\n",
    "    return f\"What is {counts.most_common(1)[0][0]}?\"\n",
    "\n",
    "# Product title as surrogate (natural for ad-serving)\n",
    "title = rel_product.split()[0:8]  # approximate title\n",
    "surr_title = \" \".join(title)\n",
    "\n",
    "print(f\"Query: {ex['query']}\")\n",
    "print(f\"Relevant product (E): {rel_product[:120]}...\")\n",
    "print(f\"Irrelevant product (I): {irrel_product[:120]}...\")\n",
    "print()\n",
    "\n",
    "print(\"QUERY-LIKELIHOOD RANKING on graded-relevance product search.\")\n",
    "print(\"  Decoder scores the QUERY (not an answer) given encoded product.\")\n",
    "print()\n",
    "\n",
    "\n",
    "def show_sample(s, doc_key='passage', n=0):\n",
    "    # Show sample info\n",
    "    doc = s[doc_key]\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"SAMPLE {n}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Query:    {s['query']}\")\n",
    "    print(f\"  Answer:   {s['answer']}\")\n",
    "    print(f\"  Document: {doc[:100]}...\")\n",
    "    print(f\"  Doc words: {len(doc.split())}\")\n",
    "    print()\n",
    "\n",
    "def show_conditions(conditions, doc_text):\n",
    "    # conditions: list of (name, description, encoder_prefix_text_or_None)\n",
    "    # For bare conditions, encoder_prefix_text is None\n",
    "    print(f\"{'Condition':<30} {'Prefix':<14} {'Encoder input (first 70 chars)'}\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    for name, desc, prefix_text in conditions:\n",
    "        if prefix_text is None:\n",
    "            enc_preview = doc_text[:70]\n",
    "            print(f\"{name:<30} {'(none)':<14} {enc_preview}...\")\n",
    "        else:\n",
    "            enc_text = prefix_text + \"\\n\" + doc_text\n",
    "            print(f\"{name:<30} {str(len(prefix_text.split()))+'w':<14} {enc_text[:70]}...\")\n",
    "        if desc:\n",
    "            print(f\"  {'':>28} ^ {desc}\")\n",
    "    print()\n",
    "\n",
    "conditions = [\n",
    "    (\"bare\", \"Product text only\", None),\n",
    "    (\"oracle_trunc\", \"Real search query\", ex['query']),\n",
    "    (\"surr_title_trunc\", \"Product title (natural surrogate)\", surr_title),\n",
    "    (\"surr_doc_trunc\", \"Top-5 TF keywords from product\", make_surrogate_from_doc(rel_product)),\n",
    "    (\"surr_template_trunc\", \"'What is [kw]?'\", make_surrogate_template(rel_product)),\n",
    "    (\"random_trunc\", \"~20w from another query's product\",\n",
    "     \" \".join(usable[1]['products'][0].split()[:20])),\n",
    "]\n",
    "print(\"For the RELEVANT product:\")\n",
    "show_conditions(conditions, rel_product)\n",
    "\n",
    "print(\"KEY DIFFERENCE from Exp 04A: decoder scores the query, not a gold answer.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
