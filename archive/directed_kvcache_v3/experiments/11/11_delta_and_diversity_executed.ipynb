{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec057599",
   "metadata": {},
   "source": [
    "# Experiment 11: Delta-as-Feature and Prefix Diversity for Ranking## Can we extract better ranking signals from the structural mechanism?### ContextExp 04A found a paradox: **structural surrogates improve ranking but oracle doesn't**.- bare AUC = 0.845- oracle\\_trunc AUC = 0.853 (ns, d=-0.007 differential)- surr\\_doc\\_trunc AUC = 0.867 (\\*\\*, d=+0.053 differential)- static\\_fact\\_trunc AUC = 0.860 (\\*\\*, d=+0.153 differential)- random\\_trunc AUC = 0.866 (\\*\\*, d=+0.117 differential)The structural surrogates create **differential signal**: they help relevant passagesMORE than irrelevant ones. This experiment explores two ways to exploit this:### Phase A: Delta-as-Feature (from existing 04A data, no GPU needed)For each passage, define: `delta = NLL_bare - NLL_primed` (positive = priming helped).Since delta is larger for relevant passages (positive differential from 04A):1. Rank by delta alone -- does higher delta = more relevant?2. Linear combination: `score = (1-lambda)*NLL_bare + lambda*NLL_primed` -- optimal weighting3. Ensemble: average NLL across multiple primed conditions### Phase B: Prefix Diversity (new GPU scoring, ~4.4 hours)Score each passage with K=10 DIFFERENT random prefixes (all with truncation).Compute per-passage NLL mean and std across prefixes.**Hypothesis**: Relevant passages respond more consistently to structural perturbation(lower NLL variance), while irrelevant passages show more erratic responses.### N=400 queries (same as Exp 04A), K=10 random prefixes, Bonferroni=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6c608a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:11.502666Z",
     "iopub.status.busy": "2026-02-19T13:00:11.502370Z",
     "iopub.status.idle": "2026-02-19T13:00:14.995958Z",
     "shell.execute_reply": "2026-02-19T13:00:14.994996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 11: Delta-as-Feature and Prefix Diversity for Ranking\n",
      "N queries: 400\n",
      "K random prefixes: 10\n",
      "Bonferroni comparisons: 8\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon, pearsonr, spearmanr\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"../../results/exp11\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_SAMPLES = 400\n",
    "MODEL_NAME = \"google/t5gemma-2-4b-4b\"\n",
    "K_PREFIXES = 10\n",
    "N_BONFERRONI = 8\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "print(f\"Exp 11: Delta-as-Feature and Prefix Diversity for Ranking\")\n",
    "print(f\"N queries: {N_SAMPLES}\")\n",
    "print(f\"K random prefixes: {K_PREFIXES}\")\n",
    "print(f\"Bonferroni comparisons: {N_BONFERRONI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b201734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:15.000181Z",
     "iopub.status.busy": "2026-02-19T13:00:14.999432Z",
     "iopub.status.idle": "2026-02-19T13:00:15.051360Z",
     "shell.execute_reply": "2026-02-19T13:00:15.050479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING EXP 04A DATA\n",
      "======================================================================\n",
      "Loaded 400 queries from Exp 04A\n",
      "\n",
      "Computing delta features for 5 conditions...\n",
      "Bare AUC reference: 0.845\n",
      "\n",
      "--- Delta vs bare NLL correlation ---\n",
      "  oracle_trunc          : Spearman rho=+0.565 (p=5.96e-277)\n",
      "  surr_template_trunc   : Spearman rho=+0.426 (p=2.89e-145)\n",
      "  surr_doc_trunc        : Spearman rho=+0.502 (p=4.48e-210)\n",
      "  random_trunc          : Spearman rho=+0.419 (p=1.80e-140)\n",
      "  static_fact_trunc     : Spearman rho=+0.358 (p=3.13e-100)\n",
      "\n",
      "--- Mean delta by relevance ---\n",
      "  Condition               delta_rel  delta_irrel     diff\n",
      "  oracle_trunc              +0.5719      +0.5708  +0.0011\n",
      "  surr_template_trunc       +0.4893      +0.3668  +0.1225\n",
      "  surr_doc_trunc            +0.4965      +0.4406  +0.0558\n",
      "  random_trunc              +0.4692      +0.3615  +0.1077\n",
      "  static_fact_trunc         +0.3823      +0.2546  +0.1276\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Exp 04A checkpoint and compute delta features\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING EXP 04A DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "EXP04A_CKPT = Path(\"../../results/exp04a/checkpoint.json\")\n",
    "assert EXP04A_CKPT.exists(), f\"Exp 04A checkpoint not found at {EXP04A_CKPT}\"\n",
    "\n",
    "with open(EXP04A_CKPT) as f:\n",
    "    exp04a = json.load(f)\n",
    "\n",
    "results_04a = exp04a['results']\n",
    "print(f\"Loaded {len(results_04a)} queries from Exp 04A\")\n",
    "\n",
    "COND_NAMES_04A = ['bare', 'oracle_trunc', 'surr_template_trunc',\n",
    "                  'surr_doc_trunc', 'random_trunc', 'static_fact_trunc']\n",
    "PRIMED_CONDITIONS = COND_NAMES_04A[1:]\n",
    "\n",
    "# Ranking metrics (reused throughout)\n",
    "def compute_auc(nlls, relevant_idx):\n",
    "    rel_nll = nlls[relevant_idx]\n",
    "    irrel_nlls = [nlls[i] for i in range(len(nlls)) if i != relevant_idx]\n",
    "    if len(irrel_nlls) == 0:\n",
    "        return 0.5\n",
    "    wins = sum(1 for nll in irrel_nlls if nll > rel_nll)\n",
    "    ties = sum(1 for nll in irrel_nlls if nll == rel_nll)\n",
    "    return (wins + 0.5 * ties) / len(irrel_nlls)\n",
    "\n",
    "def compute_mrr_at_k(nlls, relevant_idx, k=3):\n",
    "    ranked = list(np.argsort(nlls))\n",
    "    for rank, idx in enumerate(ranked[:k], 1):\n",
    "        if idx == relevant_idx:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def compute_hit_at_k(nlls, relevant_idx, k=1):\n",
    "    ranked = set(np.argsort(nlls)[:k].tolist())\n",
    "    return 1.0 if relevant_idx in ranked else 0.0\n",
    "\n",
    "# Compute delta features: delta = NLL_bare - NLL_primed\n",
    "print(f\"\\nComputing delta features for {len(PRIMED_CONDITIONS)} conditions...\")\n",
    "for r in results_04a:\n",
    "    bare_nlls = np.array(r['scores']['bare'])\n",
    "    r['deltas'] = {}\n",
    "    for cond in PRIMED_CONDITIONS:\n",
    "        primed_nlls = np.array(r['scores'][cond])\n",
    "        r['deltas'][cond] = (bare_nlls - primed_nlls).tolist()\n",
    "\n",
    "# Bare AUC reference\n",
    "bare_aucs_ref = np.array([\n",
    "    compute_auc(np.array(r['scores']['bare']), r['relevant_idx'])\n",
    "    for r in results_04a\n",
    "])\n",
    "print(f\"Bare AUC reference: {bare_aucs_ref.mean():.3f}\")\n",
    "\n",
    "# Correlation: delta vs bare NLL\n",
    "print(f\"\\n--- Delta vs bare NLL correlation ---\")\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    all_bare, all_delta = [], []\n",
    "    for r in results_04a:\n",
    "        all_bare.extend(r['scores']['bare'])\n",
    "        all_delta.extend(r['deltas'][cond])\n",
    "    r_s, p_s = spearmanr(all_bare, all_delta)\n",
    "    print(f\"  {cond:<22s}: Spearman rho={r_s:+.3f} (p={p_s:.2e})\")\n",
    "\n",
    "# Delta by relevance\n",
    "print(f\"\\n--- Mean delta by relevance ---\")\n",
    "print(f\"  {'Condition':<22s} {'delta_rel':>10} {'delta_irrel':>12} {'diff':>8}\")\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    delta_rels, delta_irrels = [], []\n",
    "    for r in results_04a:\n",
    "        rel_idx = r['relevant_idx']\n",
    "        deltas = r['deltas'][cond]\n",
    "        delta_rels.append(deltas[rel_idx])\n",
    "        for i, d in enumerate(deltas):\n",
    "            if i != rel_idx:\n",
    "                delta_irrels.append(d)\n",
    "    print(f\"  {cond:<22s} {np.mean(delta_rels):>+10.4f} {np.mean(delta_irrels):>+12.4f} \"\n",
    "          f\"{np.mean(delta_rels) - np.mean(delta_irrels):>+8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceefb792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:15.054782Z",
     "iopub.status.busy": "2026-02-19T13:00:15.054515Z",
     "iopub.status.idle": "2026-02-19T13:00:15.462842Z",
     "shell.execute_reply": "2026-02-19T13:00:15.461938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE A: DELTA-AS-FEATURE RANKING\n",
      "======================================================================\n",
      "\n",
      "--- Test 1: Rank by delta alone (higher delta = more relevant) ---\n",
      "  Condition                  AUC   MRR@3   Hit@1   Hit@3\n",
      "  -------------------------------------------------------\n",
      "  oracle_trunc             0.555   0.288   0.175   0.443\n",
      "  surr_template_trunc      0.669   0.398   0.260   0.583\n",
      "  surr_doc_trunc           0.588   0.288   0.140   0.497\n",
      "  random_trunc             0.670   0.384   0.235   0.585\n",
      "  static_fact_trunc        0.694   0.430   0.295   0.618\n",
      "  bare NLL (ref)           0.845\n",
      "\n",
      "  Delta-only vs chance (AUC=0.5):\n",
      "    oracle_trunc          : AUC=0.555, d=+0.164, p=1.63e-03 *\n",
      "    surr_template_trunc   : AUC=0.669, d=+0.553, p=2.30e-21 ***\n",
      "    surr_doc_trunc        : AUC=0.588, d=+0.292, p=7.72e-08 ***\n",
      "    random_trunc          : AUC=0.670, d=+0.591, p=7.73e-24 ***\n",
      "    static_fact_trunc     : AUC=0.694, d=+0.659, p=2.41e-27 ***\n",
      "\n",
      "--- Test 2: Lambda sweep: score = (1-lam)*NLL_bare + lam*NLL_primed ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Condition              Best lam  Best AUC    bare    Gain\n",
      "  ----------------------------------------------------------\n",
      "  oracle_trunc                1.0     0.853   0.845  +0.008\n",
      "  surr_template_trunc         1.5     0.869   0.845  +0.024\n",
      "  surr_doc_trunc              1.5     0.874   0.845  +0.028\n",
      "  random_trunc                1.5     0.868   0.845  +0.023\n",
      "  static_fact_trunc           2.0     0.866   0.845  +0.021\n",
      "\n",
      "  Best lambda vs bare (Wilcoxon):\n",
      "    oracle_trunc          : lam=1.0, AUC=0.853, d=+0.067, p=1.12e-01 ns\n",
      "    surr_template_trunc   : lam=1.5, AUC=0.869, d=+0.144, p=7.59e-03 ns\n",
      "    surr_doc_trunc        : lam=1.5, AUC=0.874, d=+0.149, p=1.06e-02 ns\n",
      "    random_trunc          : lam=1.5, AUC=0.868, d=+0.120, p=3.83e-02 ns\n",
      "    static_fact_trunc     : lam=2.0, AUC=0.866, d=+0.112, p=1.67e-02 ns\n",
      "\n",
      "--- Test 3: Ensemble -- average NLL across conditions ---\n",
      "  Structural (4 conds): AUC=0.866, d=+0.169, p=5.16e-04 **\n",
      "  All 5 primed:         AUC=0.863, d=+0.155, p=1.17e-03 **\n",
      "\n",
      "--- Phase A Summary ---\n",
      "  Bare AUC: 0.845\n",
      "  Best lambda: surr_doc_trunc lam=1.5, AUC=0.874\n",
      "  Best ensemble: structural 4-cond AUC=0.866\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Phase A -- Delta-only ranking, lambda sweep, ensemble\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE A: DELTA-AS-FEATURE RANKING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# === Test 1: Rank by delta alone ===\n",
    "print(f\"\\n--- Test 1: Rank by delta alone (higher delta = more relevant) ---\")\n",
    "print(f\"  {'Condition':<22s} {'AUC':>7} {'MRR@3':>7} {'Hit@1':>7} {'Hit@3':>7}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "delta_only_aucs = {}\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    aucs, mrr3s, hit1s, hit3s = [], [], [], []\n",
    "    for r in results_04a:\n",
    "        rel_idx = r['relevant_idx']\n",
    "        neg_deltas = [-d for d in r['deltas'][cond]]\n",
    "        aucs.append(compute_auc(neg_deltas, rel_idx))\n",
    "        mrr3s.append(compute_mrr_at_k(neg_deltas, rel_idx, k=3))\n",
    "        hit1s.append(compute_hit_at_k(neg_deltas, rel_idx, k=1))\n",
    "        hit3s.append(compute_hit_at_k(neg_deltas, rel_idx, k=3))\n",
    "    delta_only_aucs[cond] = np.array(aucs)\n",
    "    print(f\"  {cond:<22s} {np.mean(aucs):>7.3f} {np.mean(mrr3s):>7.3f} \"\n",
    "          f\"{np.mean(hit1s):>7.3f} {np.mean(hit3s):>7.3f}\")\n",
    "\n",
    "print(f\"  {'bare NLL (ref)':<22s} {bare_aucs_ref.mean():>7.3f}\")\n",
    "\n",
    "# Test delta-only vs chance\n",
    "print(f\"\\n  Delta-only vs chance (AUC=0.5):\")\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    d = cohens_d(delta_only_aucs[cond] - 0.5)\n",
    "    nonzero = delta_only_aucs[cond] - 0.5\n",
    "    nonzero = nonzero[nonzero != 0]\n",
    "    _, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "    sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "           else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "    print(f\"    {cond:<22s}: AUC={delta_only_aucs[cond].mean():.3f}, d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "# === Test 2: Lambda sweep ===\n",
    "print(f\"\\n--- Test 2: Lambda sweep: score = (1-lam)*NLL_bare + lam*NLL_primed ---\")\n",
    "LAMBDAS = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 3.0]\n",
    "\n",
    "lambda_results = {}\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    best_auc = 0\n",
    "    best_lambda = 0\n",
    "    lambda_aucs = {}\n",
    "\n",
    "    for lam in LAMBDAS:\n",
    "        aucs = []\n",
    "        for r in results_04a:\n",
    "            bare_nlls = np.array(r['scores']['bare'])\n",
    "            primed_nlls = np.array(r['scores'][cond])\n",
    "            combined = (1 - lam) * bare_nlls + lam * primed_nlls\n",
    "            aucs.append(compute_auc(combined, r['relevant_idx']))\n",
    "        mean_auc = np.mean(aucs)\n",
    "        lambda_aucs[lam] = np.array(aucs)\n",
    "        if mean_auc > best_auc:\n",
    "            best_auc = mean_auc\n",
    "            best_lambda = lam\n",
    "\n",
    "    lambda_results[cond] = {\n",
    "        'best_lambda': best_lambda,\n",
    "        'best_auc': best_auc,\n",
    "        'bare_auc': float(lambda_aucs[0.0].mean()),\n",
    "        'primed_auc': float(lambda_aucs[1.0].mean()),\n",
    "        'aucs_by_lambda': {str(l): float(a.mean()) for l, a in lambda_aucs.items()},\n",
    "        'best_lambda_aucs': lambda_aucs[best_lambda],\n",
    "    }\n",
    "\n",
    "print(f\"\\n  {'Condition':<22s} {'Best lam':>8} {'Best AUC':>9} {'bare':>7} {'Gain':>7}\")\n",
    "print(f\"  {'-'*58}\")\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    lr = lambda_results[cond]\n",
    "    gain = lr['best_auc'] - lr['bare_auc']\n",
    "    print(f\"  {cond:<22s} {lr['best_lambda']:>8.1f} {lr['best_auc']:>9.3f} \"\n",
    "          f\"{lr['bare_auc']:>7.3f} {gain:>+7.3f}\")\n",
    "\n",
    "# Test best lambda vs bare\n",
    "print(f\"\\n  Best lambda vs bare (Wilcoxon):\")\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    lr = lambda_results[cond]\n",
    "    diff = lr['best_lambda_aucs'] - bare_aucs_ref\n",
    "    d = cohens_d(diff)\n",
    "    nonzero = diff[diff != 0]\n",
    "    _, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "    sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "           else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "    print(f\"    {cond:<22s}: lam={lr['best_lambda']:.1f}, AUC={lr['best_auc']:.3f}, \"\n",
    "          f\"d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "# === Test 3: Ensemble ===\n",
    "print(f\"\\n--- Test 3: Ensemble -- average NLL across conditions ---\")\n",
    "\n",
    "structural_conds = ['surr_template_trunc', 'surr_doc_trunc', 'random_trunc', 'static_fact_trunc']\n",
    "struct_ensemble_aucs = []\n",
    "for r in results_04a:\n",
    "    mean_nlls = np.zeros(r['n_passages'])\n",
    "    for cond in structural_conds:\n",
    "        mean_nlls += np.array(r['scores'][cond])\n",
    "    mean_nlls /= len(structural_conds)\n",
    "    struct_ensemble_aucs.append(compute_auc(mean_nlls, r['relevant_idx']))\n",
    "struct_ensemble_aucs = np.array(struct_ensemble_aucs)\n",
    "\n",
    "diff = struct_ensemble_aucs - bare_aucs_ref\n",
    "d = cohens_d(diff)\n",
    "nonzero = diff[diff != 0]\n",
    "_, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "       else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "print(f\"  Structural (4 conds): AUC={struct_ensemble_aucs.mean():.3f}, \"\n",
    "      f\"d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "all5_aucs = []\n",
    "for r in results_04a:\n",
    "    mean_nlls = np.zeros(r['n_passages'])\n",
    "    for cond in PRIMED_CONDITIONS:\n",
    "        mean_nlls += np.array(r['scores'][cond])\n",
    "    mean_nlls /= len(PRIMED_CONDITIONS)\n",
    "    all5_aucs.append(compute_auc(mean_nlls, r['relevant_idx']))\n",
    "all5_aucs = np.array(all5_aucs)\n",
    "\n",
    "diff = all5_aucs - bare_aucs_ref\n",
    "d = cohens_d(diff)\n",
    "nonzero = diff[diff != 0]\n",
    "_, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "       else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "print(f\"  All 5 primed:         AUC={all5_aucs.mean():.3f}, \"\n",
    "      f\"d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "print(f\"\\n--- Phase A Summary ---\")\n",
    "print(f\"  Bare AUC: {bare_aucs_ref.mean():.3f}\")\n",
    "best_combo_cond = max(lambda_results, key=lambda c: lambda_results[c]['best_auc'])\n",
    "best_combo = lambda_results[best_combo_cond]\n",
    "print(f\"  Best lambda: {best_combo_cond} lam={best_combo['best_lambda']:.1f}, \"\n",
    "      f\"AUC={best_combo['best_auc']:.3f}\")\n",
    "print(f\"  Best ensemble: structural 4-cond AUC={struct_ensemble_aucs.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704ce72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:15.466385Z",
     "iopub.status.busy": "2026-02-19T13:00:15.466092Z",
     "iopub.status.idle": "2026-02-19T13:00:16.946087Z",
     "shell.execute_reply": "2026-02-19T13:00:16.945132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to results/exp11/phase_a_results.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Phase A visualization\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Lambda sweep\n",
    "ax = axes[0]\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    lr = lambda_results[cond]\n",
    "    lams = sorted(lr['aucs_by_lambda'].keys(), key=float)\n",
    "    aucs = [lr['aucs_by_lambda'][l] for l in lams]\n",
    "    ax.plot([float(l) for l in lams], aucs, '-o', label=cond.replace('_trunc', ''), markersize=4)\n",
    "ax.axhline(y=bare_aucs_ref.mean(), color='black', linestyle='--', alpha=0.5, label='bare')\n",
    "ax.set_xlabel('Lambda (0=bare, 1=primed)')\n",
    "ax.set_ylabel('Mean AUC')\n",
    "ax.set_title('Lambda Sweep: (1-lam)*bare + lam*primed')\n",
    "ax.legend(fontsize=7)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Delta-only ranking\n",
    "ax = axes[1]\n",
    "cond_short = [c.replace('_trunc', '') for c in PRIMED_CONDITIONS]\n",
    "delta_vals = [delta_only_aucs[c].mean() for c in PRIMED_CONDITIONS]\n",
    "colors = ['C0' if v > 0.5 else 'gray' for v in delta_vals]\n",
    "ax.bar(range(len(PRIMED_CONDITIONS)), delta_vals, color=colors, alpha=0.7)\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='chance')\n",
    "ax.axhline(y=bare_aucs_ref.mean(), color='black', linestyle='--', alpha=0.5, label='bare NLL')\n",
    "ax.set_xticks(range(len(PRIMED_CONDITIONS)))\n",
    "ax.set_xticklabels(cond_short, rotation=30, ha='right', fontsize=8)\n",
    "ax.set_ylabel('AUC')\n",
    "ax.set_title('Delta-Only Ranking (higher delta = more relevant)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = RESULTS_DIR / 'phase_a_results.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecbf858a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:16.950010Z",
     "iopub.status.busy": "2026-02-19T13:00:16.949492Z",
     "iopub.status.idle": "2026-02-19T13:01:34.400952Z",
     "shell.execute_reply": "2026-02-19T13:01:34.399942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE B SETUP: Loading model and rebuilding data\n",
      "======================================================================\n",
      "Loading google/t5gemma-2-4b-4b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d083b9420ec4fc9b418daefb0387560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.bfloat16\n",
      "GPU memory used: 15.02 GB\n",
      "\n",
      "Rebuilding MS MARCO query pools (SEED=42)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data alignment verified: all 400 queries match 04A\n",
      "\n",
      "Generated 10 fixed random prefixes:\n",
      "  Prefix 0: 'Find the water shut-off valve behind the refrigerator or und...'\n",
      "  Prefix 1: 'In the aftermath of Shepard's death, NCIS Assistant Director...'\n",
      "  Prefix 2: 'How much is it? 1 On average, a notary is going to anywhere ...'\n",
      "  Prefix 3: 'The following is a list of episodes of the A&E reality telev...'\n",
      "  Prefix 4: 'Medical assistants who wish to become registered nurses will...'\n",
      "  Prefix 5: '1 Remove the first element in a collection; to remove one el...'\n",
      "  Prefix 6: 'Amenhotep IV succeeded his father after Amenhotep III's deat...'\n",
      "  Prefix 7: 'The main difference between the programming language and scr...'\n",
      "  Prefix 8: 'The speed of light (and thus radio waves) is 3x10^8 m per se...'\n",
      "  Prefix 9: 'Republic huddle before second half of a friendly against Atl...'\n",
      "\n",
      "Total scoring calls: 32970\n",
      "Estimated runtime: ~3.7 hours\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load model and rebuild data for Phase B\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE B SETUP: Loading model and rebuilding data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "print(f\"Model loaded. dtype={next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory used: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "# Scoring helpers\n",
    "def score_nll(encoder_text, answer_text, prefix_token_count=0, truncate=False):\n",
    "    enc_ids = tokenizer(encoder_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=True, truncation=True,\n",
    "                        max_length=8192).input_ids.to(DEVICE)\n",
    "    total_enc_len = enc_ids.shape[1]\n",
    "    enc_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.get_encoder()(input_ids=enc_ids, attention_mask=enc_mask)\n",
    "    if truncate and prefix_token_count > 0:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "        cross_attn_mask[:, :prefix_token_count] = 0\n",
    "    else:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "    ans_ids = tokenizer(answer_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=False, truncation=True,\n",
    "                        max_length=256).input_ids.to(DEVICE)\n",
    "    if ans_ids.shape[1] == 0:\n",
    "        return 0.0\n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoder_outputs=encoder_outputs, attention_mask=cross_attn_mask, labels=ans_ids)\n",
    "    logits = outputs.logits\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_log_probs = log_probs[0].gather(1, ans_ids[0].unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "    del encoder_outputs, outputs, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "def count_prefix_tokens(prefix_text, document_text):\n",
    "    full_text = prefix_text + \"\\n\" + document_text\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True).input_ids\n",
    "    return len(full_ids) - len(doc_ids)\n",
    "\n",
    "# Rebuild query pools (same as 04A with SEED=42)\n",
    "print(f\"\\nRebuilding MS MARCO query pools (SEED={SEED})...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "queries = []\n",
    "all_passage_texts = []\n",
    "\n",
    "for item in ds:\n",
    "    passages_data = item.get('passages', {})\n",
    "    ptexts = passages_data.get('passage_text', [])\n",
    "    is_sel = passages_data.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "\n",
    "    word_counts = [count_words(pt) for pt in ptexts]\n",
    "    if not all(30 <= wc <= 300 for wc in word_counts):\n",
    "        continue\n",
    "\n",
    "    n_selected = sum(is_sel)\n",
    "    n_not_selected = len(is_sel) - n_selected\n",
    "    if n_selected != 1 or n_not_selected < 2:\n",
    "        continue\n",
    "\n",
    "    relevant_idx = is_sel.index(1)\n",
    "    passages = []\n",
    "    for p_idx, (pt, sel) in enumerate(zip(ptexts, is_sel)):\n",
    "        passages.append({'text': pt, 'is_selected': sel})\n",
    "\n",
    "    queries.append({\n",
    "        'query': query, 'answer': answer, 'passages': passages,\n",
    "        'relevant_idx': relevant_idx, 'n_passages': len(passages),\n",
    "    })\n",
    "    all_passage_texts.append(ptexts[0])\n",
    "\n",
    "    if len(queries) >= N_SAMPLES * 3:\n",
    "        break\n",
    "\n",
    "del ds\n",
    "gc.collect()\n",
    "\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(queries)\n",
    "queries = queries[:N_SAMPLES]\n",
    "\n",
    "# Verify alignment with 04A\n",
    "mismatches = sum(1 for q, r in zip(queries, results_04a) if q['query'][:50] != r['query'][:50])\n",
    "assert mismatches == 0, f\"{mismatches} query mismatches with 04A checkpoint\"\n",
    "print(f\"Data alignment verified: all {N_SAMPLES} queries match 04A\")\n",
    "\n",
    "# Generate K=10 fixed random prefixes (SEED+100 for independence)\n",
    "np.random.seed(SEED + 100)\n",
    "prefix_indices = np.random.choice(len(all_passage_texts), K_PREFIXES, replace=False)\n",
    "RANDOM_PREFIXES = [\" \".join(all_passage_texts[idx].split()[:20]) for idx in prefix_indices]\n",
    "\n",
    "print(f\"\\nGenerated {K_PREFIXES} fixed random prefixes:\")\n",
    "for k, pref in enumerate(RANDOM_PREFIXES):\n",
    "    print(f\"  Prefix {k}: '{pref[:60]}...'\")\n",
    "\n",
    "total_calls = sum(q['n_passages'] for q in queries) * K_PREFIXES\n",
    "print(f\"\\nTotal scoring calls: {total_calls}\")\n",
    "print(f\"Estimated runtime: ~{total_calls * 0.4 / 3600:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c56d222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:01:34.405820Z",
     "iopub.status.busy": "2026-02-19T13:01:34.404378Z",
     "iopub.status.idle": "2026-02-19T14:54:58.159233Z",
     "shell.execute_reply": "2026-02-19T14:54:58.158259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE B: SCORING WITH K=10 RANDOM PREFIXES\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0f218b85d74affa06782ced6605e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prefix diversity:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 20/400 | 5.9m | ETA 112.9m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 40/400 | 11.5m | ETA 103.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 60/400 | 16.9m | ETA 96.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 80/400 | 22.8m | ETA 91.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/400 | 28.4m | ETA 85.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 120/400 | 34.3m | ETA 80.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 140/400 | 40.4m | ETA 75.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 160/400 | 46.0m | ETA 69.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 180/400 | 51.6m | ETA 63.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/400 | 57.1m | ETA 57.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 220/400 | 62.3m | ETA 50.9m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 240/400 | 68.1m | ETA 45.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 260/400 | 73.7m | ETA 39.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 280/400 | 79.2m | ETA 34.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/400 | 85.2m | ETA 28.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 320/400 | 91.1m | ETA 22.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 340/400 | 96.4m | ETA 17.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 360/400 | 102.4m | ETA 11.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 380/400 | 107.6m | ETA 5.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 400/400 | 113.4m | ETA 0.0m\n",
      "\n",
      "Diversity scoring complete: 400 queries in 113.4 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Score with K=10 random prefixes (with checkpointing)\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE B: SCORING WITH K=%d RANDOM PREFIXES\" % K_PREFIXES)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "DIVERSITY_CKPT = RESULTS_DIR / \"diversity_checkpoint.json\"\n",
    "\n",
    "diversity_results = []\n",
    "start_idx = 0\n",
    "if DIVERSITY_CKPT.exists():\n",
    "    saved = json.loads(DIVERSITY_CKPT.read_text())\n",
    "    if saved.get('n_total') == N_SAMPLES and saved.get('k_prefixes') == K_PREFIXES:\n",
    "        saved_results = saved.get('results', [])\n",
    "        saved_queries = [r['query'][:50] for r in saved_results]\n",
    "        current_queries = [q['query'][:50] for q in queries[:len(saved_results)]]\n",
    "        if saved_queries == current_queries:\n",
    "            diversity_results = saved_results\n",
    "            start_idx = len(diversity_results)\n",
    "            print(f\"Resumed from checkpoint: {start_idx}/{N_SAMPLES} queries\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for q_idx in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "                  desc=\"Prefix diversity\"):\n",
    "    q = queries[q_idx]\n",
    "    answer = q['answer']\n",
    "\n",
    "    query_result = {\n",
    "        'query_idx': q_idx,\n",
    "        'query': q['query'],\n",
    "        'n_passages': q['n_passages'],\n",
    "        'relevant_idx': q['relevant_idx'],\n",
    "        'diversity_scores': [],\n",
    "    }\n",
    "\n",
    "    for p_idx, passage_data in enumerate(q['passages']):\n",
    "        passage_nlls = []\n",
    "        for k in range(K_PREFIXES):\n",
    "            prefix = RANDOM_PREFIXES[k]\n",
    "            enc_text = prefix + \"\\n\" + passage_data['text']\n",
    "            prefix_count = count_prefix_tokens(prefix, passage_data['text'])\n",
    "            nll = score_nll(enc_text, answer, prefix_count, truncate=True)\n",
    "            passage_nlls.append(nll)\n",
    "        query_result['diversity_scores'].append(passage_nlls)\n",
    "\n",
    "    diversity_results.append(query_result)\n",
    "\n",
    "    if (q_idx + 1) % 20 == 0 or q_idx == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'k_prefixes': K_PREFIXES,\n",
    "            'results': diversity_results,\n",
    "            'completed': len(diversity_results),\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        DIVERSITY_CKPT.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = q_idx - start_idx + 1\n",
    "        eta = (N_SAMPLES - q_idx - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {q_idx+1}/{N_SAMPLES} | {elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "elapsed_total = time.time() - t0\n",
    "print(f\"\\nDiversity scoring complete: {len(diversity_results)} queries in {elapsed_total/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aef5cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:54:58.162907Z",
     "iopub.status.busy": "2026-02-19T14:54:58.162635Z",
     "iopub.status.idle": "2026-02-19T14:54:58.481696Z",
     "shell.execute_reply": "2026-02-19T14:54:58.480744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE B: PREFIX DIVERSITY ANALYSIS\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NLL diversity by relevance ---\n",
      "   mean: relevant=3.1376, irrelevant=4.4110, diff=-1.2734, d=-0.336\n",
      "    std: relevant=0.1459, irrelevant=0.1647, diff=-0.0188, d=-0.074\n",
      "  range: relevant=0.4784, irrelevant=0.5512, diff=-0.0728, d=-0.086\n",
      "     cv: relevant=0.0498, irrelevant=0.0323, diff=+0.0175, d=+0.820\n",
      "\n",
      "--- Rank by NLL_mean (ensemble of K=10 random prefixes) ---\n",
      "  AUC=0.863 (vs bare 0.845), d=+0.129, p=1.64e-02 ns\n",
      "  MRR@3=0.765, Hit@1=0.698\n",
      "\n",
      "--- Rank by NLL_std ---\n",
      "  lower std = better: AUC=0.626, d vs 0.5=+0.367\n",
      "  higher std = better: AUC=0.374, d vs 0.5=-0.367\n",
      "  Best direction: lower std = more relevant, AUC=0.626\n",
      "\n",
      "--- Lambda sweep: (1-lam)*bare + lam*diversity_mean ---\n",
      "  Best lambda=1.5, AUC=0.871\n",
      "    lam=0.0: AUC=0.845\n",
      "    lam=0.2: AUC=0.848\n",
      "    lam=0.4: AUC=0.851\n",
      "    lam=0.5: AUC=0.855\n",
      "    lam=0.6: AUC=0.859\n",
      "    lam=0.8: AUC=0.860\n",
      "    lam=1.0: AUC=0.863\n",
      "    lam=1.5: AUC=0.871\n",
      "    lam=2.0: AUC=0.867\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Phase B -- Diversity analysis and ranking\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE B: PREFIX DIVERSITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compute per-passage diversity stats\n",
    "for dr in diversity_results:\n",
    "    dr['passage_stats'] = []\n",
    "    for p_scores in dr['diversity_scores']:\n",
    "        arr = np.array(p_scores)\n",
    "        dr['passage_stats'].append({\n",
    "            'mean': float(arr.mean()),\n",
    "            'std': float(arr.std()),\n",
    "            'range': float(arr.max() - arr.min()),\n",
    "            'cv': float(arr.std() / arr.mean()) if arr.mean() > 0 else 0,\n",
    "        })\n",
    "\n",
    "# Relevant vs irrelevant diversity\n",
    "print(f\"\\n--- NLL diversity by relevance ---\")\n",
    "for stat_name in ['mean', 'std', 'range', 'cv']:\n",
    "    rel_vals, irrel_vals = [], []\n",
    "    for dr in diversity_results:\n",
    "        rel_idx = dr['relevant_idx']\n",
    "        for p_idx, ps in enumerate(dr['passage_stats']):\n",
    "            if p_idx == rel_idx:\n",
    "                rel_vals.append(ps[stat_name])\n",
    "            else:\n",
    "                irrel_vals.append(ps[stat_name])\n",
    "    rel_mean = np.mean(rel_vals)\n",
    "    irrel_mean = np.mean(irrel_vals)\n",
    "    diff = rel_mean - irrel_mean\n",
    "    pooled_std = np.sqrt((np.var(rel_vals) * len(rel_vals) + np.var(irrel_vals) * len(irrel_vals))\n",
    "                          / (len(rel_vals) + len(irrel_vals)))\n",
    "    d = diff / pooled_std if pooled_std > 0 else 0\n",
    "    print(f\"  {stat_name:>5s}: relevant={rel_mean:.4f}, irrelevant={irrel_mean:.4f}, \"\n",
    "          f\"diff={diff:+.4f}, d={d:+.3f}\")\n",
    "\n",
    "# === Ranking by NLL_mean (ensemble of K random prefixes) ===\n",
    "print(f\"\\n--- Rank by NLL_mean (ensemble of K={K_PREFIXES} random prefixes) ---\")\n",
    "div_mean_aucs = []\n",
    "div_mean_mrr3s = []\n",
    "div_mean_hit1s = []\n",
    "for dr in diversity_results:\n",
    "    rel_idx = dr['relevant_idx']\n",
    "    mean_nlls = np.array([ps['mean'] for ps in dr['passage_stats']])\n",
    "    div_mean_aucs.append(compute_auc(mean_nlls, rel_idx))\n",
    "    div_mean_mrr3s.append(compute_mrr_at_k(mean_nlls, rel_idx, k=3))\n",
    "    div_mean_hit1s.append(compute_hit_at_k(mean_nlls, rel_idx, k=1))\n",
    "div_mean_aucs = np.array(div_mean_aucs)\n",
    "\n",
    "diff = div_mean_aucs - bare_aucs_ref\n",
    "d = cohens_d(diff)\n",
    "nonzero = diff[diff != 0]\n",
    "_, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "       else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "print(f\"  AUC={div_mean_aucs.mean():.3f} (vs bare {bare_aucs_ref.mean():.3f}), \"\n",
    "      f\"d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "print(f\"  MRR@3={np.mean(div_mean_mrr3s):.3f}, Hit@1={np.mean(div_mean_hit1s):.3f}\")\n",
    "\n",
    "# === Ranking by NLL_std (test both directions) ===\n",
    "print(f\"\\n--- Rank by NLL_std ---\")\n",
    "for direction, label in [(1, 'lower std = better'), (-1, 'higher std = better')]:\n",
    "    std_aucs = []\n",
    "    for dr in diversity_results:\n",
    "        rel_idx = dr['relevant_idx']\n",
    "        std_vals = np.array([ps['std'] for ps in dr['passage_stats']])\n",
    "        if direction == -1:\n",
    "            std_vals = -std_vals\n",
    "        std_aucs.append(compute_auc(std_vals, rel_idx))\n",
    "    std_aucs = np.array(std_aucs)\n",
    "    d_vs_chance = cohens_d(std_aucs - 0.5)\n",
    "    print(f\"  {label}: AUC={std_aucs.mean():.3f}, d vs 0.5={d_vs_chance:+.3f}\")\n",
    "\n",
    "# Store better direction\n",
    "std_aucs_lower = []\n",
    "std_aucs_higher = []\n",
    "for dr in diversity_results:\n",
    "    rel_idx = dr['relevant_idx']\n",
    "    std_vals = np.array([ps['std'] for ps in dr['passage_stats']])\n",
    "    std_aucs_lower.append(compute_auc(std_vals, rel_idx))\n",
    "    std_aucs_higher.append(compute_auc(-std_vals, rel_idx))\n",
    "std_aucs_lower = np.array(std_aucs_lower)\n",
    "std_aucs_higher = np.array(std_aucs_higher)\n",
    "if std_aucs_higher.mean() > std_aucs_lower.mean():\n",
    "    std_best_aucs = std_aucs_higher\n",
    "    std_direction = \"higher std = more relevant\"\n",
    "else:\n",
    "    std_best_aucs = std_aucs_lower\n",
    "    std_direction = \"lower std = more relevant\"\n",
    "print(f\"  Best direction: {std_direction}, AUC={std_best_aucs.mean():.3f}\")\n",
    "\n",
    "# === Lambda sweep: bare + diversity_mean ===\n",
    "print(f\"\\n--- Lambda sweep: (1-lam)*bare + lam*diversity_mean ---\")\n",
    "LAMBDAS_B = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0, 1.5, 2.0]\n",
    "best_div_auc = 0\n",
    "best_div_lambda = 0\n",
    "div_lambda_aucs = {}\n",
    "\n",
    "for lam in LAMBDAS_B:\n",
    "    aucs = []\n",
    "    for i, dr in enumerate(diversity_results):\n",
    "        rel_idx = dr['relevant_idx']\n",
    "        bare_nlls = np.array(results_04a[i]['scores']['bare'])\n",
    "        div_nlls = np.array([ps['mean'] for ps in dr['passage_stats']])\n",
    "        combined = (1 - lam) * bare_nlls + lam * div_nlls\n",
    "        aucs.append(compute_auc(combined, rel_idx))\n",
    "    mean_auc = np.mean(aucs)\n",
    "    div_lambda_aucs[lam] = np.array(aucs)\n",
    "    if mean_auc > best_div_auc:\n",
    "        best_div_auc = mean_auc\n",
    "        best_div_lambda = lam\n",
    "\n",
    "print(f\"  Best lambda={best_div_lambda:.1f}, AUC={best_div_auc:.3f}\")\n",
    "for lam in LAMBDAS_B:\n",
    "    print(f\"    lam={lam:.1f}: AUC={div_lambda_aucs[lam].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbb5e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:54:58.485379Z",
     "iopub.status.busy": "2026-02-19T14:54:58.485094Z",
     "iopub.status.idle": "2026-02-19T14:54:58.854775Z",
     "shell.execute_reply": "2026-02-19T14:54:58.853806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE C: COMBINED MULTI-FEATURE RANKING\n",
      "======================================================================\n",
      "Best single primed: surr_doc_trunc (AUC=0.874)\n",
      "\n",
      "--- Grid search: w_bare*bare + w_primed*surr_doc + w_div*div_mean ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Top 10 weight combinations:\n",
      "   w_bare  w_primed  w_div     AUC\n",
      "  ---------------------------------\n",
      "      0.1       0.9    0.0   0.867\n",
      "      0.0       1.0    0.0   0.867\n",
      "      0.0       0.9    0.1   0.867\n",
      "      0.0       0.4    0.6   0.867\n",
      "      0.1       0.5    0.4   0.867\n",
      "      0.0       0.8    0.2   0.866\n",
      "      0.0       0.5    0.5   0.866\n",
      "      0.1       0.8    0.1   0.866\n",
      "      0.1       0.7    0.2   0.866\n",
      "      0.0       0.6    0.4   0.866\n",
      "\n",
      "  Best: w=(0.1, 0.9, 0.0)\n",
      "  AUC=0.867 vs bare 0.845, d=+0.165, p=1.51e-03 *\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Phase C -- Combined multi-feature ranking\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE C: COMBINED MULTI-FEATURE RANKING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_single_cond = max(PRIMED_CONDITIONS, key=lambda c: lambda_results[c]['best_auc'])\n",
    "print(f\"Best single primed: {best_single_cond} (AUC={lambda_results[best_single_cond]['best_auc']:.3f})\")\n",
    "\n",
    "# Grid search: w_bare + w_primed + w_div = 1.0 (step 0.1)\n",
    "print(f\"\\n--- Grid search: w_bare*bare + w_primed*{best_single_cond.replace('_trunc','')} + w_div*div_mean ---\")\n",
    "grid_results = []\n",
    "\n",
    "for w_bare_pct in range(0, 11):\n",
    "    for w_primed_pct in range(0, 11 - w_bare_pct):\n",
    "        w_div_pct = 10 - w_bare_pct - w_primed_pct\n",
    "        w_bare = w_bare_pct / 10\n",
    "        w_primed = w_primed_pct / 10\n",
    "        w_div = w_div_pct / 10\n",
    "\n",
    "        aucs = []\n",
    "        for i, dr in enumerate(diversity_results):\n",
    "            rel_idx = dr['relevant_idx']\n",
    "            bare_nlls = np.array(results_04a[i]['scores']['bare'])\n",
    "            primed_nlls = np.array(results_04a[i]['scores'][best_single_cond])\n",
    "            div_nlls = np.array([ps['mean'] for ps in dr['passage_stats']])\n",
    "            combined = w_bare * bare_nlls + w_primed * primed_nlls + w_div * div_nlls\n",
    "            aucs.append(compute_auc(combined, rel_idx))\n",
    "\n",
    "        grid_results.append({\n",
    "            'w_bare': w_bare, 'w_primed': w_primed, 'w_div': w_div,\n",
    "            'auc': np.mean(aucs), 'aucs': np.array(aucs),\n",
    "        })\n",
    "\n",
    "grid_results.sort(key=lambda x: x['auc'], reverse=True)\n",
    "\n",
    "print(f\"\\n  Top 10 weight combinations:\")\n",
    "print(f\"  {'w_bare':>7} {'w_primed':>9} {'w_div':>6} {'AUC':>7}\")\n",
    "print(f\"  {'-'*33}\")\n",
    "for gr in grid_results[:10]:\n",
    "    print(f\"  {gr['w_bare']:>7.1f} {gr['w_primed']:>9.1f} {gr['w_div']:>6.1f} {gr['auc']:>7.3f}\")\n",
    "\n",
    "best_grid = grid_results[0]\n",
    "diff = best_grid['aucs'] - bare_aucs_ref\n",
    "d = cohens_d(diff)\n",
    "nonzero = diff[diff != 0]\n",
    "_, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "       else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "print(f\"\\n  Best: w=({best_grid['w_bare']:.1f}, {best_grid['w_primed']:.1f}, {best_grid['w_div']:.1f})\")\n",
    "print(f\"  AUC={best_grid['auc']:.3f} vs bare {bare_aucs_ref.mean():.3f}, d={d:+.3f}, p={p:.2e} {sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad8346f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:54:58.858269Z",
     "iopub.status.busy": "2026-02-19T14:54:58.857969Z",
     "iopub.status.idle": "2026-02-19T14:54:59.430734Z",
     "shell.execute_reply": "2026-02-19T14:54:59.429645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GRAND COMPARISON: ALL RANKING METHODS\n",
      "======================================================================\n",
      "\n",
      "    # Method                                               AUC  vs bare       d            p   sig\n",
      "  -----------------------------------------------------------------------------------------------\n",
      "    1 surr_doc (lam=1.5)                                 0.874   +0.028  +0.149     1.06e-02    ns\n",
      "    2 div_combo (lam=1.5)                                0.871   +0.026  +0.140     3.36e-03     *\n",
      "    3 surr_template (lam=1.5)                            0.869   +0.024  +0.144     7.59e-03    ns\n",
      "    4 random (lam=1.5)                                   0.868   +0.023  +0.120     3.83e-02    ns\n",
      "    5 combined (0.1/0.9/0.0)                             0.867   +0.022  +0.165     1.51e-03     *\n",
      "    6 static_fact (lam=2.0)                              0.866   +0.021  +0.112     1.67e-02    ns\n",
      "    7 ensemble_structural_4                              0.866   +0.021  +0.169     5.16e-04    **\n",
      "    8 diversity_mean (K=10)                              0.863   +0.018  +0.129     1.64e-02    ns\n",
      "    9 oracle (lam=1.0)                                   0.853   +0.008  +0.067     1.12e-01    ns\n",
      "   10 bare NLL                                           0.845       --      --           --    --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot saved to results/exp11/grand_comparison.png\n",
      "\n",
      "======================================================================\n",
      "VERDICT -- Exp 11: Delta-as-Feature and Prefix Diversity\n",
      "======================================================================\n",
      "\n",
      "--- Phase A: Delta-as-Feature ---\n",
      "  Best delta-only: static_fact, AUC=0.694\n",
      "  -> Delta carries ranking information above chance\n",
      "  Best lambda: surr_doc_trunc lam=1.5, AUC=0.874\n",
      "  Best ensemble: structural 4-cond AUC=0.866\n",
      "\n",
      "--- Phase B: Prefix Diversity ---\n",
      "  NLL_mean (K=10): AUC=0.863\n",
      "  NLL_std direction: lower std = more relevant\n",
      "  Best diversity combo: lam=1.5, AUC=0.871\n",
      "\n",
      "--- Phase C: Combined ---\n",
      "  Best multi-feature: w=(0.1, 0.9, 0.0), AUC=0.867\n",
      "\n",
      "--- OVERALL ---\n",
      "  Best method: surr_doc (lam=1.5)\n",
      "  AUC: 0.874 (bare: 0.845, gain: +0.028)\n",
      "\n",
      "  >>> PRACTICAL IMPROVEMENT: +0.028 AUC\n",
      "  >>> Structural perturbation signals ARE useful for ranking\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Results saved to results/exp11/results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Grand comparison + verdict + save\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRAND COMPARISON: ALL RANKING METHODS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "methods = {'bare NLL': bare_aucs_ref}\n",
    "\n",
    "for cond in PRIMED_CONDITIONS:\n",
    "    lr = lambda_results[cond]\n",
    "    name = f\"{cond.replace('_trunc','')} (lam={lr['best_lambda']:.1f})\"\n",
    "    methods[name] = lr['best_lambda_aucs']\n",
    "\n",
    "methods['ensemble_structural_4'] = struct_ensemble_aucs\n",
    "methods[f'diversity_mean (K={K_PREFIXES})'] = div_mean_aucs\n",
    "methods[f'div_combo (lam={best_div_lambda:.1f})'] = div_lambda_aucs[best_div_lambda]\n",
    "methods[f'combined ({best_grid[\"w_bare\"]:.1f}/{best_grid[\"w_primed\"]:.1f}/{best_grid[\"w_div\"]:.1f})'] = best_grid['aucs']\n",
    "\n",
    "sorted_methods = sorted(methods.items(), key=lambda x: x[1].mean(), reverse=True)\n",
    "\n",
    "print(f\"\\n  {'#':>3} {'Method':<48} {'AUC':>7} {'vs bare':>8} {'d':>7} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*95}\")\n",
    "for rank, (name, aucs) in enumerate(sorted_methods, 1):\n",
    "    mean_auc = aucs.mean()\n",
    "    if name == 'bare NLL':\n",
    "        print(f\"  {rank:>3} {name:<48} {mean_auc:>7.3f} {'--':>8} {'--':>7} {'--':>12} {'--':>5}\")\n",
    "    else:\n",
    "        diff = aucs - bare_aucs_ref\n",
    "        d = cohens_d(diff)\n",
    "        nonzero = diff[diff != 0]\n",
    "        _, p = wilcoxon(nonzero) if len(nonzero) >= 10 else (0, 1.0)\n",
    "        sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "               else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "        delta_str = f\"{mean_auc - bare_aucs_ref.mean():+.3f}\"\n",
    "        print(f\"  {rank:>3} {name:<48} {mean_auc:>7.3f} {delta_str:>8} {d:>+7.3f} {p:>12.2e} {sig:>5}\")\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "names = [n for n, _ in sorted_methods]\n",
    "aucs_vals = [a.mean() for _, a in sorted_methods]\n",
    "colors = ['gray' if n == 'bare NLL' else 'C0' for n in names]\n",
    "ax.barh(range(len(names)), aucs_vals, color=colors, alpha=0.7)\n",
    "ax.axvline(x=bare_aucs_ref.mean(), color='red', linestyle='--', alpha=0.5, label='bare')\n",
    "ax.set_yticks(range(len(names)))\n",
    "ax.set_yticklabels(names, fontsize=8)\n",
    "ax.set_xlabel('Mean AUC')\n",
    "ax.set_title('Exp 11: All Ranking Methods Compared')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plot_path = RESULTS_DIR / 'grand_comparison.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\nPlot saved to {plot_path}\")\n",
    "\n",
    "# === VERDICT ===\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"VERDICT -- Exp 11: Delta-as-Feature and Prefix Diversity\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "best_delta_cond = max(PRIMED_CONDITIONS, key=lambda c: delta_only_aucs[c].mean())\n",
    "print(f\"\\n--- Phase A: Delta-as-Feature ---\")\n",
    "print(f\"  Best delta-only: {best_delta_cond.replace('_trunc','')}, AUC={delta_only_aucs[best_delta_cond].mean():.3f}\")\n",
    "if delta_only_aucs[best_delta_cond].mean() > 0.55:\n",
    "    print(f\"  -> Delta carries ranking information above chance\")\n",
    "else:\n",
    "    print(f\"  -> Delta alone is near chance (not useful standalone)\")\n",
    "print(f\"  Best lambda: {best_combo_cond} lam={best_combo['best_lambda']:.1f}, \"\n",
    "      f\"AUC={best_combo['best_auc']:.3f}\")\n",
    "print(f\"  Best ensemble: structural 4-cond AUC={struct_ensemble_aucs.mean():.3f}\")\n",
    "\n",
    "print(f\"\\n--- Phase B: Prefix Diversity ---\")\n",
    "print(f\"  NLL_mean (K={K_PREFIXES}): AUC={div_mean_aucs.mean():.3f}\")\n",
    "print(f\"  NLL_std direction: {std_direction}\")\n",
    "print(f\"  Best diversity combo: lam={best_div_lambda:.1f}, AUC={best_div_auc:.3f}\")\n",
    "\n",
    "print(f\"\\n--- Phase C: Combined ---\")\n",
    "print(f\"  Best multi-feature: w=({best_grid['w_bare']:.1f}, {best_grid['w_primed']:.1f}, \"\n",
    "      f\"{best_grid['w_div']:.1f}), AUC={best_grid['auc']:.3f}\")\n",
    "\n",
    "overall_best_name, overall_best_aucs = sorted_methods[0]\n",
    "gain = overall_best_aucs.mean() - bare_aucs_ref.mean()\n",
    "print(f\"\\n--- OVERALL ---\")\n",
    "print(f\"  Best method: {overall_best_name}\")\n",
    "print(f\"  AUC: {overall_best_aucs.mean():.3f} (bare: {bare_aucs_ref.mean():.3f}, gain: {gain:+.3f})\")\n",
    "\n",
    "if gain > 0.02:\n",
    "    print(f\"\\n  >>> PRACTICAL IMPROVEMENT: +{gain:.3f} AUC\")\n",
    "    print(f\"  >>> Structural perturbation signals ARE useful for ranking\")\n",
    "elif gain > 0.01:\n",
    "    print(f\"\\n  >>> MODERATE IMPROVEMENT: +{gain:.3f} AUC\")\n",
    "else:\n",
    "    print(f\"\\n  >>> MINIMAL IMPROVEMENT over single-condition ranking from 04A\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# Save\n",
    "final_results = {\n",
    "    'experiment': 'exp11_delta_and_diversity',\n",
    "    'model': MODEL_NAME,\n",
    "    'n_queries': N_SAMPLES,\n",
    "    'k_prefixes': K_PREFIXES,\n",
    "    'n_bonferroni': N_BONFERRONI,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'phase_a': {\n",
    "        'delta_only_aucs': {c: float(delta_only_aucs[c].mean()) for c in PRIMED_CONDITIONS},\n",
    "        'lambda_results': {c: {\n",
    "            'best_lambda': lr['best_lambda'],\n",
    "            'best_auc': lr['best_auc'],\n",
    "            'aucs_by_lambda': lr['aucs_by_lambda'],\n",
    "        } for c, lr in lambda_results.items()},\n",
    "        'ensemble_structural_4_auc': float(struct_ensemble_aucs.mean()),\n",
    "        'ensemble_all_5_auc': float(all5_aucs.mean()),\n",
    "    },\n",
    "    'phase_b': {\n",
    "        'diversity_mean_auc': float(div_mean_aucs.mean()),\n",
    "        'std_direction': std_direction,\n",
    "        'std_best_auc': float(std_best_aucs.mean()),\n",
    "        'best_diversity_lambda': float(best_div_lambda),\n",
    "        'best_diversity_auc': float(best_div_auc),\n",
    "    },\n",
    "    'phase_c': {\n",
    "        'best_weights': {\n",
    "            'w_bare': best_grid['w_bare'],\n",
    "            'w_primed': best_grid['w_primed'],\n",
    "            'w_div': best_grid['w_div'],\n",
    "        },\n",
    "        'best_combined_auc': float(best_grid['auc']),\n",
    "    },\n",
    "    'bare_auc': float(bare_aucs_ref.mean()),\n",
    "    'grand_comparison': [\n",
    "        {'method': name, 'auc': float(aucs.mean())} for name, aucs in sorted_methods\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3800663f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:54:59.434596Z",
     "iopub.status.busy": "2026-02-19T14:54:59.434302Z",
     "iopub.status.idle": "2026-02-19T14:55:00.028321Z",
     "shell.execute_reply": "2026-02-19T14:55:00.027397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 15.03 GB -> 0.01 GB\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Cleanup\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, processor, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d083b9420ec4fc9b418daefb0387560": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b5a450a6db8d48789aa37e6f034bde14",
        "IPY_MODEL_452ca0e508c941e6bb9565784d5e71be",
        "IPY_MODEL_c22d5ac3cc3d4249a025857587dca062"
       ],
       "layout": "IPY_MODEL_742cb8cc6d8046d6b365c3d80b7df826",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0e0f218b85d74affa06782ced6605e72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d65e052894644435b1637c254cd7e0de",
        "IPY_MODEL_897e80d9eb6e48c3b6080f8df9e1f05b",
        "IPY_MODEL_c596f8b4b3cc47c4a58207a51f95332c"
       ],
       "layout": "IPY_MODEL_e0b557860d344803a6872ea2bbc6f244",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2dbc199aed2f423592987c1a47a646cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "34df85d6745845899c1d66d63fbea2bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "452ca0e508c941e6bb9565784d5e71be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ecbfa1df4c3410695a6a980ae3b3f86",
       "max": 1327.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2dbc199aed2f423592987c1a47a646cc",
       "tabbable": null,
       "tooltip": null,
       "value": 1327.0
      }
     },
     "4a6d9f4c5ba9486e80dc2384bdc10d60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b30bc0d8d4d433d9c2c006f3f443885": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "742cb8cc6d8046d6b365c3d80b7df826": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7495132f5c9e4733971cb5e0179efce2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83f1eb2ea00b4ed2bbe5f9961ba71442": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "897e80d9eb6e48c3b6080f8df9e1f05b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a6d9f4c5ba9486e80dc2384bdc10d60",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8bed013a97a46dc9f96ebed06fb2dd5",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "9ecbfa1df4c3410695a6a980ae3b3f86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a176c51ff8d14c0b8ed987b6faf8af39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5a450a6db8d48789aa37e6f034bde14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd18f6c7282b4dd296195742107a9298",
       "placeholder": "​",
       "style": "IPY_MODEL_7495132f5c9e4733971cb5e0179efce2",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "c22d5ac3cc3d4249a025857587dca062": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_34df85d6745845899c1d66d63fbea2bd",
       "placeholder": "​",
       "style": "IPY_MODEL_a176c51ff8d14c0b8ed987b6faf8af39",
       "tabbable": null,
       "tooltip": null,
       "value": " 1327/1327 [00:58&lt;00:00, 132.54it/s, Materializing param=model.encoder.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "c596f8b4b3cc47c4a58207a51f95332c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b30bc0d8d4d433d9c2c006f3f443885",
       "placeholder": "​",
       "style": "IPY_MODEL_83f1eb2ea00b4ed2bbe5f9961ba71442",
       "tabbable": null,
       "tooltip": null,
       "value": " 400/400 [1:53:23&lt;00:00, 18.91s/it]"
      }
     },
     "d65e052894644435b1637c254cd7e0de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e9453fe8a5d44cca9447609b1b422e2e",
       "placeholder": "​",
       "style": "IPY_MODEL_e0ab0c0c23e64f88a63829ef9210caa7",
       "tabbable": null,
       "tooltip": null,
       "value": "Prefix diversity: 100%"
      }
     },
     "e0ab0c0c23e64f88a63829ef9210caa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e0b557860d344803a6872ea2bbc6f244": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8bed013a97a46dc9f96ebed06fb2dd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e9453fe8a5d44cca9447609b1b422e2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd18f6c7282b4dd296195742107a9298": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
