{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 03: Combined Mechanisms + Suffix Length Scaling\n",
    "\n",
    "## Motivation\n",
    "Exp 02 found random-suffix (d=0.264) is ~3x stronger than random-truncated (d=0.091), with cross-mechanism correlation r=0.47. Two open questions:\n",
    "1. **Do they stack?** If partially independent, combining should yield d > 0.264.\n",
    "2. **Does suffix benefit diminish with passage length?** Random tokens are a smaller fraction of longer caches.\n",
    "\n",
    "## Conditions (5)\n",
    "\n",
    "| # | Name | Cache | Tests |\n",
    "|---|------|-------|-------|\n",
    "| 1 | **Bare** | `[BOS][doc]` (matched tokenization) | Baseline |\n",
    "| 2 | **Random-suffix** | `[BOS][doc][\\n\\nRelated question: ][random]` | Suffix alone (Exp 02 replication) |\n",
    "| 3 | **Random-truncated** | `[BOS][random\\n][doc]` → truncate + RoPE correct | Truncation alone (Exp 01/02 replication) |\n",
    "| 4 | **Random-combined** | `[BOS][random_prefix\\n][doc][\\n\\nRelated question: ][random_suffix]` → truncate prefix → RoPE correct | Both mechanisms stacked (NEW) |\n",
    "| 5 | **Separator-only** | `[BOS][doc][\\n\\nRelated question: ]` (no suffix tokens) | Separator framing vs random token regularization (NEW) |\n",
    "\n",
    "Conditions 3+4 share the same random prefix text (seed `SEED+idx`). Conditions 2+4 share the same random suffix text (seed `SEED+idx+N`). This isolates the incremental contribution of each mechanism.\n",
    "\n",
    "## Comparisons (7, Bonferroni alpha = 0.05/7 = 0.0071)\n",
    "\n",
    "**Combined mechanism:**\n",
    "- P1: Combined vs Bare — total combined effect\n",
    "- P2: Combined vs Random-suffix — does truncation add on top of suffix?\n",
    "- P3: Combined vs Random-truncated — does suffix add on top of truncation?\n",
    "\n",
    "**Separator decomposition + replication:**\n",
    "- S1: Random-suffix vs Bare — replication (expect d≈0.264)\n",
    "- S2: Random-truncated vs Bare — replication (expect d≈0.091)\n",
    "- S3: Separator-only vs Bare — does the separator framing alone help?\n",
    "- S4: Random-suffix vs Separator-only — do the random tokens add beyond the separator?\n",
    "\n",
    "**Additivity test**: paired t-test on `delta_combined - (delta_suffix + delta_truncated)` against zero.\n",
    "\n",
    "## Length scaling\n",
    "- Wider passage range: 20-500 words (vs 50-300)\n",
    "- Continuous regression: `delta ~ beta_0 + beta_1 * doc_token_len`\n",
    "- With hardness covariate: `delta ~ beta_0 + beta_1 * doc_len + beta_2 * bare_nll`\n",
    "- Quintile breakdown for all conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Results directory: results/exp03\n",
      "CUDA available: True\n",
      "GPU: NVIDIA L4\n",
      "GPU memory: 23.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup — permissions, seeds, output directory\n",
    "import os\n",
    "os.umask(0o000)  # Required: two-user environment (jupyter + CLI user)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Output directory\n",
    "RESULTS_DIR = Path(\"results/exp03\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paths\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mistralai/Mistral-7B-Instruct-v0.2 (4-bit)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcfafbf47da46b9beedfd665adf0087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.float16, device=cuda:0\n",
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load model (Mistral-7B 4-bit) — identical to Exp 01/02\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit)...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded. dtype={model.dtype}, device={model.device}\")\n",
    "print(f\"Vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  num_samples: 3000\n",
      "  passage words: 20-500\n",
      "  surrogate_prefix_template: '{surrogate}\\n'\n",
      "  document_template: '{document}'\n",
      "  query_template: '\\nQuery: {query}\\nAnswer:'\n",
      "  answer_template: ' {answer}'\n",
      "  suffix_separator: '\\n\\nRelated question: '\n",
      "  checkpoint_every: 50\n",
      "  n_comparisons: 7\n",
      "  bonferroni_alpha: 0.0071\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Library imports + config + templates\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.kv_cache import (\n",
    "    build_kv_cache,\n",
    "    build_suffix_kv_cache,\n",
    "    score_answer_with_cache,\n",
    "    deepcopy_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    ")\n",
    "from lib.data import load_ms_marco, load_evaluation_samples\n",
    "from lib.analysis import cohens_d\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_samples=3000,\n",
    "    min_passage_words=20,\n",
    "    max_passage_words=500,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Templates: NO framing to avoid \"Document:\\n\" artifact\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "\n",
    "# Query/answer format\n",
    "QUERY_TEMPLATE = \"\\nQuery: {query}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"  # Leading space for correct BPE of first word\n",
    "\n",
    "# Suffix separator\n",
    "SUFFIX_SEPARATOR = \"\\n\\nRelated question: \"\n",
    "\n",
    "# Checkpoint frequency\n",
    "CHECKPOINT_EVERY = 50\n",
    "\n",
    "# Bonferroni-corrected alpha for 7 comparisons\n",
    "N_COMPARISONS = 7\n",
    "BONFERRONI_ALPHA = 0.05 / N_COMPARISONS\n",
    "\n",
    "print(\"Config:\")\n",
    "print(f\"  num_samples: {config.num_samples}\")\n",
    "print(f\"  passage words: {config.min_passage_words}-{config.max_passage_words}\")\n",
    "print(f\"  surrogate_prefix_template: {repr(SURROGATE_PREFIX_TEMPLATE)}\")\n",
    "print(f\"  document_template: {repr(DOCUMENT_TEMPLATE)}\")\n",
    "print(f\"  query_template: {repr(QUERY_TEMPLATE)}\")\n",
    "print(f\"  answer_template: {repr(ANSWER_TEMPLATE)}\")\n",
    "print(f\"  suffix_separator: {repr(SUFFIX_SEPARATOR)}\")\n",
    "print(f\"  checkpoint_every: {CHECKPOINT_EVERY}\")\n",
    "print(f\"  n_comparisons: {N_COMPARISONS}\")\n",
    "print(f\"  bonferroni_alpha: {BONFERRONI_ALPHA:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'microsoft/ms_marco' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading microsoft/ms_marco dataset...\n",
      "Dataset loaded: 10047 samples\n",
      "Filtering samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2006f5d3b4854b0cbff54c688ea1f592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering:   0%|          | 0/10047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3000 samples\n",
      "\n",
      "Loaded 3000 samples\n",
      "\n",
      "Example sample:\n",
      "  Query: where is the rocky mountains located on a map...\n",
      "  Passage: The Rocky Mountains, commonly known as the Rockies, are a major mountain range in western North Amer...\n",
      "  Answer: Range in western North America. and also stretch from the northernmost part of British Columbia, in ...\n",
      "\n",
      "Passage word count distribution:\n",
      "  Min: 20, Max: 167\n",
      "  Mean: 73.2, Median: 74.0\n",
      "  Std: 26.3\n",
      "  Quintiles: [47 64 82 96]\n",
      "\n",
      "Word count bins:\n",
      "  [ 20- 40):   275 (9.2%)\n",
      "  [ 40- 60):   812 (27.1%)\n",
      "  [ 60- 80):   633 (21.1%)\n",
      "  [ 80-100):   788 (26.3%)\n",
      "  [100-120):   372 (12.4%)\n",
      "  [120-150):   112 (3.7%)\n",
      "  [150-200):     8 (0.3%)\n",
      "  [200-300):     0 (0.0%)\n",
      "  [300-500):     0 (0.0%)\n",
      "  [500+   ):     0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load dataset with wider word count filter; print length distribution\n",
    "dataset = load_ms_marco(config)\n",
    "\n",
    "# CRITICAL: Set seed immediately before load_evaluation_samples\n",
    "np.random.seed(SEED)\n",
    "samples = load_evaluation_samples(dataset, config, require_answer=True)\n",
    "\n",
    "N = len(samples)\n",
    "print(f\"\\nLoaded {N} samples\")\n",
    "print(f\"\\nExample sample:\")\n",
    "print(f\"  Query: {samples[0]['query'][:100]}...\")\n",
    "print(f\"  Passage: {samples[0]['passage'][:100]}...\")\n",
    "print(f\"  Answer: {samples[0]['answer'][:100]}...\")\n",
    "\n",
    "# Length distribution\n",
    "word_counts = [len(s['passage'].split()) for s in samples]\n",
    "word_counts_arr = np.array(word_counts)\n",
    "print(f\"\\nPassage word count distribution:\")\n",
    "print(f\"  Min: {word_counts_arr.min()}, Max: {word_counts_arr.max()}\")\n",
    "print(f\"  Mean: {word_counts_arr.mean():.1f}, Median: {np.median(word_counts_arr):.1f}\")\n",
    "print(f\"  Std: {word_counts_arr.std():.1f}\")\n",
    "print(f\"  Quintiles: {np.percentile(word_counts_arr, [20, 40, 60, 80]).astype(int)}\")\n",
    "\n",
    "# Histogram of word counts\n",
    "bins = [20, 40, 60, 80, 100, 120, 150, 200, 300, 500]\n",
    "print(f\"\\nWord count bins:\")\n",
    "for i in range(len(bins) - 1):\n",
    "    count = np.sum((word_counts_arr >= bins[i]) & (word_counts_arr < bins[i+1]))\n",
    "    print(f\"  [{bins[i]:>3}-{bins[i+1]:>3}): {count:>5} ({100*count/N:.1f}%)\")\n",
    "count_last = np.sum(word_counts_arr >= bins[-1])\n",
    "print(f\"  [{bins[-1]:>3}+   ): {count_last:>5} ({100*count_last/N:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle query: 'where is the rocky mountains located on a map'\n",
      "Oracle tokens: 10\n",
      "Random prefix: 'Restaur Mars didova少 DATA luxwalkshineLevel'...\n",
      "Random tokens: 10\n",
      "Length match: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: generate_random_prefix_text() — copy from Exp 01/02\n",
    "\n",
    "def generate_random_prefix_text(target_text, tokenizer, seed):\n",
    "    \"\"\"\n",
    "    Generate random text from vocabulary tokens that is length-matched\n",
    "    (in tokens) to target_text.\n",
    "    \n",
    "    Uses a decode->re-encode verification loop to ensure the random\n",
    "    prefix tokenizes to approximately the expected number of tokens.\n",
    "    \n",
    "    Args:\n",
    "        target_text: Text to match in token length\n",
    "        tokenizer: The tokenizer\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Random text string with same token count as target_text\n",
    "    \"\"\"\n",
    "    # Get target token count (no special tokens — we want content tokens only)\n",
    "    target_ids = tokenizer.encode(target_text, add_special_tokens=False)\n",
    "    target_len = len(target_ids)\n",
    "    \n",
    "    if target_len == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    vocab_size = len(tokenizer)\n",
    "    \n",
    "    # Sample random token IDs from the full vocabulary\n",
    "    # Exclude special tokens (typically IDs 0-2 for BOS, EOS, UNK)\n",
    "    min_id = 3  # Skip BOS, EOS, UNK\n",
    "    random_ids = rng.randint(min_id, vocab_size, size=target_len)\n",
    "    \n",
    "    # Decode to text\n",
    "    random_text = tokenizer.decode(random_ids.tolist(), skip_special_tokens=True)\n",
    "    \n",
    "    # Verification: re-encode and check length\n",
    "    reencoded = tokenizer.encode(random_text, add_special_tokens=False)\n",
    "    \n",
    "    # If lengths don't match after round-trip, truncate or pad\n",
    "    if len(reencoded) != target_len:\n",
    "        # Truncate the text and re-decode from exactly target_len tokens\n",
    "        if len(reencoded) > target_len:\n",
    "            random_text = tokenizer.decode(reencoded[:target_len], skip_special_tokens=True)\n",
    "        else:\n",
    "            # Pad with more random tokens\n",
    "            extra_needed = target_len - len(reencoded)\n",
    "            extra_ids = rng.randint(min_id, vocab_size, size=extra_needed)\n",
    "            extra_text = tokenizer.decode(extra_ids.tolist(), skip_special_tokens=True)\n",
    "            random_text = random_text + extra_text\n",
    "            reencoded2 = tokenizer.encode(random_text, add_special_tokens=False)\n",
    "            if len(reencoded2) > target_len:\n",
    "                random_text = tokenizer.decode(reencoded2[:target_len], skip_special_tokens=True)\n",
    "    \n",
    "    return random_text\n",
    "\n",
    "\n",
    "# Test the function\n",
    "test_query = samples[0]['query']\n",
    "test_random = generate_random_prefix_text(test_query, tokenizer, seed=SEED)\n",
    "\n",
    "oracle_tokens = tokenizer.encode(test_query, add_special_tokens=False)\n",
    "random_tokens = tokenizer.encode(test_random, add_special_tokens=False)\n",
    "\n",
    "print(f\"Oracle query: {repr(test_query)}\")\n",
    "print(f\"Oracle tokens: {len(oracle_tokens)}\")\n",
    "print(f\"Random prefix: {repr(test_random[:80])}...\")\n",
    "print(f\"Random tokens: {len(random_tokens)}\")\n",
    "print(f\"Length match: {len(oracle_tokens) == len(random_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Boundary Diagnostics\n",
      "============================================================\n",
      "\n",
      "(a) TRUNCATED: Independent vs concatenated tokenization\n",
      "  Tested 100 samples\n",
      "  BPE mismatches: 100/100 (100%)\n",
      "  -> Matched tokenization required for truncated conditions.\n",
      "\n",
      "(b) SUFFIX: Passage tokens consistency across different suffixes\n",
      "  Tested 50 samples\n",
      "  Passage tokens consistent: 50/50 (100%)\n",
      "  -> PASS: Passage tokens are identical regardless of suffix content.\n",
      "\n",
      "(c) COMBINED: Tokenization consistency check\n",
      "  Tested 50 samples\n",
      "  Combined keep_n in expected range: 50/50 (100%)\n",
      "  -> PASS: Combined condition tokenization is consistent.\n",
      "\n",
      "(d) SEPARATOR: Tokenization consistency across passages\n",
      "  Tested 50 samples\n",
      "  Separator adds 7.0 tokens on average (min=7, max=7)\n",
      "  -> PASS: Separator tokenization is perfectly consistent (7 tokens).\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: BPE diagnostics\n",
    "# (a) Truncated mismatch confirmation (same as Exp 01/02)\n",
    "# (b) Suffix passage token consistency\n",
    "# (c) Combined condition tokenization consistency\n",
    "# (d) Separator tokenization consistency\n",
    "\n",
    "print(\"BPE Boundary Diagnostics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- (a) Truncated mismatch confirmation ---\n",
    "print(\"\\n(a) TRUNCATED: Independent vs concatenated tokenization\")\n",
    "n_mismatch = 0\n",
    "n_total = min(100, N)\n",
    "\n",
    "for i in range(n_total):\n",
    "    passage = samples[i]['passage']\n",
    "    query = samples[i]['query']\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_text = oracle_prefix + document_text\n",
    "    full_ids = tokenizer.encode(full_text, add_special_tokens=True)\n",
    "    prefix_ids = tokenizer.encode(oracle_prefix, add_special_tokens=True)\n",
    "    prefix_len = len(prefix_ids)\n",
    "    doc_from_concat = full_ids[prefix_len:]\n",
    "    doc_independent = tokenizer.encode(passage, add_special_tokens=True)[1:]  # strip BOS\n",
    "    if doc_from_concat != doc_independent:\n",
    "        n_mismatch += 1\n",
    "\n",
    "print(f\"  Tested {n_total} samples\")\n",
    "print(f\"  BPE mismatches: {n_mismatch}/{n_total} ({100*n_mismatch/n_total:.0f}%)\")\n",
    "print(f\"  -> Matched tokenization required for truncated conditions.\")\n",
    "\n",
    "# --- (b) Suffix passage token consistency ---\n",
    "print(\"\\n(b) SUFFIX: Passage tokens consistency across different suffixes\")\n",
    "n_suffix_test = min(50, N)\n",
    "n_passage_consistent = 0\n",
    "\n",
    "for i in range(n_suffix_test):\n",
    "    passage = samples[i]['passage']\n",
    "    query = samples[i]['query']\n",
    "    random_text = generate_random_prefix_text(query, tokenizer, seed=SEED + i)\n",
    "\n",
    "    bare_ids = tokenizer.encode(passage, add_special_tokens=True)\n",
    "    oracle_suffix_text = passage + SUFFIX_SEPARATOR + query\n",
    "    oracle_suffix_ids = tokenizer.encode(oracle_suffix_text, add_special_tokens=True)\n",
    "    random_suffix_text = passage + SUFFIX_SEPARATOR + random_text\n",
    "    random_suffix_ids = tokenizer.encode(random_suffix_text, add_special_tokens=True)\n",
    "\n",
    "    bare_len = len(bare_ids)\n",
    "    oracle_passage_part = oracle_suffix_ids[:bare_len]\n",
    "    random_passage_part = random_suffix_ids[:bare_len]\n",
    "\n",
    "    if bare_ids == oracle_passage_part == random_passage_part:\n",
    "        n_passage_consistent += 1\n",
    "\n",
    "print(f\"  Tested {n_suffix_test} samples\")\n",
    "print(f\"  Passage tokens consistent: {n_passage_consistent}/{n_suffix_test} ({100*n_passage_consistent/n_suffix_test:.0f}%)\")\n",
    "if n_passage_consistent == n_suffix_test:\n",
    "    print(f\"  -> PASS: Passage tokens are identical regardless of suffix content.\")\n",
    "else:\n",
    "    n_diff = n_suffix_test - n_passage_consistent\n",
    "    print(f\"  -> WARNING: {n_diff} samples have different passage tokens with different suffixes.\")\n",
    "\n",
    "# --- (c) Combined condition tokenization check ---\n",
    "print(\"\\n(c) COMBINED: Tokenization consistency check\")\n",
    "n_combined_test = min(50, N)\n",
    "n_combined_ok = 0\n",
    "\n",
    "for i in range(n_combined_test):\n",
    "    passage = samples[i]['passage']\n",
    "    query = samples[i]['query']\n",
    "    random_prefix_text = generate_random_prefix_text(query, tokenizer, seed=SEED + i)\n",
    "    random_suffix_text = generate_random_prefix_text(query, tokenizer, seed=SEED + i + N)\n",
    "    \n",
    "    prefix_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=random_prefix_text)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    suffix_str = SUFFIX_SEPARATOR + random_suffix_text\n",
    "    \n",
    "    full_combined_text = prefix_str + document_text + suffix_str\n",
    "    full_combined_ids = tokenizer.encode(full_combined_text, add_special_tokens=True)\n",
    "    prefix_ids = tokenizer.encode(prefix_str, add_special_tokens=True)\n",
    "    prefix_token_len = len(prefix_ids)\n",
    "    keep_n = len(full_combined_ids) - prefix_token_len\n",
    "    \n",
    "    # Verify keep_n > 0 and reasonable\n",
    "    doc_ids = tokenizer.encode(passage, add_special_tokens=False)\n",
    "    sep_ids = tokenizer.encode(SUFFIX_SEPARATOR, add_special_tokens=False)\n",
    "    suffix_ids = tokenizer.encode(random_suffix_text, add_special_tokens=False)\n",
    "    expected_min = len(doc_ids) + len(sep_ids) + len(suffix_ids) - 5  # allow BPE variation\n",
    "    expected_max = len(doc_ids) + len(sep_ids) + len(suffix_ids) + 5\n",
    "    \n",
    "    if expected_min <= keep_n <= expected_max and keep_n > 0:\n",
    "        n_combined_ok += 1\n",
    "\n",
    "print(f\"  Tested {n_combined_test} samples\")\n",
    "print(f\"  Combined keep_n in expected range: {n_combined_ok}/{n_combined_test} ({100*n_combined_ok/n_combined_test:.0f}%)\")\n",
    "if n_combined_ok == n_combined_test:\n",
    "    print(f\"  -> PASS: Combined condition tokenization is consistent.\")\n",
    "else:\n",
    "    print(f\"  -> WARNING: {n_combined_test - n_combined_ok} samples have unexpected token counts.\")\n",
    "\n",
    "# --- (d) Separator tokenization consistency ---\n",
    "print(\"\\n(d) SEPARATOR: Tokenization consistency across passages\")\n",
    "n_sep_test = min(50, N)\n",
    "sep_only_ids_sets = []\n",
    "\n",
    "for i in range(n_sep_test):\n",
    "    passage = samples[i]['passage']\n",
    "    # separator-only: passage + separator (no suffix tokens)\n",
    "    sep_only_text = passage + SUFFIX_SEPARATOR\n",
    "    sep_only_ids = tokenizer.encode(sep_only_text, add_special_tokens=True)\n",
    "    bare_ids = tokenizer.encode(passage, add_special_tokens=True)\n",
    "    # The separator should add a consistent number of tokens\n",
    "    sep_only_ids_sets.append(len(sep_only_ids) - len(bare_ids))\n",
    "\n",
    "sep_extra = np.array(sep_only_ids_sets)\n",
    "print(f\"  Tested {n_sep_test} samples\")\n",
    "print(f\"  Separator adds {np.mean(sep_extra):.1f} tokens on average (min={sep_extra.min()}, max={sep_extra.max()})\")\n",
    "if sep_extra.min() == sep_extra.max():\n",
    "    print(f\"  -> PASS: Separator tokenization is perfectly consistent ({sep_extra[0]} tokens).\")\n",
    "else:\n",
    "    print(f\"  -> Note: Separator token count varies slightly due to BPE boundary effects.\")\n",
    "    print(f\"    This is expected and does not affect the experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare Baseline Fairness Diagnostic\n",
      "============================================================\n",
      "Comparing matched bare (from truncated tokenization) vs\n",
      "independent bare (build_kv_cache(passage)) on 20 samples.\n",
      "\n",
      "  Sample    Matched  Independent       Diff\n",
      "---------------------------------------------\n",
      "       0     1.4131       1.4258  -0.012695\n",
      "       1     2.2940       2.3565  -0.062500\n",
      "       2     0.6567       0.6581  -0.001379\n",
      "       3     0.5826       0.5772   0.005409\n",
      "       4     2.1058       2.1370  -0.031250\n",
      "       5     0.1321       0.1327  -0.000579\n",
      "       6     0.3503       0.3316   0.018663\n",
      "       7     0.0000       0.0000   0.000000\n",
      "       8     5.2344       5.1172   0.117188\n",
      "       9     0.7922       0.8000  -0.007812\n",
      "      10     1.3027       1.3009   0.001786\n",
      "      11     2.0703       2.0234   0.046875\n",
      "      12     2.4172       2.3969   0.020312\n",
      "      13     0.7026       0.6910   0.011593\n",
      "      14     1.4946       1.5009  -0.006250\n",
      "      15     0.2955       0.3209  -0.025391\n",
      "      16     0.7670       0.7622   0.004755\n",
      "      17     2.8633       2.7227   0.140625\n",
      "      18     1.2638       1.2703  -0.006541\n",
      "      19     0.1410       0.1510  -0.010062\n",
      "\n",
      "Non-zero NLL samples: 19/20\n",
      "Mean difference: 0.010671\n",
      "Mean abs difference: 0.027982\n",
      "Max abs difference: 0.140625\n",
      "\n",
      "CAUTION: Mean systematic bias (+0.0107) detected.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Bare baseline fairness diagnostic\n",
    "# Compare matched bare [BOS]+doc_ids vs independent build_kv_cache(passage) NLLs\n",
    "\n",
    "print(\"Bare Baseline Fairness Diagnostic\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing matched bare (from truncated tokenization) vs\")\n",
    "print(\"independent bare (build_kv_cache(passage)) on 20 samples.\")\n",
    "print()\n",
    "\n",
    "n_diag = 20\n",
    "matched_nlls = []\n",
    "independent_nlls = []\n",
    "\n",
    "for i in range(n_diag):\n",
    "    sample = samples[i]\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "\n",
    "    # --- Matched bare: [BOS] + doc_ids from oracle concatenation ---\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_oracle_enc = tokenizer(oracle_prefix + document_text, return_tensors=\"pt\",\n",
    "                                add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_oracle_ids = full_oracle_enc['input_ids'].to(config.device)\n",
    "    oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    oracle_prefix_len = oracle_prefix_enc['input_ids'].shape[1]\n",
    "    bos_id = full_oracle_ids[:, :1]\n",
    "    doc_ids = full_oracle_ids[:, oracle_prefix_len:]\n",
    "    bare_ids = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    bare_len = bare_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_ids, attention_mask=torch.ones_like(bare_ids),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    matched_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_out.past_key_values), bare_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    matched_nlls.append(matched_nll)\n",
    "\n",
    "    # --- Independent bare: build_kv_cache(passage) ---\n",
    "    indep_len, indep_cache = build_kv_cache(passage, model, tokenizer, config)\n",
    "    independent_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(indep_cache), indep_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    independent_nlls.append(independent_nll)\n",
    "\n",
    "    del bare_out, indep_cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "matched_nlls = np.array(matched_nlls)\n",
    "independent_nlls = np.array(independent_nlls)\n",
    "diffs = matched_nlls - independent_nlls\n",
    "\n",
    "print(f\"{'Sample':>8} {'Matched':>10} {'Independent':>12} {'Diff':>10}\")\n",
    "print(\"-\" * 45)\n",
    "for i in range(n_diag):\n",
    "    print(f\"{i:>8} {matched_nlls[i]:>10.4f} {independent_nlls[i]:>12.4f} {diffs[i]:>10.6f}\")\n",
    "\n",
    "nonzero_mask = (matched_nlls != 0.0) & (independent_nlls != 0.0)\n",
    "diffs_nonzero = diffs[nonzero_mask]\n",
    "n_nonzero = np.sum(nonzero_mask)\n",
    "\n",
    "print(f\"\\nNon-zero NLL samples: {n_nonzero}/{n_diag}\")\n",
    "print(f\"Mean difference: {np.mean(diffs_nonzero):.6f}\")\n",
    "print(f\"Mean abs difference: {np.mean(np.abs(diffs_nonzero)):.6f}\")\n",
    "print(f\"Max abs difference: {np.max(np.abs(diffs_nonzero)):.6f}\")\n",
    "\n",
    "mean_bias = np.mean(diffs_nonzero)\n",
    "if abs(mean_bias) < 0.01:\n",
    "    print(f\"\\nPASS: Mean systematic bias ({mean_bias:+.4f}) is negligible.\")\n",
    "    print(f\"Bare baseline is fair for both mechanisms.\")\n",
    "else:\n",
    "    print(f\"\\nCAUTION: Mean systematic bias ({mean_bias:+.4f}) detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENTAL CONDITIONS EXPLAINED\n",
      "======================================================================\n",
      "\n",
      "Example passage: 'The Rocky Mountains, commonly known as the Rockies, are a major mountain range i...'\n",
      "Example query:   'where is the rocky mountains located on a map'\n",
      "Example answer:  'Range in western North America. and also stretch from the no...'\n",
      "Example random prefix: 'Restaur Mars didova少 DATA luxwalkshineLevel'...\n",
      "Example random suffix: 'Douglas algoactualTCদanel associate […] civ keeps'...\n",
      "\n",
      "______________________________________________________________________\n",
      "MATCHED TOKENIZATION (for truncated conditions)\n",
      "  Tokenize oracle_prefix + passage together -> 123 tokens\n",
      "  Oracle prefix tokens (with BOS): 12\n",
      "  Document tokens (shared by truncated + bare): 111\n",
      "\n",
      "______________________________________________________________________\n",
      "### CONDITION 1: BARE (baseline) ###\n",
      "  Input IDs:  [BOS] + doc_ids (112 tokens)\n",
      "  Key insight: Pure baseline. Same doc tokens as truncated conditions.\n",
      "\n",
      "______________________________________________________________________\n",
      "### CONDITION 2: RANDOM-SUFFIX ###\n",
      "  Build:  [BOS][passage][separator][random_suffix] (128 tokens)\n",
      "  Scoring: Query attends to passage + separator + suffix KV entries\n",
      "  Key insight: Passage KV entries IDENTICAL to bare (causal masking).\n",
      "  Replicates Exp 02 (expected d~0.264).\n",
      "\n",
      "______________________________________________________________________\n",
      "### CONDITION 3: RANDOM-TRUNCATED ###\n",
      "  Build:  [BOS][random_prefix\\n][doc_ids]\n",
      "  After:  Truncate prefix -> [BOS] + doc_ids (112 tokens) + RoPE correct\n",
      "  Key insight: Value contamination from random prefix.\n",
      "  Replicates Exp 01/02 (expected d~0.091).\n",
      "\n",
      "______________________________________________________________________\n",
      "### CONDITION 4: RANDOM-COMBINED (NEW) ###\n",
      "  Build:  [BOS][random_prefix\\n][doc][separator][random_suffix] (139 tokens)\n",
      "  After:  Truncate prefix -> [BOS] + doc + sep + suffix (128 tokens) + RoPE correct\n",
      "  Key insight: Both truncation (value contamination) AND suffix (attention target).\n",
      "  Tests whether the two mechanisms stack.\n",
      "\n",
      "______________________________________________________________________\n",
      "### CONDITION 5: SEPARATOR-ONLY (NEW) ###\n",
      "  Build:  [BOS][passage][separator] (119 tokens)\n",
      "  Scoring: Query attends to passage + separator KV entries (no suffix tokens)\n",
      "  Key insight: Isolates separator framing from random token effect.\n",
      "  If S3 sig: separator framing alone helps. If S4 sig: random tokens add beyond separator.\n",
      "\n",
      "______________________________________________________________________\n",
      "DESIGN NOTES:\n",
      "  Random PREFIX (cond 3+4): seed SEED+idx (shared)\n",
      "  Random SUFFIX (cond 2+4): seed SEED+idx+N (shared, different from prefix)\n",
      "  Suffix separator: '\\n\\nRelated question: '\n",
      "  CACHE SAFETY: deepcopy_cache() before every score call.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Condition explanation printout (all 5 conditions with concrete examples)\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPERIMENTAL CONDITIONS EXPLAINED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ex = samples[0]\n",
    "ex_query = ex['query']\n",
    "ex_passage = ex['passage'][:80] + \"...\"\n",
    "ex_answer = ex['answer'][:60] + \"...\"\n",
    "ex_random_prefix = generate_random_prefix_text(ex_query, tokenizer, seed=SEED)\n",
    "ex_random_suffix = generate_random_prefix_text(ex_query, tokenizer, seed=SEED + N)\n",
    "\n",
    "print(f\"\\nExample passage: {repr(ex_passage)}\")\n",
    "print(f\"Example query:   {repr(ex_query)}\")\n",
    "print(f\"Example answer:  {repr(ex_answer)}\")\n",
    "print(f\"Example random prefix: {repr(ex_random_prefix[:60])}...\")\n",
    "print(f\"Example random suffix: {repr(ex_random_suffix[:60])}...\")\n",
    "\n",
    "# Show matched tokenization\n",
    "oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=ex_query)\n",
    "doc_text = DOCUMENT_TEMPLATE.format(document=ex['passage'])\n",
    "full_text = oracle_prefix + doc_text\n",
    "full_ids = tokenizer.encode(full_text, add_special_tokens=True)\n",
    "prefix_ids = tokenizer.encode(oracle_prefix, add_special_tokens=True)\n",
    "prefix_len = len(prefix_ids)\n",
    "doc_ids = full_ids[prefix_len:]\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"MATCHED TOKENIZATION (for truncated conditions)\")\n",
    "print(f\"  Tokenize oracle_prefix + passage together -> {len(full_ids)} tokens\")\n",
    "print(f\"  Oracle prefix tokens (with BOS): {prefix_len}\")\n",
    "print(f\"  Document tokens (shared by truncated + bare): {len(doc_ids)}\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"### CONDITION 1: BARE (baseline) ###\")\n",
    "print(f\"  Input IDs:  [BOS] + doc_ids ({1 + len(doc_ids)} tokens)\")\n",
    "print(f\"  Key insight: Pure baseline. Same doc tokens as truncated conditions.\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"### CONDITION 2: RANDOM-SUFFIX ###\")\n",
    "suffix_random_text = ex['passage'] + SUFFIX_SEPARATOR + ex_random_suffix\n",
    "suffix_random_ids = tokenizer.encode(suffix_random_text, add_special_tokens=True)\n",
    "print(f\"  Build:  [BOS][passage][separator][random_suffix] ({len(suffix_random_ids)} tokens)\")\n",
    "print(f\"  Scoring: Query attends to passage + separator + suffix KV entries\")\n",
    "print(f\"  Key insight: Passage KV entries IDENTICAL to bare (causal masking).\")\n",
    "print(f\"  Replicates Exp 02 (expected d~0.264).\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"### CONDITION 3: RANDOM-TRUNCATED ###\")\n",
    "print(f\"  Build:  [BOS][random_prefix\\\\n][doc_ids]\")\n",
    "print(f\"  After:  Truncate prefix -> [BOS] + doc_ids ({1 + len(doc_ids)} tokens) + RoPE correct\")\n",
    "print(f\"  Key insight: Value contamination from random prefix.\")\n",
    "print(f\"  Replicates Exp 01/02 (expected d~0.091).\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"### CONDITION 4: RANDOM-COMBINED (NEW) ###\")\n",
    "prefix_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=ex_random_prefix)\n",
    "suffix_str = SUFFIX_SEPARATOR + ex_random_suffix\n",
    "combined_text = prefix_str + doc_text + suffix_str\n",
    "combined_ids = tokenizer.encode(combined_text, add_special_tokens=True)\n",
    "prefix_enc = tokenizer.encode(prefix_str, add_special_tokens=True)\n",
    "keep_n_ex = len(combined_ids) - len(prefix_enc)\n",
    "print(f\"  Build:  [BOS][random_prefix\\\\n][doc][separator][random_suffix] ({len(combined_ids)} tokens)\")\n",
    "print(f\"  After:  Truncate prefix -> [BOS] + doc + sep + suffix ({1 + keep_n_ex} tokens) + RoPE correct\")\n",
    "print(f\"  Key insight: Both truncation (value contamination) AND suffix (attention target).\")\n",
    "print(f\"  Tests whether the two mechanisms stack.\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"### CONDITION 5: SEPARATOR-ONLY (NEW) ###\")\n",
    "sep_only_text = ex['passage'] + SUFFIX_SEPARATOR\n",
    "sep_only_ids = tokenizer.encode(sep_only_text, add_special_tokens=True)\n",
    "print(f\"  Build:  [BOS][passage][separator] ({len(sep_only_ids)} tokens)\")\n",
    "print(f\"  Scoring: Query attends to passage + separator KV entries (no suffix tokens)\")\n",
    "print(f\"  Key insight: Isolates separator framing from random token effect.\")\n",
    "print(f\"  If S3 sig: separator framing alone helps. If S4 sig: random tokens add beyond separator.\")\n",
    "\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"DESIGN NOTES:\")\n",
    "print(f\"  Random PREFIX (cond 3+4): seed SEED+idx (shared)\")\n",
    "print(f\"  Random SUFFIX (cond 2+4): seed SEED+idx+N (shared, different from prefix)\")\n",
    "print(f\"  Suffix separator: {repr(SUFFIX_SEPARATOR)}\")\n",
    "print(f\"  CACHE SAFETY: deepcopy_cache() before every score call.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3000\n",
      "No checkpoint found. Starting from scratch.\n",
      "Will evaluate samples 0 to 2999\n",
      "\n",
      "Conditions per sample: 5\n",
      "Total condition evaluations: 15000\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Evaluation parameters + checkpoint loading\n",
    "\n",
    "print(f\"Total samples: {N}\")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    with open(CHECKPOINT_PATH, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "\n",
    "    # Verify checkpoint matches current sample list (resume correctness)\n",
    "    ckpt_sample_ids = checkpoint.get('sample_queries', [])\n",
    "    current_sample_ids = [s['query'] for s in samples]\n",
    "\n",
    "    if ckpt_sample_ids == current_sample_ids:\n",
    "        results = checkpoint['results']\n",
    "        start_idx = len(results)\n",
    "        print(f\"Resuming from checkpoint: {start_idx}/{N} samples completed\")\n",
    "    else:\n",
    "        print(\"WARNING: Checkpoint sample list doesn't match current samples.\")\n",
    "        print(\"Starting from scratch.\")\n",
    "        results = []\n",
    "        start_idx = 0\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "\n",
    "print(f\"Will evaluate samples {start_idx} to {N-1}\")\n",
    "print(f\"\\nConditions per sample: 5\")\n",
    "print(f\"Total condition evaluations: {(N - start_idx) * 5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b959f33cff3241639df27f01215fda6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint at 50/3000 | Rate: 0.5 samples/s | ETA: 103.9 min\n",
      "  Checkpoint at 100/3000 | Rate: 0.5 samples/s | ETA: 103.1 min\n",
      "  Checkpoint at 150/3000 | Rate: 0.5 samples/s | ETA: 101.5 min\n",
      "  Checkpoint at 200/3000 | Rate: 0.5 samples/s | ETA: 100.3 min\n",
      "  Checkpoint at 250/3000 | Rate: 0.5 samples/s | ETA: 98.8 min\n",
      "  Checkpoint at 300/3000 | Rate: 0.5 samples/s | ETA: 96.8 min\n",
      "  Checkpoint at 350/3000 | Rate: 0.5 samples/s | ETA: 95.2 min\n",
      "  Checkpoint at 400/3000 | Rate: 0.5 samples/s | ETA: 93.4 min\n",
      "  Checkpoint at 450/3000 | Rate: 0.5 samples/s | ETA: 91.6 min\n",
      "  Checkpoint at 500/3000 | Rate: 0.5 samples/s | ETA: 89.8 min\n",
      "  Checkpoint at 550/3000 | Rate: 0.5 samples/s | ETA: 88.1 min\n",
      "  Checkpoint at 600/3000 | Rate: 0.5 samples/s | ETA: 86.4 min\n",
      "  Checkpoint at 650/3000 | Rate: 0.5 samples/s | ETA: 84.7 min\n",
      "  Checkpoint at 700/3000 | Rate: 0.5 samples/s | ETA: 82.9 min\n",
      "  Checkpoint at 750/3000 | Rate: 0.5 samples/s | ETA: 81.1 min\n",
      "  Checkpoint at 800/3000 | Rate: 0.5 samples/s | ETA: 79.3 min\n",
      "  Checkpoint at 850/3000 | Rate: 0.5 samples/s | ETA: 77.5 min\n",
      "  Checkpoint at 900/3000 | Rate: 0.5 samples/s | ETA: 75.8 min\n",
      "  Checkpoint at 950/3000 | Rate: 0.5 samples/s | ETA: 74.0 min\n",
      "  Checkpoint at 1000/3000 | Rate: 0.5 samples/s | ETA: 72.2 min\n",
      "  Checkpoint at 1050/3000 | Rate: 0.5 samples/s | ETA: 70.4 min\n",
      "  Checkpoint at 1100/3000 | Rate: 0.5 samples/s | ETA: 68.7 min\n",
      "  Checkpoint at 1150/3000 | Rate: 0.5 samples/s | ETA: 66.9 min\n",
      "  Checkpoint at 1200/3000 | Rate: 0.5 samples/s | ETA: 65.1 min\n",
      "  Checkpoint at 1250/3000 | Rate: 0.5 samples/s | ETA: 63.3 min\n",
      "  Checkpoint at 1300/3000 | Rate: 0.5 samples/s | ETA: 61.5 min\n",
      "  Checkpoint at 1350/3000 | Rate: 0.5 samples/s | ETA: 59.7 min\n",
      "  Checkpoint at 1400/3000 | Rate: 0.5 samples/s | ETA: 57.9 min\n",
      "  Checkpoint at 1450/3000 | Rate: 0.5 samples/s | ETA: 56.0 min\n",
      "  Checkpoint at 1500/3000 | Rate: 0.5 samples/s | ETA: 54.2 min\n",
      "  Checkpoint at 1550/3000 | Rate: 0.5 samples/s | ETA: 52.4 min\n",
      "  Checkpoint at 1600/3000 | Rate: 0.5 samples/s | ETA: 50.6 min\n",
      "  Checkpoint at 1650/3000 | Rate: 0.5 samples/s | ETA: 48.8 min\n",
      "  Checkpoint at 1700/3000 | Rate: 0.5 samples/s | ETA: 47.0 min\n",
      "  Checkpoint at 1750/3000 | Rate: 0.5 samples/s | ETA: 45.2 min\n",
      "  Checkpoint at 1800/3000 | Rate: 0.5 samples/s | ETA: 43.4 min\n",
      "  Checkpoint at 1850/3000 | Rate: 0.5 samples/s | ETA: 41.6 min\n",
      "  Checkpoint at 1900/3000 | Rate: 0.5 samples/s | ETA: 39.8 min\n",
      "  Checkpoint at 1950/3000 | Rate: 0.5 samples/s | ETA: 38.0 min\n",
      "  Checkpoint at 2000/3000 | Rate: 0.5 samples/s | ETA: 36.2 min\n",
      "  Checkpoint at 2050/3000 | Rate: 0.5 samples/s | ETA: 34.4 min\n",
      "  Checkpoint at 2100/3000 | Rate: 0.5 samples/s | ETA: 32.6 min\n",
      "  Checkpoint at 2150/3000 | Rate: 0.5 samples/s | ETA: 30.8 min\n",
      "  Checkpoint at 2200/3000 | Rate: 0.5 samples/s | ETA: 29.0 min\n",
      "  Checkpoint at 2250/3000 | Rate: 0.5 samples/s | ETA: 27.1 min\n",
      "  Checkpoint at 2300/3000 | Rate: 0.5 samples/s | ETA: 25.3 min\n",
      "  Checkpoint at 2350/3000 | Rate: 0.5 samples/s | ETA: 23.5 min\n",
      "  Checkpoint at 2400/3000 | Rate: 0.5 samples/s | ETA: 21.7 min\n",
      "  Checkpoint at 2450/3000 | Rate: 0.5 samples/s | ETA: 19.9 min\n",
      "  Checkpoint at 2500/3000 | Rate: 0.5 samples/s | ETA: 18.1 min\n",
      "  Checkpoint at 2550/3000 | Rate: 0.5 samples/s | ETA: 16.3 min\n",
      "  Checkpoint at 2600/3000 | Rate: 0.5 samples/s | ETA: 14.5 min\n",
      "  Checkpoint at 2650/3000 | Rate: 0.5 samples/s | ETA: 12.7 min\n",
      "  Checkpoint at 2700/3000 | Rate: 0.5 samples/s | ETA: 10.9 min\n",
      "  Checkpoint at 2750/3000 | Rate: 0.5 samples/s | ETA: 9.1 min\n",
      "  Checkpoint at 2800/3000 | Rate: 0.5 samples/s | ETA: 7.2 min\n",
      "  Checkpoint at 2850/3000 | Rate: 0.5 samples/s | ETA: 5.4 min\n",
      "  Checkpoint at 2900/3000 | Rate: 0.5 samples/s | ETA: 3.6 min\n",
      "  Checkpoint at 2950/3000 | Rate: 0.5 samples/s | ETA: 1.8 min\n",
      "  Checkpoint at 3000/3000 | Rate: 0.5 samples/s | ETA: 0.0 min\n",
      "\n",
      "Evaluation complete: 3000 samples in 108.6 minutes\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Main evaluation loop (5 conditions x N samples, with checkpointing)\n",
    "#\n",
    "# Conditions:\n",
    "#   1. Bare — [BOS] + doc_ids (matched tokenization)\n",
    "#   2. Random-suffix — build_suffix_kv_cache(passage, random_suffix)\n",
    "#   3. Random-truncated — [BOS][random_prefix\\n][doc_ids] -> truncate + RoPE correct\n",
    "#   4. Random-combined — [BOS][random_prefix\\n][doc][sep][random_suffix] -> truncate prefix -> RoPE correct\n",
    "#   5. Separator-only — build_suffix_kv_cache(passage, \"\", sep=SUFFIX_SEPARATOR)\n",
    "#\n",
    "# Random prefix (cond 3+4): seed SEED+idx\n",
    "# Random suffix (cond 2+4): seed SEED+idx+N\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for idx in tqdm(range(start_idx, N), initial=start_idx, total=N, desc=\"Evaluating\"):\n",
    "    sample = samples[idx]\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "\n",
    "    # === Step 1: Determine canonical document token IDs (for truncated conditions) ===\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_oracle_text = oracle_prefix + document_text\n",
    "\n",
    "    full_oracle_enc = tokenizer(full_oracle_text, return_tensors=\"pt\",\n",
    "                                add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_oracle_ids = full_oracle_enc['input_ids'].to(config.device)\n",
    "\n",
    "    oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    oracle_prefix_len = oracle_prefix_enc['input_ids'].shape[1]  # includes BOS\n",
    "\n",
    "    bos_id = full_oracle_ids[:, :1]\n",
    "    doc_ids = full_oracle_ids[:, oracle_prefix_len:]\n",
    "    doc_len = doc_ids.shape[1]\n",
    "\n",
    "    # Generate random text — two independent seeds\n",
    "    random_prefix_text = generate_random_prefix_text(query, tokenizer, seed=SEED + idx)\n",
    "    random_suffix_text = generate_random_prefix_text(query, tokenizer, seed=SEED + idx + N)\n",
    "\n",
    "    # === Condition 1: BARE — [BOS] + doc_ids ===\n",
    "    bare_ids = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    bare_len = bare_ids.shape[1]  # = 1 + doc_len\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_ids, attention_mask=torch.ones_like(bare_ids),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_cache = bare_out.past_key_values\n",
    "    bare_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_cache), bare_len, query_prompt, answer_text,\n",
    "        model, tokenizer, config\n",
    "    )\n",
    "\n",
    "    # === Condition 2: RANDOM-SUFFIX — build_suffix_kv_cache(passage, random_suffix) ===\n",
    "    random_sfx_len, random_sfx_cache = build_suffix_kv_cache(\n",
    "        passage, random_suffix_text, model, tokenizer, config, separator=SUFFIX_SEPARATOR)\n",
    "    random_suffix_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(random_sfx_cache), random_sfx_len, query_prompt, answer_text,\n",
    "        model, tokenizer, config\n",
    "    )\n",
    "\n",
    "    # === Condition 3: RANDOM-TRUNCATED — [BOS][random_prefix\\n][doc_ids] -> truncate ===\n",
    "    random_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=random_prefix_text)\n",
    "    random_prefix_enc = tokenizer(random_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=False, padding=False, truncation=False)\n",
    "    random_prefix_ids = random_prefix_enc['input_ids'].to(config.device)\n",
    "    random_full_ids = torch.cat([bos_id, random_prefix_ids, doc_ids], dim=1)\n",
    "    random_prefix_len = 1 + random_prefix_ids.shape[1]  # BOS + prefix tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        random_trunc_out = model(input_ids=random_full_ids,\n",
    "                                 attention_mask=torch.ones_like(random_full_ids),\n",
    "                                 use_cache=True, return_dict=True)\n",
    "    random_trunc_cache = extract_and_truncate_cache_with_bos(random_trunc_out.past_key_values, doc_len)\n",
    "    random_trunc_len = 1 + doc_len\n",
    "    correct_rope_positions_with_bos(random_trunc_cache, random_prefix_len - 1, model)\n",
    "    random_trunc_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(random_trunc_cache), random_trunc_len, query_prompt, answer_text,\n",
    "        model, tokenizer, config\n",
    "    )\n",
    "\n",
    "    # === Condition 4: RANDOM-COMBINED ===\n",
    "    # Build full text: prefix\\n + passage + separator + suffix\n",
    "    prefix_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=random_prefix_text)\n",
    "    suffix_str = SUFFIX_SEPARATOR + random_suffix_text\n",
    "    full_combined_text = prefix_str + document_text + suffix_str\n",
    "\n",
    "    full_combined_enc = tokenizer(full_combined_text, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_combined_ids = full_combined_enc['input_ids'].to(config.device)\n",
    "    full_combined_len = full_combined_ids.shape[1]\n",
    "\n",
    "    # Determine prefix length for truncation boundary\n",
    "    prefix_enc = tokenizer(prefix_str, return_tensors=\"pt\",\n",
    "                           add_special_tokens=True, padding=False, truncation=False)\n",
    "    prefix_token_len = prefix_enc['input_ids'].shape[1]  # includes BOS\n",
    "\n",
    "    # keep_n = everything after the prefix (doc + sep + suffix tokens)\n",
    "    keep_n = full_combined_len - prefix_token_len\n",
    "\n",
    "    with torch.no_grad():\n",
    "        combined_out = model(input_ids=full_combined_ids,\n",
    "                             attention_mask=torch.ones_like(full_combined_ids),\n",
    "                             use_cache=True, return_dict=True)\n",
    "\n",
    "    # Truncate: keep [BOS] + last keep_n positions\n",
    "    combined_cache = extract_and_truncate_cache_with_bos(combined_out.past_key_values, keep_n)\n",
    "    combined_len = 1 + keep_n  # BOS + doc + sep + suffix\n",
    "\n",
    "    # RoPE correct: shift = prefix_token_len - 1 (prefix tokens minus BOS)\n",
    "    correct_rope_positions_with_bos(combined_cache, prefix_token_len - 1, model)\n",
    "\n",
    "    combined_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(combined_cache), combined_len, query_prompt, answer_text,\n",
    "        model, tokenizer, config\n",
    "    )\n",
    "\n",
    "    # === Condition 5: SEPARATOR-ONLY — build_suffix_kv_cache(passage, \"\") ===\n",
    "    sep_only_len, sep_only_cache = build_suffix_kv_cache(\n",
    "        passage, \"\", model, tokenizer, config, separator=SUFFIX_SEPARATOR)\n",
    "    separator_only_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(sep_only_cache), sep_only_len, query_prompt, answer_text,\n",
    "        model, tokenizer, config\n",
    "    )\n",
    "\n",
    "    # Record all 5 NLLs + cache lengths + precomputed deltas\n",
    "    result = {\n",
    "        'idx': idx,\n",
    "        'bare_nll': bare_nll,\n",
    "        'random_suffix_nll': random_suffix_nll,\n",
    "        'random_trunc_nll': random_trunc_nll,\n",
    "        'combined_nll': combined_nll,\n",
    "        'separator_only_nll': separator_only_nll,\n",
    "        'bare_len': bare_len,\n",
    "        'random_suffix_len': random_sfx_len,\n",
    "        'random_trunc_len': random_trunc_len,\n",
    "        'combined_len': combined_len,\n",
    "        'separator_only_len': sep_only_len,\n",
    "        'doc_len': doc_len,\n",
    "        'passage_word_count': len(passage.split()),\n",
    "        # Precomputed deltas (positive = first condition has LOWER NLL = better)\n",
    "        # P1: Combined vs Bare\n",
    "        'delta_combined_vs_bare': bare_nll - combined_nll,\n",
    "        # P2: Combined vs Random-suffix\n",
    "        'delta_combined_vs_suffix': random_suffix_nll - combined_nll,\n",
    "        # P3: Combined vs Random-truncated\n",
    "        'delta_combined_vs_trunc': random_trunc_nll - combined_nll,\n",
    "        # S1: Random-suffix vs Bare\n",
    "        'delta_suffix_vs_bare': bare_nll - random_suffix_nll,\n",
    "        # S2: Random-truncated vs Bare\n",
    "        'delta_trunc_vs_bare': bare_nll - random_trunc_nll,\n",
    "        # S3: Separator-only vs Bare\n",
    "        'delta_seponly_vs_bare': bare_nll - separator_only_nll,\n",
    "        # S4: Random-suffix vs Separator-only\n",
    "        'delta_suffix_vs_seponly': separator_only_nll - random_suffix_nll,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    # GPU memory management\n",
    "    del bare_cache, bare_out, random_sfx_cache, random_trunc_cache, random_trunc_out\n",
    "    del combined_cache, combined_out, sep_only_cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Checkpoint\n",
    "    if (idx + 1) % CHECKPOINT_EVERY == 0 or idx == N - 1:\n",
    "        checkpoint_data = {\n",
    "            'results': results,\n",
    "            'sample_queries': [s['query'] for s in samples],\n",
    "            'completed': len(results),\n",
    "            'total': N,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, 'w') as f:\n",
    "            json.dump(checkpoint_data, f)\n",
    "\n",
    "        elapsed = time.time() - t_start\n",
    "        samples_done = idx - start_idx + 1\n",
    "        rate = samples_done / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N - idx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint at {idx+1}/{N} | Rate: {rate:.1f} samples/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nEvaluation complete: {len(results)} samples in {elapsed_total/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache Length Diagnostics\n",
      "============================================================\n",
      "\n",
      "(a) TRUNCATED: All cache lengths match bare?\n",
      "  All truncated cache lengths match (bare == random-trunc == 1+doc): True\n",
      "  PASS: Matched tokenization guarantees identical cache lengths.\n",
      "\n",
      "(b) SUFFIX: Cache length distribution\n",
      "  Random-suffix extra tokens (vs bare):  mean=13.7, min=7, max=29\n",
      "  Separator-only extra tokens (vs bare):  mean=6.9, min=5, max=9\n",
      "  Combined extra tokens (vs bare):  mean=13.9, min=8, max=29\n",
      "\n",
      "  Expected: combined_extra ~= suffix_extra (both have sep + suffix tokens)\n",
      "  Combined - Suffix extra diff: mean=0.12, min=-2, max=2\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Cache length diagnostics\n",
    "print(\"Cache Length Diagnostics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Truncated match check ---\n",
    "print(\"\\n(a) TRUNCATED: All cache lengths match bare?\")\n",
    "bare_lens = [r['bare_len'] for r in results]\n",
    "random_trunc_lens = [r['random_trunc_len'] for r in results]\n",
    "doc_lens = [r['doc_len'] for r in results]\n",
    "\n",
    "all_trunc_match = all(\n",
    "    b == rt == 1 + d\n",
    "    for b, rt, d in zip(bare_lens, random_trunc_lens, doc_lens)\n",
    ")\n",
    "print(f\"  All truncated cache lengths match (bare == random-trunc == 1+doc): {all_trunc_match}\")\n",
    "if all_trunc_match:\n",
    "    print(\"  PASS: Matched tokenization guarantees identical cache lengths.\")\n",
    "else:\n",
    "    mismatches = sum(1 for b, rt in zip(bare_lens, random_trunc_lens) if b != rt)\n",
    "    print(f\"  WARNING: {mismatches} samples have mismatched truncated lengths!\")\n",
    "\n",
    "# --- Suffix length distribution ---\n",
    "print(\"\\n(b) SUFFIX: Cache length distribution\")\n",
    "random_sfx_lens = np.array([r['random_suffix_len'] for r in results])\n",
    "sep_only_lens = np.array([r['separator_only_len'] for r in results])\n",
    "combined_lens = np.array([r['combined_len'] for r in results])\n",
    "bare_lens_arr = np.array(bare_lens)\n",
    "\n",
    "random_sfx_extra = random_sfx_lens - bare_lens_arr\n",
    "sep_only_extra = sep_only_lens - bare_lens_arr\n",
    "combined_extra = combined_lens - bare_lens_arr\n",
    "\n",
    "print(f\"  Random-suffix extra tokens (vs bare):  mean={np.mean(random_sfx_extra):.1f}, min={np.min(random_sfx_extra)}, max={np.max(random_sfx_extra)}\")\n",
    "print(f\"  Separator-only extra tokens (vs bare):  mean={np.mean(sep_only_extra):.1f}, min={np.min(sep_only_extra)}, max={np.max(sep_only_extra)}\")\n",
    "print(f\"  Combined extra tokens (vs bare):  mean={np.mean(combined_extra):.1f}, min={np.min(combined_extra)}, max={np.max(combined_extra)}\")\n",
    "\n",
    "print(f\"\\n  Expected: combined_extra ~= suffix_extra (both have sep + suffix tokens)\")\n",
    "combined_vs_sfx_diff = combined_extra - random_sfx_extra\n",
    "print(f\"  Combined - Suffix extra diff: mean={np.mean(combined_vs_sfx_diff):.2f}, min={np.min(combined_vs_sfx_diff)}, max={np.max(combined_vs_sfx_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRIMARY ANALYSIS — 7 COMPARISONS WITH BONFERRONI CORRECTION\n",
      "======================================================================\n",
      "Total samples: 3000\n",
      "Excluded (zero NLL from single-token answers): 248\n",
      "Valid samples for analysis: 2752\n",
      "Bonferroni-corrected alpha: 0.0071 (0.05 / 7)\n",
      "\n",
      "Condition              Mean NLL        Std     Median\n",
      "-------------------------------------------------------\n",
      "Bare                     1.1258     1.5961     0.6097\n",
      "Random-suffix            1.0344     1.5293     0.5359\n",
      "Random-truncated         1.0753     1.5520     0.5795\n",
      "Combined                 1.0453     1.5569     0.5357\n",
      "Separator-only           1.0255     1.4248     0.5520\n",
      "\n",
      "__________________________________________________________________________________________\n",
      "PAIRED COMPARISONS (positive delta = first condition has LOWER NLL = better)\n",
      "__________________________________________________________________________________________\n",
      "\n",
      "Comparison                            Mean D        d    Win%        t            p   Sig\n",
      "----------------------------------------------------------------------------------------\n",
      "P1: Combined vs Bare                  0.0806    0.209   63.6%    10.95    2.31e-27   ***\n",
      "P2: Combined vs Random-suffix        -0.0108   -0.047   50.1%    -2.46    1.39e-02     *\n",
      "P3: Combined vs Random-trunc          0.0300    0.104   57.7%     5.46    5.24e-08   ***\n",
      "S1: Random-suffix vs Bare             0.0914    0.270   66.9%    14.15    6.14e-44   ***\n",
      "S2: Random-trunc vs Bare              0.0505    0.160   61.7%     8.40    7.13e-17   ***\n",
      "S3: Separator-only vs Bare            0.1003    0.224   66.2%    11.76    3.60e-31   ***\n",
      "S4: Random-suffix vs Sep-only        -0.0089   -0.020   47.1%    -1.05    2.93e-01    ns\n",
      "\n",
      "Significance levels: *** p<0.001, ** p<0.0071 (Bonferroni), * p<0.05, ns = not significant\n",
      "Cohen's d interpretation: |d|<0.2 = negligible, 0.2-0.5 = small, 0.5-0.8 = medium, >0.8 = large\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Primary analysis — filter zeros, compute all 7 comparisons with Bonferroni\n",
    "print(\"=\" * 70)\n",
    "print(\"PRIMARY ANALYSIS — 7 COMPARISONS WITH BONFERRONI CORRECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "bare_nlls_raw = np.array([r['bare_nll'] for r in results])\n",
    "random_suffix_nlls_raw = np.array([r['random_suffix_nll'] for r in results])\n",
    "random_trunc_nlls_raw = np.array([r['random_trunc_nll'] for r in results])\n",
    "combined_nlls_raw = np.array([r['combined_nll'] for r in results])\n",
    "seponly_nlls_raw = np.array([r['separator_only_nll'] for r in results])\n",
    "\n",
    "# Sanity checks\n",
    "for name, arr in [('bare', bare_nlls_raw), ('random_suffix', random_suffix_nlls_raw),\n",
    "                   ('random_trunc', random_trunc_nlls_raw), ('combined', combined_nlls_raw),\n",
    "                   ('separator_only', seponly_nlls_raw)]:\n",
    "    assert not np.any(np.isnan(arr)), f\"NaN in {name} NLLs!\"\n",
    "\n",
    "# Filter out degenerate samples where ANY NLL is 0.0\n",
    "valid_mask = (\n",
    "    (bare_nlls_raw != 0.0) &\n",
    "    (random_suffix_nlls_raw != 0.0) &\n",
    "    (random_trunc_nlls_raw != 0.0) &\n",
    "    (combined_nlls_raw != 0.0) &\n",
    "    (seponly_nlls_raw != 0.0)\n",
    ")\n",
    "n_invalid = np.sum(~valid_mask)\n",
    "n_valid = np.sum(valid_mask)\n",
    "print(f\"Total samples: {len(results)}\")\n",
    "print(f\"Excluded (zero NLL from single-token answers): {n_invalid}\")\n",
    "print(f\"Valid samples for analysis: {n_valid}\")\n",
    "print(f\"Bonferroni-corrected alpha: {BONFERRONI_ALPHA:.4f} (0.05 / {N_COMPARISONS})\\n\")\n",
    "\n",
    "bare = bare_nlls_raw[valid_mask]\n",
    "random_suffix = random_suffix_nlls_raw[valid_mask]\n",
    "random_trunc = random_trunc_nlls_raw[valid_mask]\n",
    "combined = combined_nlls_raw[valid_mask]\n",
    "sep_only = seponly_nlls_raw[valid_mask]\n",
    "\n",
    "# NLL summary\n",
    "print(f\"{'Condition':<20} {'Mean NLL':>10} {'Std':>10} {'Median':>10}\")\n",
    "print(\"-\" * 55)\n",
    "for name, arr in [('Bare', bare), ('Random-suffix', random_suffix),\n",
    "                   ('Random-truncated', random_trunc), ('Combined', combined),\n",
    "                   ('Separator-only', sep_only)]:\n",
    "    print(f\"{name:<20} {np.mean(arr):>10.4f} {np.std(arr):>10.4f} {np.median(arr):>10.4f}\")\n",
    "\n",
    "# All 7 comparisons\n",
    "# Convention: positive delta = first condition is BETTER (lower NLL)\n",
    "comparisons = [\n",
    "    # Primary — Combined mechanism\n",
    "    ('P1: Combined vs Bare', bare - combined, 'Total combined effect?'),\n",
    "    ('P2: Combined vs Random-suffix', random_suffix - combined, 'Does truncation add on top of suffix?'),\n",
    "    ('P3: Combined vs Random-trunc', random_trunc - combined, 'Does suffix add on top of truncation?'),\n",
    "    # Secondary — Separator decomposition + replication\n",
    "    ('S1: Random-suffix vs Bare', bare - random_suffix, 'Replication (expect d~0.264)?'),\n",
    "    ('S2: Random-trunc vs Bare', bare - random_trunc, 'Replication (expect d~0.091)?'),\n",
    "    ('S3: Separator-only vs Bare', bare - sep_only, 'Separator framing alone?'),\n",
    "    ('S4: Random-suffix vs Sep-only', sep_only - random_suffix, 'Random tokens beyond separator?'),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'_' * 90}\")\n",
    "print(\"PAIRED COMPARISONS (positive delta = first condition has LOWER NLL = better)\")\n",
    "print(f\"{'_' * 90}\")\n",
    "print(f\"\\n{'Comparison':<35} {'Mean D':>8} {'d':>8} {'Win%':>7} {'t':>8} {'p':>12} {'Sig':>5}\")\n",
    "print(\"-\" * 88)\n",
    "\n",
    "comparison_results = {}\n",
    "for name, delta, question in comparisons:\n",
    "    d = cohens_d(delta)\n",
    "    win_rate = np.mean(delta > 0) * 100\n",
    "    t_stat, p_val = stats.ttest_1samp(delta, 0)\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    bonf_sig = p_val < BONFERRONI_ALPHA\n",
    "    print(f\"{name:<35} {np.mean(delta):>8.4f} {d:>8.3f} {win_rate:>6.1f}% {t_stat:>8.2f} {p_val:>11.2e} {sig:>5}\")\n",
    "    comparison_results[name] = {\n",
    "        'mean_delta': float(np.mean(delta)),\n",
    "        'cohens_d': float(d),\n",
    "        'win_rate': float(win_rate / 100),\n",
    "        't_stat': float(t_stat),\n",
    "        'p_value': float(p_val),\n",
    "        'bonferroni_significant': bool(bonf_sig),\n",
    "        'question': question,\n",
    "    }\n",
    "\n",
    "print(f\"\\nSignificance levels: *** p<0.001, ** p<{BONFERRONI_ALPHA:.4f} (Bonferroni), * p<0.05, ns = not significant\")\n",
    "print(f\"Cohen's d interpretation: |d|<0.2 = negligible, 0.2-0.5 = small, 0.5-0.8 = medium, >0.8 = large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY TABLE WITH VERDICTS\n",
      "======================================================================\n",
      "\n",
      "N = 2752 valid samples (of 3000 total)\n",
      "Bonferroni-corrected alpha = 0.0071\n",
      "\n",
      "Q: Total combined effect?\n",
      "  P1: Combined vs Bare\n",
      "  D = +0.0806, d = +0.209, Win% = 63.6%, p = 2.31e-27\n",
      "  -> YES — significant benefit (survives Bonferroni)\n",
      "\n",
      "Q: Does truncation add on top of suffix?\n",
      "  P2: Combined vs Random-suffix\n",
      "  D = -0.0108, d = -0.047, Win% = 50.1%, p = 1.39e-02\n",
      "  -> Suggestive harm (p<0.05 but fails Bonferroni)\n",
      "\n",
      "Q: Does suffix add on top of truncation?\n",
      "  P3: Combined vs Random-trunc\n",
      "  D = +0.0300, d = +0.104, Win% = 57.7%, p = 5.24e-08\n",
      "  -> YES — significant benefit (survives Bonferroni)\n",
      "\n",
      "Q: Replication (expect d~0.264)?\n",
      "  S1: Random-suffix vs Bare\n",
      "  D = +0.0914, d = +0.270, Win% = 66.9%, p = 6.14e-44\n",
      "  -> YES — significant benefit (survives Bonferroni)\n",
      "\n",
      "Q: Replication (expect d~0.091)?\n",
      "  S2: Random-trunc vs Bare\n",
      "  D = +0.0505, d = +0.160, Win% = 61.7%, p = 7.13e-17\n",
      "  -> YES — significant benefit (survives Bonferroni)\n",
      "\n",
      "Q: Separator framing alone?\n",
      "  S3: Separator-only vs Bare\n",
      "  D = +0.1003, d = +0.224, Win% = 66.2%, p = 3.60e-31\n",
      "  -> YES — significant benefit (survives Bonferroni)\n",
      "\n",
      "Q: Random tokens beyond separator?\n",
      "  S4: Random-suffix vs Sep-only\n",
      "  D = -0.0089, d = -0.020, Win% = 47.1%, p = 2.93e-01\n",
      "  -> NO — not significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Summary table with verdicts\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY TABLE WITH VERDICTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nN = {n_valid} valid samples (of {len(results)} total)\")\n",
    "print(f\"Bonferroni-corrected alpha = {BONFERRONI_ALPHA:.4f}\\n\")\n",
    "\n",
    "for name, delta, question in comparisons:\n",
    "    cr = comparison_results[name]\n",
    "    d = cr['cohens_d']\n",
    "    p = cr['p_value']\n",
    "    bonf = cr['bonferroni_significant']\n",
    "    win = cr['win_rate'] * 100\n",
    "\n",
    "    if bonf:\n",
    "        if cr['mean_delta'] > 0:\n",
    "            verdict = \"YES — significant benefit (survives Bonferroni)\"\n",
    "        else:\n",
    "            verdict = \"YES — significant HARM (survives Bonferroni)\"\n",
    "    elif p < 0.05:\n",
    "        if cr['mean_delta'] > 0:\n",
    "            verdict = \"Suggestive benefit (p<0.05 but fails Bonferroni)\"\n",
    "        else:\n",
    "            verdict = \"Suggestive harm (p<0.05 but fails Bonferroni)\"\n",
    "    else:\n",
    "        verdict = \"NO — not significant\"\n",
    "\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"  {name}\")\n",
    "    print(f\"  D = {cr['mean_delta']:+.4f}, d = {d:+.3f}, Win% = {win:.1f}%, p = {p:.2e}\")\n",
    "    print(f\"  -> {verdict}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ADDITIVITY TEST\n",
      "======================================================================\n",
      "\n",
      "H0: delta_combined = delta_suffix + delta_truncated\n",
      "(positive remainder = super-additive, negative = sub-additive)\n",
      "\n",
      "Mean delta_combined:   +0.0806\n",
      "Mean delta_suffix:     +0.0914\n",
      "Mean delta_truncated:  +0.0505\n",
      "Sum of individuals:    +0.1419\n",
      "Remainder (combined - sum): -0.0613\n",
      "\n",
      "Cohen's d of remainder: -0.223\n",
      "t = -11.72, p = 5.34e-31\n",
      "\n",
      "-> SUB-ADDITIVE: Combined effect is less than sum of parts.\n",
      "   (Expected given r=0.47 cross-mechanism correlation from Exp 02)\n",
      "\n",
      "Cross-mechanism correlation: r = 0.410, p = 3.82e-112\n",
      "  (Exp 02 found r = 0.47)\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Additivity test\n",
    "# Test whether combined effect = suffix effect + truncation effect\n",
    "# If sub-additive (expected given r=0.47), the remainder is negative\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ADDITIVITY TEST\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nH0: delta_combined = delta_suffix + delta_truncated\")\n",
    "print(\"(positive remainder = super-additive, negative = sub-additive)\\n\")\n",
    "\n",
    "delta_combined = bare - combined\n",
    "delta_suffix = bare - random_suffix\n",
    "delta_trunc = bare - random_trunc\n",
    "\n",
    "# Remainder: how much the combined effect exceeds the sum of individual effects\n",
    "remainder = delta_combined - (delta_suffix + delta_trunc)\n",
    "\n",
    "t_stat_add, p_val_add = stats.ttest_1samp(remainder, 0)\n",
    "d_add = cohens_d(remainder)\n",
    "\n",
    "print(f\"Mean delta_combined:   {np.mean(delta_combined):+.4f}\")\n",
    "print(f\"Mean delta_suffix:     {np.mean(delta_suffix):+.4f}\")\n",
    "print(f\"Mean delta_truncated:  {np.mean(delta_trunc):+.4f}\")\n",
    "print(f\"Sum of individuals:    {np.mean(delta_suffix) + np.mean(delta_trunc):+.4f}\")\n",
    "print(f\"Remainder (combined - sum): {np.mean(remainder):+.4f}\")\n",
    "print(f\"\\nCohen's d of remainder: {d_add:+.3f}\")\n",
    "print(f\"t = {t_stat_add:.2f}, p = {p_val_add:.2e}\")\n",
    "\n",
    "if p_val_add < 0.05:\n",
    "    if np.mean(remainder) > 0:\n",
    "        print(\"\\n-> SUPER-ADDITIVE: Combined effect exceeds sum of parts.\")\n",
    "    else:\n",
    "        print(\"\\n-> SUB-ADDITIVE: Combined effect is less than sum of parts.\")\n",
    "        print(\"   (Expected given r=0.47 cross-mechanism correlation from Exp 02)\")\n",
    "else:\n",
    "    print(\"\\n-> ADDITIVE: Combined effect ≈ sum of parts (within noise).\")\n",
    "\n",
    "# Cross-mechanism correlation in this dataset\n",
    "r_cross, p_cross = stats.pearsonr(delta_suffix, delta_trunc)\n",
    "print(f\"\\nCross-mechanism correlation: r = {r_cross:.3f}, p = {p_cross:.2e}\")\n",
    "print(f\"  (Exp 02 found r = 0.47)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LENGTH SCALING ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "--- (a) Regression: delta_suffix ~ doc_token_len ---\n",
      "  beta_0 (intercept) = 0.1965 (p = 4.19e-25)\n",
      "  beta_1 (doc_len)   = -0.000949 (p = 3.02e-09)\n",
      "  R^2 = 0.0127\n",
      "  -> Significant: suffix benefit DECREASING with passage length\n",
      "\n",
      "--- (b) Regression: delta_suffix ~ doc_len + bare_nll ---\n",
      "  beta_0 (intercept) = 0.1094 (p = 6.10e-09)\n",
      "  beta_1 (doc_len)   = -0.000796 (p = 2.03e-07)\n",
      "  beta_2 (bare_nll)  = 0.0623 (p = 2.49e-56)\n",
      "  R^2 = 0.0986\n",
      "\n",
      "--- (c) Regression: delta_suffix ~ suffix_fraction ---\n",
      "  beta_0 (intercept)        = -0.0105 (p = 5.67e-01)\n",
      "  beta_1 (suffix_fraction)  = 0.8453 (p = 3.36e-09)\n",
      "  R^2 = 0.0126\n",
      "\n",
      "--- (d) Quintile breakdown by passage length ---\n",
      "\n",
      "Bin                N       Tokens        Words   d_Suffix   Win%    d_Trunc   Win% d_Combined   Win% d_Sep-only   Win%\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Q1 (short)       539       59tok       41wds      0.369  75.3%      0.286  71.1%      0.320  72.5%      0.303  69.0%\n",
      "Q2               542       82tok       54wds      0.286  67.3%      0.267  69.0%      0.286  67.3%      0.299  65.9%\n",
      "Q3               550      109tok       74wds      0.274  65.6%      0.106  58.0%      0.167  60.0%      0.188  66.4%\n",
      "Q4               562      133tok       89wds      0.264  65.7%      0.078  57.3%      0.178  60.5%      0.189  63.9%\n",
      "Q5 (long)        559      169tok      105wds      0.136  60.6%     -0.014  53.7%      0.047  58.1%      0.118  66.2%\n",
      "\n",
      "Suffix d across quintiles: ['0.369', '0.286', '0.274', '0.264', '0.136']\n",
      "-> MONOTONICALLY DECREASING (consistent with length dilution hypothesis)\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Length scaling — regression + quintile breakdown\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LENGTH SCALING ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get per-sample data (aligned with valid_mask)\n",
    "doc_lens_valid = np.array([r['doc_len'] for r in results])[valid_mask]\n",
    "word_counts_valid = np.array([r['passage_word_count'] for r in results])[valid_mask]\n",
    "\n",
    "# ========== Continuous regression: delta_suffix ~ doc_token_len ==========\n",
    "print(\"\\n--- (a) Regression: delta_suffix ~ doc_token_len ---\")\n",
    "X = sm.add_constant(doc_lens_valid)\n",
    "model_ols = sm.OLS(delta_suffix, X).fit()\n",
    "print(f\"  beta_0 (intercept) = {model_ols.params[0]:.4f} (p = {model_ols.pvalues[0]:.2e})\")\n",
    "print(f\"  beta_1 (doc_len)   = {model_ols.params[1]:.6f} (p = {model_ols.pvalues[1]:.2e})\")\n",
    "print(f\"  R^2 = {model_ols.rsquared:.4f}\")\n",
    "if model_ols.pvalues[1] < 0.05:\n",
    "    direction = \"DECREASING\" if model_ols.params[1] < 0 else \"INCREASING\"\n",
    "    print(f\"  -> Significant: suffix benefit {direction} with passage length\")\n",
    "else:\n",
    "    print(f\"  -> Not significant: no length dependence detected\")\n",
    "\n",
    "# ========== With hardness covariate ==========\n",
    "print(\"\\n--- (b) Regression: delta_suffix ~ doc_len + bare_nll ---\")\n",
    "X2 = sm.add_constant(np.column_stack([doc_lens_valid, bare]))\n",
    "model_ols2 = sm.OLS(delta_suffix, X2).fit()\n",
    "print(f\"  beta_0 (intercept) = {model_ols2.params[0]:.4f} (p = {model_ols2.pvalues[0]:.2e})\")\n",
    "print(f\"  beta_1 (doc_len)   = {model_ols2.params[1]:.6f} (p = {model_ols2.pvalues[1]:.2e})\")\n",
    "print(f\"  beta_2 (bare_nll)  = {model_ols2.params[2]:.4f} (p = {model_ols2.pvalues[2]:.2e})\")\n",
    "print(f\"  R^2 = {model_ols2.rsquared:.4f}\")\n",
    "\n",
    "# ========== Suffix fraction regression ==========\n",
    "print(\"\\n--- (c) Regression: delta_suffix ~ suffix_fraction ---\")\n",
    "random_sfx_lens_valid = np.array([r['random_suffix_len'] for r in results])[valid_mask]\n",
    "suffix_fraction = (random_sfx_lens_valid - np.array(bare_lens)[valid_mask]) / random_sfx_lens_valid\n",
    "X3 = sm.add_constant(suffix_fraction)\n",
    "model_ols3 = sm.OLS(delta_suffix, X3).fit()\n",
    "print(f\"  beta_0 (intercept)        = {model_ols3.params[0]:.4f} (p = {model_ols3.pvalues[0]:.2e})\")\n",
    "print(f\"  beta_1 (suffix_fraction)  = {model_ols3.params[1]:.4f} (p = {model_ols3.pvalues[1]:.2e})\")\n",
    "print(f\"  R^2 = {model_ols3.rsquared:.4f}\")\n",
    "\n",
    "# ========== Quintile breakdown (by doc token length) ==========\n",
    "print(\"\\n--- (d) Quintile breakdown by passage length ---\")\n",
    "quintile_edges = np.percentile(doc_lens_valid, [0, 20, 40, 60, 80, 100])\n",
    "q_labels = ['Q1 (short)', 'Q2', 'Q3', 'Q4', 'Q5 (long)']\n",
    "\n",
    "# Header\n",
    "print(f\"\\n{'Bin':<14} {'N':>5} {'Tokens':>12} {'Words':>12}\", end='')\n",
    "for cname in ['Suffix', 'Trunc', 'Combined', 'Sep-only']:\n",
    "    print(f\" {'d_'+cname:>10} {'Win%':>6}\", end='')\n",
    "print()\n",
    "print(\"-\" * 120)\n",
    "\n",
    "quintile_results = {}\n",
    "for qi in range(5):\n",
    "    lo = quintile_edges[qi]\n",
    "    hi = quintile_edges[qi + 1]\n",
    "    if qi == 4:  # last bin inclusive\n",
    "        mask = (doc_lens_valid >= lo) & (doc_lens_valid <= hi)\n",
    "    else:\n",
    "        mask = (doc_lens_valid >= lo) & (doc_lens_valid < hi)\n",
    "    n_q = np.sum(mask)\n",
    "    mean_tokens = np.mean(doc_lens_valid[mask])\n",
    "    mean_words = np.mean(word_counts_valid[mask])\n",
    "\n",
    "    row = f\"{q_labels[qi]:<14} {n_q:>5} {mean_tokens:>8.0f}tok {mean_words:>8.0f}wds\"\n",
    "    \n",
    "    q_data = {}\n",
    "    for cname, delta_arr in [('Suffix', delta_suffix), ('Trunc', delta_trunc),\n",
    "                              ('Combined', delta_combined), ('Sep-only', bare - sep_only)]:\n",
    "        dq = delta_arr[mask]\n",
    "        d_q = cohens_d(dq)\n",
    "        win_q = np.mean(dq > 0) * 100\n",
    "        row += f\" {d_q:>10.3f} {win_q:>5.1f}%\"\n",
    "        q_data[cname] = {'d': float(d_q), 'win': float(win_q / 100), 'n': int(n_q),\n",
    "                         'mean_delta': float(np.mean(dq))}\n",
    "    \n",
    "    print(row)\n",
    "    quintile_results[q_labels[qi]] = q_data\n",
    "\n",
    "# Monotonicity: is suffix d decreasing across quintiles?\n",
    "suffix_ds = [quintile_results[ql]['Suffix']['d'] for ql in q_labels]\n",
    "print(f\"\\nSuffix d across quintiles: {[f'{d:.3f}' for d in suffix_ds]}\")\n",
    "if all(suffix_ds[i] >= suffix_ds[i+1] for i in range(4)):\n",
    "    print(\"-> MONOTONICALLY DECREASING (consistent with length dilution hypothesis)\")\n",
    "else:\n",
    "    print(\"-> NOT monotonically decreasing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SEPARATOR DECOMPOSITION BY LENGTH\n",
      "======================================================================\n",
      "\n",
      "Two competing hypotheses:\n",
      "  A (Separator framing): sep-only captures most benefit, constant with length\n",
      "  B (Random token regularization): sep-only ~0, suffix decreases with length\n",
      "\n",
      "--- Regression: delta_sep_only ~ doc_len ---\n",
      "  beta_1 (doc_len) = -0.001070 (p = 4.27e-07)\n",
      "  R^2 = 0.0093\n",
      "\n",
      "--- Regression: delta_suffix_vs_sep ~ doc_len ---\n",
      "  beta_1 (doc_len) = 0.000121 (p = 5.66e-01)\n",
      "  R^2 = 0.0001\n",
      "\n",
      "--- Quintile breakdown ---\n",
      "Bin                N  d_SepOnly    Win%  d_Sfx-Sep    Win%\n",
      "------------------------------------------------------------\n",
      "Q1 (short)       539      0.303   69.0%     -0.012   46.6%\n",
      "Q2               542      0.299   65.9%     -0.051   48.5%\n",
      "Q3               550      0.188   66.4%     -0.016   45.8%\n",
      "Q4               562      0.189   63.9%      0.006   49.3%\n",
      "Q5 (long)        559      0.118   66.2%     -0.017   45.1%\n",
      "\n",
      "Interpretation matrix:\n",
      "  S3 significant (separator alone)? True\n",
      "  S4 significant (random beyond sep)? False\n",
      "  -> Hypothesis A: SEPARATOR FRAMING explains the effect\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Separator decomposition by length\n",
    "print(\"=\" * 70)\n",
    "print(\"SEPARATOR DECOMPOSITION BY LENGTH\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nTwo competing hypotheses:\")\n",
    "print(\"  A (Separator framing): sep-only captures most benefit, constant with length\")\n",
    "print(\"  B (Random token regularization): sep-only ~0, suffix decreases with length\")\n",
    "\n",
    "delta_seponly = bare - sep_only\n",
    "delta_suffix_vs_sep = sep_only - random_suffix  # positive = suffix better than sep-only\n",
    "\n",
    "# Regression: separator-only benefit vs length\n",
    "print(\"\\n--- Regression: delta_sep_only ~ doc_len ---\")\n",
    "X_sep = sm.add_constant(doc_lens_valid)\n",
    "model_sep = sm.OLS(delta_seponly, X_sep).fit()\n",
    "print(f\"  beta_1 (doc_len) = {model_sep.params[1]:.6f} (p = {model_sep.pvalues[1]:.2e})\")\n",
    "print(f\"  R^2 = {model_sep.rsquared:.4f}\")\n",
    "\n",
    "# Regression: random tokens beyond separator vs length\n",
    "print(\"\\n--- Regression: delta_suffix_vs_sep ~ doc_len ---\")\n",
    "model_sfx_sep = sm.OLS(delta_suffix_vs_sep, X_sep).fit()\n",
    "print(f\"  beta_1 (doc_len) = {model_sfx_sep.params[1]:.6f} (p = {model_sfx_sep.pvalues[1]:.2e})\")\n",
    "print(f\"  R^2 = {model_sfx_sep.rsquared:.4f}\")\n",
    "\n",
    "# Quintile breakdown\n",
    "print(\"\\n--- Quintile breakdown ---\")\n",
    "print(f\"{'Bin':<14} {'N':>5} {'d_SepOnly':>10} {'Win%':>7} {'d_Sfx-Sep':>10} {'Win%':>7}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for qi in range(5):\n",
    "    lo = quintile_edges[qi]\n",
    "    hi = quintile_edges[qi + 1]\n",
    "    if qi == 4:\n",
    "        mask = (doc_lens_valid >= lo) & (doc_lens_valid <= hi)\n",
    "    else:\n",
    "        mask = (doc_lens_valid >= lo) & (doc_lens_valid < hi)\n",
    "    n_q = np.sum(mask)\n",
    "    \n",
    "    d_sep = cohens_d(delta_seponly[mask])\n",
    "    win_sep = np.mean(delta_seponly[mask] > 0) * 100\n",
    "    d_sfx_sep = cohens_d(delta_suffix_vs_sep[mask])\n",
    "    win_sfx_sep = np.mean(delta_suffix_vs_sep[mask] > 0) * 100\n",
    "    \n",
    "    print(f\"{q_labels[qi]:<14} {n_q:>5} {d_sep:>10.3f} {win_sep:>6.1f}% {d_sfx_sep:>10.3f} {win_sfx_sep:>6.1f}%\")\n",
    "\n",
    "# Verdict\n",
    "cr_s3 = comparison_results.get('S3: Separator-only vs Bare', {})\n",
    "cr_s4 = comparison_results.get('S4: Random-suffix vs Sep-only', {})\n",
    "s3_sig = cr_s3.get('bonferroni_significant', False)\n",
    "s4_sig = cr_s4.get('bonferroni_significant', False)\n",
    "\n",
    "print(f\"\\nInterpretation matrix:\")\n",
    "print(f\"  S3 significant (separator alone)? {s3_sig}\")\n",
    "print(f\"  S4 significant (random beyond sep)? {s4_sig}\")\n",
    "if s3_sig and not s4_sig:\n",
    "    print(\"  -> Hypothesis A: SEPARATOR FRAMING explains the effect\")\n",
    "elif not s3_sig and s4_sig:\n",
    "    print(\"  -> Hypothesis B: RANDOM TOKEN REGULARIZATION is the mechanism\")\n",
    "elif s3_sig and s4_sig:\n",
    "    print(\"  -> BOTH contribute: separator framing AND random tokens\")\n",
    "else:\n",
    "    print(\"  -> Neither alone significant: full suffix needed (interaction effect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HARDNESS INTERACTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Pearson r of bare NLL (hardness) with condition benefit:\n",
      "Condition                        r            p\n",
      "------------------------------------------------\n",
      "Random-suffix               0.2995     3.97e-58\n",
      "Random-truncated            0.2369     2.11e-36\n",
      "Combined                    0.2213     7.27e-32\n",
      "Separator-only              0.5026    4.38e-176\n",
      "\n",
      "Quartile breakdown (by bare NLL hardness):\n",
      "Quartile         N     Bare D_Random-s d_Random-s D_Random-t d_Random-t D_Combined d_Combined D_Separato d_Separato\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Q1 (easy)      688    0.079     0.0002    0.003     0.0055    0.099     0.0010    0.016    -0.0369   -0.258\n",
      "Q2             688    0.408     0.0397    0.321     0.0257    0.202     0.0384    0.240     0.0004    0.002\n",
      "Q3             688    0.941     0.0978    0.477     0.0518    0.267     0.0905    0.364     0.0840    0.239\n",
      "Q4 (hard)      688    3.075     0.2278    0.375     0.1191    0.206     0.1924    0.277     0.3536    0.494\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Hardness interaction (all 4 non-bare conditions)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HARDNESS INTERACTION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "conditions_hardness = [\n",
    "    ('Random-suffix', delta_suffix),\n",
    "    ('Random-truncated', delta_trunc),\n",
    "    ('Combined', delta_combined),\n",
    "    ('Separator-only', delta_seponly),\n",
    "]\n",
    "\n",
    "print(f\"\\nPearson r of bare NLL (hardness) with condition benefit:\")\n",
    "print(f\"{'Condition':<25} {'r':>8} {'p':>12}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "hardness_results = {}\n",
    "for name, delta in conditions_hardness:\n",
    "    r, p = stats.pearsonr(bare, delta)\n",
    "    print(f\"{name:<25} {r:>8.4f} {p:>12.2e}\")\n",
    "    hardness_results[name] = {'r': float(r), 'p': float(p)}\n",
    "\n",
    "# Quartile breakdown\n",
    "quartiles = np.percentile(bare, [25, 50, 75])\n",
    "q_labels_h = ['Q1 (easy)', 'Q2', 'Q3', 'Q4 (hard)']\n",
    "q_bounds = [(-np.inf, quartiles[0]), (quartiles[0], quartiles[1]),\n",
    "            (quartiles[1], quartiles[2]), (quartiles[2], np.inf)]\n",
    "\n",
    "print(f\"\\nQuartile breakdown (by bare NLL hardness):\")\n",
    "header = f\"{'Quartile':<12} {'N':>5} {'Bare':>8}\"\n",
    "for name, _ in conditions_hardness:\n",
    "    short = name[:8]\n",
    "    header += f\" {'D_'+short:>10} {'d_'+short:>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for label, (lo, hi) in zip(q_labels_h, q_bounds):\n",
    "    mask = (bare > lo) & (bare <= hi)\n",
    "    n_q = np.sum(mask)\n",
    "    mean_bare = np.mean(bare[mask])\n",
    "    row = f\"{label:<12} {n_q:>5} {mean_bare:>8.3f}\"\n",
    "    for name, delta in conditions_hardness:\n",
    "        dq = delta[mask]\n",
    "        row += f\" {np.mean(dq):>10.4f} {cohens_d(dq):>8.3f}\"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to results/exp03/delta_distributions.png\n",
      "Plot saved to results/exp03/length_scaling.png\n",
      "Plot saved to results/exp03/hardness_interaction.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: Plots — delta distributions, length scaling, hardness scatter\n",
    "\n",
    "# === Plot 1: Delta distributions (all 7 comparisons) ===\n",
    "fig, axes = plt.subplots(2, 4, figsize=(22, 10))\n",
    "axes_flat = axes.flat\n",
    "\n",
    "plot_configs = [\n",
    "    ('P1: Combined vs Bare', bare - combined, 'steelblue'),\n",
    "    ('P2: Combined vs Suffix', random_suffix - combined, 'forestgreen'),\n",
    "    ('P3: Combined vs Trunc', random_trunc - combined, 'darkorange'),\n",
    "    ('S1: Suffix vs Bare', bare - random_suffix, 'mediumpurple'),\n",
    "    ('S2: Trunc vs Bare', bare - random_trunc, 'teal'),\n",
    "    ('S3: Sep-only vs Bare', bare - sep_only, 'crimson'),\n",
    "    ('S4: Suffix vs Sep-only', sep_only - random_suffix, 'goldenrod'),\n",
    "]\n",
    "\n",
    "for i, (title, delta, color) in enumerate(plot_configs):\n",
    "    ax = axes_flat[i]\n",
    "    cr = comparison_results[comparisons[i][0]]\n",
    "    ax.hist(delta, bins=80, color=color, alpha=0.7, edgecolor='black', linewidth=0.3)\n",
    "    ax.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax.axvline(x=np.mean(delta), color='black', linestyle='-', alpha=0.8,\n",
    "               label=f'mean={np.mean(delta):.4f}, d={cr[\"cohens_d\"]:+.3f}')\n",
    "    ax.set_xlabel('Delta NLL')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "# Hide last subplot\n",
    "axes_flat[7].set_visible(False)\n",
    "\n",
    "plt.suptitle('Delta NLL Distributions — All 7 Comparisons', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'delta_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plot saved to {RESULTS_DIR / 'delta_distributions.png'}\")\n",
    "\n",
    "# === Plot 2: Length scaling ===\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# (a) Suffix benefit vs doc length\n",
    "axes[0].scatter(doc_lens_valid, delta_suffix, alpha=0.1, s=5, c='mediumpurple')\n",
    "axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "z = np.polyfit(doc_lens_valid, delta_suffix, 1)\n",
    "x_range = np.linspace(doc_lens_valid.min(), doc_lens_valid.max(), 100)\n",
    "axes[0].plot(x_range, np.polyval(z, x_range), 'r-', alpha=0.8,\n",
    "             label=f'beta={z[0]:.5f}, p={model_ols.pvalues[1]:.2e}')\n",
    "axes[0].set_xlabel('Document token length')\n",
    "axes[0].set_ylabel('Suffix benefit (+ = helps)')\n",
    "axes[0].set_title('Suffix Benefit vs Passage Length')\n",
    "axes[0].legend()\n",
    "\n",
    "# (b) Separator-only benefit vs doc length\n",
    "axes[1].scatter(doc_lens_valid, delta_seponly, alpha=0.1, s=5, c='crimson')\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "z2 = np.polyfit(doc_lens_valid, delta_seponly, 1)\n",
    "axes[1].plot(x_range, np.polyval(z2, x_range), 'r-', alpha=0.8,\n",
    "             label=f'beta={z2[0]:.5f}')\n",
    "axes[1].set_xlabel('Document token length')\n",
    "axes[1].set_ylabel('Sep-only benefit (+ = helps)')\n",
    "axes[1].set_title('Separator-Only Benefit vs Passage Length')\n",
    "axes[1].legend()\n",
    "\n",
    "# (c) Quintile d values for all conditions\n",
    "x_pos = np.arange(5)\n",
    "width = 0.2\n",
    "for ci, cname in enumerate(['Suffix', 'Trunc', 'Combined', 'Sep-only']):\n",
    "    ds = [quintile_results[ql][cname]['d'] for ql in q_labels]\n",
    "    colors = ['mediumpurple', 'teal', 'steelblue', 'crimson']\n",
    "    axes[2].bar(x_pos + ci * width, ds, width, label=cname, alpha=0.8, color=colors[ci])\n",
    "axes[2].set_xticks(x_pos + 1.5 * width)\n",
    "axes[2].set_xticklabels(q_labels, rotation=15)\n",
    "axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].set_ylabel(\"Cohen's d\")\n",
    "axes[2].set_title('Effect Size by Length Quintile')\n",
    "axes[2].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'length_scaling.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plot saved to {RESULTS_DIR / 'length_scaling.png'}\")\n",
    "\n",
    "# === Plot 3: Hardness scatter (2x2 grid) ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "scatter_configs = [\n",
    "    ('Random-suffix', delta_suffix, 'mediumpurple'),\n",
    "    ('Random-truncated', delta_trunc, 'teal'),\n",
    "    ('Combined', delta_combined, 'steelblue'),\n",
    "    ('Separator-only', delta_seponly, 'crimson'),\n",
    "]\n",
    "\n",
    "for ax, (name, delta, color) in zip(axes.flat, scatter_configs):\n",
    "    r, p = hardness_results[name]['r'], hardness_results[name]['p']\n",
    "    ax.scatter(bare, delta, alpha=0.12, s=5, c=color)\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    z = np.polyfit(bare, delta, 1)\n",
    "    x_range = np.linspace(bare.min(), bare.max(), 100)\n",
    "    ax.plot(x_range, np.polyval(z, x_range), 'r-', alpha=0.8, label=f'r={r:.3f}, p={p:.1e}')\n",
    "    ax.set_xlabel('Bare NLL (hardness)')\n",
    "    ax.set_ylabel(f'{name} benefit (+ = helps)')\n",
    "    ax.set_title(f'Hardness vs {name} Benefit')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Hardness Interaction — All 4 Non-Bare Conditions', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'hardness_interaction.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plot saved to {RESULTS_DIR / 'hardness_interaction.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results saved to results/exp03/results.json\n",
      "File size: 2309.5 KB\n",
      "Total samples: 3000\n",
      "Valid samples: 2752\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Save results JSON\n",
    "\n",
    "final_results = {\n",
    "    'experiment': 'exp03_combined_and_length',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': config.model_name,\n",
    "        'num_samples': config.num_samples,\n",
    "        'seed': SEED,\n",
    "        'min_passage_words': config.min_passage_words,\n",
    "        'max_passage_words': config.max_passage_words,\n",
    "        'surrogate_prefix_template': SURROGATE_PREFIX_TEMPLATE,\n",
    "        'document_template': DOCUMENT_TEMPLATE,\n",
    "        'query_template': QUERY_TEMPLATE,\n",
    "        'answer_template': ANSWER_TEMPLATE,\n",
    "        'suffix_separator': SUFFIX_SEPARATOR,\n",
    "        'n_comparisons': N_COMPARISONS,\n",
    "        'bonferroni_alpha': BONFERRONI_ALPHA,\n",
    "    },\n",
    "    'summary': {\n",
    "        'n_total': len(results),\n",
    "        'n_valid': int(n_valid),\n",
    "        'n_excluded_zero_nll': int(n_invalid),\n",
    "        'nll_means': {\n",
    "            'bare': float(np.mean(bare)),\n",
    "            'random_suffix': float(np.mean(random_suffix)),\n",
    "            'random_truncated': float(np.mean(random_trunc)),\n",
    "            'combined': float(np.mean(combined)),\n",
    "            'separator_only': float(np.mean(sep_only)),\n",
    "        },\n",
    "        'nll_stds': {\n",
    "            'bare': float(np.std(bare)),\n",
    "            'random_suffix': float(np.std(random_suffix)),\n",
    "            'random_truncated': float(np.std(random_trunc)),\n",
    "            'combined': float(np.std(combined)),\n",
    "            'separator_only': float(np.std(sep_only)),\n",
    "        },\n",
    "        'comparisons': comparison_results,\n",
    "        'additivity_test': {\n",
    "            'mean_remainder': float(np.mean(remainder)),\n",
    "            'cohens_d': float(d_add),\n",
    "            't_stat': float(t_stat_add),\n",
    "            'p_value': float(p_val_add),\n",
    "            'cross_mechanism_r': float(r_cross),\n",
    "            'cross_mechanism_p': float(p_cross),\n",
    "        },\n",
    "        'hardness_interaction': hardness_results,\n",
    "        'length_scaling': {\n",
    "            'suffix_vs_doclen': {\n",
    "                'beta_1': float(model_ols.params[1]),\n",
    "                'p_value': float(model_ols.pvalues[1]),\n",
    "                'r_squared': float(model_ols.rsquared),\n",
    "            },\n",
    "            'suffix_vs_doclen_with_hardness': {\n",
    "                'beta_1_doclen': float(model_ols2.params[1]),\n",
    "                'p_doclen': float(model_ols2.pvalues[1]),\n",
    "                'beta_2_bare_nll': float(model_ols2.params[2]),\n",
    "                'p_bare_nll': float(model_ols2.pvalues[2]),\n",
    "                'r_squared': float(model_ols2.rsquared),\n",
    "            },\n",
    "            'suffix_vs_fraction': {\n",
    "                'beta_1': float(model_ols3.params[1]),\n",
    "                'p_value': float(model_ols3.pvalues[1]),\n",
    "                'r_squared': float(model_ols3.rsquared),\n",
    "            },\n",
    "            'quintiles': quintile_results,\n",
    "        },\n",
    "    },\n",
    "    'per_sample_results': results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(f\"Final results saved to {FINAL_RESULTS_PATH}\")\n",
    "print(f\"File size: {FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"Total samples: {len(results)}\")\n",
    "print(f\"Valid samples: {n_valid}\")\n",
    "print(f\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu124.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu124:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
