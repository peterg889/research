{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17900998",
   "metadata": {},
   "source": [
    "# Exp 27b: Cross-Dataset Generalization on Gemma 3 4B\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 27 (Mistral) showed attention forcing does NOT generalize beyond MS MARCO. The target\n",
    "datasets are at ceiling for Mistral (median bare NLL = 0 on TriviaQA/HotpotQA). This experiment\n",
    "tests whether Gemma 3 4B shows the same ceiling effects, and whether the Gemma-specific toolkit\n",
    "(values-early-layers from Exps 19/21/24) can extract signal where Mistral could not.\n",
    "\n",
    "## Key Differences from Exp 27\n",
    "\n",
    "| Parameter | Exp 27 (Mistral) | Exp 27b (Gemma) |\n",
    "|-----------|-----------------|-----------------|\n",
    "| Model | Mistral 7B | Gemma 3 4B |\n",
    "| MAX_DOC_TOKENS | 4096 | 900 (sliding window constraint) |\n",
    "| Attention forcing | bias=0, 2.0, 4.0 | bias=0, 2.0 only |\n",
    "| Values manipulation | values_only (all layers) | values_only + values_early (0-15) + values_hero |\n",
    "| Hero layers | N/A | {10, 12, 14, 15, 20} from Exp 24 |\n",
    "\n",
    "## Conditions\n",
    "\n",
    "| # | Condition | Description | Expected (from prior exps) |\n",
    "|---|-----------|-------------|---------------------------|\n",
    "| 1 | bare | Baseline | -- |\n",
    "| 2 | sf_trunc | Standard priming | d ~ -0.03 (Exp 16) |\n",
    "| 3 | sf_trunc_bias2 | +2.0 bias forcing | Novel on Gemma |\n",
    "| 4 | values_only | All-layer value swap | d ~ +0.05 (Exp 16) |\n",
    "| 5 | values_early | Layers 0-15 value swap | d ~ +0.21 (Exp 19) |\n",
    "| 6 | values_hero | Layers {10,12,14,15,20} | d ~ +0.24 (Exp 24 single-layer peak) |\n",
    "\n",
    "## Sliding Window Constraint\n",
    "\n",
    "Gemma 3 has 29 sliding-window layers (SW=1024) + 5 full-attention layers.\n",
    "MAX_DOC_TOKENS = 900 ensures total sequence 1 + prefix(~10) + doc(900) = 911 < 1024,\n",
    "so no positions are evicted from sliding-window layer caches during the primed forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae89c877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:11:13.857448Z",
     "iopub.status.busy": "2026-02-16T19:11:13.857156Z",
     "iopub.status.idle": "2026-02-16T19:11:17.523635Z",
     "shell.execute_reply": "2026-02-16T19:11:17.522255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Results directory: results/exp27b\n",
      "CUDA available: True\n",
      "GPU: NVIDIA L4\n",
      "GPU memory: 23.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp27b\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "CSV_PATH = RESULTS_DIR / \"results.csv\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e60c04f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:11:17.528554Z",
     "iopub.status.busy": "2026-02-16T19:11:17.527817Z",
     "iopub.status.idle": "2026-02-16T19:12:07.298484Z",
     "shell.execute_reply": "2026-02-16T19:12:07.297542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/gemma-3-4b-it (4-bit, bfloat16)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb2d86450524541b5d836a019394afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully.\n",
      "  Num layers: 34\n",
      "  Head dim: 256\n",
      "  Model dtype: torch.bfloat16\n",
      "  Sliding window: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cache key dtype: torch.bfloat16\n",
      "  Cache key shape: torch.Size([1, 4, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Gemma 3 4B via load_model()\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.model_utils import load_model\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "\n",
    "exp_config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_type=\"gemma3\",\n",
    "    compute_dtype=\"auto\",  # resolves to bfloat16 for Gemma\n",
    "    use_4bit=True,\n",
    "    num_samples=2000,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit, bfloat16)...\")\n",
    "model, tokenizer = load_model(exp_config)\n",
    "\n",
    "from lib.kv_cache import _get_text_config, _get_head_dim, _ensure_dynamic_cache, _get_cache_keys\n",
    "\n",
    "text_config = _get_text_config(model.config)\n",
    "N_LAYERS = text_config.num_hidden_layers\n",
    "print(f\"\\nModel loaded successfully.\")\n",
    "print(f\"  Num layers: {N_LAYERS}\")\n",
    "print(f\"  Head dim: {_get_head_dim(model.config)}\")\n",
    "print(f\"  Model dtype: {model.dtype}\")\n",
    "print(f\"  Sliding window: {getattr(text_config, 'sliding_window', 'N/A')}\")\n",
    "\n",
    "# Verify with test forward pass\n",
    "sample_ids = tokenizer(\"test\", return_tensors=\"pt\")['input_ids'].to(exp_config.device)\n",
    "with torch.no_grad():\n",
    "    out = model(sample_ids, use_cache=True)\n",
    "    cache_check = _ensure_dynamic_cache(out.past_key_values)\n",
    "    k0 = _get_cache_keys(cache_check, 0)\n",
    "    print(f\"  Cache key dtype: {k0.dtype}\")\n",
    "    print(f\"  Cache key shape: {k0.shape}\")\n",
    "del out, sample_ids, cache_check\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431e77b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:12:07.302500Z",
     "iopub.status.busy": "2026-02-16T19:12:07.301720Z",
     "iopub.status.idle": "2026-02-16T19:12:07.310913Z",
     "shell.execute_reply": "2026-02-16T19:12:07.309931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready\n",
      "  Model: google/gemma-3-4b-it\n",
      "  N per dataset: 300\n",
      "  MAX_DOC_TOKENS: 900 (sliding window constraint)\n",
      "  N_LAYERS: 34\n",
      "  EARLY_LAYER_CUTOFF: 16\n",
      "  HERO_LAYERS: [10, 12, 14, 15, 20]\n",
      "  Conditions: ['bare', 'sf_trunc', 'sf_trunc_bias2', 'values_only', 'values_early', 'values_hero']\n",
      "  Static fact prefix: 'What are the key facts I need to know?'\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Lib imports + constants\n",
    "from lib.kv_cache import (\n",
    "    _get_cache_keys,\n",
    "    _get_cache_values,\n",
    "    _set_cache_keys,\n",
    "    _set_cache_values,\n",
    "    _ensure_dynamic_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    "    score_answer_with_cache,\n",
    "    deepcopy_cache,\n",
    "    replace_values_at_layers,\n",
    ")\n",
    "from lib.analysis import cohens_d\n",
    "from lib.data import count_words\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Templates -- bare text, no \"Document:\\n\" framing\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "QUERY_TEMPLATE = \"\\nQuestion: {question}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"\n",
    "\n",
    "# Prefix text\n",
    "from lib.surrogate import STATIC_SURROGATE_QUERIES\n",
    "STATIC_FACT = STATIC_SURROGATE_QUERIES['static_factual']['query']\n",
    "\n",
    "# Experiment parameters\n",
    "N_PER_DATASET = 300\n",
    "# Gemma sliding window = 1024: total seq must be < 1024\n",
    "# Primed pass: 1(BOS) + ~10(prefix) + doc_len < 1024 â†’ doc_len < ~1013\n",
    "# Cap at 900 for safety (matching Exp 21)\n",
    "MAX_DOC_TOKENS = 900\n",
    "CHECKPOINT_EVERY = 25\n",
    "\n",
    "# Conditions\n",
    "CONDITION_NAMES = ['bare', 'sf_trunc', 'sf_trunc_bias2', 'values_only',\n",
    "                   'values_early', 'values_hero']\n",
    "\n",
    "# Layer-selective conditions from Exps 19/21/24\n",
    "EARLY_LAYER_CUTOFF = 16  # layers 0-15\n",
    "HERO_LAYERS = [10, 12, 14, 15, 20]  # from Exp 24 single-layer scan\n",
    "\n",
    "# Length bins for stratified analysis (token count)\n",
    "LENGTH_BINS = [\n",
    "    ('<256', 0, 256),\n",
    "    ('256-512', 256, 512),\n",
    "    ('512-900', 512, 901),\n",
    "]\n",
    "\n",
    "print(\"Config ready\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  N per dataset: {N_PER_DATASET}\")\n",
    "print(f\"  MAX_DOC_TOKENS: {MAX_DOC_TOKENS} (sliding window constraint)\")\n",
    "print(f\"  N_LAYERS: {N_LAYERS}\")\n",
    "print(f\"  EARLY_LAYER_CUTOFF: {EARLY_LAYER_CUTOFF}\")\n",
    "print(f\"  HERO_LAYERS: {HERO_LAYERS}\")\n",
    "print(f\"  Conditions: {CONDITION_NAMES}\")\n",
    "print(f\"  Static fact prefix: '{STATIC_FACT}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa45bc66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:12:07.314328Z",
     "iopub.status.busy": "2026-02-16T19:12:07.313671Z",
     "iopub.status.idle": "2026-02-16T19:12:09.934515Z",
     "shell.execute_reply": "2026-02-16T19:12:09.933582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'trivia_qa' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING TRIVIAQA (rc.wikipedia, validation)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366ac130e0a74bc391e2cef1b8ba377d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriviaQA validation size: 7993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2d3e6b304b4eba95637d4654c2da50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering TriviaQA:   0%|          | 0/7993 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 300 samples\n",
      "TriviaQA samples: 300\n",
      "  Word counts: mean=2243, min=56, max=4916\n",
      "  Example Q: Which actress wrote the novel The Last of the Really Great Whangdoodles?\n",
      "  Example A: Julie Andrews\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load TriviaQA dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING TRIVIAQA (rc.wikipedia, validation)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "TQA_CACHE = RESULTS_DIR / \"tqa_samples.json\"\n",
    "\n",
    "if TQA_CACHE.exists():\n",
    "    with open(TQA_CACHE, 'r') as f:\n",
    "        tqa_samples = json.load(f)\n",
    "    print(f\"Loaded {len(tqa_samples)} cached TriviaQA samples\")\n",
    "else:\n",
    "    tqa_ds = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\",\n",
    "                           trust_remote_code=True)\n",
    "    print(f\"TriviaQA validation size: {len(tqa_ds)}\")\n",
    "\n",
    "    tqa_samples = []\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    for item in tqdm(tqa_ds, desc=\"Filtering TriviaQA\"):\n",
    "        entity_pages = item.get('entity_pages', {})\n",
    "        wiki_contexts = entity_pages.get('wiki_context', [])\n",
    "        if not wiki_contexts:\n",
    "            continue\n",
    "        doc_text = wiki_contexts[0]\n",
    "\n",
    "        question = item.get('question', '')\n",
    "        answer_data = item.get('answer', {})\n",
    "        answer_text = answer_data.get('value', '') if isinstance(answer_data, dict) else str(answer_data)\n",
    "\n",
    "        if not question or not answer_text or not doc_text:\n",
    "            continue\n",
    "\n",
    "        wc = count_words(doc_text)\n",
    "        if wc < 50 or wc > 5000:\n",
    "            continue\n",
    "        if answer_text.lower() not in doc_text.lower():\n",
    "            continue\n",
    "\n",
    "        tqa_samples.append({\n",
    "            'passage': doc_text,\n",
    "            'query': question,\n",
    "            'answer': answer_text,\n",
    "            'word_count': wc,\n",
    "            'dataset': 'triviaqa',\n",
    "        })\n",
    "\n",
    "        if len(tqa_samples) >= N_PER_DATASET * 3:\n",
    "            break\n",
    "\n",
    "    np.random.shuffle(tqa_samples)\n",
    "    tqa_samples = tqa_samples[:N_PER_DATASET]\n",
    "\n",
    "    with open(TQA_CACHE, 'w') as f:\n",
    "        json.dump(tqa_samples, f)\n",
    "    print(f\"Cached {len(tqa_samples)} samples\")\n",
    "\n",
    "    del tqa_ds\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"TriviaQA samples: {len(tqa_samples)}\")\n",
    "wcs = [s['word_count'] for s in tqa_samples]\n",
    "print(f\"  Word counts: mean={np.mean(wcs):.0f}, min={min(wcs)}, max={max(wcs)}\")\n",
    "if tqa_samples:\n",
    "    print(f\"  Example Q: {tqa_samples[0]['query']}\")\n",
    "    print(f\"  Example A: {tqa_samples[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2f2f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:12:09.938273Z",
     "iopub.status.busy": "2026-02-16T19:12:09.937968Z",
     "iopub.status.idle": "2026-02-16T19:13:52.706060Z",
     "shell.execute_reply": "2026-02-16T19:13:52.705085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING NATURAL QUESTIONS (validation, streaming)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f4ee00f2da4ac9bac6fe2daf42f00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9c5df5c3494e469382e9ab3fa52abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696f02516bde421ea2d53f53472697ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NQ: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 300 samples (processed 4079)\n",
      "NQ samples: 300\n",
      "  Word counts: mean=2073, min=135, max=3986\n",
      "  Example Q: who sings the theme song for the tv show cops\n",
      "  Example A: Inner Circle\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load Natural Questions dataset (streaming)\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING NATURAL QUESTIONS (validation, streaming)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "NQ_CACHE = RESULTS_DIR / \"nq_samples.json\"\n",
    "\n",
    "if NQ_CACHE.exists():\n",
    "    with open(NQ_CACHE, 'r') as f:\n",
    "        nq_samples = json.load(f)\n",
    "    print(f\"Loaded {len(nq_samples)} cached NQ samples\")\n",
    "else:\n",
    "    nq_ds = load_dataset(\n",
    "        \"google-research-datasets/natural_questions\",\n",
    "        split=\"validation\",\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    nq_samples = []\n",
    "    n_processed = 0\n",
    "\n",
    "    for example in tqdm(nq_ds, desc=\"Processing NQ\"):\n",
    "        n_processed += 1\n",
    "\n",
    "        doc_tokens = example['document']['tokens']\n",
    "        if isinstance(doc_tokens, dict):\n",
    "            token_strs = doc_tokens['token']\n",
    "            is_html_flags = doc_tokens['is_html']\n",
    "            clean_tokens = [t for t, h in zip(token_strs, is_html_flags) if not h]\n",
    "        else:\n",
    "            clean_tokens = [t['token'] for t in doc_tokens if not t['is_html']]\n",
    "\n",
    "        doc_text = ' '.join(clean_tokens)\n",
    "        wc = count_words(doc_text)\n",
    "\n",
    "        if wc < 50 or wc > 4000:\n",
    "            continue\n",
    "\n",
    "        annotations = example['annotations']\n",
    "        short_answers_list = annotations['short_answers']\n",
    "\n",
    "        answer_text = None\n",
    "        for annotator_sa in short_answers_list:\n",
    "            if not annotator_sa:\n",
    "                continue\n",
    "            texts = annotator_sa.get('text', [])\n",
    "            if texts:\n",
    "                answer_text = texts[0]\n",
    "                break\n",
    "            starts = annotator_sa.get('start_token', [])\n",
    "            ends = annotator_sa.get('end_token', [])\n",
    "            if not starts or not ends:\n",
    "                continue\n",
    "            start_tok = starts[0] if isinstance(starts, list) else starts\n",
    "            end_tok = ends[0] if isinstance(ends, list) else ends\n",
    "            if start_tok >= 0 and end_tok > start_tok:\n",
    "                if isinstance(doc_tokens, dict):\n",
    "                    ans_tokens = [\n",
    "                        doc_tokens['token'][i]\n",
    "                        for i in range(start_tok, min(end_tok, len(doc_tokens['token'])))\n",
    "                        if not doc_tokens['is_html'][i]\n",
    "                    ]\n",
    "                else:\n",
    "                    ans_tokens = [\n",
    "                        doc_tokens[i]['token']\n",
    "                        for i in range(start_tok, min(end_tok, len(doc_tokens)))\n",
    "                        if not doc_tokens[i]['is_html']\n",
    "                    ]\n",
    "                if ans_tokens:\n",
    "                    answer_text = ' '.join(ans_tokens)\n",
    "                    break\n",
    "\n",
    "        if not answer_text or len(answer_text.strip()) == 0:\n",
    "            continue\n",
    "        if len(answer_text.split()) > 20:\n",
    "            continue\n",
    "\n",
    "        question = example['question']\n",
    "        if isinstance(question, dict):\n",
    "            query = question.get('text', '')\n",
    "        else:\n",
    "            query = str(question)\n",
    "        if not query.strip():\n",
    "            continue\n",
    "\n",
    "        nq_samples.append({\n",
    "            'passage': doc_text,\n",
    "            'query': query,\n",
    "            'answer': answer_text,\n",
    "            'word_count': wc,\n",
    "            'dataset': 'nq',\n",
    "        })\n",
    "\n",
    "        if len(nq_samples) >= N_PER_DATASET * 3:\n",
    "            break\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(nq_samples)\n",
    "    nq_samples = nq_samples[:N_PER_DATASET]\n",
    "\n",
    "    with open(NQ_CACHE, 'w') as f:\n",
    "        json.dump(nq_samples, f)\n",
    "    print(f\"Cached {len(nq_samples)} samples (processed {n_processed})\")\n",
    "\n",
    "print(f\"NQ samples: {len(nq_samples)}\")\n",
    "wcs = [s['word_count'] for s in nq_samples]\n",
    "print(f\"  Word counts: mean={np.mean(wcs):.0f}, min={min(wcs)}, max={max(wcs)}\")\n",
    "if nq_samples:\n",
    "    print(f\"  Example Q: {nq_samples[0]['query']}\")\n",
    "    print(f\"  Example A: {nq_samples[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16d2714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:13:52.709862Z",
     "iopub.status.busy": "2026-02-16T19:13:52.709275Z",
     "iopub.status.idle": "2026-02-16T19:13:54.385768Z",
     "shell.execute_reply": "2026-02-16T19:13:54.384795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'hotpot_qa' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING HOTPOTQA (distractor, validation)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotpotQA validation size: 7405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0025c84fa0b94301a8c763d1bf02ef94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering HotpotQA:   0%|          | 0/7405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 300 samples\n",
      "HotpotQA samples: 300\n",
      "  Word counts: mean=921, min=112, max=2216\n",
      "  Example Q: Which of Tara Strong major voice role in animated series is an American animated television series based on the DC Comics fictional superhero team, the \"Teen Titans\"?\n",
      "  Example A: Teen Titans Go!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load HotpotQA dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING HOTPOTQA (distractor, validation)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "HQA_CACHE = RESULTS_DIR / \"hqa_samples.json\"\n",
    "\n",
    "if HQA_CACHE.exists():\n",
    "    with open(HQA_CACHE, 'r') as f:\n",
    "        hqa_samples = json.load(f)\n",
    "    print(f\"Loaded {len(hqa_samples)} cached HotpotQA samples\")\n",
    "else:\n",
    "    hqa_ds = load_dataset(\"hotpot_qa\", \"distractor\", split=\"validation\",\n",
    "                           trust_remote_code=True)\n",
    "    print(f\"HotpotQA validation size: {len(hqa_ds)}\")\n",
    "\n",
    "    hqa_samples = []\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    for item in tqdm(hqa_ds, desc=\"Filtering HotpotQA\"):\n",
    "        question = item.get('question', '')\n",
    "        answer_text = item.get('answer', '')\n",
    "\n",
    "        if not question or not answer_text:\n",
    "            continue\n",
    "\n",
    "        context = item.get('context', {})\n",
    "        titles = context.get('title', [])\n",
    "        sentences_list = context.get('sentences', [])\n",
    "\n",
    "        paragraphs = []\n",
    "        for title, sents in zip(titles, sentences_list):\n",
    "            para_text = ''.join(sents)\n",
    "            paragraphs.append(para_text)\n",
    "\n",
    "        doc_text = '\\n\\n'.join(paragraphs)\n",
    "        wc = count_words(doc_text)\n",
    "\n",
    "        if wc < 100 or wc > 3000:\n",
    "            continue\n",
    "\n",
    "        hqa_samples.append({\n",
    "            'passage': doc_text,\n",
    "            'query': question,\n",
    "            'answer': answer_text,\n",
    "            'word_count': wc,\n",
    "            'dataset': 'hotpotqa',\n",
    "        })\n",
    "\n",
    "        if len(hqa_samples) >= N_PER_DATASET * 3:\n",
    "            break\n",
    "\n",
    "    np.random.shuffle(hqa_samples)\n",
    "    hqa_samples = hqa_samples[:N_PER_DATASET]\n",
    "\n",
    "    with open(HQA_CACHE, 'w') as f:\n",
    "        json.dump(hqa_samples, f)\n",
    "    print(f\"Cached {len(hqa_samples)} samples\")\n",
    "\n",
    "    del hqa_ds\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"HotpotQA samples: {len(hqa_samples)}\")\n",
    "wcs = [s['word_count'] for s in hqa_samples]\n",
    "print(f\"  Word counts: mean={np.mean(wcs):.0f}, min={min(wcs)}, max={max(wcs)}\")\n",
    "if hqa_samples:\n",
    "    print(f\"  Example Q: {hqa_samples[0]['query']}\")\n",
    "    print(f\"  Example A: {hqa_samples[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47916e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:13:54.389634Z",
     "iopub.status.busy": "2026-02-16T19:13:54.389340Z",
     "iopub.status.idle": "2026-02-16T19:13:59.385002Z",
     "shell.execute_reply": "2026-02-16T19:13:59.384037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UNIFIED SAMPLE POOL\n",
      "======================================================================\n",
      "Total samples: 900\n",
      "  triviaqa: n=300, mean_words=2243, range=[56, 4916]\n",
      "  nq: n=300, mean_words=2073, range=[135, 3986]\n",
      "  hotpotqa: n=300, mean_words=921, range=[112, 2216]\n",
      "\n",
      "Prefix: 'What are the key facts I need to know?'\n",
      "  Token length (no BOS): 11\n",
      "  Max primed sequence: 1 + 11 + 900 = 912\n",
      "  Sliding window: 1024\n",
      "  SAFE: 912 < 1024\n",
      "\n",
      "Tokenizing documents to measure token lengths...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d599b1441f4e3d920db18505895769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Documents truncated to 900: 810/900 (90%)\n",
      "  triviaqa: mean_tok=859, median=900, truncated=267/300 (89%)\n",
      "  nq: mean_tok=880, median=900, truncated=274/300 (91%)\n",
      "  hotpotqa: mean_tok=884, median=900, truncated=269/300 (90%)\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENTAL CONDITIONS (Gemma 3 4B)\n",
      "======================================================================\n",
      "\n",
      "### 1. bare ###\n",
      "  Forward: [BOS][doc]\n",
      "  Baseline. Standard causal attention.\n",
      "\n",
      "### 2. sf_trunc (standard priming) ###\n",
      "  Forward: [BOS][prefix_11][doc]\n",
      "  Standard causal, truncate + RoPE. Expected d ~ -0.03 (Exp 16 on MARCO).\n",
      "  Keys carry negative interference on Gemma.\n",
      "\n",
      "### 3. sf_trunc_bias2 (attention forcing, bias=+2.0) ###\n",
      "  Forward: [BOS][prefix_11][doc] with +2.0 bias\n",
      "  Novel on Gemma. May amplify key interference.\n",
      "\n",
      "### 4. values_only (all layers) ###\n",
      "  Bare keys + all primed values from sf_trunc cache.\n",
      "  Expected d ~ +0.056 (Exp 16). Bypasses key interference.\n",
      "\n",
      "### 5. values_early (layers 0-15 only) ###\n",
      "  Bare keys + primed values from layers 0-15 only.\n",
      "  Expected best: d ~ +0.211 (Exp 19). Late layers carry interference.\n",
      "\n",
      "### 6. values_hero (layers {10,12,14,15,20}) ###\n",
      "  Bare keys + primed values from 5 hero layers identified in Exp 24.\n",
      "  Cherry-picking may outperform blanket cutoff=16.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Unified sample pool + tokenize prefix + condition explanation\n",
    "print(\"=\" * 70)\n",
    "print(\"UNIFIED SAMPLE POOL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_samples = []\n",
    "for ds_name, ds_samples in [(\"triviaqa\", tqa_samples), (\"nq\", nq_samples), (\"hotpotqa\", hqa_samples)]:\n",
    "    for sample in ds_samples:\n",
    "        sample['dataset'] = ds_name\n",
    "    all_samples.extend(ds_samples)\n",
    "\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "for ds_name in ['triviaqa', 'nq', 'hotpotqa']:\n",
    "    ds_s = [s for s in all_samples if s['dataset'] == ds_name]\n",
    "    wcs = [s['word_count'] for s in ds_s]\n",
    "    print(f\"  {ds_name}: n={len(ds_s)}, mean_words={np.mean(wcs):.0f}, \"\n",
    "          f\"range=[{min(wcs)}, {max(wcs)}]\")\n",
    "\n",
    "# Tokenize prefix\n",
    "sf_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=STATIC_FACT)\n",
    "sf_ids = tokenizer(sf_str, return_tensors=\"pt\",\n",
    "                    add_special_tokens=False)['input_ids'].to(exp_config.device)\n",
    "PREFIX_TOKEN_LEN = sf_ids.shape[1]\n",
    "\n",
    "print(f\"\\nPrefix: '{STATIC_FACT}'\")\n",
    "print(f\"  Token length (no BOS): {PREFIX_TOKEN_LEN}\")\n",
    "\n",
    "# Verify sliding window safety\n",
    "max_primed_seq = 1 + PREFIX_TOKEN_LEN + MAX_DOC_TOKENS\n",
    "print(f\"  Max primed sequence: 1 + {PREFIX_TOKEN_LEN} + {MAX_DOC_TOKENS} = {max_primed_seq}\")\n",
    "print(f\"  Sliding window: 1024\")\n",
    "assert max_primed_seq < 1024, f\"UNSAFE: {max_primed_seq} >= 1024\"\n",
    "print(f\"  SAFE: {max_primed_seq} < 1024\")\n",
    "\n",
    "# Tokenize doc lengths\n",
    "print(f\"\\nTokenizing documents to measure token lengths...\")\n",
    "n_truncated = 0\n",
    "for sample in tqdm(all_samples, desc=\"Tokenizing\"):\n",
    "    tok_len = len(tokenizer.encode(sample['passage'], add_special_tokens=False))\n",
    "    if tok_len > MAX_DOC_TOKENS:\n",
    "        n_truncated += 1\n",
    "    sample['doc_token_len'] = min(tok_len, MAX_DOC_TOKENS)\n",
    "    sample['answer_token_len'] = len(tokenizer.encode(sample['answer'], add_special_tokens=False))\n",
    "\n",
    "print(f\"  Documents truncated to {MAX_DOC_TOKENS}: {n_truncated}/{len(all_samples)} \"\n",
    "      f\"({100*n_truncated/len(all_samples):.0f}%)\")\n",
    "\n",
    "for ds_name in ['triviaqa', 'nq', 'hotpotqa']:\n",
    "    ds_s = [s for s in all_samples if s['dataset'] == ds_name]\n",
    "    tls = [s['doc_token_len'] for s in ds_s]\n",
    "    n_trunc = sum(1 for s in ds_s if s['doc_token_len'] == MAX_DOC_TOKENS)\n",
    "    print(f\"  {ds_name}: mean_tok={np.mean(tls):.0f}, median={np.median(tls):.0f}, \"\n",
    "          f\"truncated={n_trunc}/{len(ds_s)} ({100*n_trunc/len(ds_s):.0f}%)\")\n",
    "\n",
    "# Condition explanation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENTAL CONDITIONS (Gemma 3 4B)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n### 1. bare ###\")\n",
    "print(\"  Forward: [BOS][doc]\")\n",
    "print(\"  Baseline. Standard causal attention.\")\n",
    "\n",
    "print(\"\\n### 2. sf_trunc (standard priming) ###\")\n",
    "print(f\"  Forward: [BOS][prefix_{PREFIX_TOKEN_LEN}][doc]\")\n",
    "print(\"  Standard causal, truncate + RoPE. Expected d ~ -0.03 (Exp 16 on MARCO).\")\n",
    "print(\"  Keys carry negative interference on Gemma.\")\n",
    "\n",
    "print(\"\\n### 3. sf_trunc_bias2 (attention forcing, bias=+2.0) ###\")\n",
    "print(f\"  Forward: [BOS][prefix_{PREFIX_TOKEN_LEN}][doc] with +2.0 bias\")\n",
    "print(\"  Novel on Gemma. May amplify key interference.\")\n",
    "\n",
    "print(\"\\n### 4. values_only (all layers) ###\")\n",
    "print(\"  Bare keys + all primed values from sf_trunc cache.\")\n",
    "print(\"  Expected d ~ +0.056 (Exp 16). Bypasses key interference.\")\n",
    "\n",
    "print(\"\\n### 5. values_early (layers 0-15 only) ###\")\n",
    "print(\"  Bare keys + primed values from layers 0-15 only.\")\n",
    "print(\"  Expected best: d ~ +0.211 (Exp 19). Late layers carry interference.\")\n",
    "\n",
    "print(\"\\n### 6. values_hero (layers {10,12,14,15,20}) ###\")\n",
    "print(\"  Bare keys + primed values from 5 hero layers identified in Exp 24.\")\n",
    "print(\"  Cherry-picking may outperform blanket cutoff=16.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba39b644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:13:59.388739Z",
     "iopub.status.busy": "2026-02-16T19:13:59.388420Z",
     "iopub.status.idle": "2026-02-16T19:13:59.410252Z",
     "shell.execute_reply": "2026-02-16T19:13:59.409486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask verification (toy: BOS + 3 prefix + 5 doc = 9 total):\n",
      "  Shape: torch.Size([1, 1, 9, 9])\n",
      "  Doc->Prefix bias (row 4, col 1): 2.0 (expect +2.0)\n",
      "  Causal mask (row 3, col 5): -inf (expect -inf)\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Helper functions\n",
    "\n",
    "def build_biased_causal_mask(total_len, prefix_start, prefix_end, bias_value, dtype, device):\n",
    "    \"\"\"Build a 4D causal attention mask with logit bias on doc->prefix attention.\"\"\"\n",
    "    mask = torch.zeros((total_len, total_len), dtype=dtype, device=device)\n",
    "    causal = torch.triu(\n",
    "        torch.ones(total_len, total_len, dtype=torch.bool, device=device),\n",
    "        diagonal=1\n",
    "    )\n",
    "    mask.masked_fill_(causal, float('-inf'))\n",
    "\n",
    "    if bias_value != 0.0:\n",
    "        doc_start = prefix_end\n",
    "        mask[doc_start:, prefix_start:prefix_end] += bias_value\n",
    "\n",
    "    return mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def run_single_sample(sample, model, tokenizer, exp_config, sf_ids, sf_str,\n",
    "                      PREFIX_TOKEN_LEN, N_LAYERS, EARLY_LAYER_CUTOFF, HERO_LAYERS):\n",
    "    \"\"\"Run all 6 conditions for a single sample. Returns dict of NLLs + metadata.\"\"\"\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "    ds_name = sample['dataset']\n",
    "\n",
    "    query_prompt = QUERY_TEMPLATE.format(question=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "\n",
    "    # === Matched tokenization ===\n",
    "    full_text = sf_str + document_text\n",
    "    full_enc = tokenizer(full_text, return_tensors=\"pt\",\n",
    "                          add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_ids = full_enc['input_ids'].to(exp_config.device)\n",
    "\n",
    "    sf_prefix_enc = tokenizer(sf_str, return_tensors=\"pt\",\n",
    "                               add_special_tokens=True, padding=False, truncation=False)\n",
    "    sf_prefix_len_with_bos = sf_prefix_enc['input_ids'].shape[1]\n",
    "\n",
    "    bos_id = full_ids[:, :1]\n",
    "    doc_ids = full_ids[:, sf_prefix_len_with_bos:]\n",
    "\n",
    "    # Truncate long docs\n",
    "    if doc_ids.shape[1] > MAX_DOC_TOKENS:\n",
    "        doc_ids = doc_ids[:, :MAX_DOC_TOKENS]\n",
    "\n",
    "    doc_len = doc_ids.shape[1]\n",
    "    context_len = 1 + doc_len  # BOS + doc\n",
    "\n",
    "    del full_enc, full_ids, sf_prefix_enc\n",
    "\n",
    "    # === 1. BARE ===\n",
    "    bare_input = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_input,\n",
    "                         attention_mask=torch.ones_like(bare_input),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_cache = _ensure_dynamic_cache(bare_out.past_key_values)\n",
    "    del bare_out\n",
    "\n",
    "    bare_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "\n",
    "    # === 2. sf_trunc (standard priming, bias=0) ===\n",
    "    primed_input = torch.cat([bos_id, sf_ids, doc_ids], dim=1)\n",
    "    total_seq_len = primed_input.shape[1]\n",
    "    prefix_start = 1\n",
    "    prefix_end = 1 + sf_ids.shape[1]\n",
    "    prefix_offset = sf_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        primed_out = model(input_ids=primed_input,\n",
    "                           attention_mask=torch.ones_like(primed_input),\n",
    "                           use_cache=True, return_dict=True)\n",
    "    primed_full_std = _ensure_dynamic_cache(primed_out.past_key_values)\n",
    "    del primed_out\n",
    "\n",
    "    trunc_raw = extract_and_truncate_cache_with_bos(primed_full_std, doc_len)\n",
    "    del primed_full_std\n",
    "\n",
    "    sf_trunc_cache = deepcopy_cache(trunc_raw)\n",
    "    correct_rope_positions_with_bos(sf_trunc_cache, prefix_offset, model)\n",
    "    del trunc_raw\n",
    "\n",
    "    sf_trunc_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(sf_trunc_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "\n",
    "    # === 3. sf_trunc_bias2 (attention forcing, bias=+2.0) ===\n",
    "    mask_4d = build_biased_causal_mask(\n",
    "        total_seq_len, prefix_start, prefix_end,\n",
    "        2.0, model.dtype, exp_config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        primed_out = model(input_ids=primed_input,\n",
    "                           attention_mask=mask_4d,\n",
    "                           use_cache=True, return_dict=True)\n",
    "    primed_full_b2 = _ensure_dynamic_cache(primed_out.past_key_values)\n",
    "    del primed_out, mask_4d\n",
    "\n",
    "    trunc_raw = extract_and_truncate_cache_with_bos(primed_full_b2, doc_len)\n",
    "    del primed_full_b2\n",
    "\n",
    "    bias2_cache = deepcopy_cache(trunc_raw)\n",
    "    correct_rope_positions_with_bos(bias2_cache, prefix_offset, model)\n",
    "    del trunc_raw\n",
    "\n",
    "    bias2_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bias2_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "    del bias2_cache\n",
    "\n",
    "    # === 4. values_only (all layers) ===\n",
    "    values_all_cache = deepcopy_cache(bare_cache)\n",
    "    for layer_idx in range(N_LAYERS):\n",
    "        primed_vals = _get_cache_values(sf_trunc_cache, layer_idx)\n",
    "        _set_cache_values(values_all_cache, layer_idx, primed_vals.clone())\n",
    "\n",
    "    values_only_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(values_all_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "    del values_all_cache\n",
    "\n",
    "    # === 5. values_early (layers 0 to EARLY_LAYER_CUTOFF-1) ===\n",
    "    early_layers = list(range(EARLY_LAYER_CUTOFF))\n",
    "    values_early_cache = replace_values_at_layers(bare_cache, sf_trunc_cache, early_layers)\n",
    "\n",
    "    values_early_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(values_early_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "    del values_early_cache\n",
    "\n",
    "    # === 6. values_hero (hero layers only) ===\n",
    "    values_hero_cache = replace_values_at_layers(bare_cache, sf_trunc_cache, HERO_LAYERS)\n",
    "\n",
    "    values_hero_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(values_hero_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "    del values_hero_cache\n",
    "\n",
    "    del bare_cache, sf_trunc_cache, bare_input, primed_input\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {\n",
    "        'dataset': ds_name,\n",
    "        'query': query,\n",
    "        'answer': answer,\n",
    "        'word_count': sample['word_count'],\n",
    "        'doc_token_len': doc_len,\n",
    "        'answer_token_len': sample.get('answer_token_len', 0),\n",
    "        'bare': bare_nll,\n",
    "        'sf_trunc': sf_trunc_nll,\n",
    "        'sf_trunc_bias2': bias2_nll,\n",
    "        'values_only': values_only_nll,\n",
    "        'values_early': values_early_nll,\n",
    "        'values_hero': values_hero_nll,\n",
    "    }\n",
    "\n",
    "\n",
    "# Verify mask for a toy example\n",
    "print(\"Mask verification (toy: BOS + 3 prefix + 5 doc = 9 total):\")\n",
    "toy_mask = build_biased_causal_mask(9, 1, 4, 2.0, model.dtype, 'cpu')\n",
    "m = toy_mask.squeeze()\n",
    "print(f\"  Shape: {toy_mask.shape}\")\n",
    "print(f\"  Doc->Prefix bias (row 4, col 1): {m[4, 1].item():.1f} (expect +2.0)\")\n",
    "print(f\"  Causal mask (row 3, col 5): {m[3, 5].item()} (expect -inf)\")\n",
    "del toy_mask, m\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f394885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:13:59.413707Z",
     "iopub.status.busy": "2026-02-16T19:13:59.413123Z",
     "iopub.status.idle": "2026-02-16T19:56:08.351117Z",
     "shell.execute_reply": "2026-02-16T19:56:08.350134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENT: 900 samples, 6 conditions\n",
      "Model: Gemma 3 4B, MAX_DOC_TOKENS: 900\n",
      "======================================================================\n",
      "No checkpoint found. Starting fresh.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72dd8eb414f428bbe62a29dbd045b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Exp 27b:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 25/900 | 25 done in 1.2m | ETA: 42.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 50/900 | 50 done in 2.4m | ETA: 41.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 75/900 | 75 done in 3.6m | ETA: 40.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/900 | 100 done in 4.8m | ETA: 38.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 125/900 | 125 done in 6.1m | ETA: 37.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 150/900 | 150 done in 7.3m | ETA: 36.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 175/900 | 175 done in 8.4m | ETA: 34.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/900 | 200 done in 9.6m | ETA: 33.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 225/900 | 225 done in 10.7m | ETA: 32.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 250/900 | 250 done in 11.8m | ETA: 30.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 275/900 | 275 done in 13.0m | ETA: 29.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/900 | 300 done in 14.1m | ETA: 28.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 325/900 | 325 done in 15.3m | ETA: 27.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 350/900 | 350 done in 16.5m | ETA: 25.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 375/900 | 375 done in 17.6m | ETA: 24.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 400/900 | 400 done in 18.8m | ETA: 23.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 425/900 | 425 done in 20.0m | ETA: 22.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 450/900 | 450 done in 21.1m | ETA: 21.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 475/900 | 475 done in 22.3m | ETA: 19.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 500/900 | 500 done in 23.5m | ETA: 18.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 525/900 | 525 done in 24.6m | ETA: 17.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 550/900 | 550 done in 25.8m | ETA: 16.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 575/900 | 575 done in 27.0m | ETA: 15.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 600/900 | 600 done in 28.1m | ETA: 14.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 625/900 | 625 done in 29.3m | ETA: 12.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 650/900 | 650 done in 30.5m | ETA: 11.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 675/900 | 675 done in 31.6m | ETA: 10.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 700/900 | 700 done in 32.8m | ETA: 9.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 725/900 | 725 done in 34.0m | ETA: 8.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 750/900 | 750 done in 35.1m | ETA: 7.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 775/900 | 775 done in 36.3m | ETA: 5.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 800/900 | 800 done in 37.5m | ETA: 4.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 825/900 | 825 done in 38.6m | ETA: 3.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 850/900 | 850 done in 39.8m | ETA: 2.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 875/900 | 875 done in 41.0m | ETA: 1.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 900/900 | 900 done in 42.1m | ETA: 0.0 min\n",
      "\n",
      "Experiment complete: 900 samples in 42.1 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Main experiment loop\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"EXPERIMENT: {len(all_samples)} samples, {len(CONDITION_NAMES)} conditions\")\n",
    "print(f\"Model: Gemma 3 4B, MAX_DOC_TOKENS: {MAX_DOC_TOKENS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Checkpoint resume\n",
    "all_results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    with open(CHECKPOINT_PATH, 'r') as f:\n",
    "        ckpt = json.load(f)\n",
    "    ckpt_queries = ckpt.get('sample_queries', [])\n",
    "    current_queries = [s['query'] for s in all_samples]\n",
    "    if ckpt_queries == current_queries:\n",
    "        all_results = ckpt['results']\n",
    "        start_idx = len(all_results)\n",
    "        print(f\"Resuming from checkpoint: {start_idx}/{len(all_samples)}\")\n",
    "    else:\n",
    "        print(\"Checkpoint query mismatch. Starting fresh.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh.\")\n",
    "\n",
    "t_start = time.time()\n",
    "N_TOTAL = len(all_samples)\n",
    "\n",
    "for qidx in tqdm(range(start_idx, N_TOTAL), initial=start_idx, total=N_TOTAL,\n",
    "                  desc=\"Exp 27b\"):\n",
    "    sample = all_samples[qidx]\n",
    "\n",
    "    result = run_single_sample(\n",
    "        sample, model, tokenizer, exp_config,\n",
    "        sf_ids, sf_str, PREFIX_TOKEN_LEN, N_LAYERS,\n",
    "        EARLY_LAYER_CUTOFF, HERO_LAYERS)\n",
    "    result['query_idx'] = qidx\n",
    "    all_results.append(result)\n",
    "\n",
    "    # Checkpoint\n",
    "    if (qidx + 1) % CHECKPOINT_EVERY == 0 or qidx == N_TOTAL - 1:\n",
    "        ckpt_data = {\n",
    "            'results': all_results,\n",
    "            'sample_queries': [s['query'] for s in all_samples],\n",
    "            'completed': len(all_results),\n",
    "            'total': N_TOTAL,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, 'w') as f:\n",
    "            json.dump(ckpt_data, f)\n",
    "        elapsed = time.time() - t_start\n",
    "        n_done = qidx - start_idx + 1\n",
    "        rate = n_done / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N_TOTAL - qidx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {qidx+1}/{N_TOTAL} | {n_done} done in {elapsed/60:.1f}m | \"\n",
    "                   f\"ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nExperiment complete: {len(all_results)} samples in {elapsed_total/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b31e0f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:56:08.356339Z",
     "iopub.status.busy": "2026-02-16T19:56:08.356056Z",
     "iopub.status.idle": "2026-02-16T19:56:08.473704Z",
     "shell.execute_reply": "2026-02-16T19:56:08.472808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYSIS: PER-DATASET RESULTS (Gemma 3 4B)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "DATASET: TRIVIAQA (n=184/300, median bare NLL=0.000)\n",
      "======================================================================\n",
      "\n",
      "Condition             Mean Bare  Mean Cond     Mean D        d    Win%            p   sig\n",
      "------------------------------------------------------------------------------------------\n",
      "sf_trunc                 1.1805     1.3603    -0.1798   -0.187   38.0%     1.20e-02     *\n",
      "sf_trunc_bias2           1.1805     1.2195    -0.0390   -0.041   34.2%     5.83e-01    ns\n",
      "values_only              1.1805     1.2979    -0.1174   -0.123   29.9%     9.70e-02    ns\n",
      "values_early             1.1805     1.2057    -0.0252   -0.036   32.1%     6.22e-01    ns\n",
      "values_hero              1.1805     1.1805    +0.0001   +0.000   32.6%     9.98e-01    ns\n",
      "\n",
      "======================================================================\n",
      "DATASET: NQ (n=262/300, median bare NLL=0.006)\n",
      "======================================================================\n",
      "\n",
      "Condition             Mean Bare  Mean Cond     Mean D        d    Win%            p   sig\n",
      "------------------------------------------------------------------------------------------\n",
      "sf_trunc                 1.0448     1.0217    +0.0232   +0.035   56.9%     5.69e-01    ns\n",
      "sf_trunc_bias2           1.0448     1.0375    +0.0073   +0.010   51.5%     8.69e-01    ns\n",
      "values_only              1.0448     1.0701    -0.0253   -0.044   45.0%     4.77e-01    ns\n",
      "values_early             1.0448     1.0401    +0.0047   +0.017   50.0%     7.86e-01    ns\n",
      "values_hero              1.0448     1.0129    +0.0320   +0.229   39.7%     2.58e-04   ***\n",
      "\n",
      "======================================================================\n",
      "DATASET: HOTPOTQA (n=258/300, median bare NLL=0.003)\n",
      "======================================================================\n",
      "\n",
      "Condition             Mean Bare  Mean Cond     Mean D        d    Win%            p   sig\n",
      "------------------------------------------------------------------------------------------\n",
      "sf_trunc                 0.9697     1.1359    -0.1663   -0.196   51.2%     1.84e-03    **\n",
      "sf_trunc_bias2           0.9697     1.1072    -0.1375   -0.140   39.5%     2.55e-02     *\n",
      "values_only              0.9697     1.1155    -0.1458   -0.154   41.9%     1.42e-02     *\n",
      "values_early             0.9697     0.9896    -0.0199   -0.028   39.9%     6.59e-01    ns\n",
      "values_hero              0.9697     0.9983    -0.0287   -0.074   40.7%     2.34e-01    ns\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "CROSS-DATASET SUMMARY: Cohen's d vs bare (Gemma 3 4B)\n",
      "==========================================================================================\n",
      "\n",
      "Condition                 triviaqa            nq      hotpotqa\n",
      "--------------------------------------------------------------\n",
      "sf_trunc                -0.187   *    +0.035        -0.196  **\n",
      "sf_trunc_bias2          -0.041        +0.010        -0.140   *\n",
      "values_only             -0.123        -0.044        -0.154   *\n",
      "values_early            -0.036        +0.017        -0.028    \n",
      "values_hero             +0.000        +0.229 ***    -0.074    \n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "COMPARISON: Gemma vs Mistral (Exp 27)\n",
      "==========================================================================================\n",
      "\n",
      "Mistral Exp 27 results (for reference):\n",
      "  TriviaQA: sf_trunc d=-0.201, bias2 d=-0.162, values_only d=-0.126\n",
      "  NQ:       sf_trunc d=+0.010, bias2 d=+0.048, values_only d=+0.032\n",
      "  HotpotQA: sf_trunc d=-0.111, bias2 d=-0.061, values_only d=-0.200\n",
      "\n",
      "\n",
      "BARE NLL DISTRIBUTIONS (ceiling effect check):\n",
      "  triviaqa  : mean=0.724, median=0.000, pct_near_zero=77%\n",
      "  nq        : mean=0.912, median=0.006, pct_near_zero=55%\n",
      "  hotpotqa  : mean=0.834, median=0.003, pct_near_zero=56%\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Per-dataset analysis\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS: PER-DATASET RESULTS (Gemma 3 4B)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "dataset_names = ['triviaqa', 'nq', 'hotpotqa']\n",
    "analysis = {}\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    ds_results = [r for r in all_results if r['dataset'] == ds_name]\n",
    "    n_ds = len(ds_results)\n",
    "    if n_ds == 0:\n",
    "        continue\n",
    "\n",
    "    bare_arr = np.array([r['bare'] for r in ds_results])\n",
    "\n",
    "    # Filter invalid\n",
    "    valid = np.isfinite(bare_arr) & (bare_arr != 0)\n",
    "    for cname in CONDITION_NAMES:\n",
    "        if cname == 'bare':\n",
    "            continue\n",
    "        c_arr = np.array([r[cname] for r in ds_results])\n",
    "        valid &= np.isfinite(c_arr) & (c_arr != 0)\n",
    "\n",
    "    n_valid = int(np.sum(valid))\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"DATASET: {ds_name.upper()} (n={n_valid}/{n_ds}, \"\n",
    "          f\"median bare NLL={np.median(bare_arr):.3f})\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    print(f\"\\n{'Condition':<20} {'Mean Bare':>10} {'Mean Cond':>10} \"\n",
    "          f\"{'Mean D':>10} {'d':>8} {'Win%':>7} {'p':>12} {'sig':>5}\")\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    ds_analysis = {}\n",
    "    for cname in CONDITION_NAMES:\n",
    "        if cname == 'bare':\n",
    "            continue\n",
    "        c_arr = np.array([r[cname] for r in ds_results])\n",
    "        delta = bare_arr[valid] - c_arr[valid]\n",
    "        d = cohens_d(delta)\n",
    "        win = np.mean(delta > 0) * 100\n",
    "        t_stat, p_val = stats.ttest_1samp(delta, 0)\n",
    "        sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "        print(f\"{cname:<20} {np.mean(bare_arr[valid]):>10.4f} {np.mean(c_arr[valid]):>10.4f} \"\n",
    "              f\"{np.mean(delta):>+10.4f} {d:>+8.3f} {win:>6.1f}% {p_val:>12.2e} {sig:>5}\")\n",
    "        ds_analysis[cname] = {\n",
    "            'n_valid': n_valid,\n",
    "            'mean_bare': float(np.mean(bare_arr[valid])),\n",
    "            'mean_cond': float(np.mean(c_arr[valid])),\n",
    "            'mean_delta': float(np.mean(delta)),\n",
    "            'cohens_d': float(d),\n",
    "            'win_pct': float(win),\n",
    "            't_stat': float(t_stat),\n",
    "            'p_value': float(p_val),\n",
    "        }\n",
    "\n",
    "    analysis[ds_name] = ds_analysis\n",
    "\n",
    "# Cross-dataset summary table\n",
    "print(f\"\\n\\n{'='*90}\")\n",
    "print(\"CROSS-DATASET SUMMARY: Cohen's d vs bare (Gemma 3 4B)\")\n",
    "print(f\"{'='*90}\")\n",
    "print(f\"\\n{'Condition':<20}\", end='')\n",
    "for ds in dataset_names:\n",
    "    print(f\"{'  ' + ds:>14}\", end='')\n",
    "print()\n",
    "print(\"-\" * 62)\n",
    "for cname in CONDITION_NAMES:\n",
    "    if cname == 'bare':\n",
    "        continue\n",
    "    print(f\"{cname:<20}\", end='')\n",
    "    for ds in dataset_names:\n",
    "        if ds in analysis and cname in analysis[ds]:\n",
    "            d = analysis[ds][cname]['cohens_d']\n",
    "            p = analysis[ds][cname]['p_value']\n",
    "            sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''\n",
    "            print(f\"{d:>+10.3f}{sig:>4}\", end='')\n",
    "        else:\n",
    "            print(f\"{'n/a':>14}\", end='')\n",
    "    print()\n",
    "\n",
    "# Compare with Exp 27 (Mistral) reference\n",
    "print(f\"\\n\\n{'='*90}\")\n",
    "print(\"COMPARISON: Gemma vs Mistral (Exp 27)\")\n",
    "print(f\"{'='*90}\")\n",
    "print(\"\\nMistral Exp 27 results (for reference):\")\n",
    "print(\"  TriviaQA: sf_trunc d=-0.201, bias2 d=-0.162, values_only d=-0.126\")\n",
    "print(\"  NQ:       sf_trunc d=+0.010, bias2 d=+0.048, values_only d=+0.032\")\n",
    "print(\"  HotpotQA: sf_trunc d=-0.111, bias2 d=-0.061, values_only d=-0.200\")\n",
    "\n",
    "# Check bare NLL distributions\n",
    "print(f\"\\n\\nBARE NLL DISTRIBUTIONS (ceiling effect check):\")\n",
    "for ds in dataset_names:\n",
    "    ds_r = [r for r in all_results if r['dataset'] == ds]\n",
    "    bare = [r['bare'] for r in ds_r]\n",
    "    pct_zero = 100 * np.mean(np.array(bare) < 0.01)\n",
    "    print(f\"  {ds:10s}: mean={np.mean(bare):.3f}, median={np.median(bare):.3f}, \"\n",
    "          f\"pct_near_zero={pct_zero:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5f7690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:56:08.477728Z",
     "iopub.status.busy": "2026-02-16T19:56:08.477162Z",
     "iopub.status.idle": "2026-02-16T19:56:08.518387Z",
     "shell.execute_reply": "2026-02-16T19:56:08.517591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LENGTH STRATIFICATION (Gemma 3 4B)\n",
      "======================================================================\n",
      "\n",
      "--- TRIVIAQA ---\n",
      "  sf_trunc:\n",
      "    <256: n=5 (too few)\n",
      "    256-512: n=9 (too few)\n",
      "    512-900: n=286, d=-0.153, p=9.95e-03 **\n",
      "  sf_trunc_bias2:\n",
      "    <256: n=5 (too few)\n",
      "    256-512: n=9 (too few)\n",
      "    512-900: n=286, d=-0.043, p=4.72e-01 ns\n",
      "  values_only:\n",
      "    <256: n=5 (too few)\n",
      "    256-512: n=9 (too few)\n",
      "    512-900: n=286, d=-0.100, p=9.08e-02 ns\n",
      "  values_early:\n",
      "    <256: n=5 (too few)\n",
      "    256-512: n=9 (too few)\n",
      "    512-900: n=286, d=-0.032, p=5.86e-01 ns\n",
      "  values_hero:\n",
      "    <256: n=5 (too few)\n",
      "    256-512: n=9 (too few)\n",
      "    512-900: n=286, d=-0.001, p=9.86e-01 ns\n",
      "\n",
      "--- NQ ---\n",
      "  sf_trunc:\n",
      "    <256: n=1 (too few)\n",
      "    256-512: n=2 (too few)\n",
      "    512-900: n=297, d=+0.017, p=7.70e-01 ns\n",
      "  sf_trunc_bias2:\n",
      "    <256: n=1 (too few)\n",
      "    256-512: n=2 (too few)\n",
      "    512-900: n=297, d=+0.003, p=9.53e-01 ns\n",
      "  values_only:\n",
      "    <256: n=1 (too few)\n",
      "    256-512: n=2 (too few)\n",
      "    512-900: n=297, d=-0.047, p=4.22e-01 ns\n",
      "  values_early:\n",
      "    <256: n=1 (too few)\n",
      "    256-512: n=2 (too few)\n",
      "    512-900: n=297, d=+0.005, p=9.25e-01 ns\n",
      "  values_hero:\n",
      "    <256: n=1 (too few)\n",
      "    256-512: n=2 (too few)\n",
      "    512-900: n=297, d=+0.208, p=3.84e-04 ***\n",
      "\n",
      "--- HOTPOTQA ---\n",
      "  sf_trunc:\n",
      "    <256: n=2 (too few)\n",
      "    256-512: n=1 (too few)\n",
      "    512-900: n=297, d=-0.182, p=1.86e-03 **\n",
      "  sf_trunc_bias2:\n",
      "    <256: n=2 (too few)\n",
      "    256-512: n=1 (too few)\n",
      "    512-900: n=297, d=-0.130, p=2.55e-02 *\n",
      "  values_only:\n",
      "    <256: n=2 (too few)\n",
      "    256-512: n=1 (too few)\n",
      "    512-900: n=297, d=-0.143, p=1.42e-02 *\n",
      "  values_early:\n",
      "    <256: n=2 (too few)\n",
      "    256-512: n=1 (too few)\n",
      "    512-900: n=297, d=-0.026, p=6.59e-01 ns\n",
      "  values_hero:\n",
      "    <256: n=2 (too few)\n",
      "    256-512: n=1 (too few)\n",
      "    512-900: n=297, d=-0.069, p=2.34e-01 ns\n",
      "\n",
      "\n",
      "======================================================================\n",
      "HARDNESS QUINTILE INTERACTION (Gemma 3 4B)\n",
      "======================================================================\n",
      "\n",
      "--- TRIVIAQA (boundaries: ['0.000', '0.000', '0.000', '0.039']) ---\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  sf_trunc_bias2            -0.142      -0.673      -0.140      -0.279      -0.020      -0.032\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_only               -0.160      -0.333      -0.163      -0.202      -0.177      -0.096\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_early              -0.140      -0.441      -0.595      -0.188      -0.038      -0.029\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_hero               -0.181      -0.417      -0.355      -0.170      +0.016      +0.000\n",
      "\n",
      "--- NQ (boundaries: ['0.000', '0.001', '0.067', '1.191']) ---\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  sf_trunc_bias2            -0.141      -0.135      -0.316      -0.295      +0.147      +0.010\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_only               -0.190      -0.120      -0.231      -0.172      +0.082      -0.041\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_early              -0.051      -0.075      -0.234      -0.125      +0.084      +0.016\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_hero               -0.327      -0.443      -0.186      +0.211      +0.482      +0.213\n",
      "\n",
      "--- HOTPOTQA (boundaries: ['0.000', '0.001', '0.028', '1.201']) ---\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  sf_trunc_bias2            -0.228      -0.183      -0.239      -0.357      +0.007      -0.130\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_only               -0.356      -0.199      -0.260      -0.410      +0.153      -0.142\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_early              -0.378      -0.146      -0.225      -0.237      +0.210      -0.026\n",
      "                          Q1(easy)          Q2          Q3          Q4    Q5(hard)     Overall\n",
      "  values_hero               -0.274      -0.273      -0.201      -0.221      -0.020      -0.069\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Length stratification + hardness interaction\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LENGTH STRATIFICATION (Gemma 3 4B)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "length_strat = {}\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    ds_results = [r for r in all_results if r['dataset'] == ds_name]\n",
    "    if not ds_results:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- {ds_name.upper()} ---\")\n",
    "    ds_length_data = {}\n",
    "\n",
    "    for cname in ['sf_trunc', 'sf_trunc_bias2', 'values_only', 'values_early', 'values_hero']:\n",
    "        print(f\"  {cname}:\")\n",
    "        bin_ds = []\n",
    "        for bin_label, bin_min, bin_max in LENGTH_BINS:\n",
    "            bin_results = [r for r in ds_results\n",
    "                          if bin_min <= r['doc_token_len'] < bin_max]\n",
    "            n_bin = len(bin_results)\n",
    "            if n_bin < 10:\n",
    "                print(f\"    {bin_label}: n={n_bin} (too few)\")\n",
    "                bin_ds.append({'label': bin_label, 'n': n_bin, 'd': None})\n",
    "                continue\n",
    "            bare = np.array([r['bare'] for r in bin_results])\n",
    "            cond = np.array([r[cname] for r in bin_results])\n",
    "            delta = bare - cond\n",
    "            d = cohens_d(delta)\n",
    "            _, p_val = stats.ttest_1samp(delta, 0)\n",
    "            sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "            print(f\"    {bin_label}: n={n_bin}, d={d:+.3f}, p={p_val:.2e} {sig}\")\n",
    "            bin_ds.append({'label': bin_label, 'n': n_bin, 'd': float(d), 'p': float(p_val)})\n",
    "        ds_length_data[cname] = bin_ds\n",
    "\n",
    "    length_strat[ds_name] = ds_length_data\n",
    "\n",
    "# === HARDNESS QUINTILE INTERACTION ===\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(\"HARDNESS QUINTILE INTERACTION (Gemma 3 4B)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "hardness_data = {}\n",
    "quintile_labels = ['Q1(easy)', 'Q2', 'Q3', 'Q4', 'Q5(hard)']\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    ds_results = [r for r in all_results if r['dataset'] == ds_name]\n",
    "    if len(ds_results) < 50:\n",
    "        continue\n",
    "\n",
    "    bare_arr = np.array([r['bare'] for r in ds_results])\n",
    "    quintile_boundaries = np.percentile(bare_arr, [20, 40, 60, 80])\n",
    "    print(f\"\\n--- {ds_name.upper()} (boundaries: {[f'{b:.3f}' for b in quintile_boundaries]}) ---\")\n",
    "\n",
    "    def get_quintile(nll):\n",
    "        for i, b in enumerate(quintile_boundaries):\n",
    "            if nll <= b:\n",
    "                return i\n",
    "        return 4\n",
    "\n",
    "    quintiles = np.array([get_quintile(r['bare']) for r in ds_results])\n",
    "\n",
    "    ds_hardness = {}\n",
    "    for cname in ['sf_trunc_bias2', 'values_only', 'values_early', 'values_hero']:\n",
    "        cond_arr = np.array([r[cname] for r in ds_results])\n",
    "        delta = bare_arr - cond_arr\n",
    "        row = f\"  {cname:<20}\"\n",
    "        q_ds = []\n",
    "        for q in range(5):\n",
    "            mask_q = quintiles == q\n",
    "            n_q = int(np.sum(mask_q))\n",
    "            if n_q < 5:\n",
    "                row += f\"{'n/a':>12}\"\n",
    "                q_ds.append(None)\n",
    "            else:\n",
    "                d_q = cohens_d(delta[mask_q])\n",
    "                row += f\"{d_q:>+12.3f}\"\n",
    "                q_ds.append(float(d_q))\n",
    "        d_all = cohens_d(delta)\n",
    "        row += f\"{d_all:>+12.3f}\"\n",
    "        print(f\"  {'':20}\" + \"\".join(f\"{ql:>12}\" for ql in quintile_labels) + f\"{'Overall':>12}\")\n",
    "        print(row)\n",
    "        ds_hardness[cname] = q_ds\n",
    "\n",
    "    hardness_data[ds_name] = ds_hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b68918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:56:08.521719Z",
     "iopub.status.busy": "2026-02-16T19:56:08.521453Z",
     "iopub.status.idle": "2026-02-16T19:56:10.660418Z",
     "shell.execute_reply": "2026-02-16T19:56:10.659521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to results/exp27b/analysis_plots.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Multi-panel figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "colors = {\n",
    "    'sf_trunc': '#1f77b4',\n",
    "    'sf_trunc_bias2': '#d62728',\n",
    "    'values_only': '#7f7f7f',\n",
    "    'values_early': '#2ca02c',\n",
    "    'values_hero': '#ff7f0e',\n",
    "}\n",
    "\n",
    "# ---- Panel (a): Cohen's d by dataset x condition ----\n",
    "ax = axes[0, 0]\n",
    "x = np.arange(len(dataset_names))\n",
    "width = 0.15\n",
    "conds_plot = ['sf_trunc', 'sf_trunc_bias2', 'values_only', 'values_early', 'values_hero']\n",
    "for i, cname in enumerate(conds_plot):\n",
    "    ds_vals = []\n",
    "    for ds in dataset_names:\n",
    "        if ds in analysis and cname in analysis[ds]:\n",
    "            ds_vals.append(analysis[ds][cname]['cohens_d'])\n",
    "        else:\n",
    "            ds_vals.append(0)\n",
    "    offset = (i - 2) * width\n",
    "    bars = ax.bar(x + offset, ds_vals, width, label=cname, color=colors[cname],\n",
    "                  edgecolor='black', linewidth=0.5)\n",
    "    for j, val in enumerate(ds_vals):\n",
    "        ax.text(x[j] + offset, val + (0.01 if val >= 0 else -0.03),\n",
    "                f\"{val:+.2f}\", ha='center', va='bottom' if val >= 0 else 'top', fontsize=6)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([ds.upper() for ds in dataset_names])\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel(\"Cohen's d (positive = helps)\")\n",
    "ax.set_title(\"(a) Gemma 3 4B: Effect Size by Dataset x Condition\")\n",
    "ax.legend(fontsize=6, loc='best')\n",
    "\n",
    "# ---- Panel (b): Length stratification for values_early across datasets ----\n",
    "ax = axes[0, 1]\n",
    "for ds_name in dataset_names:\n",
    "    if ds_name not in length_strat:\n",
    "        continue\n",
    "    cname = 'values_early'\n",
    "    if cname not in length_strat[ds_name]:\n",
    "        continue\n",
    "    bins_data = length_strat[ds_name][cname]\n",
    "    valid_idx = [i for i, b in enumerate(bins_data) if b['d'] is not None]\n",
    "    if valid_idx:\n",
    "        x_vals = valid_idx\n",
    "        y_vals = [bins_data[i]['d'] for i in valid_idx]\n",
    "        ax.plot(x_vals, y_vals, marker='o', linewidth=2, markersize=6, label=ds_name)\n",
    "\n",
    "bin_labels_all = [b[0] for b in LENGTH_BINS]\n",
    "ax.set_xticks(range(len(bin_labels_all)))\n",
    "ax.set_xticklabels(bin_labels_all, rotation=30, ha='right', fontsize=8)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_xlabel(\"Document Token Length Bin\")\n",
    "ax.set_title(\"(b) values_early (layers 0-15) by Length\")\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# ---- Panel (c): Hardness heatmap for values_early ----\n",
    "ax = axes[1, 0]\n",
    "hm_rows = []\n",
    "hm_ylabels = []\n",
    "for ds_name in dataset_names:\n",
    "    if ds_name in hardness_data and 'values_early' in hardness_data[ds_name]:\n",
    "        row = hardness_data[ds_name]['values_early']\n",
    "        hm_rows.append([v if v is not None else 0 for v in row])\n",
    "        hm_ylabels.append(ds_name.upper())\n",
    "\n",
    "if hm_rows:\n",
    "    hm_arr = np.array(hm_rows)\n",
    "    im = ax.imshow(hm_arr, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "    ax.set_xticks(range(5))\n",
    "    ax.set_xticklabels(quintile_labels, fontsize=8)\n",
    "    ax.set_yticks(range(len(hm_ylabels)))\n",
    "    ax.set_yticklabels(hm_ylabels)\n",
    "    for i in range(len(hm_ylabels)):\n",
    "        for j in range(5):\n",
    "            val = hm_arr[i, j]\n",
    "            ax.text(j, i, f\"{val:+.2f}\", ha='center', va='center',\n",
    "                    fontsize=9, color='white' if abs(val) > 0.25 else 'black')\n",
    "    fig.colorbar(im, ax=ax, shrink=0.8, label=\"Cohen's d\")\n",
    "ax.set_title(\"(c) values_early: Hardness x Dataset\")\n",
    "\n",
    "# ---- Panel (d): Gemma conditions comparison (best per dataset) ----\n",
    "ax = axes[1, 1]\n",
    "conds_compare = ['sf_trunc', 'values_only', 'values_early', 'values_hero']\n",
    "x = np.arange(len(conds_compare))\n",
    "width = 0.25\n",
    "for i, ds_name in enumerate(dataset_names):\n",
    "    ds_vals = []\n",
    "    for cname in conds_compare:\n",
    "        if ds_name in analysis and cname in analysis[ds_name]:\n",
    "            ds_vals.append(analysis[ds_name][cname]['cohens_d'])\n",
    "        else:\n",
    "            ds_vals.append(0)\n",
    "    offset = (i - 1) * width\n",
    "    ax.bar(x + offset, ds_vals, width, label=ds_name, alpha=0.8,\n",
    "           edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([c.replace('values_', 'val_') for c in conds_compare], fontsize=8)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "# Reference lines from Gemma Exp 19 (MARCO)\n",
    "ax.axhline(y=0.211, color='green', linestyle=':', alpha=0.5,\n",
    "           label='Exp 19 MARCO val_early d=+0.211')\n",
    "ax.axhline(y=0.056, color='gray', linestyle=':', alpha=0.5,\n",
    "           label='Exp 16 MARCO val_only d=+0.056')\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_title(\"(d) Gemma Toolkit Comparison by Dataset\")\n",
    "ax.legend(fontsize=6)\n",
    "\n",
    "plt.suptitle('Exp 27b: Cross-Dataset Generalization (Gemma 3 4B)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plots saved to {RESULTS_DIR / 'analysis_plots.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59fa6942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:56:10.664116Z",
     "iopub.status.busy": "2026-02-16T19:56:10.663835Z",
     "iopub.status.idle": "2026-02-16T19:56:10.714102Z",
     "shell.execute_reply": "2026-02-16T19:56:10.713276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved: results/exp27b/results.csv\n",
      "\n",
      "VERDICT: SUCCESS: Gemma toolkit generalizes! Best: nq/values_hero d=+0.229\n",
      "VEL: values_early results: triviaqa=-0.036, nq=+0.017, hotpotqa=-0.028\n",
      "\n",
      "Results saved to results/exp27b/results.json\n",
      "File size: 437.0 KB\n",
      "\n",
      "======================================================================\n",
      "SUMMARY -- Exp 27b: Cross-Dataset (Gemma 3 4B)\n",
      "======================================================================\n",
      "\n",
      "  TRIVIAQA:\n",
      "    sf_trunc             d=-0.187  win=38%  *\n",
      "    sf_trunc_bias2       d=-0.041  win=34%  ns\n",
      "    values_only          d=-0.123  win=30%  ns\n",
      "    values_early         d=-0.036  win=32%  ns\n",
      "    values_hero          d=+0.000  win=33%  ns\n",
      "\n",
      "  NQ:\n",
      "    sf_trunc             d=+0.035  win=57%  ns\n",
      "    sf_trunc_bias2       d=+0.010  win=52%  ns\n",
      "    values_only          d=-0.044  win=45%  ns\n",
      "    values_early         d=+0.017  win=50%  ns\n",
      "    values_hero          d=+0.229  win=40%  ***\n",
      "\n",
      "  HOTPOTQA:\n",
      "    sf_trunc             d=-0.196  win=51%  **\n",
      "    sf_trunc_bias2       d=-0.140  win=40%  *\n",
      "    values_only          d=-0.154  win=42%  *\n",
      "    values_early         d=-0.028  win=40%  ns\n",
      "    values_hero          d=-0.074  win=41%  ns\n",
      "\n",
      "VERDICT: SUCCESS: Gemma toolkit generalizes! Best: nq/values_hero d=+0.229\n",
      "VEL: values_early results: triviaqa=-0.036, nq=+0.017, hotpotqa=-0.028\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Save results.json + CSV\n",
    "\n",
    "# --- CSV ---\n",
    "with open(CSV_PATH, 'w', newline='') as f:\n",
    "    fieldnames = ['query_idx', 'dataset', 'query', 'answer', 'word_count',\n",
    "                  'doc_token_len', 'answer_token_len',\n",
    "                  'bare', 'sf_trunc', 'sf_trunc_bias2',\n",
    "                  'values_only', 'values_early', 'values_hero']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for r in all_results:\n",
    "        writer.writerow({k: r.get(k, '') for k in fieldnames})\n",
    "print(f\"CSV saved: {CSV_PATH}\")\n",
    "\n",
    "# --- Verdict ---\n",
    "best_ds = None\n",
    "best_cond = None\n",
    "best_d = -999\n",
    "for ds_name in dataset_names:\n",
    "    if ds_name not in analysis:\n",
    "        continue\n",
    "    for cname in CONDITION_NAMES:\n",
    "        if cname == 'bare':\n",
    "            continue\n",
    "        if cname in analysis[ds_name]:\n",
    "            d = analysis[ds_name][cname]['cohens_d']\n",
    "            if d > best_d:\n",
    "                best_d = d\n",
    "                best_ds = ds_name\n",
    "                best_cond = cname\n",
    "\n",
    "if best_d > 0.15:\n",
    "    verdict = (f\"SUCCESS: Gemma toolkit generalizes! Best: {best_ds}/{best_cond} \"\n",
    "               f\"d={best_d:+.3f}\")\n",
    "elif best_d > 0.05:\n",
    "    verdict = (f\"PARTIAL: Weak generalization. Best: {best_ds}/{best_cond} \"\n",
    "               f\"d={best_d:+.3f}\")\n",
    "else:\n",
    "    verdict = (f\"FAILURE: Gemma toolkit does NOT generalize beyond MARCO. \"\n",
    "               f\"Best: {best_ds}/{best_cond} d={best_d:+.3f}\")\n",
    "\n",
    "# Check values_early on each dataset\n",
    "vel_results = {}\n",
    "for ds_name in dataset_names:\n",
    "    if ds_name in analysis and 'values_early' in analysis[ds_name]:\n",
    "        vel_results[ds_name] = analysis[ds_name]['values_early']['cohens_d']\n",
    "vel_verdict = \"values_early results: \" + \", \".join(\n",
    "    f\"{ds}={d:+.3f}\" for ds, d in vel_results.items())\n",
    "\n",
    "print(f\"\\nVERDICT: {verdict}\")\n",
    "print(f\"VEL: {vel_verdict}\")\n",
    "\n",
    "# --- results.json ---\n",
    "final = {\n",
    "    'experiment': 'exp27b_cross_dataset_gemma',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'model_type': 'gemma3',\n",
    "        'seed': SEED,\n",
    "        'n_per_dataset': N_PER_DATASET,\n",
    "        'max_doc_tokens': MAX_DOC_TOKENS,\n",
    "        'conditions': CONDITION_NAMES,\n",
    "        'early_layer_cutoff': EARLY_LAYER_CUTOFF,\n",
    "        'hero_layers': HERO_LAYERS,\n",
    "        'prefix': STATIC_FACT,\n",
    "        'prefix_token_len': PREFIX_TOKEN_LEN,\n",
    "        'datasets': dataset_names,\n",
    "        'length_bins': LENGTH_BINS,\n",
    "    },\n",
    "    'per_dataset_analysis': analysis,\n",
    "    'length_stratification': length_strat,\n",
    "    'hardness_data': hardness_data,\n",
    "    'verdict': verdict,\n",
    "    'vel_verdict': vel_verdict,\n",
    "    'per_sample_results': all_results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {FINAL_RESULTS_PATH}\")\n",
    "print(f\"File size: {FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY -- Exp 27b: Cross-Dataset (Gemma 3 4B)\")\n",
    "print(\"=\" * 70)\n",
    "for ds_name in dataset_names:\n",
    "    if ds_name not in analysis:\n",
    "        continue\n",
    "    print(f\"\\n  {ds_name.upper()}:\")\n",
    "    for cname in CONDITION_NAMES:\n",
    "        if cname == 'bare':\n",
    "            continue\n",
    "        if cname in analysis[ds_name]:\n",
    "            a = analysis[ds_name][cname]\n",
    "            sig = '***' if a['p_value'] < 0.001 else '**' if a['p_value'] < 0.01 else '*' if a['p_value'] < 0.05 else 'ns'\n",
    "            print(f\"    {cname:<20} d={a['cohens_d']:>+.3f}  win={a['win_pct']:.0f}%  {sig}\")\n",
    "\n",
    "print(f\"\\nVERDICT: {verdict}\")\n",
    "print(f\"VEL: {vel_verdict}\")\n",
    "print(f\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b49dba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T19:56:10.717600Z",
     "iopub.status.busy": "2026-02-16T19:56:10.716952Z",
     "iopub.status.idle": "2026-02-16T19:56:11.423860Z",
     "shell.execute_reply": "2026-02-16T19:56:11.423005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 3.24 GB -> 0.01 GB\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: GPU cleanup\n",
    "import gc\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0025c84fa0b94301a8c763d1bf02ef94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_680641ca9819465ea91f44bc02518688",
        "IPY_MODEL_36a626d7078e4d2bafb996382a503338",
        "IPY_MODEL_d5431b5d87c14747a40aff776f3b3776"
       ],
       "layout": "IPY_MODEL_0b2622fc80f34a739f64531347bbfee6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0211f8d931e745bb9b5c2f7a4b4808f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53c2d644be4f4743942160fe422675dc",
       "max": 287.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d36e694dfa2e46d7aaff11853777ad57",
       "tabbable": null,
       "tooltip": null,
       "value": 287.0
      }
     },
     "0320a7effa0240b186ed384679a013be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bd8b968aec494950ae7cc06823209b6c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_1e7315b23da14e46bfcbd3b92a1c52ba",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡900/900â€‡[00:04&lt;00:00,â€‡305.50it/s]"
      }
     },
     "0a6922b3e1c244678f543ab731a9f4e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b2622fc80f34a739f64531347bbfee6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f62d493745a48dfbcb6caae13c555cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0fb7549da2cb4a0ebe8f5c70d5e178a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10c8e555ec5a441aaa9e3868834ad598": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d89c16ed10a4ec19e3aca2e80e2b936": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e7315b23da14e46bfcbd3b92a1c52ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2a8913da443441299654286919051c56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2b22b1116629488689c9751b37936fe8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "32bb930d23774ff8bb316f0d6b4821df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33b225e3aeaa46f684b9e4e9824a69eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_32bb930d23774ff8bb316f0d6b4821df",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0f62d493745a48dfbcb6caae13c555cd",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡287/287â€‡[00:00&lt;00:00,â€‡11678.54it/s]"
      }
     },
     "351d9d9de1f44f288990ce7f0f348f1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "366ac130e0a74bc391e2cef1b8ba377d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3c26f57941c5455abbfe8e24df51ef70",
        "IPY_MODEL_4517c3a0ca2a4dfa96707edfa737a4b0",
        "IPY_MODEL_fe50bf8e28f448ea958b7d58dab1f629"
       ],
       "layout": "IPY_MODEL_c67304bdce7b4b0ab1cdea9f8d983385",
       "tabbable": null,
       "tooltip": null
      }
     },
     "36a626d7078e4d2bafb996382a503338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_57653872fa9f45c789074045c50c5800",
       "max": 7405.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7b8fe385e5784d84a53308e462aac348",
       "tabbable": null,
       "tooltip": null,
       "value": 900.0
      }
     },
     "3c26f57941c5455abbfe8e24df51ef70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d9ab5eb705b34b809f030cfd888056d7",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2a8913da443441299654286919051c56",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "3d0d9f5b81454e60a93f5b237151577f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3eb0e0284a73460a9da7bed73ed575c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fdaee91c22b4abb865ac51732780514": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42cb5ac662714620907df8459e27b757": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42f486fd13ce4a089d4c861516743496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7e1b85e65414471da5ea67a3dd332f9f",
       "max": 287.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7f19f71f59984ce6a723d2929fb77c56",
       "tabbable": null,
       "tooltip": null,
       "value": 287.0
      }
     },
     "4517c3a0ca2a4dfa96707edfa737a4b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d0d9f5b81454e60a93f5b237151577f",
       "max": 26.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_978a249325044466aceada59d5f2a3ad",
       "tabbable": null,
       "tooltip": null,
       "value": 26.0
      }
     },
     "4acd3a2ff0e94dc7b853a99907037124": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b2d3e6b304b4eba95637d4654c2da50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7923a3cf2a6e46b39267d019feb8ac84",
        "IPY_MODEL_fc4b515fd5304e29b91b3dab5b97f90b",
        "IPY_MODEL_e36200172a6042cc871e47fb8d368143"
       ],
       "layout": "IPY_MODEL_9ad8ad1ac9054809b2f6ee7d0b6b6486",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4bc50e982fe748248689e869d51e2d53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c390495874742f1bb6df8d245136529": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4d1176a50361455699b235d65fb91657": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f2931672ed040fd8c26ff8b0edd9b27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d89c16ed10a4ec19e3aca2e80e2b936",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0fb7549da2cb4a0ebe8f5c70d5e178a6",
       "tabbable": null,
       "tooltip": null,
       "value": "Processingâ€‡NQ:â€‡"
      }
     },
     "53c2d644be4f4743942160fe422675dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5491bc11ca94420ba6fbe36e2f2c79a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "55a6ea97de7f4f62b17758e80ee7d70a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a42befcb0384922afe68bc15fea1e55",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4c390495874742f1bb6df8d245136529",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡883/883â€‡[00:35&lt;00:00,â€‡579.38it/s,â€‡Materializingâ€‡param=model.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "56031e5dfffd48bc8e61ec1da3be4757": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57653872fa9f45c789074045c50c5800": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a42befcb0384922afe68bc15fea1e55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c8f5294a4564eec811dcfc963521b09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d22729ce3f884520bf4128f2c0cc6665",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c6ad9fd56b4b488187bfdf606908ae41",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡4078/?â€‡[01:42&lt;00:00,â€‡40.80it/s]"
      }
     },
     "680641ca9819465ea91f44bc02518688": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc0734917f9e4be7ba42102693757b56",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8774bb0486db4c5f93bf515f374edc5f",
       "tabbable": null,
       "tooltip": null,
       "value": "Filteringâ€‡HotpotQA:â€‡â€‡12%"
      }
     },
     "68c6015d71894ad5bd679b061037ada7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69390e2601704ec1a54eb3ef336305a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "696f02516bde421ea2d53f53472697ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4f2931672ed040fd8c26ff8b0edd9b27",
        "IPY_MODEL_a52527b72ce44533a3a6b143d1cf5f5c",
        "IPY_MODEL_5c8f5294a4564eec811dcfc963521b09"
       ],
       "layout": "IPY_MODEL_3fdaee91c22b4abb865ac51732780514",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6a56c2d55ce148c49d64df04068ba7a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70da9fa88b05454f96ee223d59eef48e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7377e169cac1465aadcc13fe1fe8051d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "739e651f3703478f94861e2c1409332d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "781306ea53df4db8b4b9583bf967d4f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78f4ee00f2da4ac9bac6fe2daf42f00d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4983f7a28a747f19ae9d4afa668afb0",
        "IPY_MODEL_0211f8d931e745bb9b5c2f7a4b4808f3",
        "IPY_MODEL_33b225e3aeaa46f684b9e4e9824a69eb"
       ],
       "layout": "IPY_MODEL_56031e5dfffd48bc8e61ec1da3be4757",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7923a3cf2a6e46b39267d019feb8ac84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb6831e34a8a46158ced4de97dd90a13",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_aad20c7fd82440928c678dc7922ff12b",
       "tabbable": null,
       "tooltip": null,
       "value": "Filteringâ€‡TriviaQA:â€‡â€‡19%"
      }
     },
     "7b8fe385e5784d84a53308e462aac348": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7cf3f1c1b3174e5fb23f9e4b889ea6d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7de4a0750fe94b89b674144351289311": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e1b85e65414471da5ea67a3dd332f9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e77332432664874bc001e5a4fcbd6a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7f19f71f59984ce6a723d2929fb77c56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8152f2fb760e41ba8e01f016e358b097": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8bd91083b5334132b8296c8953d8106d",
       "max": 900.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5491bc11ca94420ba6fbe36e2f2c79a5",
       "tabbable": null,
       "tooltip": null,
       "value": 900.0
      }
     },
     "83369343493f4cd289845a28d5a3538f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "872d163c0e2b49688d9a3fcdd54fc983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8774bb0486db4c5f93bf515f374edc5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8bd91083b5334132b8296c8953d8106d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d42345fb01945c093ec87ec947f47b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "978a249325044466aceada59d5f2a3ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ad8ad1ac9054809b2f6ee7d0b6b6486": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d50f7cc0fb44abf811c561eebd98a68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9f1cfb3cc8c54dfba1dba8e8c71eef30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4acd3a2ff0e94dc7b853a99907037124",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_739e651f3703478f94861e2c1409332d",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizing:â€‡100%"
      }
     },
     "a2b70fea08c74127aead8b116e786227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a39162d88493466faeb3116fcfc7174b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a4717c60fd434aa3b2cd3019c0ac3f11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a52527b72ce44533a3a6b143d1cf5f5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d50f7cc0fb44abf811c561eebd98a68",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f86139f517ed4454a401022af2496bb1",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "a918318682a449ccbe4882c2a1783d6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6a56c2d55ce148c49d64df04068ba7a9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7e77332432664874bc001e5a4fcbd6a0",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡900/900â€‡[42:08&lt;00:00,â€‡â€‡2.82s/it]"
      }
     },
     "aad20c7fd82440928c678dc7922ff12b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "afa9507939cc4b95ab0f8471914ebc0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d1176a50361455699b235d65fb91657",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7de4a0750fe94b89b674144351289311",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡287/287â€‡[00:00&lt;00:00,â€‡12482.92it/s]"
      }
     },
     "b19f8b9c1ad0444ca76dc079b2fd7b9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef509b614dd841d389bbedb7c0141c41",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7377e169cac1465aadcc13fe1fe8051d",
       "tabbable": null,
       "tooltip": null,
       "value": "Loadingâ€‡weights:â€‡100%"
      }
     },
     "b2c3f060fe7a4eee8036323dd82ad984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b45bba4933f9475a9fa7315b75f8c5f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10c8e555ec5a441aaa9e3868834ad598",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a39162d88493466faeb3116fcfc7174b",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "b4d599b1441f4e3d920db18505895769": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9f1cfb3cc8c54dfba1dba8e8c71eef30",
        "IPY_MODEL_8152f2fb760e41ba8e01f016e358b097",
        "IPY_MODEL_0320a7effa0240b186ed384679a013be"
       ],
       "layout": "IPY_MODEL_69390e2601704ec1a54eb3ef336305a8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bbbd1d7f7c904d86b1172d978f4fd4a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc0734917f9e4be7ba42102693757b56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd8b968aec494950ae7cc06823209b6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beda39269f954a958ad31db4561f44c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c67304bdce7b4b0ab1cdea9f8d983385": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6ad9fd56b4b488187bfdf606908ae41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb6831e34a8a46158ced4de97dd90a13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccb2d86450524541b5d836a019394afd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b19f8b9c1ad0444ca76dc079b2fd7b9a",
        "IPY_MODEL_faa153adb35948cc90c182e32597d58c",
        "IPY_MODEL_55a6ea97de7f4f62b17758e80ee7d70a"
       ],
       "layout": "IPY_MODEL_3eb0e0284a73460a9da7bed73ed575c0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d22729ce3f884520bf4128f2c0cc6665": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d36e694dfa2e46d7aaff11853777ad57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d5431b5d87c14747a40aff776f3b3776": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68c6015d71894ad5bd679b061037ada7",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8d42345fb01945c093ec87ec947f47b5",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡900/7405â€‡[00:00&lt;00:01,â€‡3849.51it/s]"
      }
     },
     "d9ab5eb705b34b809f030cfd888056d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e02fd63880d7444684946db3577c8fa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a4717c60fd434aa3b2cd3019c0ac3f11",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_42cb5ac662714620907df8459e27b757",
       "tabbable": null,
       "tooltip": null,
       "value": "Expâ€‡27b:â€‡100%"
      }
     },
     "e36200172a6042cc871e47fb8d368143": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0a6922b3e1c244678f543ab731a9f4e1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_351d9d9de1f44f288990ce7f0f348f1a",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1554/7993â€‡[00:01&lt;00:04,â€‡1447.12it/s]"
      }
     },
     "e4983f7a28a747f19ae9d4afa668afb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7cf3f1c1b3174e5fb23f9e4b889ea6d6",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_bbbd1d7f7c904d86b1172d978f4fd4a5",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "e72dd8eb414f428bbe62a29dbd045b78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e02fd63880d7444684946db3577c8fa3",
        "IPY_MODEL_e8c37f4f7f204d349947fe3b0cc56cf0",
        "IPY_MODEL_a918318682a449ccbe4882c2a1783d6d"
       ],
       "layout": "IPY_MODEL_70da9fa88b05454f96ee223d59eef48e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e8c37f4f7f204d349947fe3b0cc56cf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fcef73e19cad4bc5a8cc96b64a6dedfd",
       "max": 900.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_872d163c0e2b49688d9a3fcdd54fc983",
       "tabbable": null,
       "tooltip": null,
       "value": 900.0
      }
     },
     "eb9c5df5c3494e469382e9ab3fa52abd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b45bba4933f9475a9fa7315b75f8c5f9",
        "IPY_MODEL_42f486fd13ce4a089d4c861516743496",
        "IPY_MODEL_afa9507939cc4b95ab0f8471914ebc0b"
       ],
       "layout": "IPY_MODEL_beda39269f954a958ad31db4561f44c5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ef509b614dd841d389bbedb7c0141c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f86139f517ed4454a401022af2496bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "faa153adb35948cc90c182e32597d58c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a2b70fea08c74127aead8b116e786227",
       "max": 883.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2b22b1116629488689c9751b37936fe8",
       "tabbable": null,
       "tooltip": null,
       "value": 883.0
      }
     },
     "fc4b515fd5304e29b91b3dab5b97f90b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4bc50e982fe748248689e869d51e2d53",
       "max": 7993.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83369343493f4cd289845a28d5a3538f",
       "tabbable": null,
       "tooltip": null,
       "value": 1554.0
      }
     },
     "fcef73e19cad4bc5a8cc96b64a6dedfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe50bf8e28f448ea958b7d58dab1f629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b2c3f060fe7a4eee8036323dd82ad984",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_781306ea53df4db8b4b9583bf967d4f2",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡26/26â€‡[00:00&lt;00:00,â€‡2209.00it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
