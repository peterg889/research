{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1ac3f2",
   "metadata": {},
   "source": [
    "# Exp 11: Long-Document Priming — Does It Scale?\n",
    "\n",
    "## Motivation\n",
    "\n",
    "All v2 experiments (01-10) used MS MARCO v1.1, where passages average ~60 words\n",
    "(max 300 words). In production ad-serving, documents will be much longer — full\n",
    "web pages, articles, product descriptions. The key question: **does our best\n",
    "priming approach (static_fact_trunc, d=+0.438 on MS MARCO) still work on longer\n",
    "documents?**\n",
    "\n",
    "Prior evidence (v1 Exp 19) showed priming hurts on datasets with longer documents\n",
    "(CNN/DailyMail d=-1.31, NarrativeQA d=-0.35), but that used full-context mode\n",
    "with known bugs (BPE mismatch, Document:\\n framing). This experiment re-tests\n",
    "with clean v2 methodology (truncated prefix, matched tokenization, no framing).\n",
    "\n",
    "## Dataset: Natural Questions\n",
    "\n",
    "Real Google search queries over full Wikipedia articles:\n",
    "- **Queries**: Short factoid Google queries (closest to production ad queries)\n",
    "- **Documents**: Full Wikipedia article text (100-10000+ words)\n",
    "- **Answers**: Short extractive answer spans (entity names, dates, numbers)\n",
    "\n",
    "## Design\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Dataset | Natural Questions (validation) |\n",
    "| Length bins | 100-300w, 300-800w, 800-2000w, 2000-4000w |\n",
    "| Samples per bin | ~125 (500 total) |\n",
    "| Conditions | 5: bare, static_fact_trunc, random_trunc, llm_kw_trunc, oracle_trunc |\n",
    "| Forward passes | 5 × 500 = 2500 |\n",
    "| Estimated runtime | 4-6 hours |\n",
    "\n",
    "## 5 Primary Comparisons (Bonferroni alpha = 0.01)\n",
    "\n",
    "| # | Comparison | Question |\n",
    "|---|-----------|----------|\n",
    "| C1 | static_fact_trunc vs bare | Does static_fact help overall? |\n",
    "| C2 | random_trunc vs bare | Does ANY prefix help overall? |\n",
    "| C3 | llm_kw_trunc vs bare | Do LLM keywords help overall? |\n",
    "| C4 | oracle_trunc vs bare | Does the perfect query help? |\n",
    "| C5 | static_fact_trunc vs random_trunc | Is content better than noise? |\n",
    "\n",
    "## Key Interaction Analysis\n",
    "\n",
    "For each comparison, test per length bin. If static_fact benefit decreases with\n",
    "document length, we expect a negative slope in the length × d regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974d11ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:38:28.118805Z",
     "iopub.status.busy": "2026-02-12T12:38:28.118448Z",
     "iopub.status.idle": "2026-02-12T12:38:31.515867Z",
     "shell.execute_reply": "2026-02-12T12:38:31.514653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Results directory: results/exp11\n",
      "CUDA available: True\n",
      "GPU: NVIDIA L4\n",
      "GPU memory: 23.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup — permissions, seeds, results directory\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp11\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SURROGATES_DIR = RESULTS_DIR / \"surrogates\"\n",
    "SURROGATES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7976a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:38:31.519864Z",
     "iopub.status.busy": "2026-02-12T12:38:31.519380Z",
     "iopub.status.idle": "2026-02-12T12:39:20.270271Z",
     "shell.execute_reply": "2026-02-12T12:39:20.269050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mistralai/Mistral-7B-Instruct-v0.2 (4-bit)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19833a09b4c54819a6df4fa95d10ded2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.float16, device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load model (Mistral-7B 4-bit)\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit)...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded. dtype={model.dtype}, device={model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e38cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:39:20.274481Z",
     "iopub.status.busy": "2026-02-12T12:39:20.273944Z",
     "iopub.status.idle": "2026-02-12T12:39:21.058015Z",
     "shell.execute_reply": "2026-02-12T12:39:21.056463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready\n",
      "  N_EVAL: 500\n",
      "  SAMPLES_PER_BIN: 125\n",
      "  bonferroni_alpha: 0.0100 (5 comparisons)\n",
      "  conditions: 5\n",
      "  static_factual_phrase: 'What are the key facts I need to know?'\n",
      "  length_bins: [('short', 100, 300), ('medium', 300, 800), ('long', 800, 2000), ('very_long', 2000, 4000)]\n",
      "  max_doc_words: 4000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Config, constants, and helper functions\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.kv_cache import (\n",
    "    deepcopy_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    "    score_answer_with_cache,\n",
    ")\n",
    "from lib.analysis import cohens_d\n",
    "from lib.surrogate import STATIC_SURROGATE_QUERIES, generate_surrogate_with_template\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_samples=2000,  # pool to draw from\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Templates — bare text, no \"Document:\\n\" framing\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "QUERY_TEMPLATE = \"\\nQuery: {query}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"\n",
    "\n",
    "N_EVAL = 500  # total target (125 per bin)\n",
    "N_COMPARISONS = 5\n",
    "BONFERRONI_ALPHA = 0.05 / N_COMPARISONS\n",
    "CHECKPOINT_EVERY = 25\n",
    "\n",
    "STATIC_FACTUAL_PHRASE = STATIC_SURROGATE_QUERIES['static_factual']['query']\n",
    "\n",
    "# Length bins (word count)\n",
    "LENGTH_BINS = [\n",
    "    ('short',     100,  300),   # MS MARCO-like\n",
    "    ('medium',    300,  800),   # Moderate web page\n",
    "    ('long',      800,  2000),  # Full article section\n",
    "    ('very_long', 2000, 4000),  # Full article\n",
    "]\n",
    "SAMPLES_PER_BIN = 125\n",
    "MAX_DOC_WORDS = 4000  # hard cap (context window safety)\n",
    "\n",
    "CONDITION_NAMES = [\n",
    "    'bare',\n",
    "    'static_fact_trunc',\n",
    "    'random_trunc',\n",
    "    'llm_kw_trunc',\n",
    "    'oracle_trunc',\n",
    "]\n",
    "\n",
    "# LLM keyword generation prompt (same as previous experiments)\n",
    "LLM_KW_PROMPT = (\n",
    "    \"You are helping index a document for search. Write a search query the way \"\n",
    "    \"real users type into Google: just keywords, no complete sentences, no question marks. \"\n",
    "    \"Think of someone quickly typing a few relevant words. \"\n",
    "    \"Output only the keyword query (3-6 words), nothing else.\\n\\n\"\n",
    "    \"Document:\"\n",
    ")\n",
    "\n",
    "# Max words of document to show for LLM keyword generation (truncate long docs)\n",
    "LLM_KW_MAX_DOC_WORDS = 500\n",
    "\n",
    "\n",
    "def build_primed_and_truncated(prefix_text, bos_id, doc_ids, doc_len, model, tokenizer, config):\n",
    "    \"\"\"Build a primed cache: tokenize prefix, concat [BOS][prefix][doc], forward, truncate+RoPE.\n",
    "\n",
    "    Returns:\n",
    "        (trunc_cache, prefix_token_len)\n",
    "    \"\"\"\n",
    "    prefix_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=prefix_text)\n",
    "    prefix_enc = tokenizer(prefix_str, return_tensors=\"pt\",\n",
    "                           add_special_tokens=False, padding=False, truncation=False)\n",
    "    prefix_ids = prefix_enc['input_ids'].to(config.device)\n",
    "    prefix_token_len = 1 + prefix_ids.shape[1]  # BOS + prefix tokens\n",
    "\n",
    "    full_ids = torch.cat([bos_id, prefix_ids, doc_ids], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=full_ids,\n",
    "                    attention_mask=torch.ones_like(full_ids),\n",
    "                    use_cache=True, return_dict=True)\n",
    "\n",
    "    trunc_cache = extract_and_truncate_cache_with_bos(out.past_key_values, doc_len)\n",
    "    correct_rope_positions_with_bos(trunc_cache, prefix_token_len - 1, model)\n",
    "\n",
    "    del out\n",
    "    return trunc_cache, prefix_token_len\n",
    "\n",
    "\n",
    "print(\"Config ready\")\n",
    "print(f\"  N_EVAL: {N_EVAL}\")\n",
    "print(f\"  SAMPLES_PER_BIN: {SAMPLES_PER_BIN}\")\n",
    "print(f\"  bonferroni_alpha: {BONFERRONI_ALPHA:.4f} ({N_COMPARISONS} comparisons)\")\n",
    "print(f\"  conditions: {len(CONDITION_NAMES)}\")\n",
    "print(f\"  static_factual_phrase: '{STATIC_FACTUAL_PHRASE}'\")\n",
    "print(f\"  length_bins: {LENGTH_BINS}\")\n",
    "print(f\"  max_doc_words: {MAX_DOC_WORDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2c89c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:39:21.063806Z",
     "iopub.status.busy": "2026-02-12T12:39:21.063058Z",
     "iopub.status.idle": "2026-02-12T12:44:08.361678Z",
     "shell.execute_reply": "2026-02-12T12:44:08.360726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING NATURAL QUESTIONS (validation split)\n",
      "======================================================================\n",
      "Loading NQ dataset (streaming mode)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e5ee7034e9466eb734af3696c71cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9004809a56b48ae8601dc332ae48b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70840c6855044dd812db83fb562226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NQ: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00003-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00004-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00004-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00004-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00004-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'The read operation timed out' thrown while requesting GET https://huggingface.co/datasets/google-research-datasets/natural_questions/resolve/e8103d566bef4154c2c12b17c6095ec5275840cc/default/validation-00004-of-00007.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  short: 15 samples\n",
      "  medium: 125 samples\n",
      "  long: 125 samples\n",
      "  very_long: 125 samples\n",
      "\n",
      "Total samples: 390\n",
      "Processed: 7830, No answer: 3541, Too short: 0\n",
      "Cached to results/exp11/nq_samples.json\n",
      "\n",
      "======================================================================\n",
      "SAMPLE SUMMARY\n",
      "======================================================================\n",
      "  short (100-300w): n=15, mean=212w, range=[130, 284]\n",
      "  medium (300-800w): n=125, mean=586w, range=[310, 797]\n",
      "  long (800-2000w): n=125, mean=1456w, range=[811, 1990]\n",
      "  very_long (2000-4000w): n=125, mean=2903w, range=[2004, 3980]\n",
      "\n",
      "Example (short):\n",
      "  Q: what does amx stand for in french tanks\n",
      "  A: Atelier de Construction d'Issy-Les-Moulineaux\n",
      "  Doc (255w): AMX - wikipedia AMX Jump to : navigation , search AMX may refer to : AMX LLC , a manufacturer of commercial and residential control systems AMC AMX , ...\n",
      "\n",
      "Example (very_long):\n",
      "  Q: what is final season of game of thrones\n",
      "  A: the eighth season\n",
      "  Doc (3084w): Game of Thrones ( season 8 ) - wikipedia Game of Thrones ( season 8 ) Jump to : navigation , search Game of Thrones ( season 8 ) Promotional poster St...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Natural Questions — extract clean text + short answers, stratify by length\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING NATURAL QUESTIONS (validation split)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for cached samples\n",
    "SAMPLES_CACHE_PATH = RESULTS_DIR / \"nq_samples.json\"\n",
    "\n",
    "if SAMPLES_CACHE_PATH.exists():\n",
    "    with open(SAMPLES_CACHE_PATH, 'r') as f:\n",
    "        cached = json.load(f)\n",
    "    samples = cached['samples']\n",
    "    print(f\"Loaded {len(samples)} cached NQ samples from {SAMPLES_CACHE_PATH}\")\n",
    "else:\n",
    "    print(\"Loading NQ dataset (streaming mode)...\")\n",
    "    nq = load_dataset(\n",
    "        \"google-research-datasets/natural_questions\",\n",
    "        split=\"validation\",\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    # Collect samples into length bins\n",
    "    bin_samples = {name: [] for name, _, _ in LENGTH_BINS}\n",
    "    n_processed = 0\n",
    "    n_no_answer = 0\n",
    "    n_too_short = 0\n",
    "    n_too_long = 0\n",
    "\n",
    "    for example in tqdm(nq, desc=\"Processing NQ\"):\n",
    "        n_processed += 1\n",
    "\n",
    "        # Extract clean document text (non-HTML tokens)\n",
    "        doc_tokens = example['document']['tokens']\n",
    "        if isinstance(doc_tokens, dict):\n",
    "            # HF may return dict of lists instead of list of dicts\n",
    "            token_strs = doc_tokens['token']\n",
    "            is_html_flags = doc_tokens['is_html']\n",
    "            clean_tokens = [t for t, h in zip(token_strs, is_html_flags) if not h]\n",
    "        else:\n",
    "            clean_tokens = [t['token'] for t in doc_tokens if not t['is_html']]\n",
    "\n",
    "        doc_text = ' '.join(clean_tokens)\n",
    "        word_count = len(doc_text.split())\n",
    "\n",
    "        # Skip if outside our range\n",
    "        if word_count < LENGTH_BINS[0][1]:  # below minimum\n",
    "            n_too_short += 1\n",
    "            continue\n",
    "        if word_count > MAX_DOC_WORDS:\n",
    "            # Truncate to MAX_DOC_WORDS\n",
    "            words = doc_text.split()\n",
    "            doc_text = ' '.join(words[:MAX_DOC_WORDS])\n",
    "            word_count = MAX_DOC_WORDS\n",
    "\n",
    "        # Extract short answer\n",
    "        annotations = example['annotations']\n",
    "        short_answers_list = annotations['short_answers']\n",
    "\n",
    "        answer_text = None\n",
    "        # NQ short_answers is a list of dicts (one per annotator).\n",
    "        # Each dict has 'start_token', 'end_token', 'text' as lists (one entry per span).\n",
    "        # Use 'text' directly when available; fall back to token reconstruction.\n",
    "        for annotator_sa in short_answers_list:\n",
    "            if not annotator_sa:\n",
    "                continue\n",
    "            # Use pre-extracted text field if available\n",
    "            texts = annotator_sa.get('text', [])\n",
    "            if texts:\n",
    "                answer_text = texts[0]\n",
    "                break\n",
    "            # Fallback: reconstruct from document tokens\n",
    "            starts = annotator_sa.get('start_token', [])\n",
    "            ends = annotator_sa.get('end_token', [])\n",
    "            if not starts or not ends:\n",
    "                continue\n",
    "            start_tok = starts[0] if isinstance(starts, list) else starts\n",
    "            end_tok = ends[0] if isinstance(ends, list) else ends\n",
    "            if start_tok >= 0 and end_tok > start_tok:\n",
    "                if isinstance(doc_tokens, dict):\n",
    "                    ans_tokens = [\n",
    "                        doc_tokens['token'][i]\n",
    "                        for i in range(start_tok, min(end_tok, len(doc_tokens['token'])))\n",
    "                        if not doc_tokens['is_html'][i]\n",
    "                    ]\n",
    "                else:\n",
    "                    ans_tokens = [\n",
    "                        doc_tokens[i]['token']\n",
    "                        for i in range(start_tok, min(end_tok, len(doc_tokens)))\n",
    "                        if not doc_tokens[i]['is_html']\n",
    "                    ]\n",
    "                if ans_tokens:\n",
    "                    answer_text = ' '.join(ans_tokens)\n",
    "                    break\n",
    "\n",
    "        if not answer_text or len(answer_text.strip()) == 0:\n",
    "            n_no_answer += 1\n",
    "            continue\n",
    "\n",
    "        # Skip very long answers (>20 words) — we want factoid answers\n",
    "        if len(answer_text.split()) > 20:\n",
    "            continue\n",
    "\n",
    "        # Extract query\n",
    "        question = example['question']\n",
    "        if isinstance(question, dict):\n",
    "            query = question.get('text', '')\n",
    "        else:\n",
    "            query = str(question)\n",
    "\n",
    "        if not query.strip():\n",
    "            continue\n",
    "\n",
    "        # Assign to length bin\n",
    "        assigned = False\n",
    "        for bin_name, bin_min, bin_max in LENGTH_BINS:\n",
    "            if bin_min <= word_count < bin_max:\n",
    "                if len(bin_samples[bin_name]) < SAMPLES_PER_BIN:\n",
    "                    bin_samples[bin_name].append({\n",
    "                        'passage': doc_text,\n",
    "                        'query': query,\n",
    "                        'answer': answer_text,\n",
    "                        'word_count': word_count,\n",
    "                        'length_bin': bin_name,\n",
    "                    })\n",
    "                assigned = True\n",
    "                break\n",
    "\n",
    "        # Check if all bins are full\n",
    "        all_full = all(len(bin_samples[name]) >= SAMPLES_PER_BIN for name, _, _ in LENGTH_BINS)\n",
    "        if all_full:\n",
    "            print(f\"All bins full after processing {n_processed} examples.\")\n",
    "            break\n",
    "\n",
    "    # Combine all bins\n",
    "    samples = []\n",
    "    for bin_name, _, _ in LENGTH_BINS:\n",
    "        bin_s = bin_samples[bin_name]\n",
    "        np.random.seed(SEED)\n",
    "        np.random.shuffle(bin_s)\n",
    "        samples.extend(bin_s)\n",
    "        print(f\"  {bin_name}: {len(bin_s)} samples\")\n",
    "\n",
    "    print(f\"\\nTotal samples: {len(samples)}\")\n",
    "    print(f\"Processed: {n_processed}, No answer: {n_no_answer}, Too short: {n_too_short}\")\n",
    "\n",
    "    # Cache for fast reload\n",
    "    with open(SAMPLES_CACHE_PATH, 'w') as f:\n",
    "        json.dump({'samples': samples, 'n_processed': n_processed}, f)\n",
    "    print(f\"Cached to {SAMPLES_CACHE_PATH}\")\n",
    "\n",
    "N = len(samples)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"SAMPLE SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "for bin_name, bin_min, bin_max in LENGTH_BINS:\n",
    "    bin_s = [s for s in samples if s['length_bin'] == bin_name]\n",
    "    if bin_s:\n",
    "        wcs = [s['word_count'] for s in bin_s]\n",
    "        print(f\"  {bin_name} ({bin_min}-{bin_max}w): n={len(bin_s)}, \"\n",
    "              f\"mean={np.mean(wcs):.0f}w, range=[{min(wcs)}, {max(wcs)}]\")\n",
    "\n",
    "print(f\"\\nExample (short):\")\n",
    "ex_short = [s for s in samples if s['length_bin'] == 'short']\n",
    "if ex_short:\n",
    "    print(f\"  Q: {ex_short[0]['query']}\")\n",
    "    print(f\"  A: {ex_short[0]['answer']}\")\n",
    "    print(f\"  Doc ({ex_short[0]['word_count']}w): {ex_short[0]['passage'][:150]}...\")\n",
    "\n",
    "print(f\"\\nExample (very_long):\")\n",
    "ex_long = [s for s in samples if s['length_bin'] == 'very_long']\n",
    "if ex_long:\n",
    "    print(f\"  Q: {ex_long[0]['query']}\")\n",
    "    print(f\"  A: {ex_long[0]['answer']}\")\n",
    "    print(f\"  Doc ({ex_long[0]['word_count']}w): {ex_long[0]['passage'][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4727050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:44:08.365382Z",
     "iopub.status.busy": "2026-02-12T12:44:08.364817Z",
     "iopub.status.idle": "2026-02-12T12:44:08.372308Z",
     "shell.execute_reply": "2026-02-12T12:44:08.371478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENTAL CONDITIONS EXPLAINED\n",
      "======================================================================\n",
      "\n",
      "### 1. bare ###\n",
      "  Cache: [BOS][doc]\n",
      "  Detail: No prefix — baseline. Identical to bare caches used in Exps 01-10.\n",
      "\n",
      "### 2. static_fact_trunc ###\n",
      "  Cache: [BOS][static_fact\\n][doc] → truncate + RoPE\n",
      "  Detail: Best condition from Exp 07/10 (d=+0.438 on MS MARCO). Phrase: 'What are the key facts I need to know?'\n",
      "\n",
      "### 3. random_trunc ###\n",
      "  Cache: [BOS][random_tokens\\n][doc] → truncate + RoPE\n",
      "  Detail: Structural control — random vocabulary tokens. Isolates non-semantic value contamination.\n",
      "\n",
      "### 4. llm_kw_trunc ###\n",
      "  Cache: [BOS][llm_kw\\n][doc] → truncate + RoPE\n",
      "  Detail: LLM-generated keyword query from first 500 words of doc. Tests doc-specific surrogates.\n",
      "\n",
      "### 5. oracle_trunc ###\n",
      "  Cache: [BOS][oracle_query\\n][doc] → truncate + RoPE\n",
      "  Detail: Oracle (actual NQ query) as prefix. Upper bound for query-specific priming.\n",
      "\n",
      "======================================================================\n",
      "KEY QUESTION: How does each condition's d vs bare change across length bins?\n",
      "======================================================================\n",
      "\n",
      "Expected token counts per bin (approx):\n",
      "  short (100-300w): ~300 tokens per doc\n",
      "  medium (300-800w): ~825 tokens per doc\n",
      "  long (800-2000w): ~2100 tokens per doc\n",
      "  very_long (2000-4000w): ~4500 tokens per doc\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Condition explanation\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPERIMENTAL CONDITIONS EXPLAINED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "conditions_explained = [\n",
    "    (\"1. bare\",\n",
    "     \"[BOS][doc]\",\n",
    "     \"No prefix — baseline. Identical to bare caches used in Exps 01-10.\"),\n",
    "    (\"2. static_fact_trunc\",\n",
    "     \"[BOS][static_fact\\\\n][doc] → truncate + RoPE\",\n",
    "     f\"Best condition from Exp 07/10 (d=+0.438 on MS MARCO). Phrase: '{STATIC_FACTUAL_PHRASE}'\"),\n",
    "    (\"3. random_trunc\",\n",
    "     \"[BOS][random_tokens\\\\n][doc] → truncate + RoPE\",\n",
    "     \"Structural control — random vocabulary tokens. Isolates non-semantic value contamination.\"),\n",
    "    (\"4. llm_kw_trunc\",\n",
    "     \"[BOS][llm_kw\\\\n][doc] → truncate + RoPE\",\n",
    "     \"LLM-generated keyword query from first 500 words of doc. Tests doc-specific surrogates.\"),\n",
    "    (\"5. oracle_trunc\",\n",
    "     \"[BOS][oracle_query\\\\n][doc] → truncate + RoPE\",\n",
    "     \"Oracle (actual NQ query) as prefix. Upper bound for query-specific priming.\"),\n",
    "]\n",
    "\n",
    "for name, pattern, detail in conditions_explained:\n",
    "    print(f\"\\n### {name} ###\")\n",
    "    print(f\"  Cache: {pattern}\")\n",
    "    print(f\"  Detail: {detail}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"KEY QUESTION: How does each condition's d vs bare change across length bins?\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Show token counts for different length docs\n",
    "print(f\"\\nExpected token counts per bin (approx):\")\n",
    "for bin_name, bin_min, bin_max in LENGTH_BINS:\n",
    "    mid_words = (bin_min + bin_max) // 2\n",
    "    approx_tokens = int(mid_words * 1.5)  # rough word-to-token ratio\n",
    "    print(f\"  {bin_name} ({bin_min}-{bin_max}w): ~{approx_tokens} tokens per doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20903815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:44:08.375541Z",
     "iopub.status.busy": "2026-02-12T12:44:08.375191Z",
     "iopub.status.idle": "2026-02-12T13:05:52.101955Z",
     "shell.execute_reply": "2026-02-12T13:05:52.101146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 1: LLM KEYWORD GENERATION\n",
      "======================================================================\n",
      "Generating keyword surrogates for samples 0 to 389...\n",
      "(Using first 500 words of each doc for generation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b88b8017e7f4751a828ebcd27371e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Keyword surrogates:   0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 50/390 | 0.31 s/s | ETA: 18.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 100/390 | 0.30 s/s | ETA: 16.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 150/390 | 0.30 s/s | ETA: 13.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 200/390 | 0.29 s/s | ETA: 10.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 250/390 | 0.30 s/s | ETA: 7.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 300/390 | 0.30 s/s | ETA: 5.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 350/390 | 0.30 s/s | ETA: 2.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 390/390 | 0.30 s/s | ETA: 0.0 min\n",
      "Keyword surrogates complete: 390 samples\n",
      "Empty surrogates: 0/390\n",
      "Example: 'amx manufacturer control systems car index aircraft company tank disambiguation wikipedia'\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate LLM keyword surrogates\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1: LLM KEYWORD GENERATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "surrogates_path = SURROGATES_DIR / \"keyword_surrogates.json\"\n",
    "\n",
    "if surrogates_path.exists():\n",
    "    with open(surrogates_path, 'r') as f:\n",
    "        surrogates_data = json.load(f)\n",
    "    keyword_surrogates = surrogates_data['surrogates']\n",
    "    print(f\"Loaded {len(keyword_surrogates)} keyword surrogates from cache\")\n",
    "else:\n",
    "    keyword_surrogates = []\n",
    "\n",
    "start_idx_gen = len(keyword_surrogates)\n",
    "if start_idx_gen < N:\n",
    "    print(f\"Generating keyword surrogates for samples {start_idx_gen} to {N-1}...\")\n",
    "    print(f\"(Using first {LLM_KW_MAX_DOC_WORDS} words of each doc for generation)\")\n",
    "    t_start = time.time()\n",
    "\n",
    "    for idx in tqdm(range(start_idx_gen, N), initial=start_idx_gen, total=N,\n",
    "                     desc=\"Keyword surrogates\"):\n",
    "        passage = samples[idx]['passage']\n",
    "        # Truncate to first LLM_KW_MAX_DOC_WORDS for generation efficiency\n",
    "        words = passage.split()\n",
    "        if len(words) > LLM_KW_MAX_DOC_WORDS:\n",
    "            passage_for_gen = ' '.join(words[:LLM_KW_MAX_DOC_WORDS])\n",
    "        else:\n",
    "            passage_for_gen = passage\n",
    "\n",
    "        try:\n",
    "            kw = generate_surrogate_with_template(\n",
    "                passage_for_gen, LLM_KW_PROMPT, model, tokenizer, config)\n",
    "        except Exception as e:\n",
    "            print(f\"  WARNING: Generation failed for sample {idx}: {e}\")\n",
    "            kw = \"\"\n",
    "        keyword_surrogates.append(kw)\n",
    "\n",
    "        if (idx + 1) % 50 == 0 or idx == N - 1:\n",
    "            with open(surrogates_path, 'w') as f:\n",
    "                json.dump({'surrogates': keyword_surrogates}, f)\n",
    "            elapsed = time.time() - t_start\n",
    "            rate = (idx - start_idx_gen + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (N - idx - 1) / rate if rate > 0 else 0\n",
    "            tqdm.write(f\"  Saved {idx+1}/{N} | {rate:.2f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "    with open(surrogates_path, 'w') as f:\n",
    "        json.dump({'surrogates': keyword_surrogates}, f)\n",
    "    print(f\"Keyword surrogates complete: {len(keyword_surrogates)} samples\")\n",
    "else:\n",
    "    print(f\"All keyword surrogates already cached ({len(keyword_surrogates)} samples)\")\n",
    "\n",
    "n_empty = sum(1 for s in keyword_surrogates if not s.strip())\n",
    "print(f\"Empty surrogates: {n_empty}/{N}\")\n",
    "if keyword_surrogates:\n",
    "    print(f\"Example: '{keyword_surrogates[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e6aa62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T13:05:52.105981Z",
     "iopub.status.busy": "2026-02-12T13:05:52.105682Z",
     "iopub.status.idle": "2026-02-12T13:50:15.256620Z",
     "shell.execute_reply": "2026-02-12T13:50:15.255685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 2: MAIN EVALUATION (5 conditions × 390 samples)\n",
      "======================================================================\n",
      "No checkpoint found. Starting fresh.\n",
      "Evaluating samples 0 to 389\n",
      "Conditions: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f50b54a3cb44b8a0b1ac66c253db8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 25/390 | 0.34 s/s | ETA: 17.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 50/390 | 0.31 s/s | ETA: 18.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 75/390 | 0.30 s/s | ETA: 17.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/390 | 0.29 s/s | ETA: 16.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 125/390 | 0.29 s/s | ETA: 15.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 150/390 | 0.27 s/s | ETA: 14.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 175/390 | 0.25 s/s | ETA: 14.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/390 | 0.23 s/s | ETA: 13.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 225/390 | 0.22 s/s | ETA: 12.5 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 250/390 | 0.21 s/s | ETA: 11.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 275/390 | 0.20 s/s | ETA: 9.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/390 | 0.18 s/s | ETA: 8.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 325/390 | 0.17 s/s | ETA: 6.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 350/390 | 0.16 s/s | ETA: 4.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 375/390 | 0.15 s/s | ETA: 1.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 390/390 | 0.15 s/s | ETA: 0.0 min\n",
      "\n",
      "Evaluation complete: 390 samples in 44.4 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main eval loop — 5 conditions × N samples\n",
    "print(\"=\" * 70)\n",
    "print(f\"PHASE 2: MAIN EVALUATION (5 conditions × {N} samples)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    with open(CHECKPOINT_PATH, 'r') as f:\n",
    "        ckpt = json.load(f)\n",
    "    ckpt_queries = ckpt.get('sample_queries', [])\n",
    "    current_queries = [s['query'] for s in samples]\n",
    "    if ckpt_queries == current_queries:\n",
    "        results = ckpt['results']\n",
    "        start_idx = len(results)\n",
    "        print(f\"Resuming from checkpoint: {start_idx}/{N}\")\n",
    "    else:\n",
    "        print(\"Checkpoint sample mismatch. Starting fresh.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh.\")\n",
    "\n",
    "print(f\"Evaluating samples {start_idx} to {N-1}\")\n",
    "print(f\"Conditions: {len(CONDITION_NAMES)}\")\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for idx in tqdm(range(start_idx, N), initial=start_idx, total=N, desc=\"Evaluating\"):\n",
    "    sample = samples[idx]\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "    word_count = sample['word_count']\n",
    "    length_bin = sample['length_bin']\n",
    "\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "\n",
    "    # --- Matched tokenization ---\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_oracle_text = oracle_prefix + document_text\n",
    "\n",
    "    full_oracle_enc = tokenizer(full_oracle_text, return_tensors=\"pt\",\n",
    "                                add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_oracle_ids = full_oracle_enc['input_ids'].to(config.device)\n",
    "\n",
    "    oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    oracle_prefix_len = oracle_prefix_enc['input_ids'].shape[1]\n",
    "\n",
    "    bos_id = full_oracle_ids[:, :1]\n",
    "    doc_ids = full_oracle_ids[:, oracle_prefix_len:]\n",
    "    doc_len = doc_ids.shape[1]\n",
    "\n",
    "    # ===== 1. BARE =====\n",
    "    bare_ids = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_ids, attention_mask=torch.ones_like(bare_ids),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_cache = bare_out.past_key_values\n",
    "    del bare_out\n",
    "\n",
    "    nll_bare = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_cache), bare_ids.shape[1],\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # ===== 2. static_fact_trunc =====\n",
    "    trunc_cache, _ = build_primed_and_truncated(\n",
    "        STATIC_FACTUAL_PHRASE, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    nll_static = score_answer_with_cache(\n",
    "        deepcopy_cache(trunc_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del trunc_cache\n",
    "\n",
    "    # ===== 3. random_trunc =====\n",
    "    llm_kw_text = keyword_surrogates[idx] if idx < len(keyword_surrogates) else \"\"\n",
    "    n_random_tokens = max(5, len(tokenizer.encode(\n",
    "        llm_kw_text if llm_kw_text else STATIC_FACTUAL_PHRASE,\n",
    "        add_special_tokens=False)))\n",
    "    random_ids = torch.randint(100, tokenizer.vocab_size - 100, (n_random_tokens,), device='cpu')\n",
    "    random_text = tokenizer.decode(random_ids, skip_special_tokens=True)\n",
    "\n",
    "    trunc_cache, _ = build_primed_and_truncated(\n",
    "        random_text, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    nll_random = score_answer_with_cache(\n",
    "        deepcopy_cache(trunc_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del trunc_cache\n",
    "\n",
    "    # ===== 4. llm_kw_trunc =====\n",
    "    if llm_kw_text.strip():\n",
    "        trunc_cache, _ = build_primed_and_truncated(\n",
    "            llm_kw_text, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "        nll_llm_kw = score_answer_with_cache(\n",
    "            deepcopy_cache(trunc_cache), 1 + doc_len,\n",
    "            query_prompt, answer_text, model, tokenizer, config)\n",
    "        del trunc_cache\n",
    "    else:\n",
    "        nll_llm_kw = 0.0  # empty surrogate → exclude from analysis\n",
    "\n",
    "    # ===== 5. oracle_trunc =====\n",
    "    trunc_cache, _ = build_primed_and_truncated(\n",
    "        query, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    nll_oracle = score_answer_with_cache(\n",
    "        deepcopy_cache(trunc_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del trunc_cache\n",
    "\n",
    "    del bare_cache, bare_ids\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Store result ---\n",
    "    result = {\n",
    "        'idx': idx,\n",
    "        'doc_len_tokens': doc_len,\n",
    "        'word_count': word_count,\n",
    "        'length_bin': length_bin,\n",
    "        'bare': nll_bare,\n",
    "        'static_fact_trunc': nll_static,\n",
    "        'random_trunc': nll_random,\n",
    "        'llm_kw_trunc': nll_llm_kw,\n",
    "        'oracle_trunc': nll_oracle,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    if (idx + 1) % CHECKPOINT_EVERY == 0 or idx == N - 1:\n",
    "        ckpt_data = {\n",
    "            'results': results,\n",
    "            'sample_queries': [s['query'] for s in samples],\n",
    "            'completed': len(results),\n",
    "            'total': N,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, 'w') as f:\n",
    "            json.dump(ckpt_data, f)\n",
    "        elapsed = time.time() - t_start\n",
    "        rate = (idx - start_idx + 1) / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N - idx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {idx+1}/{N} | {rate:.2f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nEvaluation complete: {len(results)} samples in {elapsed_total/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d89452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T13:50:15.261355Z",
     "iopub.status.busy": "2026-02-12T13:50:15.261052Z",
     "iopub.status.idle": "2026-02-12T13:50:15.756496Z",
     "shell.execute_reply": "2026-02-12T13:50:15.755530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYSIS — LONG-DOCUMENT PRIMING\n",
      "======================================================================\n",
      "Total: 390, Valid: 369, Excluded: 21\n",
      "\n",
      "Condition                   Mean NLL        Std  d vs Bare    Win%\n",
      "-------------------------------------------------------------------\n",
      "bare                          0.3566     1.0130          —       —\n",
      "static_fact_trunc             0.3585     0.9945     -0.019  65.0% ns\n",
      "random_trunc                  0.3626     0.9728     -0.034  64.2% ns\n",
      "llm_kw_trunc                  0.3714     1.0262     -0.120  50.1% *\n",
      "oracle_trunc                  0.3906     1.0770     -0.188  61.5% ***\n",
      "\n",
      "==========================================================================================\n",
      "5 PRIMARY COMPARISONS (Bonferroni alpha = 0.0100)\n",
      "==========================================================================================\n",
      "\n",
      "Comparison                     Mean delta        d    Win%        t            p   Sig\n",
      "-------------------------------------------------------------------------------------\n",
      "C1: static_fact vs bare           -0.0019   -0.019   65.0%    -0.37    7.10e-01    ns\n",
      "C2: random vs bare                -0.0060   -0.034   64.2%    -0.66    5.09e-01    ns\n",
      "C3: llm_kw vs bare                -0.0148   -0.120   50.1%    -2.31    2.17e-02     *\n",
      "C4: oracle vs bare                -0.0340   -0.188   61.5%    -3.61    3.51e-04   ***\n",
      "C5: static_fact vs random          0.0041    0.021   50.7%     0.39    6.93e-01    ns\n",
      "\n",
      "==========================================================================================\n",
      "PER LENGTH BIN ANALYSIS — Does priming effect change with document length?\n",
      "==========================================================================================\n",
      "\n",
      "  static_fact_trunc:\n",
      "    short: n=14, d=+0.378, win=78.6%, p=1.81e-01 ns\n",
      "    medium: n=114, d=-0.053, win=62.3%, p=5.76e-01 ns\n",
      "    long: n=121, d=-0.163, win=67.8%, p=7.50e-02 ns\n",
      "    very_long: n=120, d=-0.088, win=63.3%, p=3.36e-01 ns\n",
      "\n",
      "  random_trunc:\n",
      "    short: n=14, d=-0.067, win=64.3%, p=8.05e-01 ns\n",
      "    medium: n=114, d=+0.057, win=63.2%, p=5.41e-01 ns\n",
      "    long: n=121, d=-0.202, win=66.1%, p=2.81e-02 *\n",
      "    very_long: n=120, d=-0.195, win=63.3%, p=3.52e-02 *\n",
      "\n",
      "  llm_kw_trunc:\n",
      "    short: n=14, d=-0.202, win=42.9%, p=4.63e-01 ns\n",
      "    medium: n=114, d=-0.100, win=48.2%, p=2.86e-01 ns\n",
      "    long: n=121, d=-0.166, win=52.9%, p=7.06e-02 ns\n",
      "    very_long: n=120, d=-0.127, win=50.0%, p=1.68e-01 ns\n",
      "\n",
      "  oracle_trunc:\n",
      "    short: n=14, d=-0.358, win=42.9%, p=2.03e-01 ns\n",
      "    medium: n=114, d=-0.157, win=62.3%, p=9.60e-02 ns\n",
      "    long: n=121, d=-0.224, win=62.0%, p=1.53e-02 *\n",
      "    very_long: n=120, d=-0.157, win=62.5%, p=8.84e-02 ns\n",
      "\n",
      "==========================================================================================\n",
      "LENGTH INTERACTION — Correlation between document length and priming effect\n",
      "==========================================================================================\n",
      "  static_fact_trunc: Spearman r=-0.040 (p=0.441), Pearson r=-0.054 (p=0.305)\n",
      "  random_trunc: Spearman r=-0.004 (p=0.935), Pearson r=-0.036 (p=0.491)\n",
      "  llm_kw_trunc: Spearman r=+0.038 (p=0.469), Pearson r=+0.033 (p=0.531)\n",
      "  oracle_trunc: Spearman r=+0.059 (p=0.261), Pearson r=+0.110 (p=0.035)\n",
      "\n",
      "==========================================================================================\n",
      "HARDNESS QUINTILE WITHIN EACH LENGTH BIN\n",
      "==========================================================================================\n",
      "\n",
      "  medium (n=114, median bare NLL=0.019):\n",
      "    static_fact_trunc: easy d=-0.032, hard d=-0.073\n",
      "    random_trunc: easy d=+0.305, hard d=+0.079\n",
      "    oracle_trunc: easy d=-0.181, hard d=-0.218\n",
      "\n",
      "  long (n=121, median bare NLL=0.004):\n",
      "    static_fact_trunc: easy d=+0.397, hard d=-0.234\n",
      "    random_trunc: easy d=+0.347, hard d=-0.291\n",
      "    oracle_trunc: easy d=-0.124, hard d=-0.306\n",
      "\n",
      "  very_long (n=120, median bare NLL=0.004):\n",
      "    static_fact_trunc: easy d=+0.494, hard d=-0.127\n",
      "    random_trunc: easy d=+0.447, hard d=-0.282\n",
      "    oracle_trunc: easy d=-0.086, hard d=-0.222\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Analysis — overall + per length bin\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS — LONG-DOCUMENT PRIMING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract arrays and filter zero NLLs\n",
    "cond_arrays = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    cond_arrays[cname] = np.array([r[cname] for r in results])\n",
    "\n",
    "valid = np.ones(len(results), dtype=bool)\n",
    "for cname in CONDITION_NAMES:\n",
    "    valid &= (cond_arrays[cname] != 0)\n",
    "n_valid = int(np.sum(valid))\n",
    "n_excluded = int(np.sum(~valid))\n",
    "print(f\"Total: {len(results)}, Valid: {n_valid}, Excluded: {n_excluded}\")\n",
    "\n",
    "c = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    c[cname] = cond_arrays[cname][valid]\n",
    "\n",
    "length_bins_arr = np.array([r['length_bin'] for r in results])[valid]\n",
    "word_counts_arr = np.array([r['word_count'] for r in results])[valid]\n",
    "doc_lens_arr = np.array([r['doc_len_tokens'] for r in results])[valid]\n",
    "\n",
    "# ===== OVERALL NLL SUMMARY =====\n",
    "print(f\"\\n{'Condition':<25} {'Mean NLL':>10} {'Std':>10} {'d vs Bare':>10} {'Win%':>7}\")\n",
    "print(\"-\" * 67)\n",
    "for cname in CONDITION_NAMES:\n",
    "    mean_nll = np.mean(c[cname])\n",
    "    std_nll = np.std(c[cname])\n",
    "    if cname == 'bare':\n",
    "        print(f\"{cname:<25} {mean_nll:>10.4f} {std_nll:>10.4f} {'—':>10} {'—':>7}\")\n",
    "    else:\n",
    "        delta = c['bare'] - c[cname]\n",
    "        d = cohens_d(delta)\n",
    "        win = np.mean(delta > 0) * 100\n",
    "        _, p_val = stats.ttest_1samp(delta, 0)\n",
    "        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "        print(f\"{cname:<25} {mean_nll:>10.4f} {std_nll:>10.4f} {d:>+10.3f} {win:>5.1f}% {sig}\")\n",
    "\n",
    "# ===== 5 PRIMARY COMPARISONS =====\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"5 PRIMARY COMPARISONS (Bonferroni alpha = {BONFERRONI_ALPHA:.4f})\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "comparisons = [\n",
    "    ('C1: static_fact vs bare',\n",
    "     c['bare'] - c['static_fact_trunc'],\n",
    "     'Does static_fact help overall?'),\n",
    "    ('C2: random vs bare',\n",
    "     c['bare'] - c['random_trunc'],\n",
    "     'Does ANY prefix help overall?'),\n",
    "    ('C3: llm_kw vs bare',\n",
    "     c['bare'] - c['llm_kw_trunc'],\n",
    "     'Do LLM keywords help overall?'),\n",
    "    ('C4: oracle vs bare',\n",
    "     c['bare'] - c['oracle_trunc'],\n",
    "     'Does the perfect query help?'),\n",
    "    ('C5: static_fact vs random',\n",
    "     c['random_trunc'] - c['static_fact_trunc'],\n",
    "     'Is content better than noise?'),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Comparison':<30} {'Mean delta':>10} {'d':>8} {'Win%':>7} {'t':>8} {'p':>12} {'Sig':>5}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "comparison_results = {}\n",
    "for name, delta, question in comparisons:\n",
    "    d = cohens_d(delta)\n",
    "    win = np.mean(delta > 0) * 100\n",
    "    t_stat, p_val = stats.ttest_1samp(delta, 0)\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"{name:<30} {np.mean(delta):>10.4f} {d:>8.3f} {win:>6.1f}% {t_stat:>8.2f} {p_val:>11.2e} {sig:>5}\")\n",
    "    comparison_results[name] = {\n",
    "        'mean_delta': float(np.mean(delta)),\n",
    "        'cohens_d': float(d),\n",
    "        'win_rate': float(win / 100),\n",
    "        't_stat': float(t_stat),\n",
    "        'p_value': float(p_val),\n",
    "        'bonferroni_significant': bool(p_val < BONFERRONI_ALPHA),\n",
    "        'question': question,\n",
    "    }\n",
    "\n",
    "# ===== PER LENGTH BIN ANALYSIS (KEY RESULT) =====\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"PER LENGTH BIN ANALYSIS — Does priming effect change with document length?\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "bin_names_ordered = [name for name, _, _ in LENGTH_BINS]\n",
    "per_bin_results = {}\n",
    "\n",
    "for cname in CONDITION_NAMES:\n",
    "    if cname == 'bare':\n",
    "        continue\n",
    "    print(f\"\\n  {cname}:\")\n",
    "    bin_ds = []\n",
    "    bin_wins = []\n",
    "    bin_ns = []\n",
    "    for bin_name in bin_names_ordered:\n",
    "        mask = length_bins_arr == bin_name\n",
    "        n_bin = int(np.sum(mask))\n",
    "        if n_bin < 10:\n",
    "            print(f\"    {bin_name}: n={n_bin} (too few)\")\n",
    "            bin_ds.append(None)\n",
    "            bin_wins.append(None)\n",
    "            bin_ns.append(n_bin)\n",
    "            continue\n",
    "        delta = c['bare'][mask] - c[cname][mask]\n",
    "        d = cohens_d(delta)\n",
    "        win = np.mean(delta > 0) * 100\n",
    "        _, p_val = stats.ttest_1samp(delta, 0)\n",
    "        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "        print(f\"    {bin_name}: n={n_bin}, d={d:+.3f}, win={win:.1f}%, p={p_val:.2e} {sig}\")\n",
    "        bin_ds.append(float(d))\n",
    "        bin_wins.append(float(win))\n",
    "        bin_ns.append(n_bin)\n",
    "\n",
    "    per_bin_results[cname] = {\n",
    "        'bin_names': bin_names_ordered,\n",
    "        'bin_ds': bin_ds,\n",
    "        'bin_wins': bin_wins,\n",
    "        'bin_ns': bin_ns,\n",
    "    }\n",
    "\n",
    "# ===== LENGTH INTERACTION: does d decrease with length? =====\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"LENGTH INTERACTION — Correlation between document length and priming effect\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "interaction_results = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    if cname == 'bare':\n",
    "        continue\n",
    "    delta = c['bare'] - c[cname]\n",
    "    r_spear, p_spear = spearmanr(word_counts_arr, delta)\n",
    "    r_pears, p_pears = pearsonr(word_counts_arr, delta)\n",
    "    print(f\"  {cname}: Spearman r={r_spear:+.3f} (p={p_spear:.3f}), Pearson r={r_pears:+.3f} (p={p_pears:.3f})\")\n",
    "    interaction_results[cname] = {\n",
    "        'spearman_r': float(r_spear), 'spearman_p': float(p_spear),\n",
    "        'pearson_r': float(r_pears), 'pearson_p': float(p_pears),\n",
    "    }\n",
    "\n",
    "# ===== HARDNESS QUINTILE (WITHIN EACH BIN) =====\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"HARDNESS QUINTILE WITHIN EACH LENGTH BIN\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "hardness_x_length = {}\n",
    "for bin_name in bin_names_ordered:\n",
    "    mask_bin = length_bins_arr == bin_name\n",
    "    n_bin = int(np.sum(mask_bin))\n",
    "    if n_bin < 30:\n",
    "        continue\n",
    "    bare_bin = c['bare'][mask_bin]\n",
    "    median_nll = np.median(bare_bin)\n",
    "    hard_mask_within = bare_bin >= median_nll\n",
    "    easy_mask_within = bare_bin < median_nll\n",
    "\n",
    "    print(f\"\\n  {bin_name} (n={n_bin}, median bare NLL={median_nll:.3f}):\")\n",
    "    bin_results = {}\n",
    "    for cname in ['static_fact_trunc', 'random_trunc', 'oracle_trunc']:\n",
    "        cond_bin = c[cname][mask_bin]\n",
    "        delta_easy = bare_bin[easy_mask_within] - cond_bin[easy_mask_within]\n",
    "        delta_hard = bare_bin[hard_mask_within] - cond_bin[hard_mask_within]\n",
    "        d_easy = cohens_d(delta_easy) if len(delta_easy) > 5 else float('nan')\n",
    "        d_hard = cohens_d(delta_hard) if len(delta_hard) > 5 else float('nan')\n",
    "        print(f\"    {cname}: easy d={d_easy:+.3f}, hard d={d_hard:+.3f}\")\n",
    "        bin_results[cname] = {'easy_d': float(d_easy), 'hard_d': float(d_hard)}\n",
    "    hardness_x_length[bin_name] = bin_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093661ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T13:50:15.760446Z",
     "iopub.status.busy": "2026-02-12T13:50:15.759865Z",
     "iopub.status.idle": "2026-02-12T13:50:18.278845Z",
     "shell.execute_reply": "2026-02-12T13:50:18.277946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to results/exp11/analysis_plots.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Plots (2x2 grid)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "colors = {\n",
    "    'static_fact_trunc': '#d62728',\n",
    "    'random_trunc': '#7f7f7f',\n",
    "    'llm_kw_trunc': '#2ca02c',\n",
    "    'oracle_trunc': '#1f77b4',\n",
    "}\n",
    "\n",
    "# --- Plot 1: Per-bin Cohen's d for each condition ---\n",
    "ax = axes[0, 0]\n",
    "x = np.arange(len(bin_names_ordered))\n",
    "width = 0.18\n",
    "for i, cname in enumerate(['static_fact_trunc', 'random_trunc', 'llm_kw_trunc', 'oracle_trunc']):\n",
    "    ds = per_bin_results[cname]['bin_ds']\n",
    "    ds_clean = [d if d is not None else 0 for d in ds]\n",
    "    offset = (i - 1.5) * width\n",
    "    bars = ax.bar(x + offset, ds_clean, width, label=cname.replace('_trunc', ''),\n",
    "                  color=colors[cname], edgecolor='black', linewidth=0.5, alpha=0.85)\n",
    "    for j, (d_val, bar) in enumerate(zip(ds, bars)):\n",
    "        if d_val is not None:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                    f\"{d_val:+.2f}\", ha='center', va='bottom', fontsize=6)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bin_names_ordered)\n",
    "ax.axhline(y=0, color='gray', linestyle='--')\n",
    "ax.set_ylabel(\"Cohen's d vs Bare\")\n",
    "ax.set_xlabel(\"Document Length Bin\")\n",
    "ax.set_title(\"Priming Effect by Document Length\")\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# --- Plot 2: Scatter — word count vs per-sample NLL reduction ---\n",
    "ax = axes[0, 1]\n",
    "for cname in ['static_fact_trunc', 'oracle_trunc']:\n",
    "    delta = c['bare'] - c[cname]\n",
    "    ax.scatter(word_counts_arr, delta, alpha=0.15, s=8, color=colors[cname], label=cname.replace('_trunc', ''))\n",
    "    # Trend line (binned means)\n",
    "    n_trend_bins = 20\n",
    "    edges = np.linspace(word_counts_arr.min(), word_counts_arr.max(), n_trend_bins + 1)\n",
    "    for k in range(n_trend_bins):\n",
    "        mask_k = (word_counts_arr >= edges[k]) & (word_counts_arr < edges[k+1])\n",
    "        if np.sum(mask_k) > 5:\n",
    "            ax.scatter((edges[k] + edges[k+1])/2, np.mean(delta[mask_k]),\n",
    "                      s=40, color=colors[cname], edgecolor='black', linewidth=0.5, zorder=5)\n",
    "ax.axhline(y=0, color='gray', linestyle='--')\n",
    "ax.set_xlabel(\"Document Word Count\")\n",
    "ax.set_ylabel(\"NLL Reduction (bare - primed)\")\n",
    "ax.set_title(\"NLL Reduction vs Document Length\")\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# --- Plot 3: Overall bar chart (all conditions) ---\n",
    "ax = axes[1, 0]\n",
    "conds_sorted = sorted(\n",
    "    [(cn, cohens_d(c['bare'] - c[cn])) for cn in CONDITION_NAMES if cn != 'bare'],\n",
    "    key=lambda x: x[1], reverse=True\n",
    ")\n",
    "names_sorted = [x[0] for x in conds_sorted]\n",
    "ds_sorted = [x[1] for x in conds_sorted]\n",
    "bar_colors = [colors.get(cn, 'gray') for cn in names_sorted]\n",
    "bars = ax.barh(range(len(names_sorted)), ds_sorted, color=bar_colors, edgecolor='black', linewidth=0.5)\n",
    "ax.set_yticks(range(len(names_sorted)))\n",
    "ax.set_yticklabels([n.replace('_trunc', '') for n in names_sorted], fontsize=9)\n",
    "for i, (name, d_val) in enumerate(conds_sorted):\n",
    "    ax.text(d_val + 0.005, i, f\"d={d_val:+.3f}\", va='center', fontsize=8)\n",
    "ax.axvline(x=0, color='gray', linestyle='--')\n",
    "ax.set_xlabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title(\"Overall Priming Effect (All Length Bins)\")\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Reference line from MS MARCO\n",
    "ax.axvline(x=0.438, color='red', linestyle=':', alpha=0.5, label='Exp10 MS MARCO static_fact')\n",
    "ax.legend(fontsize=7)\n",
    "\n",
    "# --- Plot 4: Hardness × Length heatmap for static_fact_trunc ---\n",
    "ax = axes[1, 1]\n",
    "hm_data = []\n",
    "hm_labels_y = []\n",
    "for bin_name in bin_names_ordered:\n",
    "    if bin_name in hardness_x_length:\n",
    "        hm_data.append([\n",
    "            hardness_x_length[bin_name]['static_fact_trunc']['easy_d'],\n",
    "            hardness_x_length[bin_name]['static_fact_trunc']['hard_d'],\n",
    "        ])\n",
    "        hm_labels_y.append(bin_name)\n",
    "if hm_data:\n",
    "    hm_data = np.array(hm_data)\n",
    "    im = ax.imshow(hm_data, cmap='RdBu_r', vmin=-0.5, vmax=1.0, aspect='auto')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Easy (below median)', 'Hard (above median)'])\n",
    "    ax.set_yticks(range(len(hm_labels_y)))\n",
    "    ax.set_yticklabels(hm_labels_y)\n",
    "    for i in range(len(hm_labels_y)):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, f\"{hm_data[i,j]:+.2f}\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax, label=\"Cohen's d vs bare\")\n",
    "    ax.set_title(\"static_fact_trunc: Hardness × Length\")\n",
    "\n",
    "plt.suptitle('Exp 11: Long-Document Priming', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plots saved to {RESULTS_DIR / 'analysis_plots.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832cb218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T13:50:18.282146Z",
     "iopub.status.busy": "2026-02-12T13:50:18.281867Z",
     "iopub.status.idle": "2026-02-12T13:50:18.298668Z",
     "shell.execute_reply": "2026-02-12T13:50:18.297819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/exp11/results.json\n",
      "File size: 128.4 KB\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save comprehensive results JSON\n",
    "\n",
    "nll_summary = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    nll_summary[cname] = {\n",
    "        'mean': float(np.mean(c[cname])),\n",
    "        'std': float(np.std(c[cname])),\n",
    "        'cohens_d_vs_bare': float(cohens_d(c['bare'] - c[cname])) if cname != 'bare' else 0.0,\n",
    "    }\n",
    "\n",
    "final = {\n",
    "    'experiment': 'exp11_long_document_priming',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': config.model_name,\n",
    "        'seed': SEED,\n",
    "        'n_eval': N,\n",
    "        'n_valid': n_valid,\n",
    "        'n_excluded': n_excluded,\n",
    "        'n_conditions': len(CONDITION_NAMES),\n",
    "        'n_comparisons': N_COMPARISONS,\n",
    "        'bonferroni_alpha': BONFERRONI_ALPHA,\n",
    "        'dataset': 'google-research-datasets/natural_questions',\n",
    "        'dataset_split': 'validation',\n",
    "        'length_bins': LENGTH_BINS,\n",
    "        'max_doc_words': MAX_DOC_WORDS,\n",
    "    },\n",
    "    'condition_names': CONDITION_NAMES,\n",
    "    'nll_summary': nll_summary,\n",
    "    'primary_comparisons': comparison_results,\n",
    "    'per_bin_results': per_bin_results,\n",
    "    'interaction_results': interaction_results,\n",
    "    'hardness_x_length': hardness_x_length,\n",
    "    'per_sample_results': results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {FINAL_RESULTS_PATH}\")\n",
    "print(f\"File size: {FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3a0654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T13:50:18.301956Z",
     "iopub.status.busy": "2026-02-12T13:50:18.301266Z",
     "iopub.status.idle": "2026-02-12T13:50:18.851580Z",
     "shell.execute_reply": "2026-02-12T13:50:18.850656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 4.14 GB -> 0.01 GB\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: GPU cleanup\n",
    "import gc\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0254112769a144e6a58f0dca65a197c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "100931b0fc82452581e61896cfaf78b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1035d28868944fa697a1d6f1840d0e70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "12f50b54a3cb44b8a0b1ac66c253db8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e6889babcddf40c18b1b876df3d3772e",
        "IPY_MODEL_b67d93990735485885c8bd622836c7b1",
        "IPY_MODEL_f2ff194a57b14a548dcd294929aa238c"
       ],
       "layout": "IPY_MODEL_24e44c4dadb94b7eb8574261f4ce8581",
       "tabbable": null,
       "tooltip": null
      }
     },
     "17103b661f34421b894dfd91be73bbd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18c1a041d7234d48b228bdce6c8441b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19833a09b4c54819a6df4fa95d10ded2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4f1b31dfb1444dd1ace90192fe020cdd",
        "IPY_MODEL_924295b81eb44a97a3f7a34ad527d4ee",
        "IPY_MODEL_b75b5a352e284ca0b3af11f3dd3613f4"
       ],
       "layout": "IPY_MODEL_df8b51fa03ef41c9960ed36106eb702d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "221f0c4659dc439da7997bce27e6f2c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23e2f9051b194476a3a1aa58cb8e6168": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "24e44c4dadb94b7eb8574261f4ce8581": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2babc9d63ee04a11850bf8aaf4eb252c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "310627cdc11d48dda97ddd4b95e8ecac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a27ec4d8bd04790951de9b59caab586": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c08ea04b66b4008a0162732ae3ea0c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3c4f5875a8364d89a8ce2ceefbae0327": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d176d2817f2d45e3a46fece625c64f85",
       "max": 287.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_23e2f9051b194476a3a1aa58cb8e6168",
       "tabbable": null,
       "tooltip": null,
       "value": 287.0
      }
     },
     "43696c97304d4e859ca340c54916477b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4b7dd3b6fc314a49b494e5f3d9256106": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4f1b31dfb1444dd1ace90192fe020cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac656911572b47689779c05488ba1317",
       "placeholder": "​",
       "style": "IPY_MODEL_946d5a5995474bfe9b4629b8f1ad15fe",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "506db4fb7e9047f9b9041454f63ecc89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b20827e23354b1da4b7f90020e857e4",
       "placeholder": "​",
       "style": "IPY_MODEL_4b7dd3b6fc314a49b494e5f3d9256106",
       "tabbable": null,
       "tooltip": null,
       "value": "Processing NQ: "
      }
     },
     "5395ad8dec88419a87df086bff292a55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55fa72ae7e584f4c99064cde4e8ada43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59ee2b3b088c4d5ca78a001735ff4a84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b20827e23354b1da4b7f90020e857e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b88b8017e7f4751a828ebcd27371e3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_978c7094499d4329b855663a20069bfc",
        "IPY_MODEL_6f290064789d460dbda3cdfe1f79214a",
        "IPY_MODEL_9d8f1fd44f004c4d9ceb2964fd2c0dbf"
       ],
       "layout": "IPY_MODEL_ac33cb27c1ff432f9f3f84489dbba91f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5f1cc65f7e7d4a96b887d0e7cc53032e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "62ddbecf9e4d4ce0824bdc16b5ace44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aad538c322b840308c2e2fb7f47ef7e5",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f4e65da01dd546abae507ac44053fc28",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "657c18e3ca8b4102a5ac7f28cb3ca417": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "660a647fc6bc495884f37999a6af077b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69ed8485fe284a9d8f23b846b37f8c01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6c6d13542fa74f10b61983dfa375f624": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18c1a041d7234d48b228bdce6c8441b2",
       "placeholder": "​",
       "style": "IPY_MODEL_1035d28868944fa697a1d6f1840d0e70",
       "tabbable": null,
       "tooltip": null,
       "value": " 287/287 [00:00&lt;00:00, 9574.13it/s]"
      }
     },
     "6ccbe419d39749cba1e5ddf17d299d7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d31992028cc4b098d4474bbad6f4233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d59121b351f4505a5760b815cdd4360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a1e18dc02e9e43758f34a7b3ef5ac3ee",
       "placeholder": "​",
       "style": "IPY_MODEL_2babc9d63ee04a11850bf8aaf4eb252c",
       "tabbable": null,
       "tooltip": null,
       "value": " 7830/? [04:44&lt;00:00, 46.49it/s]"
      }
     },
     "6f290064789d460dbda3cdfe1f79214a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59ee2b3b088c4d5ca78a001735ff4a84",
       "max": 390.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_892523aa3cd94b59898223c2587f35e6",
       "tabbable": null,
       "tooltip": null,
       "value": 390.0
      }
     },
     "80ac685c755c4fadb36f5730e4194a6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "863cf91c6f3e4643971fcd19102f0344": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "892523aa3cd94b59898223c2587f35e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "924295b81eb44a97a3f7a34ad527d4ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80ac685c755c4fadb36f5730e4194a6e",
       "max": 291.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_43696c97304d4e859ca340c54916477b",
       "tabbable": null,
       "tooltip": null,
       "value": 291.0
      }
     },
     "92975573692a44a783dd17813bfa393e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_55fa72ae7e584f4c99064cde4e8ada43",
       "max": 287.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cd5e22b9a1bd47a3815c6761b333eb62",
       "tabbable": null,
       "tooltip": null,
       "value": 287.0
      }
     },
     "946d5a5995474bfe9b4629b8f1ad15fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "978c7094499d4329b855663a20069bfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_221f0c4659dc439da7997bce27e6f2c6",
       "placeholder": "​",
       "style": "IPY_MODEL_5f1cc65f7e7d4a96b887d0e7cc53032e",
       "tabbable": null,
       "tooltip": null,
       "value": "Keyword surrogates: 100%"
      }
     },
     "9b9caa08426b47be856a0617623efb9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_657c18e3ca8b4102a5ac7f28cb3ca417",
       "placeholder": "​",
       "style": "IPY_MODEL_6ccbe419d39749cba1e5ddf17d299d7b",
       "tabbable": null,
       "tooltip": null,
       "value": " 287/287 [00:00&lt;00:00, 9740.46it/s]"
      }
     },
     "9d8f1fd44f004c4d9ceb2964fd2c0dbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_310627cdc11d48dda97ddd4b95e8ecac",
       "placeholder": "​",
       "style": "IPY_MODEL_6d31992028cc4b098d4474bbad6f4233",
       "tabbable": null,
       "tooltip": null,
       "value": " 390/390 [21:43&lt;00:00,  3.33s/it]"
      }
     },
     "a1e18dc02e9e43758f34a7b3ef5ac3ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9004809a56b48ae8601dc332ae48b60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ea1495fde5024aca93c462d29a879ff8",
        "IPY_MODEL_92975573692a44a783dd17813bfa393e",
        "IPY_MODEL_9b9caa08426b47be856a0617623efb9d"
       ],
       "layout": "IPY_MODEL_de06825b0ae04f8b8c6ea176d864fa79",
       "tabbable": null,
       "tooltip": null
      }
     },
     "aad538c322b840308c2e2fb7f47ef7e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "abd96d4025464837b59f59516db7c796": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac33cb27c1ff432f9f3f84489dbba91f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac656911572b47689779c05488ba1317": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b67d93990735485885c8bd622836c7b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17103b661f34421b894dfd91be73bbd4",
       "max": 390.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0254112769a144e6a58f0dca65a197c4",
       "tabbable": null,
       "tooltip": null,
       "value": 390.0
      }
     },
     "b75b5a352e284ca0b3af11f3dd3613f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3a27ec4d8bd04790951de9b59caab586",
       "placeholder": "​",
       "style": "IPY_MODEL_69ed8485fe284a9d8f23b846b37f8c01",
       "tabbable": null,
       "tooltip": null,
       "value": " 291/291 [00:38&lt;00:00,  9.38it/s, Materializing param=model.norm.weight]"
      }
     },
     "b8e5ee7034e9466eb734af3696c71cc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d55c1bb2a299411696314e2156327e29",
        "IPY_MODEL_3c4f5875a8364d89a8ce2ceefbae0327",
        "IPY_MODEL_6c6d13542fa74f10b61983dfa375f624"
       ],
       "layout": "IPY_MODEL_ce4eb8e22d64457e892bdfa544faff0c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cd5e22b9a1bd47a3815c6761b333eb62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ce4eb8e22d64457e892bdfa544faff0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfabcf2255e74ab78e54ba6209e21809": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d176d2817f2d45e3a46fece625c64f85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d55c1bb2a299411696314e2156327e29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cfabcf2255e74ab78e54ba6209e21809",
       "placeholder": "​",
       "style": "IPY_MODEL_eea7f17ae4c74dfea682edbe15af086b",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolving data files: 100%"
      }
     },
     "d70840c6855044dd812db83fb562226c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_506db4fb7e9047f9b9041454f63ecc89",
        "IPY_MODEL_62ddbecf9e4d4ce0824bdc16b5ace44c",
        "IPY_MODEL_6d59121b351f4505a5760b815cdd4360"
       ],
       "layout": "IPY_MODEL_abd96d4025464837b59f59516db7c796",
       "tabbable": null,
       "tooltip": null
      }
     },
     "de06825b0ae04f8b8c6ea176d864fa79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df8b51fa03ef41c9960ed36106eb702d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6889babcddf40c18b1b876df3d3772e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5395ad8dec88419a87df086bff292a55",
       "placeholder": "​",
       "style": "IPY_MODEL_100931b0fc82452581e61896cfaf78b2",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "ea1495fde5024aca93c462d29a879ff8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_660a647fc6bc495884f37999a6af077b",
       "placeholder": "​",
       "style": "IPY_MODEL_3c08ea04b66b4008a0162732ae3ea0c3",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolving data files: 100%"
      }
     },
     "eea7f17ae4c74dfea682edbe15af086b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f2ff194a57b14a548dcd294929aa238c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_faf10a864ec142e587232bee1c4a7632",
       "placeholder": "​",
       "style": "IPY_MODEL_863cf91c6f3e4643971fcd19102f0344",
       "tabbable": null,
       "tooltip": null,
       "value": " 390/390 [44:23&lt;00:00, 11.73s/it]"
      }
     },
     "f4e65da01dd546abae507ac44053fc28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "faf10a864ec142e587232bee1c4a7632": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
