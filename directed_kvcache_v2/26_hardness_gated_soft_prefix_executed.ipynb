{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.003881,
     "end_time": "2026-02-16T20:11:23.629023",
     "exception": false,
     "start_time": "2026-02-16T20:11:23.625142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exp 26: Hardness-Gated Soft Prefix\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 25 showed soft prefix optimization beats discrete prefix (d=+0.288 vs +0.195) but has a\n",
    "problem: **it hurts easy queries** (Q1: d=-0.43) while massively helping hard ones (Q4: d=+0.85).\n",
    "This suggests a simple gating strategy: only apply the soft prefix when the query is hard enough\n",
    "to benefit.\n",
    "\n",
    "## Design\n",
    "\n",
    "| Part | Data | Description |\n",
    "|------|------|-------------|\n",
    "| 1 | Exp 25 eval CSV (275 valid samples) | Threshold sweep on existing data |\n",
    "| 2 | 300 fresh validation queries (seed=44) | Test generalization of optimal threshold |\n",
    "| 3 | Cross-validation of threshold | Does Part 1 threshold hold on Part 2 data? |\n",
    "\n",
    "### Gating Rule\n",
    "\n",
    "```\n",
    "gated_nll = soft_fact_nll  if bare_nll >= threshold\n",
    "            bare_nll       otherwise\n",
    "```\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "- **Primary**: Gated d > ungated d (+0.288) on fresh validation data\n",
    "- **Secondary**: Q1 harm eliminated (d >= 0 for easiest quintile)\n",
    "- **Tertiary**: Optimal threshold generalizes from Exp 25 data to fresh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:23.637434Z",
     "iopub.status.busy": "2026-02-16T20:11:23.636656Z",
     "iopub.status.idle": "2026-02-16T20:11:28.122756Z",
     "shell.execute_reply": "2026-02-16T20:11:28.121588Z"
    },
    "papermill": {
     "duration": 4.492266,
     "end_time": "2026-02-16T20:11:28.124668",
     "exception": false,
     "start_time": "2026-02-16T20:11:23.632402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Results directory: results/exp26\n",
      "Exp 25 CSV: results/exp25/eval_results.csv (exists: True)\n",
      "Exp 25 soft_prefix_fact: results/exp25/soft_prefix_fact.pt (exists: True)\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "GPU memory: 42.3 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp26\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXP25_CSV = Path(\"results/exp25/eval_results.csv\")\n",
    "EXP25_SOFT_FACT = Path(\"results/exp25/soft_prefix_fact.pt\")\n",
    "CHECKPOINT_EVAL_PATH = RESULTS_DIR / \"checkpoint_eval.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "CSV_EVAL_PATH = RESULTS_DIR / \"eval_results.csv\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Exp 25 CSV: {EXP25_CSV} (exists: {EXP25_CSV.exists()})\")\n",
    "print(f\"Exp 25 soft_prefix_fact: {EXP25_SOFT_FACT} (exists: {EXP25_SOFT_FACT.exists()})\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:28.134119Z",
     "iopub.status.busy": "2026-02-16T20:11:28.133083Z",
     "iopub.status.idle": "2026-02-16T20:11:31.413465Z",
     "shell.execute_reply": "2026-02-16T20:11:31.412585Z"
    },
    "papermill": {
     "duration": 3.286866,
     "end_time": "2026-02-16T20:11:31.415213",
     "exception": false,
     "start_time": "2026-02-16T20:11:28.128347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 1: THRESHOLD SIMULATION ON EXP 25 DATA\n",
      "======================================================================\n",
      "Loaded 300 rows from Exp 25 CSV\n",
      "Valid samples: 275/300\n",
      "Bare NLL: mean=0.6982, std=1.2316\n",
      "Soft fact NLL: mean=0.4980, std=0.8835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ungated soft_fact: d=+0.288, win=64.0%, p=2.87e-06\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Exp 25 evaluation data\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 1: THRESHOLD SIMULATION ON EXP 25 DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load CSV\n",
    "exp25_data = []\n",
    "with open(EXP25_CSV, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        exp25_data.append({\n",
    "            'query_idx': int(row['query_idx']),\n",
    "            'doc_len': int(row['doc_len']),\n",
    "            'bare_nll': float(row['bare_nll']),\n",
    "            'vel_soft_fact_nll': float(row['vel_soft_fact_nll']),\n",
    "        })\n",
    "\n",
    "print(f\"Loaded {len(exp25_data)} rows from Exp 25 CSV\")\n",
    "\n",
    "bare_arr = np.array([r['bare_nll'] for r in exp25_data])\n",
    "soft_arr = np.array([r['vel_soft_fact_nll'] for r in exp25_data])\n",
    "\n",
    "# Filter valid samples (same as Exp 25)\n",
    "valid = (\n",
    "    (bare_arr != 0) & np.isfinite(bare_arr) &\n",
    "    (soft_arr != 0) & np.isfinite(soft_arr)\n",
    ")\n",
    "bare = bare_arr[valid]\n",
    "soft = soft_arr[valid]\n",
    "n_valid = int(np.sum(valid))\n",
    "\n",
    "print(f\"Valid samples: {n_valid}/{len(exp25_data)}\")\n",
    "print(f\"Bare NLL: mean={np.mean(bare):.4f}, std={np.std(bare):.4f}\")\n",
    "print(f\"Soft fact NLL: mean={np.mean(soft):.4f}, std={np.std(soft):.4f}\")\n",
    "\n",
    "# Ungated reference\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "ungated_delta = bare - soft\n",
    "ungated_d = cohens_d(ungated_delta)\n",
    "ungated_win = np.mean(ungated_delta > 0) * 100\n",
    "_, ungated_p = stats.ttest_1samp(ungated_delta, 0)\n",
    "\n",
    "print(f\"\\nUngated soft_fact: d={ungated_d:+.3f}, win={ungated_win:.1f}%, p={ungated_p:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:31.423917Z",
     "iopub.status.busy": "2026-02-16T20:11:31.423000Z",
     "iopub.status.idle": "2026-02-16T20:11:31.545249Z",
     "shell.execute_reply": "2026-02-16T20:11:31.544359Z"
    },
    "papermill": {
     "duration": 0.128237,
     "end_time": "2026-02-16T20:11:31.546992",
     "exception": false,
     "start_time": "2026-02-16T20:11:31.418755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "THRESHOLD SWEEP\n",
      "======================================================================\n",
      "\n",
      "Sweep: 112 thresholds tested\n",
      "\n",
      "Optimal threshold: 0.3092\n",
      "  Cohen's d: +0.328 (ungated: +0.288)\n",
      "  Win%: 40.4% (ungated: 64.0%)\n",
      "  p-value: 1.24e-07\n",
      "  N gated: 129/275 (46.9%)\n",
      "\n",
      "Percentile    Threshold        d    Win%  N gated  % gated\n",
      "----------------------------------------------------------\n",
      "P0               0.0000   +0.288   64.0%      275   100.0%\n",
      "P10              0.0109   +0.293   63.6%      247    89.8%\n",
      "P20              0.0452   +0.297   60.7%      220    80.0%\n",
      "P30              0.0906   +0.312   58.2%      192    69.8%\n",
      "P40              0.1771   +0.304   49.5%      165    60.0%\n",
      "P50              0.2788   +0.304   42.9%      138    50.2%\n",
      "P60              0.3718   +0.315   34.2%      110    40.0%\n",
      "P70              0.5456   +0.290   26.2%       83    30.2%\n",
      "P75              0.7998   +0.270   21.5%       69    25.1%\n",
      "P80              0.9947   +0.242   17.1%       55    20.0%\n",
      "P85              1.3106   +0.213   12.7%       42    15.3%\n",
      "P90              1.8421   +0.168    8.0%       28    10.2%\n",
      "P95              3.0609   +0.116    3.3%       14     5.1%\n",
      "\n",
      "Candidate thresholds for fresh validation:\n",
      "  P50: threshold=0.2788, d=+0.304, win=42.9%, gated=50%\n",
      "  P60: threshold=0.3718, d=+0.315, win=34.2%, gated=40%\n",
      "  P70: threshold=0.5456, d=+0.290, win=26.2%, gated=30%\n",
      "  P75: threshold=0.7998, d=+0.270, win=21.5%, gated=25%\n",
      "  P80: threshold=0.9947, d=+0.242, win=17.1%, gated=20%\n",
      "  optimal: threshold=0.3092, d=+0.328, win=40.4%, gated=47%\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Threshold simulation sweep\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"THRESHOLD SWEEP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def compute_gated_metrics(bare, soft, threshold):\n",
    "    \"\"\"Apply hardness gating and compute metrics.\n",
    "    \n",
    "    Gated NLL = soft_nll if bare_nll >= threshold, else bare_nll.\n",
    "    Returns dict with d, win%, p, n_gated, fraction_gated.\n",
    "    \"\"\"\n",
    "    gated = np.where(bare >= threshold, soft, bare)\n",
    "    delta = bare - gated\n",
    "    n_gated = int(np.sum(bare >= threshold))\n",
    "    \n",
    "    d = cohens_d(delta)\n",
    "    win_pct = np.mean(delta > 0) * 100\n",
    "    _, p_val = stats.ttest_1samp(delta, 0)\n",
    "    \n",
    "    return {\n",
    "        'threshold': float(threshold),\n",
    "        'cohens_d': float(d),\n",
    "        'win_pct': float(win_pct),\n",
    "        'p_value': float(p_val),\n",
    "        'n_gated': n_gated,\n",
    "        'frac_gated': n_gated / len(bare),\n",
    "        'mean_delta': float(np.mean(delta)),\n",
    "    }\n",
    "\n",
    "# Sweep: percentile-based + fine grid\n",
    "percentiles = [0, 10, 20, 30, 40, 50, 60, 70, 75, 80, 85, 90, 95]\n",
    "percentile_thresholds = np.percentile(bare, percentiles)\n",
    "\n",
    "# Also sweep a fine grid of absolute thresholds\n",
    "fine_thresholds = np.linspace(0, np.percentile(bare, 95), 100)\n",
    "\n",
    "# Combine and deduplicate\n",
    "all_thresholds = np.unique(np.concatenate([percentile_thresholds, fine_thresholds]))\n",
    "all_thresholds.sort()\n",
    "\n",
    "sweep_results = []\n",
    "for t in all_thresholds:\n",
    "    metrics = compute_gated_metrics(bare, soft, t)\n",
    "    sweep_results.append(metrics)\n",
    "\n",
    "# Find optimal threshold\n",
    "best_idx = np.argmax([r['cohens_d'] for r in sweep_results])\n",
    "best = sweep_results[best_idx]\n",
    "\n",
    "print(f\"\\nSweep: {len(all_thresholds)} thresholds tested\")\n",
    "print(f\"\\nOptimal threshold: {best['threshold']:.4f}\")\n",
    "print(f\"  Cohen's d: {best['cohens_d']:+.3f} (ungated: {ungated_d:+.3f})\")\n",
    "print(f\"  Win%: {best['win_pct']:.1f}% (ungated: {ungated_win:.1f}%)\")\n",
    "print(f\"  p-value: {best['p_value']:.2e}\")\n",
    "print(f\"  N gated: {best['n_gated']}/{n_valid} ({best['frac_gated']*100:.1f}%)\")\n",
    "\n",
    "# Show percentile-based results\n",
    "print(f\"\\n{'Percentile':<12} {'Threshold':>10} {'d':>8} {'Win%':>7} {'N gated':>8} {'% gated':>8}\")\n",
    "print(\"-\" * 58)\n",
    "for pct in percentiles:\n",
    "    t = np.percentile(bare, pct)\n",
    "    m = compute_gated_metrics(bare, soft, t)\n",
    "    marker = \" <<<\" if abs(t - best['threshold']) < 1e-6 else \"\"\n",
    "    print(f\"P{pct:<11} {t:>10.4f} {m['cohens_d']:>+8.3f} {m['win_pct']:>6.1f}% \"\n",
    "          f\"{m['n_gated']:>8} {m['frac_gated']*100:>7.1f}%{marker}\")\n",
    "\n",
    "# Select top-5 candidate thresholds for fresh validation\n",
    "# Percentile-based: P50, P60, P70, P75, P80 + absolute optimal\n",
    "candidate_percentiles = [50, 60, 70, 75, 80]\n",
    "candidate_thresholds = {f'P{p}': float(np.percentile(bare, p)) for p in candidate_percentiles}\n",
    "candidate_thresholds['optimal'] = best['threshold']\n",
    "\n",
    "print(f\"\\nCandidate thresholds for fresh validation:\")\n",
    "for name, t in candidate_thresholds.items():\n",
    "    m = compute_gated_metrics(bare, soft, t)\n",
    "    print(f\"  {name}: threshold={t:.4f}, d={m['cohens_d']:+.3f}, \"\n",
    "          f\"win={m['win_pct']:.1f}%, gated={m['frac_gated']*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:31.556112Z",
     "iopub.status.busy": "2026-02-16T20:11:31.555394Z",
     "iopub.status.idle": "2026-02-16T20:11:32.385135Z",
     "shell.execute_reply": "2026-02-16T20:11:32.384411Z"
    },
    "papermill": {
     "duration": 0.836192,
     "end_time": "2026-02-16T20:11:32.386761",
     "exception": false,
     "start_time": "2026-02-16T20:11:31.550569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BOOTSTRAP CONFIDENCE INTERVALS & ORACLE GATING\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ungated d: +0.288 (95% CI: [+0.215, +0.442])\n",
      "Optimal gated d: +0.328 (95% CI: [+0.262, +0.497])\n",
      "\n",
      "Candidate           d   CI low  CI high\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P50            +0.304   +0.227   +0.465\n",
      "P60            +0.315   +0.248   +0.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P70            +0.290   +0.230   +0.433\n",
      "P75            +0.270   +0.211   +0.402\n",
      "P80            +0.242   +0.185   +0.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal        +0.328   +0.262   +0.497\n",
      "\n",
      "Oracle gating (perfect knowledge):\n",
      "  d=+0.384, win=64.0%\n",
      "  This is the UPPER BOUND — no threshold can beat this.\n",
      "  Fraction where soft helps: 64.0%\n",
      "  Fraction where soft hurts: 35.6%\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Bootstrap CI + oracle gating upper bound\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP CONFIDENCE INTERVALS & ORACLE GATING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "N_BOOTSTRAP = 1000\n",
    "\n",
    "def bootstrap_d(bare, soft, threshold, n_boot=N_BOOTSTRAP, seed=42):\n",
    "    \"\"\"Bootstrap 95% CI for gated Cohen's d.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    ds = []\n",
    "    n = len(bare)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(n, size=n, replace=True)\n",
    "        b, s = bare[idx], soft[idx]\n",
    "        gated = np.where(b >= threshold, s, b)\n",
    "        delta = b - gated\n",
    "        d = cohens_d(delta)\n",
    "        ds.append(d)\n",
    "    ds = np.array(ds)\n",
    "    return {\n",
    "        'mean': float(np.mean(ds)),\n",
    "        'ci_low': float(np.percentile(ds, 2.5)),\n",
    "        'ci_high': float(np.percentile(ds, 97.5)),\n",
    "        'std': float(np.std(ds)),\n",
    "    }\n",
    "\n",
    "# Bootstrap for ungated\n",
    "boot_ungated = bootstrap_d(bare, soft, 0.0)  # threshold=0 means all gated\n",
    "print(f\"\\nUngated d: {ungated_d:+.3f} (95% CI: [{boot_ungated['ci_low']:+.3f}, {boot_ungated['ci_high']:+.3f}])\")\n",
    "\n",
    "# Bootstrap for optimal threshold\n",
    "boot_optimal = bootstrap_d(bare, soft, best['threshold'])\n",
    "print(f\"Optimal gated d: {best['cohens_d']:+.3f} (95% CI: [{boot_optimal['ci_low']:+.3f}, {boot_optimal['ci_high']:+.3f}])\")\n",
    "\n",
    "# Bootstrap for each candidate\n",
    "print(f\"\\n{'Candidate':<12} {'d':>8} {'CI low':>8} {'CI high':>8}\")\n",
    "print(\"-\" * 40)\n",
    "boot_candidates = {}\n",
    "for name, t in candidate_thresholds.items():\n",
    "    m = compute_gated_metrics(bare, soft, t)\n",
    "    boot = bootstrap_d(bare, soft, t)\n",
    "    boot_candidates[name] = boot\n",
    "    print(f\"{name:<12} {m['cohens_d']:>+8.3f} {boot['ci_low']:>+8.3f} {boot['ci_high']:>+8.3f}\")\n",
    "\n",
    "# Oracle gating: apply soft only when it actually helps\n",
    "oracle_gated = np.where(soft < bare, soft, bare)\n",
    "oracle_delta = bare - oracle_gated\n",
    "oracle_d = cohens_d(oracle_delta)\n",
    "oracle_win = np.mean(oracle_delta > 0) * 100\n",
    "\n",
    "print(f\"\\nOracle gating (perfect knowledge):\")\n",
    "print(f\"  d={oracle_d:+.3f}, win={oracle_win:.1f}%\")\n",
    "print(f\"  This is the UPPER BOUND — no threshold can beat this.\")\n",
    "print(f\"  Fraction where soft helps: {np.mean(soft < bare)*100:.1f}%\")\n",
    "print(f\"  Fraction where soft hurts: {np.mean(soft > bare)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:32.397809Z",
     "iopub.status.busy": "2026-02-16T20:11:32.397424Z",
     "iopub.status.idle": "2026-02-16T20:11:34.017688Z",
     "shell.execute_reply": "2026-02-16T20:11:34.016895Z"
    },
    "papermill": {
     "duration": 1.627466,
     "end_time": "2026-02-16T20:11:34.019336",
     "exception": false,
     "start_time": "2026-02-16T20:11:32.391870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to results/exp26/part1_threshold_sweep.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Part 1 plots\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# --- Panel 1: d vs threshold curve ---\n",
    "ax = axes[0]\n",
    "thresholds = [r['threshold'] for r in sweep_results]\n",
    "ds = [r['cohens_d'] for r in sweep_results]\n",
    "\n",
    "ax.plot(thresholds, ds, linewidth=2, color='#1f77b4')\n",
    "ax.axhline(y=ungated_d, color='red', linestyle='--', linewidth=1.5,\n",
    "           label=f'Ungated d={ungated_d:+.3f}')\n",
    "ax.axhline(y=oracle_d, color='green', linestyle=':', linewidth=1.5,\n",
    "           label=f'Oracle d={oracle_d:+.3f}')\n",
    "ax.axvline(x=best['threshold'], color='orange', linestyle='--', alpha=0.7,\n",
    "           label=f'Optimal t={best[\"threshold\"]:.3f}')\n",
    "ax.set_xlabel('Bare NLL Threshold')\n",
    "ax.set_ylabel(\"Cohen's d (gated)\")\n",
    "ax.set_title('Gated d vs Threshold')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# --- Panel 2: Per-quintile heatmap (gated vs ungated) ---\n",
    "ax = axes[1]\n",
    "\n",
    "quintile_bounds = np.percentile(bare, [20, 40, 60, 80])\n",
    "qlabels = ['Q1\\neasy', 'Q2', 'Q3', 'Q4', 'Q5\\nhard']\n",
    "quintiles = np.digitize(bare, quintile_bounds)\n",
    "\n",
    "# Compare ungated vs optimal gated per quintile\n",
    "gated_optimal = np.where(bare >= best['threshold'], soft, bare)\n",
    "conditions = {\n",
    "    'ungated': soft,\n",
    "    'gated_optimal': gated_optimal,\n",
    "}\n",
    "\n",
    "heatmap = np.zeros((len(conditions), 5))\n",
    "for i, (cname, carr) in enumerate(conditions.items()):\n",
    "    delta = bare - carr\n",
    "    for q in range(5):\n",
    "        mask = quintiles == q\n",
    "        if np.sum(mask) >= 5:\n",
    "            heatmap[i, q] = cohens_d(delta[mask])\n",
    "\n",
    "im = ax.imshow(heatmap, cmap='RdBu', aspect='auto', vmin=-0.5, vmax=1.0)\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels(qlabels, fontsize=8)\n",
    "ax.set_yticks(range(len(conditions)))\n",
    "ax.set_yticklabels(['ungated', 'gated'])\n",
    "ax.set_title('Quintile d: Ungated vs Gated')\n",
    "\n",
    "for i in range(len(conditions)):\n",
    "    for j in range(5):\n",
    "        val = heatmap[i, j]\n",
    "        ax.text(j, i, f\"{val:+.2f}\", ha='center', va='center',\n",
    "                fontsize=9, color='white' if abs(val) > 0.3 else 'black')\n",
    "fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# --- Panel 3: Scatter (bare NLL vs delta) with threshold ---\n",
    "ax = axes[2]\n",
    "delta_ungated = bare - soft\n",
    "ax.scatter(bare, delta_ungated, alpha=0.4, s=20, c='#1f77b4', edgecolors='none',\n",
    "           label='ungated')\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "ax.axvline(x=best['threshold'], color='orange', linestyle='--', linewidth=2,\n",
    "           label=f'threshold={best[\"threshold\"]:.3f}')\n",
    "ax.set_xlabel('Bare NLL (difficulty)')\n",
    "ax.set_ylabel('Delta (bare - soft, positive = helps)')\n",
    "ax.set_title('Per-Sample: Difficulty vs Benefit')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Annotate regions\n",
    "ax.text(best['threshold'] * 0.4, ax.get_ylim()[0] * 0.7,\n",
    "        'SKIP\\n(easy)', ha='center', fontsize=10, color='red', alpha=0.7)\n",
    "ax.text(best['threshold'] * 1.5 if best['threshold'] > 0 else 0.5,\n",
    "        ax.get_ylim()[1] * 0.7,\n",
    "        'APPLY\\n(hard)', ha='center', fontsize=10, color='green', alpha=0.7)\n",
    "\n",
    "plt.suptitle('Exp 26 Part 1: Threshold Simulation on Exp 25 Data', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'part1_threshold_sweep.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved to {RESULTS_DIR / 'part1_threshold_sweep.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:34.029273Z",
     "iopub.status.busy": "2026-02-16T20:11:34.028316Z",
     "iopub.status.idle": "2026-02-16T20:11:44.476419Z",
     "shell.execute_reply": "2026-02-16T20:11:44.475433Z"
    },
    "papermill": {
     "duration": 10.454801,
     "end_time": "2026-02-16T20:11:44.478158",
     "exception": false,
     "start_time": "2026-02-16T20:11:34.023357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 2: FRESH VALIDATION\n",
      "======================================================================\n",
      "Loading google/gemma-3-4b-it (4-bit, bfloat16)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1378dd15950b443ca05a851b794fc094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Layers=34, hidden=2560\n",
      "Loaded soft_prefix_fact: shape=torch.Size([1, 11, 2560])\n",
      "Embedding layer: Gemma3TextScaledWordEmbedding, shape=torch.Size([262208, 2560])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load Gemma 3 4B + Exp 25 soft_prefix_fact.pt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 2: FRESH VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.model_utils import load_model\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "\n",
    "exp_config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_type=\"gemma3\",\n",
    "    compute_dtype=\"auto\",\n",
    "    use_4bit=True,\n",
    "    num_samples=300,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit, bfloat16)...\")\n",
    "model, tokenizer = load_model(exp_config)\n",
    "\n",
    "from lib.kv_cache import (\n",
    "    _get_text_config, _get_head_dim,\n",
    "    _get_cache_keys, _get_cache_values,\n",
    "    _set_cache_keys, _set_cache_values,\n",
    "    _ensure_dynamic_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    "    score_answer_with_cache,\n",
    "    deepcopy_cache,\n",
    "    replace_values_at_layers,\n",
    ")\n",
    "\n",
    "text_config = _get_text_config(model.config)\n",
    "NUM_LAYERS = text_config.num_hidden_layers\n",
    "HIDDEN_SIZE = text_config.hidden_size\n",
    "\n",
    "print(f\"Model loaded. Layers={NUM_LAYERS}, hidden={HIDDEN_SIZE}\")\n",
    "\n",
    "# Load soft prefix\n",
    "soft_prefix_fact = torch.load(EXP25_SOFT_FACT).to(exp_config.device)\n",
    "print(f\"Loaded soft_prefix_fact: shape={soft_prefix_fact.shape}\")\n",
    "\n",
    "# Get embedding function\n",
    "embed_fn = model.get_input_embeddings()\n",
    "print(f\"Embedding layer: {type(embed_fn).__name__}, shape={embed_fn.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:44.489092Z",
     "iopub.status.busy": "2026-02-16T20:11:44.488147Z",
     "iopub.status.idle": "2026-02-16T20:11:45.866856Z",
     "shell.execute_reply": "2026-02-16T20:11:45.866140Z"
    },
    "papermill": {
     "duration": 1.386255,
     "end_time": "2026-02-16T20:11:45.868932",
     "exception": false,
     "start_time": "2026-02-16T20:11:44.482677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO validation with seed=44...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 10047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db00f835d0e4487a3747f851d886f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering:   0%|          | 0/10047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected 300 fresh validation samples (seed=44)\n",
      "Word counts: mean=71, min=15, max=146\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load 300 fresh validation queries (seed=44, non-overlapping with Exp 25's seed=43)\n",
    "\n",
    "from lib.data import count_words\n",
    "from lib.surrogate import STATIC_SURROGATE_QUERIES\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "CUTOFF = 16\n",
    "MAX_PASSAGE_WORDS = 300\n",
    "N_FRESH = 300\n",
    "FRESH_SEED = 44  # Different from Exp 25 train (42) and eval (43)\n",
    "CHECKPOINT_EVERY = 50\n",
    "\n",
    "STATIC_FACT = STATIC_SURROGATE_QUERIES['static_factual']['query']\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "QUERY_TEMPLATE = \"\\nQuery: {query}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"\n",
    "\n",
    "sf_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=STATIC_FACT)\n",
    "sf_ids = tokenizer(sf_str, return_tensors=\"pt\",\n",
    "                    add_special_tokens=False)['input_ids'].to(exp_config.device)\n",
    "PREFIX_LEN = sf_ids.shape[1]\n",
    "\n",
    "print(f\"Loading MS MARCO validation with seed={FRESH_SEED}...\")\n",
    "\n",
    "dataset = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "print(f\"Total items: {len(dataset)}\")\n",
    "\n",
    "fresh_samples = []\n",
    "np.random.seed(FRESH_SEED)\n",
    "\n",
    "for item in tqdm(dataset, desc=\"Filtering\"):\n",
    "    passages_info = item.get('passages', {})\n",
    "    passage_texts = passages_info.get('passage_text', [])\n",
    "    is_selected = passages_info.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "\n",
    "    if not passage_texts or not query:\n",
    "        continue\n",
    "\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] != '[]':\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    for ptext, sel in zip(passage_texts, is_selected):\n",
    "        if sel == 1 and count_words(ptext) <= MAX_PASSAGE_WORDS:\n",
    "            fresh_samples.append({\n",
    "                'query': query,\n",
    "                'answer': answer,\n",
    "                'passage': ptext,\n",
    "                'word_count': count_words(ptext),\n",
    "            })\n",
    "            break\n",
    "\n",
    "    if len(fresh_samples) >= N_FRESH * 3:\n",
    "        break\n",
    "\n",
    "np.random.shuffle(fresh_samples)\n",
    "fresh_samples = fresh_samples[:N_FRESH]\n",
    "\n",
    "del dataset\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nSelected {len(fresh_samples)} fresh validation samples (seed={FRESH_SEED})\")\n",
    "print(f\"Word counts: mean={np.mean([q['word_count'] for q in fresh_samples]):.0f}, \"\n",
    "      f\"min={min(q['word_count'] for q in fresh_samples)}, \"\n",
    "      f\"max={max(q['word_count'] for q in fresh_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:11:45.881346Z",
     "iopub.status.busy": "2026-02-16T20:11:45.881009Z",
     "iopub.status.idle": "2026-02-16T20:17:40.437142Z",
     "shell.execute_reply": "2026-02-16T20:17:40.436317Z"
    },
    "papermill": {
     "duration": 354.5648,
     "end_time": "2026-02-16T20:17:40.439560",
     "exception": false,
     "start_time": "2026-02-16T20:11:45.874760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCORING 300 FRESH QUERIES (bare + soft_fact)\n",
      "======================================================================\n",
      "No checkpoint found. Starting fresh.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4247b07bce83421eb91fde572e5d8c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 50/300 | 50 done in 1.0m | ETA: 5.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/300 | 100 done in 2.0m | ETA: 4.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 150/300 | 150 done in 3.0m | ETA: 3.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/300 | 200 done in 3.9m | ETA: 2.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 250/300 | 250 done in 4.9m | ETA: 1.0 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/300 | 300 done in 5.9m | ETA: 0.0 min\n",
      "\n",
      "Scoring complete: 300 queries in 5.9 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Score bare + soft_fact for all 300 fresh queries\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"SCORING {N_FRESH} FRESH QUERIES (bare + soft_fact)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "layer_indices = list(range(CUTOFF))\n",
    "\n",
    "# Checkpoint resume\n",
    "fresh_results = []\n",
    "fresh_start_idx = 0\n",
    "\n",
    "if CHECKPOINT_EVAL_PATH.exists():\n",
    "    with open(CHECKPOINT_EVAL_PATH, 'r') as f:\n",
    "        ckpt = json.load(f)\n",
    "    ckpt_queries = ckpt.get('query_texts', [])\n",
    "    current_queries = [q['query'] for q in fresh_samples[:N_FRESH]]\n",
    "    if ckpt_queries == current_queries:\n",
    "        fresh_results = ckpt['results']\n",
    "        fresh_start_idx = len(fresh_results)\n",
    "        print(f\"Resuming from checkpoint: {fresh_start_idx}/{N_FRESH}\")\n",
    "    else:\n",
    "        print(\"Checkpoint query mismatch. Starting fresh.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh.\")\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for qidx in tqdm(range(fresh_start_idx, N_FRESH), initial=fresh_start_idx,\n",
    "                  total=N_FRESH, desc=\"Scoring\"):\n",
    "    qdata = fresh_samples[qidx]\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=qdata['query'])\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=qdata['answer'])\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=qdata['passage'])\n",
    "\n",
    "    # Matched tokenization\n",
    "    full_text = sf_str + document_text\n",
    "    full_enc = tokenizer(full_text, return_tensors=\"pt\",\n",
    "                          add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_ids = full_enc['input_ids'].to(exp_config.device)\n",
    "    sf_prefix_enc = tokenizer(sf_str, return_tensors=\"pt\",\n",
    "                               add_special_tokens=True, padding=False, truncation=False)\n",
    "    sf_prefix_len_matched = sf_prefix_enc['input_ids'].shape[1]\n",
    "    bos_id = full_ids[:, :1]\n",
    "    doc_ids = full_ids[:, sf_prefix_len_matched:]\n",
    "    doc_len = doc_ids.shape[1]\n",
    "    context_len = 1 + doc_len\n",
    "\n",
    "    del full_enc, full_ids, sf_prefix_enc\n",
    "\n",
    "    # --- Bare NLL ---\n",
    "    bare_input = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_input,\n",
    "                         attention_mask=torch.ones_like(bare_input),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_cache = _ensure_dynamic_cache(bare_out.past_key_values)\n",
    "    del bare_out\n",
    "\n",
    "    bare_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_cache), context_len,\n",
    "        query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "\n",
    "    # --- Soft fact NLL ---\n",
    "    with torch.no_grad():\n",
    "        bos_emb = embed_fn(bos_id)\n",
    "        doc_emb = embed_fn(doc_ids)\n",
    "        soft_cast = soft_prefix_fact.to(device=exp_config.device, dtype=bos_emb.dtype)\n",
    "\n",
    "        inputs_embeds = torch.cat([bos_emb, soft_cast, doc_emb], dim=1)\n",
    "        total_len = inputs_embeds.shape[1]\n",
    "        attn_mask = torch.ones((1, total_len), device=exp_config.device, dtype=torch.long)\n",
    "\n",
    "        soft_out = model(inputs_embeds=inputs_embeds,\n",
    "                        attention_mask=attn_mask,\n",
    "                        use_cache=True, return_dict=True)\n",
    "        soft_cache = _ensure_dynamic_cache(soft_out.past_key_values)\n",
    "        del soft_out\n",
    "\n",
    "        soft_trunc = extract_and_truncate_cache_with_bos(soft_cache, doc_len)\n",
    "        del soft_cache\n",
    "\n",
    "        vel_soft_cache = replace_values_at_layers(bare_cache, soft_trunc, layer_indices)\n",
    "        del soft_trunc\n",
    "\n",
    "        soft_fact_nll = score_answer_with_cache(\n",
    "            deepcopy_cache(vel_soft_cache), context_len,\n",
    "            query_prompt, answer_text, model, tokenizer, exp_config)\n",
    "        del vel_soft_cache\n",
    "\n",
    "    del bare_cache, bare_input\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    fresh_results.append({\n",
    "        'query_idx': qidx,\n",
    "        'doc_len': doc_len,\n",
    "        'bare_nll': float(bare_nll),\n",
    "        'soft_fact_nll': float(soft_fact_nll),\n",
    "    })\n",
    "\n",
    "    # Checkpoint\n",
    "    if (qidx + 1) % CHECKPOINT_EVERY == 0 or qidx == N_FRESH - 1:\n",
    "        ckpt_data = {\n",
    "            'results': fresh_results,\n",
    "            'query_texts': [q['query'] for q in fresh_samples[:N_FRESH]],\n",
    "            'completed': len(fresh_results),\n",
    "            'total': N_FRESH,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_EVAL_PATH, 'w') as f:\n",
    "            json.dump(ckpt_data, f)\n",
    "        elapsed = time.time() - t_start\n",
    "        n_done = qidx - fresh_start_idx + 1\n",
    "        rate = n_done / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N_FRESH - qidx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {qidx+1}/{N_FRESH} | {n_done} done in {elapsed/60:.1f}m | \"\n",
    "                   f\"ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nScoring complete: {len(fresh_results)} queries in {elapsed_total/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:17:40.451614Z",
     "iopub.status.busy": "2026-02-16T20:17:40.450945Z",
     "iopub.status.idle": "2026-02-16T20:17:40.541677Z",
     "shell.execute_reply": "2026-02-16T20:17:40.540947Z"
    },
    "papermill": {
     "duration": 0.098607,
     "end_time": "2026-02-16T20:17:40.543300",
     "exception": false,
     "start_time": "2026-02-16T20:17:40.444693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GATED METRICS ON FRESH DATA\n",
      "======================================================================\n",
      "Fresh valid samples: 264/300\n",
      "\n",
      "Fresh ungated: d=+0.340, win=63.6%, p=7.80e-08\n",
      "\n",
      "Candidate     Threshold        d    Win%            p  N gated   Improve?\n",
      "---------------------------------------------------------------------------\n",
      "P50              0.2788   +0.355   42.4%     2.19e-08      125        YES\n",
      "P60              0.3718   +0.335   33.0%     1.17e-07       98         no\n",
      "P70              0.5456   +0.313   25.8%     6.73e-07       72         no\n",
      "P75              0.7998   +0.276   17.8%     1.06e-05       49         no\n",
      "P80              0.9947   +0.255   14.4%     4.72e-05       40         no\n",
      "optimal          0.3092   +0.349   39.0%     3.62e-08      116        YES\n",
      "\n",
      "Oracle gating on fresh data: d=+0.389\n",
      "Fresh-optimal threshold: 0.1073, d=+0.364\n",
      "Exp25-optimal threshold: 0.3092\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Apply threshold candidates to fresh data\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GATED METRICS ON FRESH DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fresh_bare = np.array([r['bare_nll'] for r in fresh_results])\n",
    "fresh_soft = np.array([r['soft_fact_nll'] for r in fresh_results])\n",
    "\n",
    "# Filter valid\n",
    "fresh_valid = (\n",
    "    (fresh_bare != 0) & np.isfinite(fresh_bare) &\n",
    "    (fresh_soft != 0) & np.isfinite(fresh_soft)\n",
    ")\n",
    "fb = fresh_bare[fresh_valid]\n",
    "fs = fresh_soft[fresh_valid]\n",
    "n_fresh_valid = int(np.sum(fresh_valid))\n",
    "\n",
    "print(f\"Fresh valid samples: {n_fresh_valid}/{len(fresh_results)}\")\n",
    "\n",
    "# Ungated on fresh data\n",
    "fresh_ungated_delta = fb - fs\n",
    "fresh_ungated_d = cohens_d(fresh_ungated_delta)\n",
    "fresh_ungated_win = np.mean(fresh_ungated_delta > 0) * 100\n",
    "_, fresh_ungated_p = stats.ttest_1samp(fresh_ungated_delta, 0)\n",
    "\n",
    "print(f\"\\nFresh ungated: d={fresh_ungated_d:+.3f}, win={fresh_ungated_win:.1f}%, p={fresh_ungated_p:.2e}\")\n",
    "\n",
    "# Apply each candidate threshold\n",
    "print(f\"\\n{'Candidate':<12} {'Threshold':>10} {'d':>8} {'Win%':>7} {'p':>12} {'N gated':>8} {'Improve?':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "fresh_gated_results = {}\n",
    "for name, t in candidate_thresholds.items():\n",
    "    m = compute_gated_metrics(fb, fs, t)\n",
    "    improve = \"YES\" if m['cohens_d'] > fresh_ungated_d else \"no\"\n",
    "    sig = '***' if m['p_value'] < 0.001 else '**' if m['p_value'] < 0.01 else '*' if m['p_value'] < 0.05 else 'ns'\n",
    "    print(f\"{name:<12} {t:>10.4f} {m['cohens_d']:>+8.3f} {m['win_pct']:>6.1f}% \"\n",
    "          f\"{m['p_value']:>12.2e} {m['n_gated']:>8} {improve:>10}\")\n",
    "    fresh_gated_results[name] = m\n",
    "\n",
    "# Oracle gating on fresh data\n",
    "fresh_oracle_gated = np.where(fs < fb, fs, fb)\n",
    "fresh_oracle_delta = fb - fresh_oracle_gated\n",
    "fresh_oracle_d = cohens_d(fresh_oracle_delta)\n",
    "print(f\"\\nOracle gating on fresh data: d={fresh_oracle_d:+.3f}\")\n",
    "\n",
    "# Also sweep fresh data for its own optimal\n",
    "fresh_sweep = []\n",
    "for t in np.linspace(0, np.percentile(fb, 95), 100):\n",
    "    m = compute_gated_metrics(fb, fs, t)\n",
    "    fresh_sweep.append(m)\n",
    "\n",
    "fresh_best_idx = np.argmax([r['cohens_d'] for r in fresh_sweep])\n",
    "fresh_best = fresh_sweep[fresh_best_idx]\n",
    "print(f\"Fresh-optimal threshold: {fresh_best['threshold']:.4f}, d={fresh_best['cohens_d']:+.3f}\")\n",
    "print(f\"Exp25-optimal threshold: {best['threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:17:40.556387Z",
     "iopub.status.busy": "2026-02-16T20:17:40.555602Z",
     "iopub.status.idle": "2026-02-16T20:17:40.769179Z",
     "shell.execute_reply": "2026-02-16T20:17:40.768404Z"
    },
    "papermill": {
     "duration": 0.221626,
     "end_time": "2026-02-16T20:17:40.770797",
     "exception": false,
     "start_time": "2026-02-16T20:17:40.549171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 3: GENERALIZATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Threshold transfer analysis:\n",
      "  Exp 25 optimal threshold: 0.3092\n",
      "  Fresh optimal threshold:  0.1073\n",
      "  Difference: 0.2019\n",
      "\n",
      "  Exp25 threshold on Exp25 data: d=+0.328\n",
      "  Exp25 threshold on fresh data: d=+0.349\n",
      "  Fresh threshold on fresh data: d=+0.364\n",
      "  Ungated on fresh data:         d=+0.340\n",
      "\n",
      "Best candidate on fresh data: P50 (threshold=0.2788)\n",
      "\n",
      "Quintile      Ungated d    Gated d   Improve?\n",
      "----------------------------------------------\n",
      "Q1 easy          -0.599     +0.000        YES\n",
      "Q2               -0.122     +0.000        YES\n",
      "Q3               +0.329     +0.310         no\n",
      "Q4               +1.035     +1.035         no\n",
      "Q5 hard          +0.760     +0.760         no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fresh ungated d: +0.340 (95% CI: [+0.273, +0.511])\n",
      "Fresh gated d:   +0.355 (95% CI: [+0.285, +0.541])\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Generalization analysis\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 3: GENERALIZATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Does the Exp 25-optimal threshold generalize to fresh data?\n",
    "exp25_optimal_on_fresh = compute_gated_metrics(fb, fs, best['threshold'])\n",
    "fresh_optimal_on_fresh = fresh_best\n",
    "\n",
    "print(f\"\\nThreshold transfer analysis:\")\n",
    "print(f\"  Exp 25 optimal threshold: {best['threshold']:.4f}\")\n",
    "print(f\"  Fresh optimal threshold:  {fresh_best['threshold']:.4f}\")\n",
    "print(f\"  Difference: {abs(best['threshold'] - fresh_best['threshold']):.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"  Exp25 threshold on Exp25 data: d={best['cohens_d']:+.3f}\")\n",
    "print(f\"  Exp25 threshold on fresh data: d={exp25_optimal_on_fresh['cohens_d']:+.3f}\")\n",
    "print(f\"  Fresh threshold on fresh data: d={fresh_optimal_on_fresh['cohens_d']:+.3f}\")\n",
    "print(f\"  Ungated on fresh data:         d={fresh_ungated_d:+.3f}\")\n",
    "\n",
    "# Per-quintile analysis on fresh data (gated vs ungated)\n",
    "fresh_quintile_bounds = np.percentile(fb, [20, 40, 60, 80])\n",
    "fresh_quintiles = np.digitize(fb, fresh_quintile_bounds)\n",
    "fresh_qlabels = ['Q1 easy', 'Q2', 'Q3', 'Q4', 'Q5 hard']\n",
    "\n",
    "# Use the best performing threshold from fresh_gated_results\n",
    "best_fresh_name = max(fresh_gated_results, key=lambda k: fresh_gated_results[k]['cohens_d'])\n",
    "best_fresh_t = candidate_thresholds[best_fresh_name]\n",
    "fresh_gated_best = np.where(fb >= best_fresh_t, fs, fb)\n",
    "\n",
    "print(f\"\\nBest candidate on fresh data: {best_fresh_name} (threshold={best_fresh_t:.4f})\")\n",
    "\n",
    "print(f\"\\n{'Quintile':<12} {'Ungated d':>10} {'Gated d':>10} {'Improve?':>10}\")\n",
    "print(\"-\" * 46)\n",
    "for q in range(5):\n",
    "    mask = fresh_quintiles == q\n",
    "    n_q = int(np.sum(mask))\n",
    "    if n_q < 5:\n",
    "        print(f\"{fresh_qlabels[q]:<12} {'n/a':>10} {'n/a':>10}\")\n",
    "        continue\n",
    "    \n",
    "    d_ungated = cohens_d(fb[mask] - fs[mask])\n",
    "    d_gated = cohens_d(fb[mask] - fresh_gated_best[mask])\n",
    "    improve = \"YES\" if d_gated > d_ungated else \"no\"\n",
    "    print(f\"{fresh_qlabels[q]:<12} {d_ungated:>+10.3f} {d_gated:>+10.3f} {improve:>10}\")\n",
    "\n",
    "# Bootstrap CI on fresh data\n",
    "boot_fresh_ungated = bootstrap_d(fb, fs, 0.0, seed=44)\n",
    "boot_fresh_gated = bootstrap_d(fb, fs, best_fresh_t, seed=44)\n",
    "print(f\"\\nFresh ungated d: {fresh_ungated_d:+.3f} (95% CI: [{boot_fresh_ungated['ci_low']:+.3f}, {boot_fresh_ungated['ci_high']:+.3f}])\")\n",
    "print(f\"Fresh gated d:   {fresh_gated_results[best_fresh_name]['cohens_d']:+.3f} (95% CI: [{boot_fresh_gated['ci_low']:+.3f}, {boot_fresh_gated['ci_high']:+.3f}])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:17:40.783548Z",
     "iopub.status.busy": "2026-02-16T20:17:40.783144Z",
     "iopub.status.idle": "2026-02-16T20:17:42.767601Z",
     "shell.execute_reply": "2026-02-16T20:17:42.766885Z"
    },
    "papermill": {
     "duration": 1.992439,
     "end_time": "2026-02-16T20:17:42.769159",
     "exception": false,
     "start_time": "2026-02-16T20:17:40.776720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to results/exp26/comprehensive_plots.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Comprehensive 6-panel visualization\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# --- Panel 1: d vs threshold (Exp 25 data) ---\n",
    "ax = axes[0, 0]\n",
    "thresholds_p1 = [r['threshold'] for r in sweep_results]\n",
    "ds_p1 = [r['cohens_d'] for r in sweep_results]\n",
    "ax.plot(thresholds_p1, ds_p1, linewidth=2, color='#1f77b4', label='Exp 25 data')\n",
    "ax.axhline(y=ungated_d, color='red', linestyle='--', linewidth=1.5,\n",
    "           label=f'Ungated d={ungated_d:+.3f}')\n",
    "ax.axvline(x=best['threshold'], color='orange', linestyle='--', alpha=0.7,\n",
    "           label=f'Exp25 optimal')\n",
    "ax.set_xlabel('Bare NLL Threshold')\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_title('Part 1: Threshold Sweep (Exp 25)')\n",
    "ax.legend(fontsize=7)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# --- Panel 2: d vs threshold (fresh data) ---\n",
    "ax = axes[0, 1]\n",
    "fresh_ts = [r['threshold'] for r in fresh_sweep]\n",
    "fresh_ds = [r['cohens_d'] for r in fresh_sweep]\n",
    "ax.plot(fresh_ts, fresh_ds, linewidth=2, color='#ff7f0e', label='Fresh data')\n",
    "ax.axhline(y=fresh_ungated_d, color='red', linestyle='--', linewidth=1.5,\n",
    "           label=f'Ungated d={fresh_ungated_d:+.3f}')\n",
    "ax.axvline(x=best['threshold'], color='blue', linestyle='--', alpha=0.7,\n",
    "           label=f'Exp25 optimal t')\n",
    "ax.axvline(x=fresh_best['threshold'], color='orange', linestyle=':', alpha=0.7,\n",
    "           label=f'Fresh optimal t')\n",
    "ax.set_xlabel('Bare NLL Threshold')\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_title('Part 2: Threshold Sweep (Fresh)')\n",
    "ax.legend(fontsize=7)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# --- Panel 3: Bar chart comparing conditions ---\n",
    "ax = axes[0, 2]\n",
    "bar_names = ['Ungated\\n(Exp25)', f'Gated\\n(Exp25)', 'Ungated\\n(Fresh)', f'Gated\\n(Fresh)']\n",
    "bar_ds = [ungated_d, best['cohens_d'], fresh_ungated_d,\n",
    "          fresh_gated_results[best_fresh_name]['cohens_d']]\n",
    "bar_colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']\n",
    "\n",
    "bars = ax.bar(range(4), bar_ds, color=bar_colors, edgecolor='black', linewidth=0.5)\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(bar_names, fontsize=8)\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_title('Summary: Ungated vs Gated')\n",
    "for i, d_val in enumerate(bar_ds):\n",
    "    ax.text(i, d_val + 0.01, f\"{d_val:+.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# --- Panel 4: Per-quintile comparison (fresh data) ---\n",
    "ax = axes[1, 0]\n",
    "\n",
    "q_ungated_ds = []\n",
    "q_gated_ds = []\n",
    "for q in range(5):\n",
    "    mask = fresh_quintiles == q\n",
    "    if np.sum(mask) >= 5:\n",
    "        q_ungated_ds.append(cohens_d(fb[mask] - fs[mask]))\n",
    "        q_gated_ds.append(cohens_d(fb[mask] - fresh_gated_best[mask]))\n",
    "    else:\n",
    "        q_ungated_ds.append(0)\n",
    "        q_gated_ds.append(0)\n",
    "\n",
    "x = np.arange(5)\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, q_ungated_ds, width, label='Ungated', color='#1f77b4', alpha=0.7)\n",
    "ax.bar(x + width/2, q_gated_ds, width, label='Gated', color='#2ca02c', alpha=0.7)\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(fresh_qlabels, fontsize=8)\n",
    "ax.set_ylabel(\"Cohen's d\")\n",
    "ax.set_title('Per-Quintile: Ungated vs Gated (Fresh)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- Panel 5: Scatter bare NLL vs delta (fresh data) ---\n",
    "ax = axes[1, 1]\n",
    "delta_fresh = fb - fs\n",
    "ax.scatter(fb, delta_fresh, alpha=0.4, s=20, c='#ff7f0e', edgecolors='none')\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "ax.axvline(x=best_fresh_t, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'threshold={best_fresh_t:.3f}')\n",
    "ax.set_xlabel('Bare NLL (difficulty)')\n",
    "ax.set_ylabel('Delta (bare - soft, positive = helps)')\n",
    "ax.set_title('Fresh Data: Difficulty vs Benefit')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# --- Panel 6: NLL distribution (fresh) ---\n",
    "ax = axes[1, 2]\n",
    "ax.hist(fb, bins=40, alpha=0.5, color='#1f77b4', label='Bare', density=True)\n",
    "ax.hist(fs, bins=40, alpha=0.5, color='#ff7f0e', label='Soft fact', density=True)\n",
    "ax.axvline(x=best_fresh_t, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'Gate threshold')\n",
    "ax.set_xlabel('NLL')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Fresh: NLL Distributions')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Exp 26: Hardness-Gated Soft Prefix', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'comprehensive_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved to {RESULTS_DIR / 'comprehensive_plots.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:17:42.781752Z",
     "iopub.status.busy": "2026-02-16T20:17:42.781162Z",
     "iopub.status.idle": "2026-02-16T20:17:42.799177Z",
     "shell.execute_reply": "2026-02-16T20:17:42.798461Z"
    },
    "papermill": {
     "duration": 0.026375,
     "end_time": "2026-02-16T20:17:42.800981",
     "exception": false,
     "start_time": "2026-02-16T20:17:42.774606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved: results/exp26/eval_results.csv\n",
      "Results saved: results/exp26/results.json (41.8 KB)\n",
      "\n",
      "======================================================================\n",
      "FINAL VERDICT — Exp 26: Hardness-Gated Soft Prefix\n",
      "======================================================================\n",
      "\n",
      "Part 1 (Exp 25 data, 275 samples):\n",
      "  Ungated d: +0.288\n",
      "  Best gated d: +0.328 (threshold=0.3092)\n",
      "  Oracle d: +0.384\n",
      "\n",
      "Part 2 (Fresh data, 264 samples):\n",
      "  Ungated d: +0.340\n",
      "  Best gated d: +0.355 (threshold=0.2788, P50)\n",
      "  Oracle d: +0.389\n",
      "\n",
      "VERDICT: Hardness gating MATCHES ungated soft prefix \n",
      "  (+0.355 vs +0.340 on fresh data).\n",
      "  Gating does not significantly change overall effect.\n",
      "\n",
      "Threshold generalizes: YES\n",
      "  (Exp25 optimal on fresh: d=+0.349, Fresh optimal: d=+0.364)\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Save results.json + CSV + final verdict\n",
    "\n",
    "# --- CSV ---\n",
    "with open(CSV_EVAL_PATH, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\n",
    "        'query_idx', 'doc_len', 'bare_nll', 'soft_fact_nll'])\n",
    "    writer.writeheader()\n",
    "    for r in fresh_results:\n",
    "        writer.writerow(r)\n",
    "print(f\"CSV saved: {CSV_EVAL_PATH}\")\n",
    "\n",
    "# --- Results JSON ---\n",
    "final = {\n",
    "    'experiment': 'exp26_hardness_gated_soft_prefix',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'cutoff': CUTOFF,\n",
    "        'fresh_seed': FRESH_SEED,\n",
    "        'n_fresh': N_FRESH,\n",
    "        'n_fresh_valid': n_fresh_valid,\n",
    "        'soft_prefix_source': str(EXP25_SOFT_FACT),\n",
    "    },\n",
    "    'part1_exp25_data': {\n",
    "        'n_valid': n_valid,\n",
    "        'ungated_d': ungated_d,\n",
    "        'ungated_win_pct': ungated_win,\n",
    "        'ungated_p': float(ungated_p),\n",
    "        'optimal_threshold': best['threshold'],\n",
    "        'optimal_d': best['cohens_d'],\n",
    "        'oracle_d': oracle_d,\n",
    "        'candidate_thresholds': candidate_thresholds,\n",
    "        'bootstrap_ungated': boot_ungated,\n",
    "        'bootstrap_optimal': boot_optimal,\n",
    "    },\n",
    "    'part2_fresh_data': {\n",
    "        'n_valid': n_fresh_valid,\n",
    "        'ungated_d': fresh_ungated_d,\n",
    "        'ungated_win_pct': fresh_ungated_win,\n",
    "        'ungated_p': float(fresh_ungated_p),\n",
    "        'fresh_optimal_threshold': fresh_best['threshold'],\n",
    "        'fresh_optimal_d': fresh_best['cohens_d'],\n",
    "        'oracle_d': float(fresh_oracle_d),\n",
    "        'gated_results': fresh_gated_results,\n",
    "        'bootstrap_ungated': boot_fresh_ungated,\n",
    "        'bootstrap_gated': boot_fresh_gated,\n",
    "    },\n",
    "    'part3_generalization': {\n",
    "        'exp25_threshold': best['threshold'],\n",
    "        'fresh_threshold': fresh_best['threshold'],\n",
    "        'exp25_threshold_on_exp25': best['cohens_d'],\n",
    "        'exp25_threshold_on_fresh': exp25_optimal_on_fresh['cohens_d'],\n",
    "        'fresh_threshold_on_fresh': fresh_best['cohens_d'],\n",
    "        'best_candidate_name': best_fresh_name,\n",
    "        'best_candidate_threshold': candidate_thresholds[best_fresh_name],\n",
    "        'best_candidate_d': fresh_gated_results[best_fresh_name]['cohens_d'],\n",
    "    },\n",
    "    'fresh_per_query': fresh_results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final, f, indent=2)\n",
    "print(f\"Results saved: {FINAL_RESULTS_PATH} ({FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "# --- Final verdict ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL VERDICT — Exp 26: Hardness-Gated Soft Prefix\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPart 1 (Exp 25 data, {n_valid} samples):\")\n",
    "print(f\"  Ungated d: {ungated_d:+.3f}\")\n",
    "print(f\"  Best gated d: {best['cohens_d']:+.3f} (threshold={best['threshold']:.4f})\")\n",
    "print(f\"  Oracle d: {oracle_d:+.3f}\")\n",
    "print(f\"\\nPart 2 (Fresh data, {n_fresh_valid} samples):\")\n",
    "print(f\"  Ungated d: {fresh_ungated_d:+.3f}\")\n",
    "print(f\"  Best gated d: {fresh_gated_results[best_fresh_name]['cohens_d']:+.3f} \"\n",
    "      f\"(threshold={candidate_thresholds[best_fresh_name]:.4f}, {best_fresh_name})\")\n",
    "print(f\"  Oracle d: {fresh_oracle_d:+.3f}\")\n",
    "\n",
    "gated_d_fresh = fresh_gated_results[best_fresh_name]['cohens_d']\n",
    "if gated_d_fresh > fresh_ungated_d + 0.02:\n",
    "    print(f\"\\nVERDICT: Hardness gating IMPROVES over ungated soft prefix \")\n",
    "    print(f\"  ({gated_d_fresh:+.3f} vs {fresh_ungated_d:+.3f} on fresh data).\")\n",
    "    print(f\"  Gating avoids easy-query harm while preserving hard-query benefit.\")\n",
    "elif gated_d_fresh > fresh_ungated_d - 0.02:\n",
    "    print(f\"\\nVERDICT: Hardness gating MATCHES ungated soft prefix \")\n",
    "    print(f\"  ({gated_d_fresh:+.3f} vs {fresh_ungated_d:+.3f} on fresh data).\")\n",
    "    print(f\"  Gating does not significantly change overall effect.\")\n",
    "else:\n",
    "    print(f\"\\nVERDICT: Hardness gating HURTS vs ungated soft prefix \")\n",
    "    print(f\"  ({gated_d_fresh:+.3f} vs {fresh_ungated_d:+.3f} on fresh data).\")\n",
    "    print(f\"  Excluding easy queries reduces total positive signal.\")\n",
    "\n",
    "exp25_transfers = abs(exp25_optimal_on_fresh['cohens_d'] - fresh_best['cohens_d']) < 0.05\n",
    "print(f\"\\nThreshold generalizes: {'YES' if exp25_transfers else 'NO'}\")\n",
    "print(f\"  (Exp25 optimal on fresh: d={exp25_optimal_on_fresh['cohens_d']:+.3f}, \"\n",
    "      f\"Fresh optimal: d={fresh_best['cohens_d']:+.3f})\")\n",
    "\n",
    "print(f\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T20:17:42.813708Z",
     "iopub.status.busy": "2026-02-16T20:17:42.812987Z",
     "iopub.status.idle": "2026-02-16T20:17:43.437582Z",
     "shell.execute_reply": "2026-02-16T20:17:43.436883Z"
    },
    "papermill": {
     "duration": 0.632622,
     "end_time": "2026-02-16T20:17:43.439196",
     "exception": false,
     "start_time": "2026-02-16T20:17:42.806574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 3.25 GB -> 1.35 GB\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: GPU cleanup\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "if 'soft_prefix_fact' in dir():\n",
    "    del soft_prefix_fact\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 384.41524,
   "end_time": "2026-02-16T20:17:47.091704",
   "environment_variables": {},
   "exception": null,
   "input_path": "26_hardness_gated_soft_prefix.ipynb",
   "output_path": "26_hardness_gated_soft_prefix_executed.ipynb",
   "parameters": {},
   "start_time": "2026-02-16T20:11:22.676464",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "038def2052ca42ecb0793fa5bec56073": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18785bc138274f379f64c168558bff35",
       "max": 10047.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_803622d9e1754481ad49dfd09b92eeca",
       "tabbable": null,
       "tooltip": null,
       "value": 925.0
      }
     },
     "04935b059b9449a2b751cf2b350ecb04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51622c5e408f4569b300bbea9920cedc",
       "placeholder": "​",
       "style": "IPY_MODEL_ef11e3e45f534d249b451e69806bc219",
       "tabbable": null,
       "tooltip": null,
       "value": " 925/10047 [00:00&lt;00:01, 7492.79it/s]"
      }
     },
     "05c29d0cbb9943419b116de49f603d8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3e2651ed84d74b12b54e524953aff791",
       "placeholder": "​",
       "style": "IPY_MODEL_c88f6304dda444b4951b43a85cd66024",
       "tabbable": null,
       "tooltip": null,
       "value": "Filtering:   9%"
      }
     },
     "1378dd15950b443ca05a851b794fc094": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_746debbe3a3b4014b2a690f81a9e8c9d",
        "IPY_MODEL_68e61b51fbfd42628c21ae8150f3dec9",
        "IPY_MODEL_5003dba76870406984f675be3eac162c"
       ],
       "layout": "IPY_MODEL_eae876f1ed784ff3aabe0e8182025683",
       "tabbable": null,
       "tooltip": null
      }
     },
     "18785bc138274f379f64c168558bff35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1db00f835d0e4487a3747f851d886f01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05c29d0cbb9943419b116de49f603d8f",
        "IPY_MODEL_038def2052ca42ecb0793fa5bec56073",
        "IPY_MODEL_04935b059b9449a2b751cf2b350ecb04"
       ],
       "layout": "IPY_MODEL_8f902c6223ac4f76a7ef6eca933d6aff",
       "tabbable": null,
       "tooltip": null
      }
     },
     "28d2d864c9c049f8857c50872e95dc80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36d54a5ca7b74c3588778fb436eb008b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d1ff4ded172464fb61f1b3a2c62dccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c31e34fbe37547ea8f75f46891fd05b8",
       "placeholder": "​",
       "style": "IPY_MODEL_8ba51179e95a4a13be68d5ce6f533154",
       "tabbable": null,
       "tooltip": null,
       "value": " 300/300 [05:54&lt;00:00,  1.15s/it]"
      }
     },
     "3e2651ed84d74b12b54e524953aff791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41266b09365e416eb6b8299f5e50790d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4247b07bce83421eb91fde572e5d8c32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d147a91431c24ec0a2da1a7366b9e11c",
        "IPY_MODEL_45f321278a9e47b28220aec8d6978be9",
        "IPY_MODEL_3d1ff4ded172464fb61f1b3a2c62dccb"
       ],
       "layout": "IPY_MODEL_4fc7fb4d7ce44b74aafe3dd3af4f1737",
       "tabbable": null,
       "tooltip": null
      }
     },
     "45f321278a9e47b28220aec8d6978be9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6873a52d0b548919efe06df68a1a705",
       "max": 300.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_36d54a5ca7b74c3588778fb436eb008b",
       "tabbable": null,
       "tooltip": null,
       "value": 300.0
      }
     },
     "4fc7fb4d7ce44b74aafe3dd3af4f1737": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5003dba76870406984f675be3eac162c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6866657a875a4968a0cfb776ffa898d1",
       "placeholder": "​",
       "style": "IPY_MODEL_41266b09365e416eb6b8299f5e50790d",
       "tabbable": null,
       "tooltip": null,
       "value": " 883/883 [00:03&lt;00:00, 835.72it/s, Materializing param=model.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "51622c5e408f4569b300bbea9920cedc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "615bd7cfa9eb46b98cc6e5cd02d7cfeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6866657a875a4968a0cfb776ffa898d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68e61b51fbfd42628c21ae8150f3dec9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_615bd7cfa9eb46b98cc6e5cd02d7cfeb",
       "max": 883.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_90f8830f9c464f44b472a4f634be2bd8",
       "tabbable": null,
       "tooltip": null,
       "value": 883.0
      }
     },
     "746debbe3a3b4014b2a690f81a9e8c9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28d2d864c9c049f8857c50872e95dc80",
       "placeholder": "​",
       "style": "IPY_MODEL_a1cf0fe04cd54580883608101348b911",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "803622d9e1754481ad49dfd09b92eeca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ba51179e95a4a13be68d5ce6f533154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f902c6223ac4f76a7ef6eca933d6aff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90f8830f9c464f44b472a4f634be2bd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a1cf0fe04cd54580883608101348b911": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae6ae32cd34d47ca87d43e2ef3f055cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b6873a52d0b548919efe06df68a1a705": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b691a8f6ac9f474a844f481b68551716": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c31e34fbe37547ea8f75f46891fd05b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c88f6304dda444b4951b43a85cd66024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d147a91431c24ec0a2da1a7366b9e11c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b691a8f6ac9f474a844f481b68551716",
       "placeholder": "​",
       "style": "IPY_MODEL_ae6ae32cd34d47ca87d43e2ef3f055cd",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring: 100%"
      }
     },
     "eae876f1ed784ff3aabe0e8182025683": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef11e3e45f534d249b451e69806bc219": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}