{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 05: Hardness-Gated Semantic Priming + LLM Surrogates\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 01-03 consistently show priming helps MORE for hard samples (r=0.15-0.30 hardness\n",
    "correlation). But the overall effect is dragged to zero by easy samples where priming\n",
    "interferes. This experiment asks: **if we only prime hard samples, does oracle beat random?**\n",
    "\n",
    "Also tests LLM-generated surrogates — the production scenario where you generate a topic\n",
    "query rather than having the oracle.\n",
    "\n",
    "## Design (two-pass)\n",
    "\n",
    "1. **First pass**: Score bare NLL on 4000 MS MARCO samples\n",
    "2. **Filter**: Keep hardest 50% (bare NLL > median) → ~2000 samples\n",
    "3. **Generate**: LLM surrogates for each hard sample using Mistral-7B chat\n",
    "4. **Second pass**: Full 5-condition eval on hard samples\n",
    "\n",
    "## Conditions (5)\n",
    "\n",
    "| # | Condition | Cache | Tests |\n",
    "|---|-----------|-------|-------|\n",
    "| 1 | Bare | `[BOS][doc]` | Baseline |\n",
    "| 2 | Oracle-truncated | `[BOS][query\\n][doc]` → truncate + RoPE | Semantic signal |\n",
    "| 3 | Random-truncated | `[BOS][random\\n][doc]` → truncate + RoPE | Structural control |\n",
    "| 4 | Separator-only | `[BOS][doc][\\n\\nRelated question: ]` | Framing effect |\n",
    "| 5 | LLM-surrogate-truncated | `[BOS][llm_query\\n][doc]` → truncate + RoPE | Production scenario |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:06:35.762380Z",
     "iopub.status.busy": "2026-02-08T02:06:35.762086Z",
     "iopub.status.idle": "2026-02-08T02:06:39.362040Z",
     "shell.execute_reply": "2026-02-08T02:06:39.360927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 42\n",
      "Results directory: results/exp05\n",
      "CUDA available: True\n",
      "GPU: NVIDIA L4\n",
      "GPU memory: 23.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp05\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "SURROGATES_PATH = RESULTS_DIR / \"surrogates.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:06:39.403540Z",
     "iopub.status.busy": "2026-02-08T02:06:39.402498Z",
     "iopub.status.idle": "2026-02-08T02:07:43.441807Z",
     "shell.execute_reply": "2026-02-08T02:07:43.440916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mistralai/Mistral-7B-Instruct-v0.2 (4-bit)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15393c7030e04d77a7efc51091a14595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.float16, device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit)...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded. dtype={model.dtype}, device={model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:07:43.445729Z",
     "iopub.status.busy": "2026-02-08T02:07:43.444832Z",
     "iopub.status.idle": "2026-02-08T02:07:43.928655Z",
     "shell.execute_reply": "2026-02-08T02:07:43.927810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready\n",
      "  num_samples pool: 4000\n",
      "  passage words: 20-500\n",
      "  bonferroni_alpha: 0.0071\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Imports + config + templates + shared functions\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.kv_cache import (\n",
    "    build_kv_cache,\n",
    "    build_suffix_kv_cache,\n",
    "    score_answer_with_cache,\n",
    "    deepcopy_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    ")\n",
    "from lib.data import load_ms_marco, load_evaluation_samples\n",
    "from lib.analysis import cohens_d\n",
    "from lib.surrogate import generate_surrogate\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_samples=4000,\n",
    "    min_passage_words=20,\n",
    "    max_passage_words=500,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "QUERY_TEMPLATE = \"\\nQuery: {query}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"\n",
    "SUFFIX_SEPARATOR = \"\\n\\nRelated question: \"\n",
    "CHECKPOINT_EVERY = 50\n",
    "N_COMPARISONS = 7\n",
    "BONFERRONI_ALPHA = 0.05 / N_COMPARISONS\n",
    "\n",
    "\n",
    "def generate_random_prefix_text(target_text, tokenizer, seed):\n",
    "    target_ids = tokenizer.encode(target_text, add_special_tokens=False)\n",
    "    target_len = len(target_ids)\n",
    "    if target_len == 0:\n",
    "        return \"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    vocab_size = len(tokenizer)\n",
    "    min_id = 3\n",
    "    random_ids = rng.randint(min_id, vocab_size, size=target_len)\n",
    "    random_text = tokenizer.decode(random_ids.tolist(), skip_special_tokens=True)\n",
    "    reencoded = tokenizer.encode(random_text, add_special_tokens=False)\n",
    "    if len(reencoded) != target_len:\n",
    "        if len(reencoded) > target_len:\n",
    "            random_text = tokenizer.decode(reencoded[:target_len], skip_special_tokens=True)\n",
    "        else:\n",
    "            extra_needed = target_len - len(reencoded)\n",
    "            extra_ids = rng.randint(min_id, vocab_size, size=extra_needed)\n",
    "            extra_text = tokenizer.decode(extra_ids.tolist(), skip_special_tokens=True)\n",
    "            random_text = random_text + extra_text\n",
    "            reencoded2 = tokenizer.encode(random_text, add_special_tokens=False)\n",
    "            if len(reencoded2) > target_len:\n",
    "                random_text = tokenizer.decode(reencoded2[:target_len], skip_special_tokens=True)\n",
    "    return random_text\n",
    "\n",
    "\n",
    "print(\"Config ready\")\n",
    "print(f\"  num_samples pool: {config.num_samples}\")\n",
    "print(f\"  passage words: {config.min_passage_words}-{config.max_passage_words}\")\n",
    "print(f\"  bonferroni_alpha: {BONFERRONI_ALPHA:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:07:43.932512Z",
     "iopub.status.busy": "2026-02-08T02:07:43.931535Z",
     "iopub.status.idle": "2026-02-08T02:07:45.640210Z",
     "shell.execute_reply": "2026-02-08T02:07:45.639300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'microsoft/ms_marco' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading microsoft/ms_marco dataset...\n",
      "Dataset loaded: 10047 samples\n",
      "Filtering samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73de1fbdc6344fcb8337f5d8421124bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering:   0%|          | 0/10047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 4000 samples\n",
      "Loaded 4000 samples for hardness screening\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load MS MARCO (large pool)\n",
    "dataset = load_ms_marco(config)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "all_samples = load_evaluation_samples(dataset, config, require_answer=True)\n",
    "\n",
    "N_POOL = len(all_samples)\n",
    "print(f\"Loaded {N_POOL} samples for hardness screening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:07:45.643828Z",
     "iopub.status.busy": "2026-02-08T02:07:45.643101Z",
     "iopub.status.idle": "2026-02-08T02:36:12.181937Z",
     "shell.execute_reply": "2026-02-08T02:36:12.181110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FIRST PASS: BARE NLL SCORING\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be523ae8af0848eb913933695109ce40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bare NLL:   0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200/4000 | 2.3 s/s | ETA: 27.3 min\n",
      "  400/4000 | 2.3 s/s | ETA: 25.8 min\n",
      "  600/4000 | 2.3 s/s | ETA: 24.3 min\n",
      "  800/4000 | 2.3 s/s | ETA: 22.9 min\n",
      "  1000/4000 | 2.3 s/s | ETA: 21.4 min\n",
      "  1200/4000 | 2.3 s/s | ETA: 20.0 min\n",
      "  1400/4000 | 2.3 s/s | ETA: 18.5 min\n",
      "  1600/4000 | 2.3 s/s | ETA: 17.1 min\n",
      "  1800/4000 | 2.3 s/s | ETA: 15.7 min\n",
      "  2000/4000 | 2.3 s/s | ETA: 14.2 min\n",
      "  2200/4000 | 2.3 s/s | ETA: 12.8 min\n",
      "  2400/4000 | 2.3 s/s | ETA: 11.4 min\n",
      "  2600/4000 | 2.3 s/s | ETA: 10.0 min\n",
      "  2800/4000 | 2.3 s/s | ETA: 8.5 min\n",
      "  3000/4000 | 2.3 s/s | ETA: 7.1 min\n",
      "  3200/4000 | 2.3 s/s | ETA: 5.7 min\n",
      "  3400/4000 | 2.3 s/s | ETA: 4.3 min\n",
      "  3600/4000 | 2.3 s/s | ETA: 2.8 min\n",
      "  3800/4000 | 2.3 s/s | ETA: 1.4 min\n",
      "  4000/4000 | 2.3 s/s | ETA: 0.0 min\n",
      "First pass: 4000 samples in 28.4 min\n",
      "\n",
      "Bare NLL distribution (non-zero only, N=3669):\n",
      "  Mean: 1.119, Median: 0.610\n",
      "  Q25: 0.221, Q75: 1.370\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: First pass — score bare NLL on all samples\n",
    "# This identifies the \"hard\" samples where priming is most likely to help.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FIRST PASS: BARE NLL SCORING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "bare_nlls_path = RESULTS_DIR / \"bare_nlls.json\"\n",
    "\n",
    "if bare_nlls_path.exists():\n",
    "    with open(bare_nlls_path, 'r') as f:\n",
    "        bare_data = json.load(f)\n",
    "    bare_nlls_all = bare_data['bare_nlls']\n",
    "    print(f\"Loaded {len(bare_nlls_all)} bare NLLs from cache\")\n",
    "else:\n",
    "    bare_nlls_all = []\n",
    "    t_start = time.time()\n",
    "\n",
    "    for idx in tqdm(range(len(bare_nlls_all), N_POOL), initial=len(bare_nlls_all),\n",
    "                     total=N_POOL, desc=\"Bare NLL\"):\n",
    "        sample = all_samples[idx]\n",
    "        passage = sample['passage']\n",
    "        query = sample['query']\n",
    "        answer = sample['answer']\n",
    "        query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "        answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "\n",
    "        bare_len, bare_cache = build_kv_cache(passage, model, tokenizer, config)\n",
    "        bare_nll = score_answer_with_cache(\n",
    "            deepcopy_cache(bare_cache), bare_len,\n",
    "            query_prompt, answer_text, model, tokenizer, config)\n",
    "        bare_nlls_all.append(bare_nll)\n",
    "\n",
    "        del bare_cache\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if (idx + 1) % 200 == 0:\n",
    "            with open(bare_nlls_path, 'w') as f:\n",
    "                json.dump({'bare_nlls': bare_nlls_all}, f)\n",
    "            elapsed = time.time() - t_start\n",
    "            rate = (idx + 1) / elapsed\n",
    "            print(f\"  {idx+1}/{N_POOL} | {rate:.1f} s/s | ETA: {(N_POOL-idx-1)/rate/60:.1f} min\")\n",
    "\n",
    "    with open(bare_nlls_path, 'w') as f:\n",
    "        json.dump({'bare_nlls': bare_nlls_all}, f)\n",
    "\n",
    "    elapsed = time.time() - t_start\n",
    "    print(f\"First pass: {N_POOL} samples in {elapsed/60:.1f} min\")\n",
    "\n",
    "bare_nlls_arr = np.array(bare_nlls_all)\n",
    "nonzero_mask = bare_nlls_arr > 0\n",
    "print(f\"\\nBare NLL distribution (non-zero only, N={np.sum(nonzero_mask)}):\")\n",
    "bnz = bare_nlls_arr[nonzero_mask]\n",
    "print(f\"  Mean: {bnz.mean():.3f}, Median: {np.median(bnz):.3f}\")\n",
    "print(f\"  Q25: {np.percentile(bnz, 25):.3f}, Q75: {np.percentile(bnz, 75):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:36:12.185412Z",
     "iopub.status.busy": "2026-02-08T02:36:12.184821Z",
     "iopub.status.idle": "2026-02-08T03:22:52.698459Z",
     "shell.execute_reply": "2026-02-08T03:22:52.697654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FILTERING TO HARD SAMPLES + GENERATING SURROGATES\n",
      "======================================================================\n",
      "Median bare NLL (non-zero): 0.610\n",
      "Selected 1833 hard samples\n",
      "Hard sample bare NLL: mean=1.999, median=1.377\n",
      "\n",
      "Generating LLM surrogates for 1833 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6616177bd6450f9ff010abb249085d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LLM Surrogates:   0%|          | 0/1833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated 100/1833 | 0.7 s/s | ETA: 38.8 min\n",
      "  Generated 200/1833 | 0.7 s/s | ETA: 39.5 min\n",
      "  Generated 300/1833 | 0.7 s/s | ETA: 37.3 min\n",
      "  Generated 400/1833 | 0.7 s/s | ETA: 34.3 min\n",
      "  Generated 500/1833 | 0.7 s/s | ETA: 32.6 min\n",
      "  Generated 600/1833 | 0.7 s/s | ETA: 30.4 min\n",
      "  Generated 700/1833 | 0.7 s/s | ETA: 27.9 min\n",
      "  Generated 800/1833 | 0.7 s/s | ETA: 25.6 min\n",
      "  Generated 900/1833 | 0.7 s/s | ETA: 23.2 min\n",
      "  Generated 1000/1833 | 0.7 s/s | ETA: 20.9 min\n",
      "  Generated 1100/1833 | 0.7 s/s | ETA: 18.4 min\n",
      "  Generated 1200/1833 | 0.7 s/s | ETA: 15.9 min\n",
      "  Generated 1300/1833 | 0.7 s/s | ETA: 13.3 min\n",
      "  Generated 1400/1833 | 0.7 s/s | ETA: 10.8 min\n",
      "  Generated 1500/1833 | 0.7 s/s | ETA: 8.4 min\n",
      "  Generated 1600/1833 | 0.7 s/s | ETA: 5.9 min\n",
      "  Generated 1700/1833 | 0.7 s/s | ETA: 3.4 min\n",
      "  Generated 1800/1833 | 0.7 s/s | ETA: 0.8 min\n",
      "  Generated 1833/1833 | 0.7 s/s | ETA: 0.0 min\n",
      "\n",
      "Surrogate examples:\n",
      "  Oracle:    what is provider based billing mean...\n",
      "  LLM:       Provider Based Billing hospital services Medicare Medicaid r...\n",
      "\n",
      "  Oracle:    when was fontana dam built...\n",
      "  LLM:       Fontana Dam facts and statistics...\n",
      "\n",
      "  Oracle:    what does a cumulonimbus look like...\n",
      "  LLM:       Cumulonimbus clouds height in atmosphere...\n",
      "\n",
      "  Oracle:    which types of waves are absorbed by the atmosphere...\n",
      "  LLM:       Earth's atmosphere absorbs ultraviolet, X-rays, gamma rays...\n",
      "\n",
      "  Oracle:    Epsom Salt to Water Ratio...\n",
      "  LLM:       epsom salt lawn application 3000 sqft...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Filter to hard samples + generate LLM surrogates\n",
    "print(\"=\" * 70)\n",
    "print(\"FILTERING TO HARD SAMPLES + GENERATING SURROGATES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Filter: keep samples with non-zero bare NLL above median\n",
    "median_nll = np.median(bare_nlls_arr[bare_nlls_arr > 0])\n",
    "print(f\"Median bare NLL (non-zero): {median_nll:.3f}\")\n",
    "\n",
    "hard_indices = []\n",
    "for i, nll in enumerate(bare_nlls_all):\n",
    "    if nll > median_nll:\n",
    "        hard_indices.append(i)\n",
    "\n",
    "np.random.seed(SEED + 100)\n",
    "np.random.shuffle(hard_indices)\n",
    "hard_indices = hard_indices[:2000]\n",
    "hard_indices.sort()  # sort for deterministic ordering\n",
    "\n",
    "hard_samples = [all_samples[i] for i in hard_indices]\n",
    "hard_bare_nlls = [bare_nlls_all[i] for i in hard_indices]\n",
    "\n",
    "N_HARD = len(hard_samples)\n",
    "print(f\"Selected {N_HARD} hard samples\")\n",
    "print(f\"Hard sample bare NLL: mean={np.mean(hard_bare_nlls):.3f}, \"\n",
    "      f\"median={np.median(hard_bare_nlls):.3f}\")\n",
    "\n",
    "# Generate LLM surrogates\n",
    "print(f\"\\nGenerating LLM surrogates for {N_HARD} samples...\")\n",
    "\n",
    "if SURROGATES_PATH.exists():\n",
    "    with open(SURROGATES_PATH, 'r') as f:\n",
    "        surrogates_data = json.load(f)\n",
    "    surrogates = surrogates_data['surrogates']\n",
    "    print(f\"Loaded {len(surrogates)} surrogates from cache\")\n",
    "else:\n",
    "    surrogates = []\n",
    "\n",
    "start_gen = len(surrogates)\n",
    "if start_gen < N_HARD:\n",
    "    t_start = time.time()\n",
    "    for idx in tqdm(range(start_gen, N_HARD), initial=start_gen, total=N_HARD,\n",
    "                     desc=\"LLM Surrogates\"):\n",
    "        sample = hard_samples[idx]\n",
    "        try:\n",
    "            surrogate = generate_surrogate(sample['passage'], model, tokenizer, config)\n",
    "        except Exception as e:\n",
    "            surrogate = sample['query'][:30]  # fallback\n",
    "            print(f\"  WARNING: Generation failed for sample {idx}: {e}\")\n",
    "        surrogates.append(surrogate)\n",
    "\n",
    "        if (idx + 1) % 100 == 0 or idx == N_HARD - 1:\n",
    "            with open(SURROGATES_PATH, 'w') as f:\n",
    "                json.dump({'surrogates': surrogates}, f)\n",
    "            elapsed = time.time() - t_start\n",
    "            rate = (idx - start_gen + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (N_HARD - idx - 1) / rate if rate > 0 else 0\n",
    "            tqdm.write(f\"  Generated {idx+1}/{N_HARD} | {rate:.1f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "    with open(SURROGATES_PATH, 'w') as f:\n",
    "        json.dump({'surrogates': surrogates}, f)\n",
    "\n",
    "# Show examples\n",
    "print(f\"\\nSurrogate examples:\")\n",
    "for i in range(min(5, N_HARD)):\n",
    "    print(f\"  Oracle:    {hard_samples[i]['query'][:60]}...\")\n",
    "    print(f\"  LLM:       {surrogates[i][:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T03:22:52.702109Z",
     "iopub.status.busy": "2026-02-08T03:22:52.701841Z",
     "iopub.status.idle": "2026-02-08T04:29:33.729406Z",
     "shell.execute_reply": "2026-02-08T04:29:33.728507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECOND PASS: 5-CONDITION EVAL ON HARD SAMPLES\n",
      "======================================================================\n",
      "No checkpoint found. Starting fresh.\n",
      "Evaluating samples 0 to 1832\n",
      "Conditions: 5 (bare, oracle, random, separator, LLM-surrogate)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec99abb0fefd49768921843caa9b0328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 50/1833 | 0.46 s/s | ETA: 64.3 min\n",
      "  Checkpoint 100/1833 | 0.46 s/s | ETA: 62.7 min\n",
      "  Checkpoint 150/1833 | 0.46 s/s | ETA: 61.1 min\n",
      "  Checkpoint 200/1833 | 0.46 s/s | ETA: 59.4 min\n",
      "  Checkpoint 250/1833 | 0.46 s/s | ETA: 57.7 min\n",
      "  Checkpoint 300/1833 | 0.46 s/s | ETA: 55.8 min\n",
      "  Checkpoint 350/1833 | 0.46 s/s | ETA: 54.0 min\n",
      "  Checkpoint 400/1833 | 0.46 s/s | ETA: 52.1 min\n",
      "  Checkpoint 450/1833 | 0.46 s/s | ETA: 50.3 min\n",
      "  Checkpoint 500/1833 | 0.46 s/s | ETA: 48.5 min\n",
      "  Checkpoint 550/1833 | 0.46 s/s | ETA: 46.6 min\n",
      "  Checkpoint 600/1833 | 0.46 s/s | ETA: 44.8 min\n",
      "  Checkpoint 650/1833 | 0.46 s/s | ETA: 43.0 min\n",
      "  Checkpoint 700/1833 | 0.46 s/s | ETA: 41.2 min\n",
      "  Checkpoint 750/1833 | 0.46 s/s | ETA: 39.4 min\n",
      "  Checkpoint 800/1833 | 0.46 s/s | ETA: 37.6 min\n",
      "  Checkpoint 850/1833 | 0.46 s/s | ETA: 35.8 min\n",
      "  Checkpoint 900/1833 | 0.46 s/s | ETA: 33.9 min\n",
      "  Checkpoint 950/1833 | 0.46 s/s | ETA: 32.1 min\n",
      "  Checkpoint 1000/1833 | 0.46 s/s | ETA: 30.3 min\n",
      "  Checkpoint 1050/1833 | 0.46 s/s | ETA: 28.5 min\n",
      "  Checkpoint 1100/1833 | 0.46 s/s | ETA: 26.6 min\n",
      "  Checkpoint 1150/1833 | 0.46 s/s | ETA: 24.8 min\n",
      "  Checkpoint 1200/1833 | 0.46 s/s | ETA: 23.0 min\n",
      "  Checkpoint 1250/1833 | 0.46 s/s | ETA: 21.2 min\n",
      "  Checkpoint 1300/1833 | 0.46 s/s | ETA: 19.4 min\n",
      "  Checkpoint 1350/1833 | 0.46 s/s | ETA: 17.6 min\n",
      "  Checkpoint 1400/1833 | 0.46 s/s | ETA: 15.7 min\n",
      "  Checkpoint 1450/1833 | 0.46 s/s | ETA: 13.9 min\n",
      "  Checkpoint 1500/1833 | 0.46 s/s | ETA: 12.1 min\n",
      "  Checkpoint 1550/1833 | 0.46 s/s | ETA: 10.3 min\n",
      "  Checkpoint 1600/1833 | 0.46 s/s | ETA: 8.5 min\n",
      "  Checkpoint 1650/1833 | 0.46 s/s | ETA: 6.7 min\n",
      "  Checkpoint 1700/1833 | 0.46 s/s | ETA: 4.8 min\n",
      "  Checkpoint 1750/1833 | 0.46 s/s | ETA: 3.0 min\n",
      "  Checkpoint 1800/1833 | 0.46 s/s | ETA: 1.2 min\n",
      "  Checkpoint 1833/1833 | 0.46 s/s | ETA: 0.0 min\n",
      "\n",
      "Evaluation complete: 1833 samples in 66.7 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main eval loop — 5 conditions on hard samples\n",
    "print(\"=\" * 70)\n",
    "print(\"SECOND PASS: 5-CONDITION EVAL ON HARD SAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    with open(CHECKPOINT_PATH, 'r') as f:\n",
    "        ckpt = json.load(f)\n",
    "    ckpt_queries = ckpt.get('sample_queries', [])\n",
    "    current_queries = [s['query'] for s in hard_samples]\n",
    "    if ckpt_queries == current_queries:\n",
    "        results = ckpt['results']\n",
    "        start_idx = len(results)\n",
    "        print(f\"Resuming from checkpoint: {start_idx}/{N_HARD}\")\n",
    "    else:\n",
    "        print(\"Checkpoint mismatch. Starting fresh.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh.\")\n",
    "\n",
    "print(f\"Evaluating samples {start_idx} to {N_HARD-1}\")\n",
    "print(f\"Conditions: 5 (bare, oracle, random, separator, LLM-surrogate)\")\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for idx in tqdm(range(start_idx, N_HARD), initial=start_idx, total=N_HARD,\n",
    "                 desc=\"Evaluating\"):\n",
    "    sample = hard_samples[idx]\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "    llm_surrogate = surrogates[idx]\n",
    "\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "\n",
    "    # Matched tokenization\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_oracle_text = oracle_prefix + document_text\n",
    "\n",
    "    full_oracle_enc = tokenizer(full_oracle_text, return_tensors=\"pt\",\n",
    "                                add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_oracle_ids = full_oracle_enc['input_ids'].to(config.device)\n",
    "\n",
    "    oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    oracle_prefix_len = oracle_prefix_enc['input_ids'].shape[1]\n",
    "\n",
    "    bos_id = full_oracle_ids[:, :1]\n",
    "    doc_ids = full_oracle_ids[:, oracle_prefix_len:]\n",
    "    doc_len = doc_ids.shape[1]\n",
    "\n",
    "    random_text = generate_random_prefix_text(query, tokenizer, seed=SEED + idx)\n",
    "\n",
    "    # === Condition 1: BARE ===\n",
    "    bare_ids = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    bare_len = bare_ids.shape[1]\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_ids, attention_mask=torch.ones_like(bare_ids),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_out.past_key_values), bare_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Condition 2: ORACLE-TRUNCATED ===\n",
    "    with torch.no_grad():\n",
    "        oracle_out = model(input_ids=full_oracle_ids,\n",
    "                           attention_mask=torch.ones_like(full_oracle_ids),\n",
    "                           use_cache=True, return_dict=True)\n",
    "    oracle_cache = extract_and_truncate_cache_with_bos(oracle_out.past_key_values, doc_len)\n",
    "    correct_rope_positions_with_bos(oracle_cache, oracle_prefix_len - 1, model)\n",
    "    oracle_trunc_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(oracle_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Condition 3: RANDOM-TRUNCATED ===\n",
    "    random_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=random_text)\n",
    "    random_prefix_enc = tokenizer(random_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=False, padding=False, truncation=False)\n",
    "    random_prefix_ids = random_prefix_enc['input_ids'].to(config.device)\n",
    "    random_full_ids = torch.cat([bos_id, random_prefix_ids, doc_ids], dim=1)\n",
    "    random_prefix_len = 1 + random_prefix_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        random_out = model(input_ids=random_full_ids,\n",
    "                           attention_mask=torch.ones_like(random_full_ids),\n",
    "                           use_cache=True, return_dict=True)\n",
    "    random_cache = extract_and_truncate_cache_with_bos(random_out.past_key_values, doc_len)\n",
    "    correct_rope_positions_with_bos(random_cache, random_prefix_len - 1, model)\n",
    "    random_trunc_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(random_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Condition 4: SEPARATOR-ONLY ===\n",
    "    sep_only_len, sep_only_cache = build_suffix_kv_cache(\n",
    "        passage, \"\", model, tokenizer, config, separator=SUFFIX_SEPARATOR)\n",
    "    separator_only_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(sep_only_cache), sep_only_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Condition 5: LLM-SURROGATE-TRUNCATED ===\n",
    "    llm_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=llm_surrogate)\n",
    "    llm_prefix_enc = tokenizer(llm_prefix, return_tensors=\"pt\",\n",
    "                                add_special_tokens=False, padding=False, truncation=False)\n",
    "    llm_prefix_ids = llm_prefix_enc['input_ids'].to(config.device)\n",
    "    llm_full_ids = torch.cat([bos_id, llm_prefix_ids, doc_ids], dim=1)\n",
    "    llm_prefix_len = 1 + llm_prefix_ids.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        llm_out = model(input_ids=llm_full_ids,\n",
    "                        attention_mask=torch.ones_like(llm_full_ids),\n",
    "                        use_cache=True, return_dict=True)\n",
    "    llm_cache = extract_and_truncate_cache_with_bos(llm_out.past_key_values, doc_len)\n",
    "    correct_rope_positions_with_bos(llm_cache, llm_prefix_len - 1, model)\n",
    "    llm_trunc_nll = score_answer_with_cache(\n",
    "        deepcopy_cache(llm_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    result = {\n",
    "        'idx': idx,\n",
    "        'bare_nll': bare_nll,\n",
    "        'oracle_trunc_nll': oracle_trunc_nll,\n",
    "        'random_trunc_nll': random_trunc_nll,\n",
    "        'separator_only_nll': separator_only_nll,\n",
    "        'llm_trunc_nll': llm_trunc_nll,\n",
    "        'doc_len': doc_len,\n",
    "        'passage_word_count': len(passage.split()),\n",
    "        'pre_filter_bare_nll': hard_bare_nlls[idx],\n",
    "        'llm_surrogate': llm_surrogate,\n",
    "        'delta_oracle_vs_bare': bare_nll - oracle_trunc_nll,\n",
    "        'delta_random_vs_bare': bare_nll - random_trunc_nll,\n",
    "        'delta_oracle_vs_random': random_trunc_nll - oracle_trunc_nll,\n",
    "        'delta_seponly_vs_bare': bare_nll - separator_only_nll,\n",
    "        'delta_llm_vs_bare': bare_nll - llm_trunc_nll,\n",
    "        'delta_llm_vs_random': random_trunc_nll - llm_trunc_nll,\n",
    "        'delta_llm_vs_oracle': oracle_trunc_nll - llm_trunc_nll,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    del bare_out, oracle_out, oracle_cache, random_out, random_cache\n",
    "    del sep_only_cache, llm_out, llm_cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if (idx + 1) % CHECKPOINT_EVERY == 0 or idx == N_HARD - 1:\n",
    "        ckpt_data = {\n",
    "            'results': results,\n",
    "            'sample_queries': [s['query'] for s in hard_samples],\n",
    "            'completed': len(results),\n",
    "            'total': N_HARD,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, 'w') as f:\n",
    "            json.dump(ckpt_data, f)\n",
    "        elapsed = time.time() - t_start\n",
    "        rate = (idx - start_idx + 1) / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N_HARD - idx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {idx+1}/{N_HARD} | {rate:.2f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nEvaluation complete: {len(results)} samples in {elapsed_total/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T04:29:33.734082Z",
     "iopub.status.busy": "2026-02-08T04:29:33.733787Z",
     "iopub.status.idle": "2026-02-08T04:29:34.208965Z",
     "shell.execute_reply": "2026-02-08T04:29:34.208092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYSIS — HARDNESS-GATED SEMANTIC PRIMING\n",
      "======================================================================\n",
      "Total: 1833, Valid: 1833, Excluded: 0\n",
      "Bonferroni alpha: 0.0071 (7 comparisons)\n",
      "\n",
      "Condition                   Mean NLL        Std\n",
      "--------------------------------------------------\n",
      "Bare                          1.9998     1.8515\n",
      "Oracle-truncated              1.9305     1.8396\n",
      "Random-truncated              1.9290     1.8609\n",
      "Separator-only                1.7865     1.6843\n",
      "LLM-surrogate-trunc           1.8241     1.7409\n",
      "\n",
      "Comparison                  Mean D        d    Win%        t            p   Sig\n",
      "--------------------------------------------------------------------------------\n",
      "Oracle vs Bare              0.0693    0.131   58.6%     5.59    2.59e-08   ***\n",
      "Random vs Bare              0.0708    0.153   60.2%     6.55    7.65e-11   ***\n",
      "Oracle vs Random           -0.0015   -0.003   51.1%    -0.12    9.06e-01    ns\n",
      "Sep-only vs Bare            0.2133    0.372   81.0%    15.93    1.39e-53   ***\n",
      "LLM vs Bare                 0.1757    0.374   74.7%    16.01    4.17e-54   ***\n",
      "LLM vs Random               0.1049    0.209   66.0%     8.95    8.44e-19   ***\n",
      "LLM vs Oracle               0.1064    0.202   62.9%     8.66    1.03e-17   ***\n",
      "\n",
      "Hardness interaction (within hard subset):\n",
      "  Oracle         : r=0.166, p=9.79e-13\n",
      "  Random         : r=0.105, p=7.09e-06\n",
      "  LLM            : r=0.355, p=1.22e-55\n",
      "  Sep-only       : r=0.433, p=9.03e-85\n",
      "\n",
      "______________________________________________________________________\n",
      "VERDICTS:\n",
      "  Oracle vs Random: No semantic signal even in hard samples (d=-0.003, ns)\n",
      "  LLM vs Random: LLM surrogates ADD value beyond random (d=+0.209)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Analysis\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS — HARDNESS-GATED SEMANTIC PRIMING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "bare_raw = np.array([r['bare_nll'] for r in results])\n",
    "oracle_raw = np.array([r['oracle_trunc_nll'] for r in results])\n",
    "random_raw = np.array([r['random_trunc_nll'] for r in results])\n",
    "seponly_raw = np.array([r['separator_only_nll'] for r in results])\n",
    "llm_raw = np.array([r['llm_trunc_nll'] for r in results])\n",
    "\n",
    "valid = (bare_raw != 0) & (oracle_raw != 0) & (random_raw != 0) & (seponly_raw != 0) & (llm_raw != 0)\n",
    "n_valid = int(np.sum(valid))\n",
    "n_excluded = int(np.sum(~valid))\n",
    "\n",
    "bare = bare_raw[valid]\n",
    "oracle = oracle_raw[valid]\n",
    "random = random_raw[valid]\n",
    "sep_only = seponly_raw[valid]\n",
    "llm = llm_raw[valid]\n",
    "\n",
    "print(f\"Total: {len(results)}, Valid: {n_valid}, Excluded: {n_excluded}\")\n",
    "print(f\"Bonferroni alpha: {BONFERRONI_ALPHA:.4f} ({N_COMPARISONS} comparisons)\")\n",
    "\n",
    "# NLL summary\n",
    "print(f\"\\n{'Condition':<25} {'Mean NLL':>10} {'Std':>10}\")\n",
    "print(\"-\" * 50)\n",
    "for name, arr in [('Bare', bare), ('Oracle-truncated', oracle),\n",
    "                   ('Random-truncated', random), ('Separator-only', sep_only),\n",
    "                   ('LLM-surrogate-trunc', llm)]:\n",
    "    print(f\"{name:<25} {np.mean(arr):>10.4f} {np.std(arr):>10.4f}\")\n",
    "\n",
    "# Comparisons\n",
    "comparisons = [\n",
    "    ('Oracle vs Bare', bare - oracle, 'Does oracle help hard samples?'),\n",
    "    ('Random vs Bare', bare - random, 'Does random help hard samples?'),\n",
    "    ('Oracle vs Random', random - oracle, 'KEY: semantic priming in hard?'),\n",
    "    ('Sep-only vs Bare', bare - sep_only, 'Separator on hard samples?'),\n",
    "    ('LLM vs Bare', bare - llm, 'LLM surrogate overall?'),\n",
    "    ('LLM vs Random', random - llm, 'LLM better than random?'),\n",
    "    ('LLM vs Oracle', oracle - llm, 'LLM better than oracle?'),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Comparison':<25} {'Mean D':>8} {'d':>8} {'Win%':>7} {'t':>8} {'p':>12} {'Sig':>5}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "comparison_results = {}\n",
    "for name, delta, question in comparisons:\n",
    "    d = cohens_d(delta)\n",
    "    win = np.mean(delta > 0) * 100\n",
    "    t_stat, p_val = stats.ttest_1samp(delta, 0)\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"{name:<25} {np.mean(delta):>8.4f} {d:>8.3f} {win:>6.1f}% {t_stat:>8.2f} {p_val:>11.2e} {sig:>5}\")\n",
    "    comparison_results[name] = {\n",
    "        'mean_delta': float(np.mean(delta)),\n",
    "        'cohens_d': float(d),\n",
    "        'win_rate': float(win / 100),\n",
    "        't_stat': float(t_stat),\n",
    "        'p_value': float(p_val),\n",
    "        'bonferroni_significant': bool(p_val < BONFERRONI_ALPHA),\n",
    "        'question': question,\n",
    "    }\n",
    "\n",
    "# Hardness interaction within hard samples\n",
    "print(f\"\\nHardness interaction (within hard subset):\")\n",
    "for name, delta in [('Oracle', bare - oracle), ('Random', bare - random),\n",
    "                     ('LLM', bare - llm), ('Sep-only', bare - sep_only)]:\n",
    "    r, p = stats.pearsonr(bare, delta)\n",
    "    print(f\"  {name:<15}: r={r:.3f}, p={p:.2e}\")\n",
    "\n",
    "# Summary verdict\n",
    "print(f\"\\n{'_' * 70}\")\n",
    "print(\"VERDICTS:\")\n",
    "d_or = comparison_results['Oracle vs Random']['cohens_d']\n",
    "p_or = comparison_results['Oracle vs Random']['p_value']\n",
    "d_lr = comparison_results['LLM vs Random']['cohens_d']\n",
    "p_lr = comparison_results['LLM vs Random']['p_value']\n",
    "\n",
    "if p_or < 0.05 and d_or > 0:\n",
    "    print(f\"  Oracle vs Random: SEMANTIC PRIMING DETECTED in hard samples (d={d_or:+.3f})\")\n",
    "elif p_or < 0.05 and d_or < 0:\n",
    "    print(f\"  Oracle vs Random: Oracle still INTERFERES even for hard samples (d={d_or:+.3f})\")\n",
    "else:\n",
    "    print(f\"  Oracle vs Random: No semantic signal even in hard samples (d={d_or:+.3f}, ns)\")\n",
    "\n",
    "if p_lr < 0.05 and d_lr > 0:\n",
    "    print(f\"  LLM vs Random: LLM surrogates ADD value beyond random (d={d_lr:+.3f})\")\n",
    "else:\n",
    "    print(f\"  LLM vs Random: LLM surrogates no better than random (d={d_lr:+.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T04:29:34.212676Z",
     "iopub.status.busy": "2026-02-08T04:29:34.212104Z",
     "iopub.status.idle": "2026-02-08T04:29:36.564721Z",
     "shell.execute_reply": "2026-02-08T04:29:36.563963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to results/exp05/analysis_plots.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Plot 1: Delta distributions — Oracle vs Random (THE key test)\n",
    "delta_or = random - oracle\n",
    "axes[0, 0].hist(delta_or, bins=60, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.3)\n",
    "axes[0, 0].axvline(x=0, color='red', linestyle='--')\n",
    "axes[0, 0].axvline(x=np.mean(delta_or), color='black', linestyle='-',\n",
    "                    label=f'd={cohens_d(delta_or):+.3f}')\n",
    "axes[0, 0].set_title('Oracle vs Random (hard samples)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: Delta distributions — LLM vs Random\n",
    "delta_lr = random - llm\n",
    "axes[0, 1].hist(delta_lr, bins=60, color='forestgreen', alpha=0.7, edgecolor='black', linewidth=0.3)\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--')\n",
    "axes[0, 1].axvline(x=np.mean(delta_lr), color='black', linestyle='-',\n",
    "                    label=f'd={cohens_d(delta_lr):+.3f}')\n",
    "axes[0, 1].set_title('LLM Surrogate vs Random (hard samples)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: All conditions bar chart\n",
    "cond_names = ['Oracle', 'Random', 'Sep-only', 'LLM']\n",
    "cond_d = [cohens_d(bare - oracle), cohens_d(bare - random),\n",
    "          cohens_d(bare - sep_only), cohens_d(bare - llm)]\n",
    "colors = ['steelblue', 'darkorange', 'crimson', 'forestgreen']\n",
    "axes[0, 2].bar(range(4), cond_d, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0, 2].set_xticks(range(4))\n",
    "axes[0, 2].set_xticklabels(cond_names)\n",
    "axes[0, 2].axhline(y=0, color='gray', linestyle='--')\n",
    "axes[0, 2].set_ylabel(\"Cohen's d vs Bare\")\n",
    "axes[0, 2].set_title('All Conditions vs Bare (hard samples)')\n",
    "\n",
    "# Plot 4: Hardness scatter — Oracle benefit\n",
    "axes[1, 0].scatter(bare, bare - oracle, alpha=0.15, s=5, c='steelblue')\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--')\n",
    "z = np.polyfit(bare, bare - oracle, 1)\n",
    "x_range = np.linspace(bare.min(), bare.max(), 100)\n",
    "axes[1, 0].plot(x_range, np.polyval(z, x_range), 'r-', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Bare NLL')\n",
    "axes[1, 0].set_ylabel('Oracle benefit')\n",
    "axes[1, 0].set_title('Hardness vs Oracle Benefit')\n",
    "\n",
    "# Plot 5: Hardness scatter — LLM benefit\n",
    "axes[1, 1].scatter(bare, bare - llm, alpha=0.15, s=5, c='forestgreen')\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--')\n",
    "z2 = np.polyfit(bare, bare - llm, 1)\n",
    "axes[1, 1].plot(x_range, np.polyval(z2, x_range), 'r-', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Bare NLL')\n",
    "axes[1, 1].set_ylabel('LLM benefit')\n",
    "axes[1, 1].set_title('Hardness vs LLM Surrogate Benefit')\n",
    "\n",
    "# Plot 6: LLM surrogate quality\n",
    "# Token overlap between LLM surrogate and oracle query\n",
    "from lib.analysis import compute_token_overlap\n",
    "overlaps = []\n",
    "for r in results[:min(500, len(results))]:\n",
    "    s = hard_samples[r['idx']]\n",
    "    overlap = compute_token_overlap(s['query'], r['llm_surrogate'], tokenizer)\n",
    "    overlaps.append(overlap)\n",
    "axes[1, 2].hist(overlaps, bins=40, color='mediumpurple', alpha=0.7, edgecolor='black', linewidth=0.3)\n",
    "axes[1, 2].set_xlabel('Token Jaccard similarity')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "axes[1, 2].set_title(f'LLM vs Oracle Query Similarity (mean={np.mean(overlaps):.3f})')\n",
    "\n",
    "plt.suptitle('Exp 05: Hardness-Gated Semantic Priming + LLM Surrogates', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plot saved to {RESULTS_DIR / 'analysis_plots.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T04:29:36.568158Z",
     "iopub.status.busy": "2026-02-08T04:29:36.567590Z",
     "iopub.status.idle": "2026-02-08T04:29:36.642001Z",
     "shell.execute_reply": "2026-02-08T04:29:36.641197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/exp05/results.json\n",
      "File size: 1335.8 KB\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save results\n",
    "final = {\n",
    "    'experiment': 'exp05_hardness_gated_surrogates',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': config.model_name,\n",
    "        'seed': SEED,\n",
    "        'n_pool': N_POOL,\n",
    "        'n_hard': N_HARD,\n",
    "        'median_nll_threshold': float(median_nll),\n",
    "        'min_passage_words': config.min_passage_words,\n",
    "        'max_passage_words': config.max_passage_words,\n",
    "        'bonferroni_alpha': BONFERRONI_ALPHA,\n",
    "    },\n",
    "    'summary': {\n",
    "        'n_total': len(results),\n",
    "        'n_valid': n_valid,\n",
    "        'n_excluded': n_excluded,\n",
    "        'nll_means': {\n",
    "            'bare': float(np.mean(bare)),\n",
    "            'oracle_trunc': float(np.mean(oracle)),\n",
    "            'random_trunc': float(np.mean(random)),\n",
    "            'separator_only': float(np.mean(sep_only)),\n",
    "            'llm_trunc': float(np.mean(llm)),\n",
    "        },\n",
    "        'comparisons': comparison_results,\n",
    "    },\n",
    "    'per_sample_results': results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {FINAL_RESULTS_PATH}\")\n",
    "print(f\"File size: {FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T04:29:36.645252Z",
     "iopub.status.busy": "2026-02-08T04:29:36.644772Z",
     "iopub.status.idle": "2026-02-08T04:29:37.166084Z",
     "shell.execute_reply": "2026-02-08T04:29:37.165172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up GPU memory...\n",
      "GPU memory: 4.14 GB -> 0.01 GB\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: GPU cleanup — free all VRAM\n",
    "import gc\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu124.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu124:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c4bfdbdb8342ddbc05905c83b3dcc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "027b9598e8d6459987f880a4042e2013": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f0139d9dc08470f81e9b0d62cd10e07",
       "placeholder": "​",
       "style": "IPY_MODEL_143803748adf4c0c94d9fd6021f7f30e",
       "tabbable": null,
       "tooltip": null,
       "value": " 4000/4000 [28:26&lt;00:00,  2.27it/s]"
      }
     },
     "0b678741fbdc47949bfa4edc7063641f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9dd8b7315d34472180748372b58ea9b9",
       "placeholder": "​",
       "style": "IPY_MODEL_d6455e95409e4c599214ee7d74c43e25",
       "tabbable": null,
       "tooltip": null,
       "value": "Bare NLL: 100%"
      }
     },
     "0b86445646ab4ec09858df075904f5b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3d60bf8567d4d48b9d5bf5aa577b299",
       "max": 1833,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_be37d3c6f2534f9c9b3983a338a3ce35",
       "tabbable": null,
       "tooltip": null,
       "value": 1833
      }
     },
     "0fd070fd485d44049069fcd601ba3654": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "143803748adf4c0c94d9fd6021f7f30e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14d910e1a69242e58de44c923a99b716": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15393c7030e04d77a7efc51091a14595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c7edfa9823ab4d5aace98b781368fb41",
        "IPY_MODEL_cd05a1537fcd406c9bd1f99601d93b85",
        "IPY_MODEL_f0f84dee66294dd5ac994fb385b2981a"
       ],
       "layout": "IPY_MODEL_eb03731182874d63a36c2cfafdab4260",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1926995855ee4aa681a459892f086209": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a78055d7f654ccd9e348b3fc721259e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bb8003c47d745da8aa6a075b3900193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1e08e22a0e4247cab245cf7c55e4cf35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25ae6c8e9aa2439c9f71700260b6ea53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2776d6028a5a46909187e579da58986a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1926995855ee4aa681a459892f086209",
       "placeholder": "​",
       "style": "IPY_MODEL_b47b279f69044824afb4ea28dbb10604",
       "tabbable": null,
       "tooltip": null,
       "value": "LLM Surrogates: 100%"
      }
     },
     "2f0139d9dc08470f81e9b0d62cd10e07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "371faaf8c0184800acc20abb780d7bfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5cf605b55ab24037a00c5345e7608527",
       "max": 1833,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6627aefbe6b24f0db957bb7b71d5e79b",
       "tabbable": null,
       "tooltip": null,
       "value": 1833
      }
     },
     "44eec2b2e766455a9064325a68941486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25ae6c8e9aa2439c9f71700260b6ea53",
       "max": 10047,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4b63fe26166453bb70b720e6a4801d7",
       "tabbable": null,
       "tooltip": null,
       "value": 8322
      }
     },
     "4e852da37f9e421ea2c4c65590b931ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5914930a9e7747a39fd197599339a80c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cf605b55ab24037a00c5345e7608527": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63d475d22469402ebd5bebada8843426": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7b47c7e7b4574c8f80c6527cb5dd2012",
       "placeholder": "​",
       "style": "IPY_MODEL_8421a0025d194c2fb3a8ca650ffa793e",
       "tabbable": null,
       "tooltip": null,
       "value": "Evaluating: 100%"
      }
     },
     "6627aefbe6b24f0db957bb7b71d5e79b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "67c1ba7dc3084897816416b2f403a50b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6f69c4f828964ae8b01abd96b499b430": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73de1fbdc6344fcb8337f5d8421124bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e276c163cf7d4e1592c8855753d3ae40",
        "IPY_MODEL_44eec2b2e766455a9064325a68941486",
        "IPY_MODEL_df5fffadc61f445f90c3b03e56ebc59d"
       ],
       "layout": "IPY_MODEL_9241ad6fd9a14cf888d0c8d6eeab491b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7612c761ed2e43918fbc864179ac35f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76e140c2e72d4da09f51fbc4a4fc7798": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5914930a9e7747a39fd197599339a80c",
       "placeholder": "​",
       "style": "IPY_MODEL_00c4bfdbdb8342ddbc05905c83b3dcc1",
       "tabbable": null,
       "tooltip": null,
       "value": " 1833/1833 [1:06:41&lt;00:00,  2.25s/it]"
      }
     },
     "7b47c7e7b4574c8f80c6527cb5dd2012": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81dff1fdc9b0475193c09e967940cc28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83e75d8b62364f9f9837103b8ae9b997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8421a0025d194c2fb3a8ca650ffa793e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9241ad6fd9a14cf888d0c8d6eeab491b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ac16ad1618f4334a556ccecf47bda9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dd8b7315d34472180748372b58ea9b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4b63fe26166453bb70b720e6a4801d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aa57bb069b4f4c9287e1522aa5c6c604": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2b51aac70664111b70fad72d2a04787": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3d60bf8567d4d48b9d5bf5aa577b299": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b47b279f69044824afb4ea28dbb10604": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd6616177bd6450f9ff010abb249085d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2776d6028a5a46909187e579da58986a",
        "IPY_MODEL_0b86445646ab4ec09858df075904f5b6",
        "IPY_MODEL_e264d5ff536d466db325c76a3c9bbc5b"
       ],
       "layout": "IPY_MODEL_14d910e1a69242e58de44c923a99b716",
       "tabbable": null,
       "tooltip": null
      }
     },
     "be37d3c6f2534f9c9b3983a338a3ce35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "be523ae8af0848eb913933695109ce40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0b678741fbdc47949bfa4edc7063641f",
        "IPY_MODEL_f7083e0282984ec4ad5c766ee788d5ee",
        "IPY_MODEL_027b9598e8d6459987f880a4042e2013"
       ],
       "layout": "IPY_MODEL_b2b51aac70664111b70fad72d2a04787",
       "tabbable": null,
       "tooltip": null
      }
     },
     "be99bb9a019c4ced9a55e0323c9bdf1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c24c3baf2e584cc9a2eecf6a472b9403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7edfa9823ab4d5aace98b781368fb41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f0b88ff299f94dd99b89cfa68de2ecff",
       "placeholder": "​",
       "style": "IPY_MODEL_1bb8003c47d745da8aa6a075b3900193",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "cd05a1537fcd406c9bd1f99601d93b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ac16ad1618f4334a556ccecf47bda9d",
       "max": 291,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c24c3baf2e584cc9a2eecf6a472b9403",
       "tabbable": null,
       "tooltip": null,
       "value": 291
      }
     },
     "d6455e95409e4c599214ee7d74c43e25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df5fffadc61f445f90c3b03e56ebc59d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0fd070fd485d44049069fcd601ba3654",
       "placeholder": "​",
       "style": "IPY_MODEL_81dff1fdc9b0475193c09e967940cc28",
       "tabbable": null,
       "tooltip": null,
       "value": " 8322/10047 [00:01&lt;00:00, 7677.93it/s]"
      }
     },
     "e264d5ff536d466db325c76a3c9bbc5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a78055d7f654ccd9e348b3fc721259e",
       "placeholder": "​",
       "style": "IPY_MODEL_7612c761ed2e43918fbc864179ac35f1",
       "tabbable": null,
       "tooltip": null,
       "value": " 1833/1833 [46:40&lt;00:00,  1.77s/it]"
      }
     },
     "e276c163cf7d4e1592c8855753d3ae40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e08e22a0e4247cab245cf7c55e4cf35",
       "placeholder": "​",
       "style": "IPY_MODEL_6f69c4f828964ae8b01abd96b499b430",
       "tabbable": null,
       "tooltip": null,
       "value": "Filtering:  83%"
      }
     },
     "eb03731182874d63a36c2cfafdab4260": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec99abb0fefd49768921843caa9b0328": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_63d475d22469402ebd5bebada8843426",
        "IPY_MODEL_371faaf8c0184800acc20abb780d7bfc",
        "IPY_MODEL_76e140c2e72d4da09f51fbc4a4fc7798"
       ],
       "layout": "IPY_MODEL_aa57bb069b4f4c9287e1522aa5c6c604",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f0b88ff299f94dd99b89cfa68de2ecff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0f84dee66294dd5ac994fb385b2981a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83e75d8b62364f9f9837103b8ae9b997",
       "placeholder": "​",
       "style": "IPY_MODEL_be99bb9a019c4ced9a55e0323c9bdf1e",
       "tabbable": null,
       "tooltip": null,
       "value": " 291/291 [00:55&lt;00:00,  5.45it/s, Materializing param=model.norm.weight]"
      }
     },
     "f7083e0282984ec4ad5c766ee788d5ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e852da37f9e421ea2c4c65590b931ef",
       "max": 4000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_67c1ba7dc3084897816416b2f403a50b",
       "tabbable": null,
       "tooltip": null,
       "value": 4000
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
