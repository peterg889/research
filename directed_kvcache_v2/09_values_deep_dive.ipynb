{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 09: Values Deep Dive\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Exp 08 showed value vectors carry 100% of the priming effect (d=+0.275) while keys\n",
    "contribute nothing (d=-0.009). This experiment investigates the values-only mechanism\n",
    "across 5 directions:\n",
    "\n",
    "1. **Layer-wise isolation** \u2014 Which layers carry the signal?\n",
    "2. **Prefix type variation** \u2014 Does the prefix content matter in values-only mode?\n",
    "3. **Interpolation** \u2014 How does blending bare/primed values at different ratios affect quality?\n",
    "4. **Cross-document transfer** \u2014 Do primed values generalize across documents?\n",
    "5. **Positional isolation** \u2014 Which token positions carry the signal?\n",
    "\n",
    "## 17 Experimental Conditions\n",
    "\n",
    "| # | Name | Category | Construction |\n",
    "|---|------|----------|-------------|\n",
    "| 1 | `bare` | Baseline | `[BOS][doc]` |\n",
    "| 2 | `full_llm_kw` | Baseline | LLM-kw truncated (keys+values) |\n",
    "| 3 | `values_only_llm_kw` | Baseline | Values from LLM-kw, keys from bare |\n",
    "| 4 | `values_layers_0_7` | Layer-wise | Primed values in layers 0-7 only |\n",
    "| 5 | `values_layers_8_15` | Layer-wise | Primed values in layers 8-15 only |\n",
    "| 6 | `values_layers_16_23` | Layer-wise | Primed values in layers 16-23 only |\n",
    "| 7 | `values_layers_24_31` | Layer-wise | Primed values in layers 24-31 only |\n",
    "| 8 | `values_only_static_fact` | Prefix type | Values from \"What are the key facts?\" prefix |\n",
    "| 9 | `values_only_oracle` | Prefix type | Values from actual query prefix |\n",
    "| 10 | `values_only_random` | Prefix type | Values from random token prefix |\n",
    "| 11 | `values_interp_025` | Interpolation | 25% primed + 75% bare values |\n",
    "| 12 | `values_interp_050` | Interpolation | 50/50 blend |\n",
    "| 13 | `values_interp_075` | Interpolation | 75% primed + 25% bare values |\n",
    "| 14 | `values_cross_doc` | Cross-doc | Primed values from previous sample's document |\n",
    "| 15 | `values_first_quarter` | Positional | Primed values in first 25% of doc positions |\n",
    "| 16 | `values_last_quarter` | Positional | Primed values in last 25% of doc positions |\n",
    "| 17 | `values_middle_half` | Positional | Primed values in middle 50% of doc positions |\n",
    "\n",
    "## 10 Primary Comparisons (Bonferroni alpha = 0.005)\n",
    "\n",
    "| # | Comparison | Question |\n",
    "|---|-----------|----------|\n",
    "| C1 | values_layers_0_7 vs bare | Early layers carry signal? |\n",
    "| C2 | values_layers_8_15 vs bare | Early-mid layers? |\n",
    "| C3 | values_layers_16_23 vs bare | Mid-late layers? |\n",
    "| C4 | values_layers_24_31 vs bare | Late layers? |\n",
    "| C5 | values_only_static_fact vs values_only_llm_kw | Static advantage in values? |\n",
    "| C6 | values_only_random vs bare | Random-primed values help? |\n",
    "| C7 | values_interp_050 vs bare | 50% blend helps? |\n",
    "| C8 | values_cross_doc vs bare | Wrong-doc values help? |\n",
    "| C9 | values_cross_doc vs values_only_llm_kw | Same-doc vs cross-doc? |\n",
    "| C10 | values_first_quarter vs values_last_quarter | Beginning vs end positions? |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 1: Setup \u2014 permissions, seeds, results directory\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp09\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SURROGATES_DIR = RESULTS_DIR / \"surrogates\"\n",
    "SURROGATES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "FINAL_RESULTS_PATH = RESULTS_DIR / \"results.json\"\n",
    "\n",
    "print(f\"SEED: {SEED}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Load model (Mistral-7B 4-bit)\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (4-bit)...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded. dtype={model.dtype}, device={model.device}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: Imports + config + constants\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from lib.config import ExperimentConfig\n",
    "from lib.kv_cache import (\n",
    "    build_hybrid_cache,\n",
    "    replace_values_at_layers,\n",
    "    interpolate_values,\n",
    "    replace_values_at_positions,\n",
    "    build_cross_doc_cache,\n",
    "    deepcopy_cache,\n",
    "    extract_and_truncate_cache_with_bos,\n",
    "    correct_rope_positions_with_bos,\n",
    "    score_answer_with_cache,\n",
    "    _get_cache_keys,\n",
    "    _get_cache_values,\n",
    "    _set_cache_values,\n",
    "    _ensure_dynamic_cache,\n",
    ")\n",
    "from lib.data import load_ms_marco, load_evaluation_samples\n",
    "from lib.analysis import cohens_d\n",
    "from lib.surrogate import generate_all_5_surrogates, STATIC_SURROGATE_QUERIES\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_samples=2000,\n",
    "    min_passage_words=20,\n",
    "    max_passage_words=500,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Templates \u2014 bare text, no \"Document:\\n\" framing\n",
    "SURROGATE_PREFIX_TEMPLATE = \"{surrogate}\\n\"\n",
    "DOCUMENT_TEMPLATE = \"{document}\"\n",
    "QUERY_TEMPLATE = \"\\nQuery: {query}\\nAnswer:\"\n",
    "ANSWER_TEMPLATE = \" {answer}\"\n",
    "\n",
    "N_EVAL = 1000\n",
    "N_COMPARISONS = 10\n",
    "BONFERRONI_ALPHA = 0.05 / N_COMPARISONS\n",
    "CHECKPOINT_EVERY = 50\n",
    "\n",
    "STATIC_FACTUAL_PHRASE = STATIC_SURROGATE_QUERIES['static_factual']['query']\n",
    "\n",
    "LAYER_GROUPS = {\n",
    "    'layers_0_7': list(range(0, 8)),\n",
    "    'layers_8_15': list(range(8, 16)),\n",
    "    'layers_16_23': list(range(16, 24)),\n",
    "    'layers_24_31': list(range(24, 32)),\n",
    "}\n",
    "\n",
    "INTERP_ALPHAS = [0.25, 0.50, 0.75]\n",
    "\n",
    "CONDITION_NAMES = [\n",
    "    'bare', 'full_llm_kw', 'values_only_llm_kw',\n",
    "    'values_layers_0_7', 'values_layers_8_15', 'values_layers_16_23', 'values_layers_24_31',\n",
    "    'values_only_static_fact', 'values_only_oracle', 'values_only_random',\n",
    "    'values_interp_025', 'values_interp_050', 'values_interp_075',\n",
    "    'values_cross_doc',\n",
    "    'values_first_quarter', 'values_last_quarter', 'values_middle_half',\n",
    "]\n",
    "\n",
    "print(\"Config ready\")\n",
    "print(f\"  num_samples pool: {config.num_samples}\")\n",
    "print(f\"  eval samples: {N_EVAL}\")\n",
    "print(f\"  bonferroni_alpha: {BONFERRONI_ALPHA:.4f} ({N_COMPARISONS} comparisons)\")\n",
    "print(f\"  conditions: {len(CONDITION_NAMES)}\")\n",
    "print(f\"  static_factual_phrase: '{STATIC_FACTUAL_PHRASE}'\")\n",
    "print(f\"  layer_groups: {list(LAYER_GROUPS.keys())}\")\n",
    "print(f\"  interp_alphas: {INTERP_ALPHAS}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 4: Load MS MARCO (1000 samples)\n",
    "dataset = load_ms_marco(config)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "all_samples = load_evaluation_samples(dataset, config, require_answer=True)\n",
    "\n",
    "samples = all_samples[:N_EVAL]\n",
    "N = len(samples)\n",
    "print(f\"Loaded {len(all_samples)} candidates, using first {N} for evaluation\")\n",
    "print(f\"Example passage ({len(samples[0]['passage'].split())} words): {samples[0]['passage'][:100]}...\")\n",
    "print(f\"Example query: {samples[0]['query']}\")\n",
    "print(f\"Example answer: {samples[0]['answer']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Generate LLM keyword surrogates (fresh, independent from Exp 08)\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1: LLM SURROGATE GENERATION (keyword only)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "surrogates_path = SURROGATES_DIR / \"keyword_surrogates.json\"\n",
    "\n",
    "if surrogates_path.exists():\n",
    "    with open(surrogates_path, 'r') as f:\n",
    "        surrogates_data = json.load(f)\n",
    "    keyword_surrogates = surrogates_data['surrogates']\n",
    "    print(f\"Loaded {len(keyword_surrogates)} keyword surrogates from cache\")\n",
    "else:\n",
    "    keyword_surrogates = []\n",
    "\n",
    "start_idx_gen = len(keyword_surrogates)\n",
    "if start_idx_gen < N:\n",
    "    print(f\"Generating keyword surrogates for samples {start_idx_gen} to {N-1}...\")\n",
    "    t_start = time.time()\n",
    "    for idx in tqdm(range(start_idx_gen, N), initial=start_idx_gen, total=N,\n",
    "                     desc=\"Keyword surrogates\"):\n",
    "        passage = samples[idx]['passage']\n",
    "        try:\n",
    "            s5 = generate_all_5_surrogates(passage, model, tokenizer, config)\n",
    "            kw = s5.get('keyword_query', '')\n",
    "        except Exception as e:\n",
    "            print(f\"  WARNING: Generation failed for sample {idx}: {e}\")\n",
    "            kw = \"\"\n",
    "        keyword_surrogates.append(kw)\n",
    "\n",
    "        if (idx + 1) % 100 == 0 or idx == N - 1:\n",
    "            with open(surrogates_path, 'w') as f:\n",
    "                json.dump({'surrogates': keyword_surrogates}, f)\n",
    "            elapsed = time.time() - t_start\n",
    "            rate = (idx - start_idx_gen + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (N - idx - 1) / rate if rate > 0 else 0\n",
    "            tqdm.write(f\"  Saved {idx+1}/{N} | {rate:.2f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "    with open(surrogates_path, 'w') as f:\n",
    "        json.dump({'surrogates': keyword_surrogates}, f)\n",
    "    print(f\"Keyword surrogates complete: {len(keyword_surrogates)} samples\")\n",
    "else:\n",
    "    print(f\"All keyword surrogates already cached ({len(keyword_surrogates)} samples)\")\n",
    "\n",
    "n_empty = sum(1 for s in keyword_surrogates if not s.strip())\n",
    "print(f\"Empty surrogates: {n_empty}/{N}\")\n",
    "print(f\"Example: '{keyword_surrogates[0]}'\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: Condition explanation with concrete examples\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPERIMENTAL CONDITIONS EXPLAINED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ex_kw = keyword_surrogates[0]\n",
    "ex_query = samples[0]['query']\n",
    "\n",
    "conditions_explained = [\n",
    "    (\"1. bare\",\n",
    "     \"[BOS][doc]\",\n",
    "     \"No prefix \u2014 baseline\"),\n",
    "    (\"2. full_llm_kw\",\n",
    "     \"[BOS][llm_kw\\\\n][doc] \u2192 truncate + RoPE\",\n",
    "     f\"Standard truncated prefix (keys+values): '{ex_kw}'\"),\n",
    "    (\"3. values_only_llm_kw\",\n",
    "     \"Keys from bare, values from full_llm_kw cache\",\n",
    "     \"Values-only baseline (replicates Exp 08 finding)\"),\n",
    "    (\"4-7. values_layers_X_Y\",\n",
    "     \"Keys from bare, values from primed cache at specified layers only\",\n",
    "     \"Layer-wise isolation: which layer groups carry the signal?\"),\n",
    "    (\"8. values_only_static_fact\",\n",
    "     f\"Prefix: '{STATIC_FACTUAL_PHRASE}' \u2192 truncate \u2192 values-only\",\n",
    "     \"Static factual prefix \u2014 same for every document\"),\n",
    "    (\"9. values_only_oracle\",\n",
    "     f\"Prefix: '{ex_query}' \u2192 truncate \u2192 values-only\",\n",
    "     \"Oracle (actual query) prefix \u2014 best possible semantic prefix\"),\n",
    "    (\"10. values_only_random\",\n",
    "     \"Prefix: random tokens \u2192 truncate \u2192 values-only\",\n",
    "     \"Random token prefix \u2014 structural control for values\"),\n",
    "    (\"11-13. values_interp_XXX\",\n",
    "     \"v = alpha * v_primed + (1-alpha) * v_bare\",\n",
    "     \"Value interpolation at alpha = 0.25, 0.50, 0.75\"),\n",
    "    (\"14. values_cross_doc\",\n",
    "     \"Values from PREVIOUS sample's primed cache\",\n",
    "     \"Cross-document transfer \u2014 wrong-doc values\"),\n",
    "    (\"15-17. values_first/last/middle\",\n",
    "     \"Primed values at specific token positions only\",\n",
    "     \"Positional isolation: first 25%, last 25%, middle 50%\"),\n",
    "]\n",
    "\n",
    "for name, pattern, detail in conditions_explained:\n",
    "    print(f\"\\n### {name} ###\")\n",
    "    print(f\"  Cache: {pattern}\")\n",
    "    print(f\"  Detail: {detail}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"5 FORWARD PASSES PER SAMPLE:\")\n",
    "print(\"  1. Bare: [BOS][doc] \u2192 bare_cache\")\n",
    "print(\"  2. LLM-kw: [BOS][kw\\\\n][doc] \u2192 truncate+RoPE \u2192 primed_llm_cache\")\n",
    "print(\"  3. Static fact: [BOS][static_fact\\\\n][doc] \u2192 truncate+RoPE\")\n",
    "print(\"  4. Oracle: [BOS][query\\\\n][doc] \u2192 truncate+RoPE\")\n",
    "print(\"  5. Random: [BOS][random_tokens\\\\n][doc] \u2192 truncate+RoPE\")\n",
    "print(\"  Cross-doc reuses previous sample's primed_llm_cache \u2014 no extra pass\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Convenience wrapper for building primed+truncated caches\n",
    "\n",
    "def build_primed_and_truncated(prefix_text, bos_id, doc_ids, doc_len, model, tokenizer, config):\n",
    "    \"\"\"Build a primed cache: tokenize prefix, concat [BOS][prefix][doc], forward, truncate+RoPE.\n",
    "\n",
    "    Args:\n",
    "        prefix_text: Raw prefix text (will be formatted with SURROGATE_PREFIX_TEMPLATE)\n",
    "        bos_id: BOS token id tensor (1, 1)\n",
    "        doc_ids: Document token ids (1, doc_len)\n",
    "        doc_len: Number of document tokens\n",
    "        model: The language model\n",
    "        tokenizer: The tokenizer\n",
    "        config: ExperimentConfig\n",
    "\n",
    "    Returns:\n",
    "        (trunc_cache, prefix_token_len) where prefix_token_len includes BOS\n",
    "    \"\"\"\n",
    "    prefix_str = SURROGATE_PREFIX_TEMPLATE.format(surrogate=prefix_text)\n",
    "    prefix_enc = tokenizer(prefix_str, return_tensors=\"pt\",\n",
    "                           add_special_tokens=False, padding=False, truncation=False)\n",
    "    prefix_ids = prefix_enc['input_ids'].to(config.device)\n",
    "    prefix_token_len = 1 + prefix_ids.shape[1]  # BOS + prefix tokens\n",
    "\n",
    "    full_ids = torch.cat([bos_id, prefix_ids, doc_ids], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=full_ids,\n",
    "                    attention_mask=torch.ones_like(full_ids),\n",
    "                    use_cache=True, return_dict=True)\n",
    "\n",
    "    trunc_cache = extract_and_truncate_cache_with_bos(out.past_key_values, doc_len)\n",
    "    correct_rope_positions_with_bos(trunc_cache, prefix_token_len - 1, model)\n",
    "\n",
    "    del out\n",
    "    return trunc_cache, prefix_token_len\n",
    "\n",
    "print(\"Helper defined: build_primed_and_truncated()\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 8: Main eval loop \u2014 17 conditions \u00d7 1000 samples\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 2: MAIN EVALUATION (17 conditions \u00d7 1000 samples)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "prev_primed_cache = None\n",
    "prev_doc_len = None\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    with open(CHECKPOINT_PATH, 'r') as f:\n",
    "        ckpt = json.load(f)\n",
    "    ckpt_queries = ckpt.get('sample_queries', [])\n",
    "    current_queries = [s['query'] for s in samples]\n",
    "    if ckpt_queries == current_queries:\n",
    "        results = ckpt['results']\n",
    "        start_idx = len(results)\n",
    "        print(f\"Resuming from checkpoint: {start_idx}/{N}\")\n",
    "\n",
    "        # Rebuild prev_primed_cache from sample start_idx - 1\n",
    "        if start_idx > 0:\n",
    "            print(f\"Rebuilding prev_primed_cache from sample {start_idx - 1}...\")\n",
    "            prev_sample = samples[start_idx - 1]\n",
    "            prev_passage = prev_sample['passage']\n",
    "            prev_query = prev_sample['query']\n",
    "            prev_kw = keyword_surrogates[start_idx - 1]\n",
    "\n",
    "            oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=prev_query)\n",
    "            document_text = DOCUMENT_TEMPLATE.format(document=prev_passage)\n",
    "            full_text = oracle_prefix + document_text\n",
    "\n",
    "            full_enc = tokenizer(full_text, return_tensors=\"pt\",\n",
    "                                 add_special_tokens=True, padding=False, truncation=False)\n",
    "            full_ids_prev = full_enc['input_ids'].to(config.device)\n",
    "\n",
    "            oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                          add_special_tokens=True, padding=False, truncation=False)\n",
    "            prev_prefix_len = oracle_prefix_enc['input_ids'].shape[1]\n",
    "\n",
    "            prev_bos_id = full_ids_prev[:, :1]\n",
    "            prev_doc_ids = full_ids_prev[:, prev_prefix_len:]\n",
    "            prev_doc_len_rebuild = prev_doc_ids.shape[1]\n",
    "\n",
    "            prev_primed_cache, _ = build_primed_and_truncated(\n",
    "                prev_kw, prev_bos_id, prev_doc_ids, prev_doc_len_rebuild,\n",
    "                model, tokenizer, config)\n",
    "            prev_doc_len = prev_doc_len_rebuild\n",
    "            print(f\"Rebuilt prev_primed_cache (doc_len={prev_doc_len})\")\n",
    "            del full_ids_prev\n",
    "    else:\n",
    "        print(\"Checkpoint sample mismatch. Starting fresh.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh.\")\n",
    "\n",
    "print(f\"Evaluating samples {start_idx} to {N-1}\")\n",
    "print(f\"Conditions: {len(CONDITION_NAMES)}\")\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for idx in tqdm(range(start_idx, N), initial=start_idx, total=N, desc=\"Evaluating\"):\n",
    "    sample = samples[idx]\n",
    "    passage = sample['passage']\n",
    "    query = sample['query']\n",
    "    answer = sample['answer']\n",
    "\n",
    "    query_prompt = QUERY_TEMPLATE.format(query=query)\n",
    "    answer_text = ANSWER_TEMPLATE.format(answer=answer)\n",
    "    llm_kw_text = keyword_surrogates[idx]\n",
    "\n",
    "    # --- Matched tokenization ---\n",
    "    oracle_prefix = SURROGATE_PREFIX_TEMPLATE.format(surrogate=query)\n",
    "    document_text = DOCUMENT_TEMPLATE.format(document=passage)\n",
    "    full_oracle_text = oracle_prefix + document_text\n",
    "\n",
    "    full_oracle_enc = tokenizer(full_oracle_text, return_tensors=\"pt\",\n",
    "                                add_special_tokens=True, padding=False, truncation=False)\n",
    "    full_oracle_ids = full_oracle_enc['input_ids'].to(config.device)\n",
    "\n",
    "    oracle_prefix_enc = tokenizer(oracle_prefix, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, padding=False, truncation=False)\n",
    "    oracle_prefix_len = oracle_prefix_enc['input_ids'].shape[1]\n",
    "\n",
    "    bos_id = full_oracle_ids[:, :1]\n",
    "    doc_ids = full_oracle_ids[:, oracle_prefix_len:]\n",
    "    doc_len = doc_ids.shape[1]\n",
    "\n",
    "    # === Forward pass 1: BARE ===\n",
    "    bare_ids = torch.cat([bos_id, doc_ids], dim=1)\n",
    "    with torch.no_grad():\n",
    "        bare_out = model(input_ids=bare_ids, attention_mask=torch.ones_like(bare_ids),\n",
    "                         use_cache=True, return_dict=True)\n",
    "    bare_cache = bare_out.past_key_values\n",
    "    del bare_out\n",
    "\n",
    "    nll_bare = score_answer_with_cache(\n",
    "        deepcopy_cache(bare_cache), bare_ids.shape[1],\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Forward pass 2: LLM-KW (primed) ===\n",
    "    primed_llm_cache, llm_prefix_token_len = build_primed_and_truncated(\n",
    "        llm_kw_text, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "\n",
    "    nll_full_llm_kw = score_answer_with_cache(\n",
    "        deepcopy_cache(primed_llm_cache), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "\n",
    "    # === Condition 3: VALUES-ONLY LLM-KW ===\n",
    "    hybrid_vals = build_hybrid_cache(bare_cache, primed_llm_cache)\n",
    "    nll_values_only_llm_kw = score_answer_with_cache(\n",
    "        deepcopy_cache(hybrid_vals), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del hybrid_vals\n",
    "\n",
    "    # === Conditions 4-7: LAYER-WISE ===\n",
    "    nll_layers = {}\n",
    "    for group_name, layer_indices in LAYER_GROUPS.items():\n",
    "        layer_cache = replace_values_at_layers(bare_cache, primed_llm_cache, layer_indices)\n",
    "        nll_layers[f'values_{group_name}'] = score_answer_with_cache(\n",
    "            deepcopy_cache(layer_cache), 1 + doc_len,\n",
    "            query_prompt, answer_text, model, tokenizer, config)\n",
    "        del layer_cache\n",
    "\n",
    "    # === Conditions 11-13: INTERPOLATION ===\n",
    "    nll_interp = {}\n",
    "    for alpha in INTERP_ALPHAS:\n",
    "        interp_cache = interpolate_values(bare_cache, primed_llm_cache, alpha)\n",
    "        key_name = f'values_interp_{int(alpha*100):03d}'\n",
    "        nll_interp[key_name] = score_answer_with_cache(\n",
    "            deepcopy_cache(interp_cache), 1 + doc_len,\n",
    "            query_prompt, answer_text, model, tokenizer, config)\n",
    "        del interp_cache\n",
    "\n",
    "    # === Conditions 15-17: POSITIONAL ===\n",
    "    # Positions are within the cache: BOS=0, doc starts at 1\n",
    "    first_q_end = 1 + max(1, doc_len // 4)\n",
    "    last_q_start = 1 + doc_len - max(1, doc_len // 4)\n",
    "    mid_start = 1 + max(1, doc_len // 4)\n",
    "    mid_end = 1 + doc_len - max(1, doc_len // 4)\n",
    "\n",
    "    pos_first = replace_values_at_positions(bare_cache, primed_llm_cache, 1, first_q_end)\n",
    "    nll_first_quarter = score_answer_with_cache(\n",
    "        deepcopy_cache(pos_first), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del pos_first\n",
    "\n",
    "    pos_last = replace_values_at_positions(bare_cache, primed_llm_cache, last_q_start, 1 + doc_len)\n",
    "    nll_last_quarter = score_answer_with_cache(\n",
    "        deepcopy_cache(pos_last), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del pos_last\n",
    "\n",
    "    pos_mid = replace_values_at_positions(bare_cache, primed_llm_cache, mid_start, mid_end)\n",
    "    nll_middle_half = score_answer_with_cache(\n",
    "        deepcopy_cache(pos_mid), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del pos_mid\n",
    "\n",
    "    # === Condition 14: CROSS-DOC ===\n",
    "    if prev_primed_cache is not None and prev_doc_len is not None:\n",
    "        cross_cache = build_cross_doc_cache(bare_cache, prev_primed_cache, doc_len)\n",
    "        nll_cross_doc = score_answer_with_cache(\n",
    "            deepcopy_cache(cross_cache), 1 + doc_len,\n",
    "            query_prompt, answer_text, model, tokenizer, config)\n",
    "        del cross_cache\n",
    "    else:\n",
    "        nll_cross_doc = 0.0  # First sample \u2014 no previous cache\n",
    "\n",
    "    # Save prev_primed_cache for next sample\n",
    "    prev_primed_cache = deepcopy_cache(primed_llm_cache)\n",
    "    prev_doc_len = doc_len\n",
    "\n",
    "    # === Forward pass 3: STATIC FACT ===\n",
    "    static_cache, _ = build_primed_and_truncated(\n",
    "        STATIC_FACTUAL_PHRASE, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    hybrid_static = build_hybrid_cache(bare_cache, static_cache)\n",
    "    nll_static_fact = score_answer_with_cache(\n",
    "        deepcopy_cache(hybrid_static), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del static_cache, hybrid_static\n",
    "\n",
    "    # === Forward pass 4: ORACLE ===\n",
    "    oracle_cache, _ = build_primed_and_truncated(\n",
    "        query, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    hybrid_oracle = build_hybrid_cache(bare_cache, oracle_cache)\n",
    "    nll_oracle = score_answer_with_cache(\n",
    "        deepcopy_cache(hybrid_oracle), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del oracle_cache, hybrid_oracle\n",
    "\n",
    "    # === Forward pass 5: RANDOM ===\n",
    "    # Generate random token prefix of similar length to keyword surrogate\n",
    "    n_random_tokens = max(5, len(tokenizer.encode(llm_kw_text, add_special_tokens=False)))\n",
    "    random_ids = torch.randint(100, tokenizer.vocab_size - 100,\n",
    "                               (n_random_tokens,), device='cpu')\n",
    "    random_text = tokenizer.decode(random_ids, skip_special_tokens=True)\n",
    "    random_cache, _ = build_primed_and_truncated(\n",
    "        random_text, bos_id, doc_ids, doc_len, model, tokenizer, config)\n",
    "    hybrid_random = build_hybrid_cache(bare_cache, random_cache)\n",
    "    nll_random = score_answer_with_cache(\n",
    "        deepcopy_cache(hybrid_random), 1 + doc_len,\n",
    "        query_prompt, answer_text, model, tokenizer, config)\n",
    "    del random_cache, hybrid_random\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    del bare_cache, primed_llm_cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Store result ---\n",
    "    result = {\n",
    "        'idx': idx,\n",
    "        'doc_len': doc_len,\n",
    "        'prev_doc_len': int(prev_doc_len) if prev_doc_len is not None else None,\n",
    "        'passage_word_count': len(passage.split()),\n",
    "        'bare': nll_bare,\n",
    "        'full_llm_kw': nll_full_llm_kw,\n",
    "        'values_only_llm_kw': nll_values_only_llm_kw,\n",
    "        **nll_layers,\n",
    "        'values_only_static_fact': nll_static_fact,\n",
    "        'values_only_oracle': nll_oracle,\n",
    "        'values_only_random': nll_random,\n",
    "        **nll_interp,\n",
    "        'values_cross_doc': nll_cross_doc,\n",
    "        'values_first_quarter': nll_first_quarter,\n",
    "        'values_last_quarter': nll_last_quarter,\n",
    "        'values_middle_half': nll_middle_half,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    if (idx + 1) % CHECKPOINT_EVERY == 0 or idx == N - 1:\n",
    "        ckpt_data = {\n",
    "            'results': results,\n",
    "            'sample_queries': [s['query'] for s in samples],\n",
    "            'completed': len(results),\n",
    "            'total': N,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, 'w') as f:\n",
    "            json.dump(ckpt_data, f)\n",
    "        elapsed = time.time() - t_start\n",
    "        rate = (idx - start_idx + 1) / elapsed if elapsed > 0 else 0\n",
    "        remaining = (N - idx - 1) / rate if rate > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {idx+1}/{N} | {rate:.2f} s/s | ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "elapsed_total = time.time() - t_start\n",
    "print(f\"\\nEvaluation complete: {len(results)} samples in {elapsed_total/60:.1f} min\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Primary analysis \u2014 NLL summary + 10 comparisons + all vs bare\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS \u2014 VALUES DEEP DIVE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract arrays and filter zero NLLs (cross-doc sample 0)\n",
    "cond_arrays = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    cond_arrays[cname] = np.array([r[cname] for r in results])\n",
    "\n",
    "valid = np.ones(len(results), dtype=bool)\n",
    "for cname in CONDITION_NAMES:\n",
    "    valid &= (cond_arrays[cname] != 0)\n",
    "n_valid = int(np.sum(valid))\n",
    "n_excluded = int(np.sum(~valid))\n",
    "print(f\"Total: {len(results)}, Valid: {n_valid}, Excluded (cross-doc sample 0): {n_excluded}\")\n",
    "\n",
    "c = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    c[cname] = cond_arrays[cname][valid]\n",
    "\n",
    "# NLL summary table\n",
    "print(f\"\\n{'Condition':<30} {'Mean NLL':>10} {'Std':>10} {'d vs Bare':>10}\")\n",
    "print(\"-\" * 65)\n",
    "for cname in CONDITION_NAMES:\n",
    "    mean_nll = np.mean(c[cname])\n",
    "    std_nll = np.std(c[cname])\n",
    "    if cname == 'bare':\n",
    "        d_str = \"\u2014\"\n",
    "    else:\n",
    "        d = cohens_d(c['bare'] - c[cname])\n",
    "        d_str = f\"{d:+.3f}\"\n",
    "    print(f\"{cname:<30} {mean_nll:>10.4f} {std_nll:>10.4f} {d_str:>10}\")\n",
    "\n",
    "# 10 primary comparisons\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"10 PRIMARY COMPARISONS (Bonferroni alpha = {BONFERRONI_ALPHA:.4f})\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "comparisons = [\n",
    "    ('C1: layers_0_7 vs bare',\n",
    "     c['bare'] - c['values_layers_0_7'],\n",
    "     'Early layers carry signal?'),\n",
    "    ('C2: layers_8_15 vs bare',\n",
    "     c['bare'] - c['values_layers_8_15'],\n",
    "     'Early-mid layers?'),\n",
    "    ('C3: layers_16_23 vs bare',\n",
    "     c['bare'] - c['values_layers_16_23'],\n",
    "     'Mid-late layers?'),\n",
    "    ('C4: layers_24_31 vs bare',\n",
    "     c['bare'] - c['values_layers_24_31'],\n",
    "     'Late layers?'),\n",
    "    ('C5: static_fact vs llm_kw',\n",
    "     c['values_only_llm_kw'] - c['values_only_static_fact'],\n",
    "     'Static advantage in values?'),\n",
    "    ('C6: random vs bare',\n",
    "     c['bare'] - c['values_only_random'],\n",
    "     'Random-primed values help?'),\n",
    "    ('C7: interp_050 vs bare',\n",
    "     c['bare'] - c['values_interp_050'],\n",
    "     '50% blend helps?'),\n",
    "    ('C8: cross_doc vs bare',\n",
    "     c['bare'] - c['values_cross_doc'],\n",
    "     'Wrong-doc values help?'),\n",
    "    ('C9: cross_doc vs llm_kw',\n",
    "     c['values_only_llm_kw'] - c['values_cross_doc'],\n",
    "     'Same-doc vs cross-doc?'),\n",
    "    ('C10: first_q vs last_q',\n",
    "     c['values_last_quarter'] - c['values_first_quarter'],\n",
    "     'Beginning vs end positions?'),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Comparison':<35} {'Mean \u0394':>8} {'d':>8} {'Win%':>7} {'t':>8} {'p':>12} {'Sig':>5}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "comparison_results = {}\n",
    "for name, delta, question in comparisons:\n",
    "    d = cohens_d(delta)\n",
    "    win = np.mean(delta > 0) * 100\n",
    "    t_stat, p_val = stats.ttest_1samp(delta, 0)\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"{name:<35} {np.mean(delta):>8.4f} {d:>8.3f} {win:>6.1f}% {t_stat:>8.2f} {p_val:>11.2e} {sig:>5}\")\n",
    "    comparison_results[name] = {\n",
    "        'mean_delta': float(np.mean(delta)),\n",
    "        'cohens_d': float(d),\n",
    "        'win_rate': float(win / 100),\n",
    "        't_stat': float(t_stat),\n",
    "        'p_value': float(p_val),\n",
    "        'bonferroni_significant': bool(p_val < BONFERRONI_ALPHA),\n",
    "        'question': question,\n",
    "    }\n",
    "\n",
    "# All vs Bare\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"ALL CONDITIONS vs BARE\")\n",
    "print(f\"{'='*90}\")\n",
    "print(f\"\\n{'Condition':<30} {'d vs Bare':>10} {'Win%':>7} {'p':>12}\")\n",
    "print(\"-\" * 65)\n",
    "all_vs_bare = {}\n",
    "for cname in CONDITION_NAMES:\n",
    "    if cname == 'bare':\n",
    "        continue\n",
    "    delta = c['bare'] - c[cname]\n",
    "    d = cohens_d(delta)\n",
    "    win = np.mean(delta > 0) * 100\n",
    "    _, p_val = stats.ttest_1samp(delta, 0)\n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < BONFERRONI_ALPHA else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"{cname:<30} {d:>10.3f} {win:>6.1f}% {p_val:>11.2e} {sig:>5}\")\n",
    "    all_vs_bare[cname] = {'cohens_d': float(d), 'win_rate': float(win/100), 'p_value': float(p_val)}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Direction-specific deep-dive\n",
    "\n",
    "# --- LAYERS ---\n",
    "print(\"=\" * 70)\n",
    "print(\"DIRECTION 1: LAYER-WISE DECOMPOSITION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "layer_ds = {}\n",
    "for group_name in LAYER_GROUPS:\n",
    "    cname = f'values_{group_name}'\n",
    "    d = cohens_d(c['bare'] - c[cname])\n",
    "    layer_ds[group_name] = d\n",
    "    print(f\"  {group_name}: d = {d:+.3f}\")\n",
    "\n",
    "d_all_values = cohens_d(c['bare'] - c['values_only_llm_kw'])\n",
    "d_sum = sum(layer_ds.values())\n",
    "print(f\"\\n  Sum of 4 groups: d = {d_sum:+.3f}\")\n",
    "print(f\"  All layers (values_only_llm_kw): d = {d_all_values:+.3f}\")\n",
    "print(f\"  Additivity ratio: {d_sum/d_all_values:.2f}\" if d_all_values != 0 else \"  All-layers d = 0\")\n",
    "\n",
    "ranked = sorted(layer_ds.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"  Ranked: {' > '.join(f'{n}({d:+.3f})' for n, d in ranked)}\")\n",
    "\n",
    "# --- PREFIX TYPES ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DIRECTION 2: PREFIX TYPE COMPARISON (VALUES-ONLY MODE)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "prefix_conds = {\n",
    "    'values_only_llm_kw': 'LLM keyword',\n",
    "    'values_only_static_fact': 'Static factual',\n",
    "    'values_only_oracle': 'Oracle (actual query)',\n",
    "    'values_only_random': 'Random tokens',\n",
    "}\n",
    "for cname, label in prefix_conds.items():\n",
    "    d = cohens_d(c['bare'] - c[cname])\n",
    "    print(f\"  {label:<25} d = {d:+.3f}\")\n",
    "\n",
    "# --- INTERPOLATION ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DIRECTION 3: INTERPOLATION CURVE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "alphas = [0.0] + INTERP_ALPHAS + [1.0]\n",
    "interp_ds = []\n",
    "for alpha in alphas:\n",
    "    if alpha == 0.0:\n",
    "        d = 0.0  # bare vs bare\n",
    "    elif alpha == 1.0:\n",
    "        d = cohens_d(c['bare'] - c['values_only_llm_kw'])\n",
    "    else:\n",
    "        cname = f'values_interp_{int(alpha*100):03d}'\n",
    "        d = cohens_d(c['bare'] - c[cname])\n",
    "    interp_ds.append(d)\n",
    "    print(f\"  alpha={alpha:.2f}: d = {d:+.3f}\")\n",
    "\n",
    "# Fit linear to 0.25, 0.50, 0.75\n",
    "from numpy.polynomial import polynomial as P\n",
    "xs = np.array(INTERP_ALPHAS)\n",
    "ys = np.array([interp_ds[1], interp_ds[2], interp_ds[3]])\n",
    "slope, intercept = np.polyfit(xs, ys, 1)\n",
    "y_pred_lin = slope * xs + intercept\n",
    "ss_res = np.sum((ys - y_pred_lin) ** 2)\n",
    "ss_tot = np.sum((ys - np.mean(ys)) ** 2)\n",
    "r2_lin = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "print(f\"\\n  Linear fit: d = {slope:.3f} * alpha + {intercept:.3f}, R\u00b2 = {r2_lin:.4f}\")\n",
    "\n",
    "# --- CROSS-DOC ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DIRECTION 4: CROSS-DOCUMENT TRANSFER\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "d_cross = cohens_d(c['bare'] - c['values_cross_doc'])\n",
    "d_same = cohens_d(c['bare'] - c['values_only_llm_kw'])\n",
    "print(f\"  Cross-doc vs bare: d = {d_cross:+.3f}\")\n",
    "print(f\"  Same-doc vs bare:  d = {d_same:+.3f}\")\n",
    "print(f\"  Cross-doc retains {d_cross/d_same*100:.0f}% of same-doc effect\" if d_same != 0 else \"\")\n",
    "\n",
    "# Length-match robustness: filter pairs where doc lengths are within 20%\n",
    "doc_lens = np.array([r['doc_len'] for r in results])[valid]\n",
    "prev_doc_lens = np.array([r.get('prev_doc_len', 0) or 0 for r in results])[valid]\n",
    "length_ratio = np.where(prev_doc_lens > 0, doc_lens / prev_doc_lens, 0)\n",
    "length_matched = (length_ratio > 0.8) & (length_ratio < 1.2)\n",
    "n_matched = int(np.sum(length_matched))\n",
    "if n_matched > 30:\n",
    "    d_cross_matched = cohens_d(c['bare'][length_matched] - c['values_cross_doc'][length_matched])\n",
    "    print(f\"  Length-matched pairs ({n_matched}): d = {d_cross_matched:+.3f}\")\n",
    "\n",
    "# --- POSITIONAL ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DIRECTION 5: POSITIONAL ISOLATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "pos_conds = {\n",
    "    'values_first_quarter': ('First 25%', 0.25),\n",
    "    'values_middle_half': ('Middle 50%', 0.50),\n",
    "    'values_last_quarter': ('Last 25%', 0.25),\n",
    "}\n",
    "for cname, (label, frac) in pos_conds.items():\n",
    "    d = cohens_d(c['bare'] - c[cname])\n",
    "    d_per_frac = d / frac if frac > 0 else 0\n",
    "    print(f\"  {label:<15} d = {d:+.3f} (d per fraction = {d_per_frac:+.3f})\")\n",
    "\n",
    "d_all = cohens_d(c['bare'] - c['values_only_llm_kw'])\n",
    "print(f\"  All positions: d = {d_all:+.3f}\")\n",
    "\n",
    "# --- HARDNESS QUINTILE BREAKDOWN ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"HARDNESS QUINTILE BREAKDOWN (key conditions)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "bare_valid = c['bare']\n",
    "quintile_boundaries = np.percentile(bare_valid, [20, 40, 60, 80])\n",
    "quintile_labels = ['Q1 (easy)', 'Q2', 'Q3', 'Q4', 'Q5 (hard)']\n",
    "\n",
    "def get_quintile(nll, boundaries):\n",
    "    for i, b in enumerate(boundaries):\n",
    "        if nll <= b:\n",
    "            return i\n",
    "    return len(boundaries)\n",
    "\n",
    "quintiles = np.array([get_quintile(nll, quintile_boundaries) for nll in bare_valid])\n",
    "\n",
    "key_conds = ['values_only_llm_kw', 'values_layers_0_7', 'values_layers_24_31',\n",
    "             'values_only_oracle', 'values_only_random', 'values_interp_050',\n",
    "             'values_cross_doc', 'values_first_quarter', 'values_last_quarter']\n",
    "\n",
    "header = f\"{'Condition':<30}\" + \"\".join(f\"{ql:>14}\" for ql in quintile_labels) + f\"{'Overall':>14}\"\n",
    "print(f\"\\n{header}\")\n",
    "print(\"-\" * (30 + 14 * 6))\n",
    "\n",
    "hardness_breakdown = {}\n",
    "for cname in key_conds:\n",
    "    row = f\"{cname:<30}\"\n",
    "    quintile_ds = []\n",
    "    for q in range(5):\n",
    "        mask_q = quintiles == q\n",
    "        if np.sum(mask_q) < 10:\n",
    "            row += f\"{'n/a':>14}\"\n",
    "            quintile_ds.append(None)\n",
    "        else:\n",
    "            delta = bare_valid[mask_q] - c[cname][mask_q]\n",
    "            d = cohens_d(delta)\n",
    "            row += f\"{d:>+14.3f}\"\n",
    "            quintile_ds.append(float(d))\n",
    "    d_all = cohens_d(bare_valid - c[cname])\n",
    "    row += f\"{d_all:>+14.3f}\"\n",
    "    print(row)\n",
    "    hardness_breakdown[cname] = {'quintile_ds': quintile_ds, 'overall_d': float(d_all)}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 11: Plots (2x3 grid)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Color-coding by direction\n",
    "direction_colors = {\n",
    "    'full_llm_kw': 'forestgreen', 'values_only_llm_kw': 'forestgreen',\n",
    "    'values_layers_0_7': '#1f77b4', 'values_layers_8_15': '#2ca02c',\n",
    "    'values_layers_16_23': '#ff7f0e', 'values_layers_24_31': '#d62728',\n",
    "    'values_only_static_fact': 'goldenrod', 'values_only_oracle': 'gold',\n",
    "    'values_only_random': 'khaki',\n",
    "    'values_interp_025': 'mediumpurple', 'values_interp_050': 'darkorchid',\n",
    "    'values_interp_075': 'purple',\n",
    "    'values_cross_doc': 'coral',\n",
    "    'values_first_quarter': 'lightblue', 'values_last_quarter': 'steelblue',\n",
    "    'values_middle_half': 'cornflowerblue',\n",
    "}\n",
    "\n",
    "# --- Plot 1: All conditions bar chart ---\n",
    "ax = axes[0, 0]\n",
    "cnames_sorted = sorted(\n",
    "    [cn for cn in CONDITION_NAMES if cn != 'bare'],\n",
    "    key=lambda cn: cohens_d(c['bare'] - c[cn]),\n",
    "    reverse=True\n",
    ")\n",
    "ds_bar = [cohens_d(c['bare'] - c[cn]) for cn in cnames_sorted]\n",
    "colors_bar = [direction_colors.get(cn, 'lightgray') for cn in cnames_sorted]\n",
    "ax.barh(range(len(cnames_sorted)), ds_bar, color=colors_bar, edgecolor='black', linewidth=0.5)\n",
    "ax.set_yticks(range(len(cnames_sorted)))\n",
    "ax.set_yticklabels(cnames_sorted, fontsize=7)\n",
    "ax.axvline(x=0, color='gray', linestyle='--')\n",
    "ax.set_xlabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title('All Conditions vs Bare')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# --- Plot 2: Layer-wise decomposition ---\n",
    "ax = axes[0, 1]\n",
    "layer_names = list(LAYER_GROUPS.keys())\n",
    "layer_d_vals = [cohens_d(c['bare'] - c[f'values_{gn}']) for gn in layer_names]\n",
    "layer_colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']\n",
    "bars = ax.bar(range(len(layer_names)), layer_d_vals, color=layer_colors,\n",
    "              edgecolor='black', linewidth=0.5)\n",
    "# Add all-layers reference\n",
    "ax.axhline(y=d_all_values, color='forestgreen', linestyle='--', label=f'All layers (d={d_all_values:+.3f})')\n",
    "ax.set_xticks(range(len(layer_names)))\n",
    "ax.set_xticklabels([n.replace('layers_', 'L') for n in layer_names], fontsize=9)\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.set_ylabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title('Layer-wise Decomposition')\n",
    "ax.legend(fontsize=8)\n",
    "for i, v in enumerate(layer_d_vals):\n",
    "    ax.text(i, v + 0.005, f\"{v:+.3f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# --- Plot 3: Prefix type comparison ---\n",
    "ax = axes[0, 2]\n",
    "prefix_names = list(prefix_conds.keys())\n",
    "prefix_labels = list(prefix_conds.values())\n",
    "prefix_ds = [cohens_d(c['bare'] - c[cn]) for cn in prefix_names]\n",
    "prefix_bar_colors = ['forestgreen', 'goldenrod', 'gold', 'khaki']\n",
    "bars = ax.bar(range(len(prefix_names)), prefix_ds, color=prefix_bar_colors,\n",
    "              edgecolor='black', linewidth=0.5)\n",
    "ax.set_xticks(range(len(prefix_names)))\n",
    "ax.set_xticklabels(prefix_labels, fontsize=8, rotation=15)\n",
    "ax.axhline(y=0, color='gray', linestyle='--')\n",
    "ax.set_ylabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title('Prefix Type (Values-Only)')\n",
    "for i, v in enumerate(prefix_ds):\n",
    "    ax.text(i, v + 0.005, f\"{v:+.3f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# --- Plot 4: Interpolation curve ---\n",
    "ax = axes[1, 0]\n",
    "ax.plot(alphas, interp_ds, 'o-', color='purple', linewidth=2, markersize=8)\n",
    "# Linear fit overlay\n",
    "xs_fit = np.linspace(0, 1, 50)\n",
    "ys_fit = slope * xs_fit + intercept\n",
    "ax.plot(xs_fit, ys_fit, '--', color='gray', alpha=0.5, label=f'Linear fit (R\u00b2={r2_lin:.3f})')\n",
    "ax.set_xlabel('Alpha (primed fraction)')\n",
    "ax.set_ylabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title('Value Interpolation Curve')\n",
    "ax.set_xticks(alphas)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=8)\n",
    "for x, y in zip(alphas, interp_ds):\n",
    "    ax.annotate(f\"d={y:+.3f}\", (x, y), textcoords=\"offset points\",\n",
    "                xytext=(0, 10), ha='center', fontsize=8)\n",
    "\n",
    "# --- Plot 5: Positional breakdown ---\n",
    "ax = axes[1, 1]\n",
    "pos_names = ['first_quarter', 'middle_half', 'last_quarter']\n",
    "pos_labels = ['First 25%', 'Middle 50%', 'Last 25%']\n",
    "pos_ds = [cohens_d(c['bare'] - c[f'values_{pn}']) for pn in pos_names]\n",
    "pos_colors = ['lightblue', 'cornflowerblue', 'steelblue']\n",
    "bars = ax.bar(range(len(pos_names)), pos_ds, color=pos_colors,\n",
    "              edgecolor='black', linewidth=0.5)\n",
    "# All-positions reference\n",
    "ax.axhline(y=d_all_values, color='forestgreen', linestyle='--',\n",
    "           label=f'All positions (d={d_all_values:+.3f})')\n",
    "ax.set_xticks(range(len(pos_names)))\n",
    "ax.set_xticklabels(pos_labels, fontsize=9)\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.set_ylabel(\"Cohen's d vs Bare\")\n",
    "ax.set_title('Positional Breakdown')\n",
    "ax.legend(fontsize=8)\n",
    "for i, v in enumerate(pos_ds):\n",
    "    ax.text(i, v + 0.005, f\"{v:+.3f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# --- Plot 6: Hardness \u00d7 condition heatmap ---\n",
    "ax = axes[1, 2]\n",
    "hm_data = []\n",
    "for cname in key_conds:\n",
    "    row = []\n",
    "    for q in range(5):\n",
    "        mask_q = quintiles == q\n",
    "        if np.sum(mask_q) < 10:\n",
    "            row.append(0)\n",
    "        else:\n",
    "            delta = bare_valid[mask_q] - c[cname][mask_q]\n",
    "            row.append(cohens_d(delta))\n",
    "    hm_data.append(row)\n",
    "hm_data = np.array(hm_data)\n",
    "im = ax.imshow(hm_data, cmap='RdBu_r', vmin=-0.5, vmax=0.7, aspect='auto')\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels(quintile_labels, fontsize=7)\n",
    "ax.set_yticks(range(len(key_conds)))\n",
    "ax.set_yticklabels([cn.replace('values_', '') for cn in key_conds], fontsize=7)\n",
    "for i in range(len(key_conds)):\n",
    "    for j in range(5):\n",
    "        ax.text(j, i, f\"{hm_data[i,j]:+.2f}\", ha='center', va='center', fontsize=6)\n",
    "plt.colorbar(im, ax=ax, label=\"Cohen's d vs bare\")\n",
    "ax.set_title('Hardness \u00d7 Condition')\n",
    "\n",
    "plt.suptitle('Exp 09: Values Deep Dive', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'analysis_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Plots saved to {RESULTS_DIR / 'analysis_plots.png'}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 12: Save comprehensive results JSON\n",
    "\n",
    "# Direction-specific summaries\n",
    "layer_summary = {}\n",
    "for group_name in LAYER_GROUPS:\n",
    "    cname = f'values_{group_name}'\n",
    "    layer_summary[group_name] = {\n",
    "        'cohens_d': float(cohens_d(c['bare'] - c[cname])),\n",
    "        'layers': LAYER_GROUPS[group_name],\n",
    "    }\n",
    "\n",
    "prefix_summary = {}\n",
    "for cname, label in prefix_conds.items():\n",
    "    prefix_summary[label] = {\n",
    "        'cohens_d': float(cohens_d(c['bare'] - c[cname])),\n",
    "    }\n",
    "\n",
    "interp_summary = {}\n",
    "for alpha, d_val in zip(alphas, interp_ds):\n",
    "    interp_summary[f'alpha_{alpha:.2f}'] = float(d_val)\n",
    "interp_summary['linear_slope'] = float(slope)\n",
    "interp_summary['linear_intercept'] = float(intercept)\n",
    "interp_summary['linear_r2'] = float(r2_lin)\n",
    "\n",
    "cross_doc_summary = {\n",
    "    'd_cross_doc_vs_bare': float(d_cross),\n",
    "    'd_same_doc_vs_bare': float(d_same),\n",
    "    'retention_fraction': float(d_cross / d_same) if d_same != 0 else 0,\n",
    "}\n",
    "\n",
    "positional_summary = {}\n",
    "for cname, (label, frac) in pos_conds.items():\n",
    "    d = cohens_d(c['bare'] - c[cname])\n",
    "    positional_summary[label] = {\n",
    "        'cohens_d': float(d),\n",
    "        'fraction': frac,\n",
    "        'd_per_fraction': float(d / frac) if frac > 0 else 0,\n",
    "    }\n",
    "\n",
    "final = {\n",
    "    'experiment': 'exp09_values_deep_dive',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'config': {\n",
    "        'model_name': config.model_name,\n",
    "        'seed': SEED,\n",
    "        'n_eval': N,\n",
    "        'n_valid': n_valid,\n",
    "        'n_excluded': n_excluded,\n",
    "        'min_passage_words': config.min_passage_words,\n",
    "        'max_passage_words': config.max_passage_words,\n",
    "        'n_conditions': len(CONDITION_NAMES),\n",
    "        'n_comparisons': N_COMPARISONS,\n",
    "        'bonferroni_alpha': BONFERRONI_ALPHA,\n",
    "    },\n",
    "    'condition_names': CONDITION_NAMES,\n",
    "    'nll_summary': {\n",
    "        cname: {\n",
    "            'mean': float(np.mean(c[cname])),\n",
    "            'std': float(np.std(c[cname])),\n",
    "            'cohens_d_vs_bare': float(cohens_d(c['bare'] - c[cname])) if cname != 'bare' else 0.0,\n",
    "        }\n",
    "        for cname in CONDITION_NAMES\n",
    "    },\n",
    "    'direction_summaries': {\n",
    "        'layer_wise': layer_summary,\n",
    "        'prefix_types': prefix_summary,\n",
    "        'interpolation': interp_summary,\n",
    "        'cross_document': cross_doc_summary,\n",
    "        'positional': positional_summary,\n",
    "    },\n",
    "    'primary_comparisons': comparison_results,\n",
    "    'all_vs_bare': all_vs_bare,\n",
    "    'hardness_breakdown': hardness_breakdown,\n",
    "    'per_sample_results': results,\n",
    "}\n",
    "\n",
    "with open(FINAL_RESULTS_PATH, 'w') as f:\n",
    "    json.dump(final, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {FINAL_RESULTS_PATH}\")\n",
    "print(f\"File size: {FINAL_RESULTS_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "print(\"\\nDone!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 13: GPU cleanup\n",
    "import gc\n",
    "\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Cleanup complete.\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}