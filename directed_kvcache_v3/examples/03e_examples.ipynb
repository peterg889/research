{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5b6a15",
   "metadata": {},
   "source": [
    "# Experiment 03e: Attention Probing — Condition Examples\n",
    "\n",
    "This notebook shows the actual text for each experimental condition using real data from the dataset. No GPU needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1359821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 500\n",
    "\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"neural-bridge/rag-dataset-12000\", split=\"train\")\n",
    "\n",
    "all_candidates = []\n",
    "for row in ds:\n",
    "    q = row.get(\"question\", \"\")\n",
    "    doc = row.get(\"context\", \"\")\n",
    "    answer = row.get(\"answer\", \"\")\n",
    "    if not q or not doc or not answer:\n",
    "        continue\n",
    "    q_words = len(q.split())\n",
    "    a_words = len(answer.split())\n",
    "    if q_words >= 15 and a_words >= 5:\n",
    "        all_candidates.append({\n",
    "            \"query\": q, \"document\": doc, \"answer\": answer,\n",
    "            \"query_words\": q_words, \"doc_words\": len(doc.split()),\n",
    "            \"answer_words\": a_words,\n",
    "        })\n",
    "\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds\n",
    "\n",
    "# Verify against checkpoint\n",
    "def verify_checkpoint(exp_name):\n",
    "    ckpt_path = Path(f\"results/{exp_name}/checkpoint.json\")\n",
    "    if ckpt_path.exists():\n",
    "        ckpt = json.loads(ckpt_path.read_text())\n",
    "        meta = ckpt.get('sample_meta', ckpt.get('results', []))\n",
    "        if meta and meta[0].get('query', '')[:50] == samples[0]['query'][:50]:\n",
    "            print(f\"  Checkpoint verification: MATCH ({exp_name})\")\n",
    "            return True\n",
    "    return None\n",
    "\n",
    "print(f\"Loaded {len(samples)} neural-bridge samples (SEED={SEED})\")\n",
    "print(f\"Sample 0 query ({samples[0]['query_words']}w): {samples[0]['query'][:70]}\")\n",
    "\n",
    "\n",
    "def show_sample(s, doc_key='passage', n=0):\n",
    "    # Show sample info\n",
    "    doc = s[doc_key]\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"SAMPLE {n}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Query:    {s['query']}\")\n",
    "    print(f\"  Answer:   {s['answer']}\")\n",
    "    print(f\"  Document: {doc[:100]}...\")\n",
    "    print(f\"  Doc words: {len(doc.split())}\")\n",
    "    print()\n",
    "\n",
    "def show_conditions(conditions, doc_text):\n",
    "    # conditions: list of (name, description, encoder_prefix_text_or_None)\n",
    "    # For bare conditions, encoder_prefix_text is None\n",
    "    print(f\"{'Condition':<30} {'Prefix':<14} {'Encoder input (first 70 chars)'}\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    for name, desc, prefix_text in conditions:\n",
    "        if prefix_text is None:\n",
    "            enc_preview = doc_text[:70]\n",
    "            print(f\"{name:<30} {'(none)':<14} {enc_preview}...\")\n",
    "        else:\n",
    "            enc_text = prefix_text + \"\\n\" + doc_text\n",
    "            print(f\"{name:<30} {str(len(prefix_text.split()))+'w':<14} {enc_text[:70]}...\")\n",
    "        if desc:\n",
    "            print(f\"  {'':>28} ^ {desc}\")\n",
    "    print()\n",
    "\n",
    "show_sample(samples[0], doc_key='document')\n",
    "verify_checkpoint(\"exp03e\")\n",
    "\n",
    "ex = samples[0]\n",
    "query_words = ex['query'].split()\n",
    "n_qw = len(query_words)\n",
    "\n",
    "other_idx = (0 + N_SAMPLES // 2) % N_SAMPLES\n",
    "other_doc = samples[other_idx]['document']\n",
    "rand_matched = \" \".join(other_doc.split()[:n_qw])\n",
    "repeat_the = \" \".join([\"the\"] * n_qw)\n",
    "\n",
    "conditions = [\n",
    "    (\"bare\", \"Document only — baseline encoder attention\", None),\n",
    "    (\"oracle_trunc\", \"Real query — do prefix tokens get special attention?\", ex['query']),\n",
    "    (\"random_matched_trunc\", f\"Random words, {n_qw}w — structural control\", rand_matched),\n",
    "    (\"repeat_the_trunc\", f\"'the' x {n_qw} — minimal diversity control\", repeat_the),\n",
    "]\n",
    "\n",
    "show_conditions(conditions, ex['document'])\n",
    "\n",
    "print(\"PROBES (all measured at encoder attention layers):\")\n",
    "print(\"  A: Attention mass — how much doc-token attention goes to prefix?\")\n",
    "print(\"  B: Entropy — does prefix increase or decrease attention entropy?\")\n",
    "print(\"  C: Doc-doc redistribution — KL divergence of doc-doc attention pattern\")\n",
    "print(\"  D: Shift magnitude — L2 distance of doc representations (bare vs prefixed)\")\n",
    "print(\"  E: Shift direction — cosine similarity of shift vectors across conditions\")\n",
    "print(\"  F: Attention sinks — does prefix take over the sink role from <bos>?\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
