{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845c61db",
   "metadata": {},
   "source": [
    "# Experiment 3E: Attention Mechanism Probing\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Experiments 2B and 3D established that **~85% of the oracle headroom is \"structural\"** --\n",
    "prepending ANY text (even \"the the the...\") to the encoder improves document\n",
    "representations. But we don't understand WHY.\n",
    "\n",
    "**Three hypotheses**:\n",
    "1. **Attention redistribution**: prefix tokens absorb attention mass, changing how\n",
    "   document tokens attend to each other\n",
    "2. **RoPE position shift**: document tokens move to later positions, changing their\n",
    "   frequency signatures\n",
    "3. **Representation regularization**: prefix acts as noise injection that produces\n",
    "   more distributed/robust representations\n",
    "\n",
    "This experiment extracts encoder attention weights and hidden states to directly\n",
    "measure what changes.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- 34 encoder layers, 5 full-attention (layers 5, 11, 17, 23, 29), 29 sliding window\n",
    "- 8 attention heads (GQA: 4 KV heads expanded to 8)\n",
    "- Hidden size: 2560, head dim: 256\n",
    "- Sliding window: bidirectional, 513 tokens each direction\n",
    "- For a 20-token prefix + 600-word doc: only the 5 full-attention layers can directly\n",
    "  connect prefix to distant document tokens\n",
    "\n",
    "## Design\n",
    "\n",
    "**N=500** from neural-bridge/rag-12000 (same samples as Exp 3D).\n",
    "\n",
    "**4 conditions** (all with truncation mask):\n",
    "1. `bare` -- document only\n",
    "2. `oracle_trunc` -- real query + document\n",
    "3. `random_matched_trunc` -- random words + document\n",
    "4. `repeat_the_trunc` -- \"the\"xN + document\n",
    "\n",
    "## Probes\n",
    "\n",
    "| Probe | What it measures |\n",
    "|-------|-----------------|\n",
    "| **A: Attention mass on prefix** | Fraction of document tokens' attention going to prefix |\n",
    "| **B: Attention entropy** | Whether prefix increases or decreases entropy of doc token attention |\n",
    "| **C: Doc-doc redistribution** | How the remaining doc-doc attention changes with prefix |\n",
    "| **D: Shift magnitude** | L2 distance of doc token representations (bare vs prefixed) |\n",
    "| **E: Shift direction** | Cosine similarity of shift vectors across conditions (structural vs semantic) |\n",
    "| **F: Attention sinks** | Whether prefix tokens take over the \"sink\" role |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b56a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Setup + load dataset\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, re, gc, random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 500\n",
    "MODEL_NAME = \"google/t5gemma-2-4b-4b\"\n",
    "\n",
    "RESULTS_DIR = Path(\"../../results/exp03e\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "# Load dataset (same as Exp 3D)\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "ds = load_dataset(\"neural-bridge/rag-dataset-12000\", split=\"train\")\n",
    "\n",
    "all_candidates = []\n",
    "for row in ds:\n",
    "    q = row.get(\"question\", \"\")\n",
    "    doc = row.get(\"context\", \"\")\n",
    "    answer = row.get(\"answer\", \"\")\n",
    "    if not q or not doc or not answer:\n",
    "        continue\n",
    "    q_words = len(q.split())\n",
    "    a_words = len(answer.split())\n",
    "    if q_words >= 15 and a_words >= 5:\n",
    "        all_candidates.append({\n",
    "            \"query\": q,\n",
    "            \"document\": doc,\n",
    "            \"answer\": answer,\n",
    "            \"query_words\": q_words,\n",
    "            \"doc_words\": len(doc.split()),\n",
    "            \"answer_words\": a_words,\n",
    "        })\n",
    "\n",
    "print(f\"Candidates (q>=15w, a>=5w): {len(all_candidates)}\")\n",
    "\n",
    "# Same shuffle and selection as Exp 3D\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "\n",
    "q_lens = np.array([s[\"query_words\"] for s in samples])\n",
    "d_lens = np.array([s[\"doc_words\"] for s in samples])\n",
    "\n",
    "print(f\"\\nSample statistics (N={N_SAMPLES}):\")\n",
    "print(f\"  Query length:  mean={q_lens.mean():.1f}, range=[{q_lens.min()}, {q_lens.max()}]\")\n",
    "print(f\"  Doc length:    mean={d_lens.mean():.1f}, range=[{d_lens.min()}, {d_lens.max()}]\")\n",
    "\n",
    "del ds\n",
    "gc.collect()\n",
    "print(\"Dataset loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49daba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load model with eager attention + define hooks\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} with attn_implementation='eager'...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=HF_TOKEN,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "print(f\"Model loaded. dtype={next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "# Get encoder text model reference (T5Gemma2 has multimodal wrapper)\n",
    "# model.model.encoder = T5Gemma2Encoder (multimodal)\n",
    "# model.model.encoder.text_model = T5Gemma2TextEncoder (has .layers)\n",
    "encoder_text = model.model.encoder.text_model\n",
    "n_layers = len(encoder_text.layers)\n",
    "print(f\"Encoder layers: {n_layers}\")\n",
    "\n",
    "# Verify eager attention is active (SDPA returns None for attention weights)\n",
    "enc_attn_impl = encoder_text.layers[0].self_attn.config._attn_implementation\n",
    "print(f\"Encoder attn_implementation: {enc_attn_impl}\")\n",
    "assert enc_attn_impl == \"eager\", (\n",
    "    f\"Expected 'eager' but got '{enc_attn_impl}'. \"\n",
    "    f\"SDPA will return None attention weights!\"\n",
    ")\n",
    "\n",
    "# Identify full-attention vs sliding-window layers\n",
    "layer_types = []\n",
    "full_attn_layers = []\n",
    "for i in range(n_layers):\n",
    "    lt = encoder_text.layers[i].attention_type\n",
    "    layer_types.append(lt)\n",
    "    if lt == \"full_attention\":\n",
    "        full_attn_layers.append(i)\n",
    "\n",
    "print(f\"Full-attention layers: {full_attn_layers}\")\n",
    "print(f\"Sliding-window layers: {[i for i in range(n_layers) if layer_types[i] != 'full_attention']}\")\n",
    "\n",
    "# Layers to probe: first layer, all full-attention layers, final layer\n",
    "ATTN_LAYERS = sorted(set([0] + full_attn_layers))\n",
    "HIDDEN_LAYERS = sorted(set([0] + full_attn_layers + [n_layers - 1]))\n",
    "print(f\"\\nAttention probe layers: {ATTN_LAYERS}\")\n",
    "print(f\"Hidden state probe layers: {HIDDEN_LAYERS}\")\n",
    "\n",
    "# Hook infrastructure: stores captured tensors per forward pass\n",
    "captured_attn = {}\n",
    "captured_hidden = {}\n",
    "hook_handles = []\n",
    "\n",
    "\n",
    "def make_attn_hook(layer_idx):\n",
    "    # Hook on self_attn: captures (attn_output, attn_weights)\n",
    "    def hook_fn(module, input, output):\n",
    "        attn_output, attn_weights = output\n",
    "        if attn_weights is not None:\n",
    "            # attn_weights: (batch, n_heads, seq_len, seq_len)\n",
    "            captured_attn[layer_idx] = attn_weights.detach().float()\n",
    "        else:\n",
    "            print(f\"WARNING: Layer {layer_idx} returned None attention weights!\")\n",
    "    return hook_fn\n",
    "\n",
    "\n",
    "def make_hidden_hook(layer_idx):\n",
    "    # Hook on encoder layer: captures hidden_states output\n",
    "    def hook_fn(module, input, output):\n",
    "        # T5GemmaEncoderLayer.forward returns just hidden_states (a single tensor)\n",
    "        if isinstance(output, tuple):\n",
    "            h = output[0]\n",
    "        else:\n",
    "            h = output\n",
    "        captured_hidden[layer_idx] = h.detach().float()\n",
    "    return hook_fn\n",
    "\n",
    "\n",
    "def register_hooks():\n",
    "    global hook_handles\n",
    "    remove_hooks()\n",
    "    for layer_idx in ATTN_LAYERS:\n",
    "        h = encoder_text.layers[layer_idx].self_attn.register_forward_hook(\n",
    "            make_attn_hook(layer_idx)\n",
    "        )\n",
    "        hook_handles.append(h)\n",
    "    for layer_idx in HIDDEN_LAYERS:\n",
    "        h = encoder_text.layers[layer_idx].register_forward_hook(\n",
    "            make_hidden_hook(layer_idx)\n",
    "        )\n",
    "        hook_handles.append(h)\n",
    "\n",
    "\n",
    "def remove_hooks():\n",
    "    global hook_handles\n",
    "    for h in hook_handles:\n",
    "        h.remove()\n",
    "    hook_handles = []\n",
    "\n",
    "\n",
    "def clear_captures():\n",
    "    captured_attn.clear()\n",
    "    captured_hidden.clear()\n",
    "\n",
    "\n",
    "# Token counting helper (same as Exp 3D)\n",
    "def count_prefix_tokens(prefix_text, document_text):\n",
    "    full_text = prefix_text + \"\\n\" + document_text\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True, truncation=True,\n",
    "                         max_length=2048).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids\n",
    "    return len(full_ids) - len(doc_ids)\n",
    "\n",
    "\n",
    "print(\"Hooks and helpers defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Generate conditions for each sample (same as Exp 3D)\n",
    "\n",
    "# Build word pool from unrelated documents\n",
    "other_words_pool = []\n",
    "for i, s in enumerate(samples):\n",
    "    other_idx = (i + N_SAMPLES // 2) % N_SAMPLES\n",
    "    other_doc = samples[other_idx]['document']\n",
    "    other_words_pool.append(other_doc.split())\n",
    "\n",
    "for i, s in enumerate(samples):\n",
    "    query_words = s['query'].split()\n",
    "    n_query_words = len(query_words)\n",
    "    other_words = other_words_pool[i]\n",
    "\n",
    "    # random_matched: N random words from unrelated doc\n",
    "    if len(other_words) >= n_query_words:\n",
    "        s['random_matched'] = \" \".join(other_words[:n_query_words])\n",
    "    else:\n",
    "        padded = other_words * ((n_query_words // len(other_words)) + 1)\n",
    "        s['random_matched'] = \" \".join(padded[:n_query_words])\n",
    "\n",
    "    # repeat_the: \"the\" repeated N times\n",
    "    s['repeat_the'] = \" \".join([\"the\"] * n_query_words)\n",
    "\n",
    "COND_NAMES = ['bare', 'oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']\n",
    "\n",
    "# Show prefix token stats\n",
    "print(f\"Conditions: {COND_NAMES}\")\n",
    "print(f\"\\nPrefix token counts (first 50 samples):\")\n",
    "for c in COND_NAMES:\n",
    "    if c == 'bare':\n",
    "        continue\n",
    "    if c == 'oracle_trunc':\n",
    "        toks = [count_prefix_tokens(s['query'], s['document']) for s in samples[:50]]\n",
    "    else:\n",
    "        key = c.replace('_trunc', '')\n",
    "        toks = [count_prefix_tokens(s[key], s['document']) for s in samples[:50]]\n",
    "    print(f\"  {c:<28} mean={np.mean(toks):.1f}, range=[{min(toks)}, {max(toks)}]\")\n",
    "\n",
    "# Example\n",
    "ex = samples[0]\n",
    "print(f\"\\nExample (sample 0):\")\n",
    "print(f\"  Query ({ex['query_words']}w): {ex['query'][:100]}...\")\n",
    "print(f\"  Document ({ex['doc_words']}w): {ex['document'][:80]}...\")\n",
    "\n",
    "# Show what each condition's encoder input looks like\n",
    "print(f\"\\n--- Encoder input for each condition (sample 0) ---\")\n",
    "cond_examples = {\n",
    "    'bare': ex['document'],\n",
    "    'oracle_trunc': ex['query'] + \"\\n\" + ex['document'],\n",
    "    'random_matched_trunc': ex['random_matched'] + \"\\n\" + ex['document'],\n",
    "    'repeat_the_trunc': ex['repeat_the'] + \"\\n\" + ex['document'],\n",
    "}\n",
    "for cond_name, enc_text in cond_examples.items():\n",
    "    if cond_name == 'bare':\n",
    "        ptoks = 0\n",
    "        prefix_display = \"(none)\"\n",
    "    else:\n",
    "        key = cond_name.replace('_trunc', '')\n",
    "        prefix_text = ex[key]\n",
    "        ptoks = count_prefix_tokens(prefix_text, ex['document'])\n",
    "        prefix_display = prefix_text[:60]\n",
    "    print(f\"  {cond_name:<28} ({ptoks:>3} prefix toks)\")\n",
    "    if cond_name != 'bare':\n",
    "        print(f\"    prefix: {prefix_display}\")\n",
    "    print(f\"    enc input: {enc_text[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61603559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run extraction loop\n",
    "# For each sample x condition: run encoder, capture attention + hidden states,\n",
    "# compute all probe metrics on-the-fly, store only aggregated results.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXTRACTION LOOP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize accumulators for all probes\n",
    "# Indexed by [condition][layer] where appropriate.\n",
    "\n",
    "# Probe A: mean attention mass on prefix per doc token, per layer/head\n",
    "# Shape per entry: (n_heads,) -- mean across doc tokens and samples\n",
    "probe_a_mass = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES if c != 'bare'}\n",
    "# Also store per-head mass distribution across doc token positions (mean across samples)\n",
    "probe_a_by_position = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES if c != 'bare'}\n",
    "\n",
    "# Probe B: attention entropy per doc token, per layer\n",
    "# Store: mean entropy per layer, for each condition\n",
    "probe_b_entropy = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES}\n",
    "\n",
    "# Probe C: doc-doc attention pattern divergence\n",
    "# KL divergence between bare doc-doc attention and prefixed doc-doc attention\n",
    "probe_c_kl = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES if c != 'bare'}\n",
    "# Also: entropy of doc-doc sub-pattern (separate from full entropy)\n",
    "probe_c_docdoc_entropy = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES}\n",
    "\n",
    "# Probe D: representation shift magnitude per layer\n",
    "# Mean L2 distance of doc token reps (bare vs prefixed)\n",
    "probe_d_shift = {c: {l: [] for l in HIDDEN_LAYERS} for c in COND_NAMES if c != 'bare'}\n",
    "# Per-position shift (binned into 10 position bins)\n",
    "N_POS_BINS = 10\n",
    "probe_d_by_position = {c: {l: [] for l in HIDDEN_LAYERS} for c in COND_NAMES if c != 'bare'}\n",
    "\n",
    "# Probe E: shift direction similarity\n",
    "# Cosine similarity between (h_oracle - h_bare) and (h_X - h_bare) per doc token per layer\n",
    "probe_e_cosine = {c: {l: [] for l in HIDDEN_LAYERS}\n",
    "                  for c in COND_NAMES if c not in ('bare', 'oracle_trunc')}\n",
    "\n",
    "# Probe F: attention sinks -- total attention received by each position\n",
    "# For bare: which doc positions absorb most attention\n",
    "# For prefixed: do prefix tokens absorb it instead\n",
    "probe_f_received = {c: {l: [] for l in ATTN_LAYERS} for c in COND_NAMES}\n",
    "# Separate: total attention received by prefix positions\n",
    "probe_f_prefix_received = {c: {l: [] for l in ATTN_LAYERS}\n",
    "                           for c in COND_NAMES if c != 'bare'}\n",
    "\n",
    "# NLL scores for cross-reference with Exp 3D\n",
    "nll_scores = {c: [] for c in COND_NAMES}\n",
    "\n",
    "# Per-sample metadata\n",
    "sample_meta = []\n",
    "\n",
    "# ---- Helper: compute attention entropy ----\n",
    "def attn_entropy(weights, mask=None):\n",
    "    # weights: (n_heads, seq, seq) -- attention probabilities\n",
    "    # mask: (seq,) boolean -- True for positions to include\n",
    "    # Returns: (n_heads, seq) mean entropy per head per query position\n",
    "    eps = 1e-10\n",
    "    # Only compute for positions indicated by mask\n",
    "    log_w = torch.log(weights + eps)\n",
    "    ent = -(weights * log_w).sum(dim=-1)  # (n_heads, seq)\n",
    "    return ent\n",
    "\n",
    "# ---- Helper: encode and extract ----\n",
    "def encode_and_extract(text):\n",
    "    # Returns encoder outputs (via hooks on text_model layers) and input_ids\n",
    "    enc_ids = tokenizer(text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids.to(DEVICE)\n",
    "    enc_mask = torch.ones(1, enc_ids.shape[1], device=DEVICE, dtype=torch.long)\n",
    "    clear_captures()\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.get_encoder()(\n",
    "            input_ids=enc_ids, attention_mask=enc_mask\n",
    "        )\n",
    "    return enc_ids, encoder_outputs\n",
    "\n",
    "# ---- Helper: score NLL ----\n",
    "def score_nll(encoder_outputs, total_enc_len, answer_text, prefix_token_count=0,\n",
    "              truncate=False):\n",
    "    if truncate and prefix_token_count > 0:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "        cross_attn_mask[:, :prefix_token_count] = 0\n",
    "    else:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    ans_ids = tokenizer(answer_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=False, truncation=True,\n",
    "                        max_length=256).input_ids.to(DEVICE)\n",
    "    if ans_ids.shape[1] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            attention_mask=cross_attn_mask,\n",
    "            labels=ans_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_log_probs = log_probs[0].gather(1, ans_ids[0].unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "\n",
    "    del outputs, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "# ---- Main loop ----\n",
    "register_hooks()\n",
    "\n",
    "start_idx = 0\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    ckpt = json.loads(CHECKPOINT_PATH.read_text())\n",
    "    if (ckpt.get('n_total') == N_SAMPLES\n",
    "            and len(ckpt.get('sample_meta', [])) > 0):\n",
    "        saved_qs = [m['query'][:50] for m in ckpt['sample_meta']]\n",
    "        current_qs = [s['query'][:50] for s in samples[:len(saved_qs)]]\n",
    "        if saved_qs == current_qs:\n",
    "            start_idx = len(saved_qs)\n",
    "            # Restore accumulators\n",
    "            for key in ['probe_a_mass', 'probe_b_entropy', 'probe_c_kl',\n",
    "                        'probe_c_docdoc_entropy', 'probe_d_shift',\n",
    "                        'probe_d_by_position', 'probe_e_cosine',\n",
    "                        'probe_f_received', 'probe_f_prefix_received',\n",
    "                        'nll_scores', 'sample_meta']:\n",
    "                saved = ckpt.get(key)\n",
    "                if saved is not None:\n",
    "                    local_var = locals()[key]\n",
    "                    if isinstance(local_var, dict) and isinstance(saved, dict):\n",
    "                        # Nested dict: convert string keys back to int\n",
    "                        for ck, cv in saved.items():\n",
    "                            if isinstance(cv, dict):\n",
    "                                local_var[ck] = {int(lk): lv for lk, lv in cv.items()}\n",
    "                            else:\n",
    "                                local_var[ck] = cv\n",
    "                    elif isinstance(local_var, list):\n",
    "                        local_var.clear()\n",
    "                        local_var.extend(saved)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {N_SAMPLES} samples x {len(COND_NAMES)} conditions \"\n",
    "          f\"= {N_SAMPLES * len(COND_NAMES)} forward passes\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for sample_idx in tqdm(range(start_idx, N_SAMPLES), initial=start_idx,\n",
    "                       total=N_SAMPLES, desc=\"Extracting\"):\n",
    "    s = samples[sample_idx]\n",
    "\n",
    "    # ---- Build encoder texts for each condition ----\n",
    "    cond_texts = {}\n",
    "    cond_ptoks = {}\n",
    "    for c in COND_NAMES:\n",
    "        if c == 'bare':\n",
    "            cond_texts[c] = s['document']\n",
    "            cond_ptoks[c] = 0\n",
    "        elif c == 'oracle_trunc':\n",
    "            cond_texts[c] = s['query'] + \"\\n\" + s['document']\n",
    "            cond_ptoks[c] = count_prefix_tokens(s['query'], s['document'])\n",
    "        else:\n",
    "            key = c.replace('_trunc', '')\n",
    "            cond_texts[c] = s[key] + \"\\n\" + s['document']\n",
    "            cond_ptoks[c] = count_prefix_tokens(s[key], s['document'])\n",
    "\n",
    "    # ---- Run encoder for each condition ----\n",
    "    cond_attn = {}    # condition -> layer -> attn_weights\n",
    "    cond_hidden = {}  # condition -> layer -> hidden_states\n",
    "\n",
    "    for c in COND_NAMES:\n",
    "        enc_ids, enc_out = encode_and_extract(cond_texts[c])\n",
    "        seq_len = enc_ids.shape[1]\n",
    "\n",
    "        # Copy captured tensors (they'll be overwritten next forward pass)\n",
    "        cond_attn[c] = {l: captured_attn[l].clone() for l in ATTN_LAYERS\n",
    "                        if l in captured_attn}\n",
    "        cond_hidden[c] = {l: captured_hidden[l].clone() for l in HIDDEN_LAYERS\n",
    "                          if l in captured_hidden}\n",
    "\n",
    "        # Score NLL for cross-reference\n",
    "        nll = score_nll(enc_out, seq_len, s['answer'],\n",
    "                        cond_ptoks[c], truncate=(c != 'bare'))\n",
    "        nll_scores[c].append(nll)\n",
    "\n",
    "        del enc_ids, enc_out\n",
    "        clear_captures()\n",
    "\n",
    "    # ---- Record metadata ----\n",
    "    bare_seq_len = list(cond_hidden['bare'].values())[0].shape[1]\n",
    "    sample_meta.append({\n",
    "        'query': s['query'],\n",
    "        'query_words': s['query_words'],\n",
    "        'doc_words': s['doc_words'],\n",
    "        'bare_seq_len': bare_seq_len,\n",
    "        'prefix_tokens': {c: cond_ptoks[c] for c in COND_NAMES},\n",
    "    })\n",
    "\n",
    "    # ---- Compute probe metrics ----\n",
    "    n_doc_bare = bare_seq_len  # all tokens are \"document\" in bare\n",
    "\n",
    "    for c in COND_NAMES:\n",
    "        ptoks = cond_ptoks[c]\n",
    "        n_doc = (list(cond_hidden[c].values())[0].shape[1]) - ptoks\n",
    "\n",
    "        for l in ATTN_LAYERS:\n",
    "            if l not in cond_attn[c]:\n",
    "                continue\n",
    "            # attn: (1, n_heads, seq, seq) -> (n_heads, seq, seq)\n",
    "            attn = cond_attn[c][l][0]\n",
    "            n_heads = attn.shape[0]\n",
    "            seq = attn.shape[1]\n",
    "\n",
    "            if c != 'bare':\n",
    "                # Probe A: attention mass on prefix from each doc token\n",
    "                # doc tokens are positions [ptoks:], prefix at [:ptoks]\n",
    "                doc_to_prefix = attn[:, ptoks:, :ptoks]  # (heads, n_doc, ptoks)\n",
    "                mass_per_head = doc_to_prefix.sum(dim=-1).mean(dim=-1)  # (heads,)\n",
    "                probe_a_mass[c][l].append(mass_per_head.cpu().numpy().tolist())\n",
    "\n",
    "                # Position-dependent: mass on prefix by doc token position (10 bins)\n",
    "                doc_mass = doc_to_prefix.sum(dim=-1).mean(dim=0)  # (n_doc,)\n",
    "                if n_doc >= N_POS_BINS:\n",
    "                    bins = np.array_split(doc_mass.cpu().numpy(), N_POS_BINS)\n",
    "                    binned = [float(np.mean(b)) for b in bins]\n",
    "                else:\n",
    "                    binned = doc_mass.cpu().numpy().tolist()\n",
    "                probe_a_by_position[c][l].append(binned)\n",
    "\n",
    "            # Probe B: attention entropy for doc tokens\n",
    "            if c == 'bare':\n",
    "                doc_attn_rows = attn[:, :, :]  # all tokens are doc\n",
    "            else:\n",
    "                doc_attn_rows = attn[:, ptoks:, :]  # doc token rows\n",
    "            ent = attn_entropy(doc_attn_rows)  # (heads, n_doc)\n",
    "            mean_ent = ent.mean(dim=-1).mean(dim=0).item()  # scalar\n",
    "            probe_b_entropy[c][l].append(mean_ent)\n",
    "\n",
    "            # Probe C: doc-doc sub-attention\n",
    "            if c == 'bare':\n",
    "                docdoc = attn[:, :, :]  # all is doc-doc\n",
    "            else:\n",
    "                docdoc = attn[:, ptoks:, ptoks:]  # doc-to-doc submatrix\n",
    "            # Renormalize doc-doc to sum to 1 per row\n",
    "            docdoc_sum = docdoc.sum(dim=-1, keepdim=True).clamp(min=1e-10)\n",
    "            docdoc_norm = docdoc / docdoc_sum\n",
    "            ent_dd = attn_entropy(docdoc_norm)\n",
    "            mean_ent_dd = ent_dd.mean(dim=-1).mean(dim=0).item()\n",
    "            probe_c_docdoc_entropy[c][l].append(mean_ent_dd)\n",
    "\n",
    "            if c != 'bare':\n",
    "                # KL(bare_docdoc || prefixed_docdoc) for matching doc positions\n",
    "                # bare doc-doc: all positions are doc\n",
    "                bare_attn = cond_attn['bare'][l][0]\n",
    "                bare_n = bare_attn.shape[1]\n",
    "                # Use the last min(bare_n, n_doc) positions for alignment\n",
    "                align_n = min(bare_n, n_doc)\n",
    "                if align_n > 0:\n",
    "                    bare_dd = bare_attn[:, -align_n:, -align_n:]\n",
    "                    pref_dd = docdoc_norm[:, -align_n:, -align_n:]\n",
    "                    # Renormalize bare to same window\n",
    "                    bare_dd_sum = bare_dd.sum(dim=-1, keepdim=True).clamp(min=1e-10)\n",
    "                    bare_dd_norm = bare_dd / bare_dd_sum\n",
    "                    # KL divergence per position per head, then mean\n",
    "                    eps = 1e-10\n",
    "                    kl = (bare_dd_norm * (torch.log(bare_dd_norm + eps)\n",
    "                                          - torch.log(pref_dd + eps)))\n",
    "                    kl = kl.sum(dim=-1).mean(dim=-1).mean(dim=0).item()\n",
    "                    probe_c_kl[c][l].append(kl)\n",
    "                else:\n",
    "                    probe_c_kl[c][l].append(0.0)\n",
    "\n",
    "            # Probe F: attention received per position (attention sink)\n",
    "            # Sum attention each position receives from all other positions\n",
    "            received = attn.sum(dim=1).mean(dim=0)  # (seq,) mean across heads\n",
    "            # Normalize by seq_len so it's comparable across conditions\n",
    "            received = received / seq\n",
    "            if c == 'bare':\n",
    "                # Store stats about top-k sinks\n",
    "                top_vals, top_idxs = received.topk(min(5, seq))\n",
    "                probe_f_received[c][l].append({\n",
    "                    'top5_vals': top_vals.cpu().numpy().tolist(),\n",
    "                    'top5_idxs': top_idxs.cpu().numpy().tolist(),\n",
    "                    'first_pos_val': received[0].item(),\n",
    "                    'mean_val': received.mean().item(),\n",
    "                })\n",
    "            else:\n",
    "                prefix_recv = received[:ptoks].mean().item() if ptoks > 0 else 0\n",
    "                doc_recv = received[ptoks:].mean().item()\n",
    "                top_vals, top_idxs = received.topk(min(5, seq))\n",
    "                probe_f_received[c][l].append({\n",
    "                    'prefix_mean_recv': prefix_recv,\n",
    "                    'doc_mean_recv': doc_recv,\n",
    "                    'top5_vals': top_vals.cpu().numpy().tolist(),\n",
    "                    'top5_idxs': top_idxs.cpu().numpy().tolist(),\n",
    "                })\n",
    "                probe_f_prefix_received[c][l].append(prefix_recv)\n",
    "\n",
    "        # Probe D: representation shift\n",
    "        if c != 'bare':\n",
    "            for l in HIDDEN_LAYERS:\n",
    "                if l not in cond_hidden[c] or l not in cond_hidden['bare']:\n",
    "                    continue\n",
    "                h_bare = cond_hidden['bare'][l][0]   # (bare_seq, hidden)\n",
    "                h_pref = cond_hidden[c][l][0]        # (pref_seq, hidden)\n",
    "\n",
    "                # Align on last n_doc positions (document tokens)\n",
    "                align_n = min(h_bare.shape[0], n_doc)\n",
    "                if align_n > 0:\n",
    "                    h_b = h_bare[-align_n:]\n",
    "                    h_p = h_pref[-align_n:]\n",
    "                    shifts = (h_p - h_b).norm(dim=-1)  # (align_n,)\n",
    "                    probe_d_shift[c][l].append(shifts.mean().item())\n",
    "\n",
    "                    # Position-binned shifts\n",
    "                    if align_n >= N_POS_BINS:\n",
    "                        bins = np.array_split(shifts.cpu().numpy(), N_POS_BINS)\n",
    "                        binned = [float(np.mean(b)) for b in bins]\n",
    "                    else:\n",
    "                        binned = shifts.cpu().numpy().tolist()\n",
    "                    probe_d_by_position[c][l].append(binned)\n",
    "\n",
    "        # Probe E: shift direction cosine similarity\n",
    "        if c not in ('bare', 'oracle_trunc'):\n",
    "            for l in HIDDEN_LAYERS:\n",
    "                if (l not in cond_hidden[c] or l not in cond_hidden['bare']\n",
    "                        or l not in cond_hidden.get('oracle_trunc', {})):\n",
    "                    continue\n",
    "                h_bare = cond_hidden['bare'][l][0]\n",
    "                h_oracle = cond_hidden['oracle_trunc'][l][0]\n",
    "                h_other = cond_hidden[c][l][0]\n",
    "\n",
    "                n_doc_oracle = h_oracle.shape[0] - cond_ptoks['oracle_trunc']\n",
    "                n_doc_other = h_other.shape[0] - cond_ptoks[c]\n",
    "                align_n = min(h_bare.shape[0], n_doc_oracle, n_doc_other)\n",
    "\n",
    "                if align_n > 0:\n",
    "                    shift_oracle = h_oracle[-align_n:] - h_bare[-align_n:]\n",
    "                    shift_other = h_other[-align_n:] - h_bare[-align_n:]\n",
    "                    # Cosine similarity per token\n",
    "                    cos = F.cosine_similarity(shift_oracle, shift_other, dim=-1)\n",
    "                    probe_e_cosine[c][l].append(cos.mean().item())\n",
    "\n",
    "    # Free condition tensors\n",
    "    del cond_attn, cond_hidden\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Checkpoint every 20 samples\n",
    "    if (sample_idx + 1) % 20 == 0 or sample_idx == N_SAMPLES - 1:\n",
    "        # Convert all accumulators to serializable form\n",
    "        def to_serializable(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {str(k): to_serializable(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return obj\n",
    "            elif isinstance(obj, (np.floating, np.integer)):\n",
    "                return float(obj)\n",
    "            return obj\n",
    "\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'probe_a_mass': to_serializable(probe_a_mass),\n",
    "            'probe_b_entropy': to_serializable(probe_b_entropy),\n",
    "            'probe_c_kl': to_serializable(probe_c_kl),\n",
    "            'probe_c_docdoc_entropy': to_serializable(probe_c_docdoc_entropy),\n",
    "            'probe_d_shift': to_serializable(probe_d_shift),\n",
    "            'probe_d_by_position': to_serializable(probe_d_by_position),\n",
    "            'probe_e_cosine': to_serializable(probe_e_cosine),\n",
    "            'probe_f_received': to_serializable(probe_f_received),\n",
    "            'probe_f_prefix_received': to_serializable(probe_f_prefix_received),\n",
    "            'nll_scores': nll_scores,\n",
    "            'sample_meta': sample_meta,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CHECKPOINT_PATH.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = sample_idx - start_idx + 1\n",
    "        eta = (N_SAMPLES - sample_idx - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {sample_idx+1}/{N_SAMPLES} | \"\n",
    "                   f\"{elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "remove_hooks()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nExtraction complete: {N_SAMPLES} samples, \"\n",
    "      f\"{len(COND_NAMES)} conditions in {elapsed/60:.1f} min\")\n",
    "print(f\"NLL cross-check: bare={np.mean(nll_scores['bare']):.4f}, \"\n",
    "      f\"oracle={np.mean(nll_scores['oracle_trunc']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Probe A — Attention mass on prefix\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE A: ATTENTION MASS ON PREFIX\")\n",
    "print(\"=\" * 70)\n",
    "print(\"For prefixed conditions, what fraction of each document token's attention\")\n",
    "print(\"goes to prefix tokens? By layer and head.\\n\")\n",
    "\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    print(f\"\\n--- {c} ---\")\n",
    "    print(f\"{'Layer':>6} {'Type':>10} {'Mean mass':>11} {'Std':>8} {'Min head':>10} {'Max head':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for l in ATTN_LAYERS:\n",
    "        data = probe_a_mass[c][l]\n",
    "        if not data:\n",
    "            continue\n",
    "        # data is list of (n_heads,) per sample -> (N, n_heads)\n",
    "        arr = np.array(data)  # (N, n_heads)\n",
    "        mean_per_head = arr.mean(axis=0)  # (n_heads,)\n",
    "        overall_mean = mean_per_head.mean()\n",
    "        overall_std = arr.mean(axis=1).std()\n",
    "        lt = layer_types[l][:4]\n",
    "        print(f\"  {l:>4}  {lt:>10} {overall_mean:>11.4f} {overall_std:>8.4f} \"\n",
    "              f\"{mean_per_head.min():>10.4f} {mean_per_head.max():>10.4f}\")\n",
    "\n",
    "# Compare across conditions at full-attention layers\n",
    "print(f\"\\n\\n--- Cross-condition comparison (full-attention layers only) ---\")\n",
    "print(f\"{'Layer':>6} {'oracle':>10} {'random':>10} {'repeat_the':>12} {'orc-rand':>10}\")\n",
    "print(\"-\" * 60)\n",
    "for l in full_attn_layers:\n",
    "    o_mass = np.array(probe_a_mass['oracle_trunc'][l]).mean()\n",
    "    r_mass = np.array(probe_a_mass['random_matched_trunc'][l]).mean()\n",
    "    t_mass = np.array(probe_a_mass['repeat_the_trunc'][l]).mean()\n",
    "    print(f\"  {l:>4} {o_mass:>10.4f} {r_mass:>10.4f} {t_mass:>12.4f} \"\n",
    "          f\"{o_mass - r_mass:>+10.4f}\")\n",
    "\n",
    "# Position-dependent attention mass (does prefix attract equally from all doc positions?)\n",
    "print(f\"\\n\\n--- Position-dependent prefix attention mass (oracle, mean across heads) ---\")\n",
    "print(f\"Position bin: 0=start of doc, 9=end of doc\")\n",
    "for l in full_attn_layers:\n",
    "    data = probe_a_by_position['oracle_trunc'][l]\n",
    "    if not data or not all(len(d) == N_POS_BINS for d in data):\n",
    "        # Skip if variable length\n",
    "        continue\n",
    "    arr = np.array(data)  # (N, N_POS_BINS)\n",
    "    means = arr.mean(axis=0)\n",
    "    print(f\"  Layer {l}: \" + \" \".join(f\"{m:.3f}\" for m in means))\n",
    "\n",
    "print(f\"\\nKey question: is mass UNIFORM across doc positions or CONCENTRATED?\")\n",
    "for l in full_attn_layers:\n",
    "    data = probe_a_by_position['oracle_trunc'][l]\n",
    "    if not data or not all(len(d) == N_POS_BINS for d in data):\n",
    "        continue\n",
    "    arr = np.array(data).mean(axis=0)\n",
    "    cv = np.std(arr) / np.mean(arr) if np.mean(arr) > 0 else 0\n",
    "    print(f\"  Layer {l}: CV (coeff of variation) = {cv:.3f} \"\n",
    "          f\"({'uniform' if cv < 0.3 else 'concentrated'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Probe B — Attention entropy\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE B: ATTENTION ENTROPY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Does the prefix INCREASE entropy (dilution/regularization)\")\n",
    "print(\"or DECREASE it (focusing)?\\n\")\n",
    "\n",
    "print(f\"{'Layer':>6} {'Type':>10} {'bare':>10} {'oracle':>10} {'random':>10} \"\n",
    "      f\"{'repeat':>10} {'orc-bare':>10} {'rand-bare':>10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "entropy_changes = {c: [] for c in COND_NAMES if c != 'bare'}\n",
    "\n",
    "for l in ATTN_LAYERS:\n",
    "    bare_ent = np.mean(probe_b_entropy['bare'][l])\n",
    "    lt = layer_types[l][:4]\n",
    "    vals = [f\"  {l:>4}  {lt:>10} {bare_ent:>10.3f}\"]\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        c_ent = np.mean(probe_b_entropy[c][l])\n",
    "        vals.append(f\"{c_ent:>10.3f}\")\n",
    "    # Deltas\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc']:\n",
    "        c_ent = np.mean(probe_b_entropy[c][l])\n",
    "        delta = c_ent - bare_ent\n",
    "        vals.append(f\"{delta:>+10.3f}\")\n",
    "        entropy_changes[c].append(delta)\n",
    "    print(\" \".join(vals))\n",
    "\n",
    "# Statistical test: is entropy change significant?\n",
    "print(f\"\\n--- Statistical tests ---\")\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    for l in ATTN_LAYERS:\n",
    "        bare_arr = np.array(probe_b_entropy['bare'][l])\n",
    "        cond_arr = np.array(probe_b_entropy[c][l])\n",
    "        if len(bare_arr) == len(cond_arr) and len(bare_arr) > 1:\n",
    "            diff = cond_arr - bare_arr\n",
    "            d = cohens_d(diff)\n",
    "            _, p = stats.ttest_1samp(diff, 0)\n",
    "            sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "            if l in full_attn_layers:\n",
    "                print(f\"  {c} layer {l} (full): d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n--- Summary ---\")\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    increases = 0\n",
    "    decreases = 0\n",
    "    for l in ATTN_LAYERS:\n",
    "        bare_ent = np.mean(probe_b_entropy['bare'][l])\n",
    "        cond_ent = np.mean(probe_b_entropy[c][l])\n",
    "        if cond_ent > bare_ent:\n",
    "            increases += 1\n",
    "        else:\n",
    "            decreases += 1\n",
    "    direction = \"INCREASES\" if increases > decreases else \"DECREASES\"\n",
    "    print(f\"  {c}: entropy {direction} in {increases}/{len(ATTN_LAYERS)} layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Probe C — Document-document attention redistribution\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE C: DOC-DOC ATTENTION REDISTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"After removing attention to prefix, how does the remaining doc-doc\")\n",
    "print(\"attention pattern compare to bare?\\n\")\n",
    "\n",
    "# Doc-doc entropy\n",
    "print(f\"{'Layer':>6} {'bare dd':>10} {'oracle dd':>12} {'random dd':>12} \"\n",
    "      f\"{'repeat dd':>12} {'orc-bare':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for l in ATTN_LAYERS:\n",
    "    bare_dd = np.mean(probe_c_docdoc_entropy['bare'][l])\n",
    "    vals = [f\"  {l:>4} {bare_dd:>10.3f}\"]\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        c_dd = np.mean(probe_c_docdoc_entropy[c][l])\n",
    "        vals.append(f\"{c_dd:>12.3f}\")\n",
    "    delta = np.mean(probe_c_docdoc_entropy['oracle_trunc'][l]) - bare_dd\n",
    "    vals.append(f\"{delta:>+10.3f}\")\n",
    "    print(\" \".join(vals))\n",
    "\n",
    "# KL divergence\n",
    "print(f\"\\n--- KL divergence: bare doc-doc || prefixed doc-doc ---\")\n",
    "print(f\"{'Layer':>6} {'Type':>10} {'oracle KL':>12} {'random KL':>12} {'repeat KL':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for l in ATTN_LAYERS:\n",
    "    lt = layer_types[l][:4]\n",
    "    vals = [f\"  {l:>4}  {lt:>10}\"]\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        kl = np.mean(probe_c_kl[c][l]) if probe_c_kl[c][l] else 0\n",
    "        vals.append(f\"{kl:>12.4f}\")\n",
    "    print(\" \".join(vals))\n",
    "\n",
    "# Key question: does oracle redistribute MORE than random?\n",
    "print(f\"\\n--- Does oracle redistribute more than random? ---\")\n",
    "for l in full_attn_layers:\n",
    "    o_kl = np.array(probe_c_kl['oracle_trunc'][l])\n",
    "    r_kl = np.array(probe_c_kl['random_matched_trunc'][l])\n",
    "    if len(o_kl) > 1 and len(r_kl) > 1:\n",
    "        diff = o_kl - r_kl\n",
    "        d = cohens_d(diff)\n",
    "        _, p = stats.ttest_1samp(diff, 0)\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        winner = \"oracle\" if d > 0 else \"random\"\n",
    "        print(f\"  Layer {l}: d={d:+.3f}, p={p:.2e} {sig} [{winner} redistributes more]\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  High KL = prefix causes large change to doc-doc attention pattern\")\n",
    "print(f\"  Similar KL across conditions = redistribution is structural\")\n",
    "print(f\"  Oracle KL > Random KL = oracle causes content-specific redistribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Probe D — Representation shift magnitude\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE D: REPRESENTATION SHIFT MAGNITUDE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"L2 distance between bare and prefixed doc token representations.\\n\")\n",
    "\n",
    "print(f\"{'Layer':>6} {'oracle L2':>12} {'random L2':>12} {'repeat L2':>12} \"\n",
    "      f\"{'orc/rand':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for l in HIDDEN_LAYERS:\n",
    "    vals = [f\"  {l:>4}\"]\n",
    "    o_shift = np.mean(probe_d_shift['oracle_trunc'][l])\n",
    "    r_shift = np.mean(probe_d_shift['random_matched_trunc'][l])\n",
    "    t_shift = np.mean(probe_d_shift['repeat_the_trunc'][l])\n",
    "    ratio = o_shift / r_shift if r_shift > 0 else 0\n",
    "    vals.append(f\"{o_shift:>12.4f}\")\n",
    "    vals.append(f\"{r_shift:>12.4f}\")\n",
    "    vals.append(f\"{t_shift:>12.4f}\")\n",
    "    vals.append(f\"{ratio:>10.2f}x\")\n",
    "    print(\" \".join(vals))\n",
    "\n",
    "# Does shift grow with layer depth?\n",
    "print(f\"\\n--- Shift growth across layers ---\")\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    shifts = [np.mean(probe_d_shift[c][l]) for l in HIDDEN_LAYERS\n",
    "              if probe_d_shift[c][l]]\n",
    "    if len(shifts) >= 2:\n",
    "        ratio = shifts[-1] / shifts[0] if shifts[0] > 0 else 0\n",
    "        print(f\"  {c}: first layer={shifts[0]:.4f}, last layer={shifts[-1]:.4f}, \"\n",
    "              f\"ratio={ratio:.1f}x\")\n",
    "\n",
    "# Position-dependent shift\n",
    "print(f\"\\n--- Position-dependent shift (last hidden layer) ---\")\n",
    "last_l = HIDDEN_LAYERS[-1]\n",
    "print(f\"Position bin: 0=start of doc, 9=end of doc\")\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    data = probe_d_by_position[c][last_l]\n",
    "    if data and all(len(d) == N_POS_BINS for d in data):\n",
    "        arr = np.array(data).mean(axis=0)\n",
    "        print(f\"  {c}: \" + \" \".join(f\"{v:.3f}\" for v in arr))\n",
    "\n",
    "# Statistical test: does oracle shift MORE than random?\n",
    "print(f\"\\n--- Oracle vs Random shift magnitude ---\")\n",
    "for l in HIDDEN_LAYERS:\n",
    "    o_arr = np.array(probe_d_shift['oracle_trunc'][l])\n",
    "    r_arr = np.array(probe_d_shift['random_matched_trunc'][l])\n",
    "    if len(o_arr) > 1 and len(r_arr) > 1:\n",
    "        diff = o_arr - r_arr\n",
    "        d = cohens_d(diff)\n",
    "        _, p = stats.ttest_1samp(diff, 0)\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        print(f\"  Layer {l}: d={d:+.3f}, p={p:.2e} {sig}\")\n",
    "\n",
    "print(f\"\\nKey question: if oracle and random shift by SIMILAR amounts,\")\n",
    "print(f\"  the shift is structural. If oracle shifts MORE, there's a semantic component.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Probe E — Representation shift direction\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE E: REPRESENTATION SHIFT DIRECTION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Cosine similarity between shift vectors: (h_oracle - h_bare) vs (h_X - h_bare)\")\n",
    "print(\"High cosine = all prefixes push in same direction (structural)\")\n",
    "print(\"Low cosine = different prefixes push differently (semantic)\\n\")\n",
    "\n",
    "print(f\"{'Layer':>6} {'rand vs orc':>14} {'repeat vs orc':>16} {'interpretation':>20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for l in HIDDEN_LAYERS:\n",
    "    vals = [f\"  {l:>4}\"]\n",
    "    cosines = {}\n",
    "    for c in ['random_matched_trunc', 'repeat_the_trunc']:\n",
    "        if probe_e_cosine[c][l]:\n",
    "            cos_mean = np.mean(probe_e_cosine[c][l])\n",
    "            cosines[c] = cos_mean\n",
    "            vals.append(f\"{cos_mean:>14.4f}\")\n",
    "        else:\n",
    "            vals.append(f\"{'N/A':>14}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if cosines:\n",
    "        avg_cos = np.mean(list(cosines.values()))\n",
    "        if avg_cos > 0.7:\n",
    "            interp = \"STRUCTURAL\"\n",
    "        elif avg_cos > 0.3:\n",
    "            interp = \"MIXED\"\n",
    "        else:\n",
    "            interp = \"SEMANTIC\"\n",
    "        vals.append(f\"{interp:>20}\")\n",
    "    print(\" \".join(vals))\n",
    "\n",
    "# Distribution across samples (for the last full-attention layer)\n",
    "print(f\"\\n--- Distribution across samples (layer {full_attn_layers[-1]}) ---\")\n",
    "target_l = full_attn_layers[-1]\n",
    "for c in ['random_matched_trunc', 'repeat_the_trunc']:\n",
    "    if probe_e_cosine[c][target_l]:\n",
    "        arr = np.array(probe_e_cosine[c][target_l])\n",
    "        print(f\"  {c}:\")\n",
    "        print(f\"    mean={arr.mean():.4f}, std={arr.std():.4f}\")\n",
    "        pcts = np.percentile(arr, [10, 25, 50, 75, 90])\n",
    "        print(f\"    10th={pcts[0]:.3f}, 25th={pcts[1]:.3f}, median={pcts[2]:.3f}, \"\n",
    "              f\"75th={pcts[3]:.3f}, 90th={pcts[4]:.3f}\")\n",
    "        print(f\"    % > 0.5: {100*np.mean(arr > 0.5):.1f}%\")\n",
    "        print(f\"    % > 0.7: {100*np.mean(arr > 0.7):.1f}%\")\n",
    "\n",
    "# Cosine between random and repeat_the shifts (both non-oracle)\n",
    "print(f\"\\n--- random vs repeat_the shift direction ---\")\n",
    "for l in HIDDEN_LAYERS:\n",
    "    r_cos = probe_e_cosine.get('random_matched_trunc', {}).get(l, [])\n",
    "    t_cos = probe_e_cosine.get('repeat_the_trunc', {}).get(l, [])\n",
    "    if r_cos and t_cos:\n",
    "        # Both are vs oracle. If both have high cosine with oracle,\n",
    "        # they also have high cosine with each other.\n",
    "        r_mean = np.mean(r_cos)\n",
    "        t_mean = np.mean(t_cos)\n",
    "        print(f\"  Layer {l}: random-vs-oracle={r_mean:.4f}, \"\n",
    "              f\"repeat-vs-oracle={t_mean:.4f}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "overall_cos = []\n",
    "for c in ['random_matched_trunc', 'repeat_the_trunc']:\n",
    "    for l in HIDDEN_LAYERS:\n",
    "        if probe_e_cosine[c][l]:\n",
    "            overall_cos.append(np.mean(probe_e_cosine[c][l]))\n",
    "if overall_cos:\n",
    "    avg = np.mean(overall_cos)\n",
    "    print(f\"  Overall mean cosine: {avg:.4f}\")\n",
    "    if avg > 0.7:\n",
    "        print(f\"  --> Shift is overwhelmingly STRUCTURAL (same direction regardless of prefix)\")\n",
    "    elif avg > 0.3:\n",
    "        print(f\"  --> MIXED: partially structural, partially content-dependent\")\n",
    "    else:\n",
    "        print(f\"  --> Shift is content-DEPENDENT (different prefixes push differently)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Probe F — Attention sink analysis\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBE F: ATTENTION SINK ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Which positions absorb the most attention from other tokens?\")\n",
    "print(\"Do prefix tokens take over the 'sink' role?\\n\")\n",
    "\n",
    "# Bare: which positions are sinks?\n",
    "print(\"--- Bare condition: top sink positions ---\")\n",
    "for l in full_attn_layers:\n",
    "    data = probe_f_received['bare'][l]\n",
    "    if not data:\n",
    "        continue\n",
    "    # Average first-position attention received\n",
    "    first_vals = [d['first_pos_val'] for d in data]\n",
    "    mean_vals = [d['mean_val'] for d in data]\n",
    "    first_mean = np.mean(first_vals)\n",
    "    avg_mean = np.mean(mean_vals)\n",
    "    ratio = first_mean / avg_mean if avg_mean > 0 else 0\n",
    "    print(f\"  Layer {l}: first_pos receives {first_mean:.4f} \"\n",
    "          f\"(avg pos receives {avg_mean:.4f}), ratio={ratio:.1f}x\")\n",
    "\n",
    "# Prefixed: do prefix tokens absorb attention?\n",
    "print(f\"\\n--- Prefixed conditions: prefix vs doc attention received ---\")\n",
    "print(f\"{'Layer':>6} {'Condition':>26} {'prefix recv':>14} {'doc recv':>12} \"\n",
    "      f\"{'prefix/doc':>12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for l in full_attn_layers:\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        data = probe_f_received[c][l]\n",
    "        if not data:\n",
    "            continue\n",
    "        p_recv = np.mean([d['prefix_mean_recv'] for d in data])\n",
    "        d_recv = np.mean([d['doc_mean_recv'] for d in data])\n",
    "        ratio = p_recv / d_recv if d_recv > 0 else 0\n",
    "        print(f\"  {l:>4}  {c:>26} {p_recv:>14.4f} {d_recv:>12.4f} {ratio:>12.1f}x\")\n",
    "\n",
    "# Does prefix absorb MORE attention for oracle vs random?\n",
    "print(f\"\\n--- Oracle vs Random prefix attention received ---\")\n",
    "for l in full_attn_layers:\n",
    "    o_data = probe_f_prefix_received['oracle_trunc'][l]\n",
    "    r_data = probe_f_prefix_received['random_matched_trunc'][l]\n",
    "    if len(o_data) > 1 and len(r_data) > 1:\n",
    "        o_arr = np.array(o_data)\n",
    "        r_arr = np.array(r_data)\n",
    "        diff = o_arr - r_arr\n",
    "        d = cohens_d(diff)\n",
    "        _, p = stats.ttest_1samp(diff, 0)\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        winner = \"oracle\" if d > 0 else \"random\"\n",
    "        print(f\"  Layer {l}: d={d:+.3f}, p={p:.2e} {sig} [{winner} receives more]\")\n",
    "\n",
    "# Sink transfer: in bare, position 0 is often the sink.\n",
    "# With prefix, does position 0 of the prefix take over?\n",
    "print(f\"\\n--- Sink transfer hypothesis ---\")\n",
    "for l in full_attn_layers:\n",
    "    bare_data = probe_f_received['bare'][l]\n",
    "    pref_data = probe_f_received['oracle_trunc'][l]\n",
    "    if bare_data and pref_data:\n",
    "        bare_first = np.mean([d['first_pos_val'] for d in bare_data])\n",
    "        pref_prefix = np.mean([d['prefix_mean_recv'] for d in pref_data])\n",
    "        pref_doc_first = np.mean([d['doc_mean_recv'] for d in pref_data])\n",
    "        print(f\"  Layer {l}: bare pos0={bare_first:.4f}, \"\n",
    "              f\"prefixed prefix_mean={pref_prefix:.4f}, \"\n",
    "              f\"prefixed doc_mean={pref_doc_first:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8217e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Synthesis + save results\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SYNTHESIS: ATTENTION MECHANISM PROBING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ---- NLL cross-reference with Exp 3D ----\n",
    "bare_nlls = np.array(nll_scores['bare'])\n",
    "oracle_nlls = np.array(nll_scores['oracle_trunc'])\n",
    "oracle_benefit = bare_nlls - oracle_nlls\n",
    "\n",
    "print(f\"\\n1. NLL CROSS-REFERENCE:\")\n",
    "print(f\"   bare NLL:   {bare_nlls.mean():.4f}\")\n",
    "print(f\"   oracle NLL: {oracle_nlls.mean():.4f}\")\n",
    "print(f\"   headroom:   {oracle_benefit.mean():+.4f} (d={cohens_d(oracle_benefit):+.3f})\")\n",
    "print(f\"   (Should match Exp 3D results)\")\n",
    "\n",
    "# ---- Probe A summary ----\n",
    "print(f\"\\n2. PROBE A — ATTENTION MASS ON PREFIX:\")\n",
    "for l in full_attn_layers:\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        if probe_a_mass[c][l]:\n",
    "            mass = np.array(probe_a_mass[c][l]).mean()\n",
    "            cname = c.replace('_trunc', '')\n",
    "            print(f\"   Layer {l} {cname}: {mass:.1%} of doc attention -> prefix\")\n",
    "\n",
    "# ---- Probe B summary ----\n",
    "print(f\"\\n3. PROBE B — ENTROPY CHANGE:\")\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    increases = sum(1 for l in ATTN_LAYERS\n",
    "                    if np.mean(probe_b_entropy[c][l]) > np.mean(probe_b_entropy['bare'][l]))\n",
    "    direction = \"INCREASES\" if increases > len(ATTN_LAYERS)/2 else \"DECREASES\"\n",
    "    print(f\"   {c}: entropy {direction} in {increases}/{len(ATTN_LAYERS)} layers\")\n",
    "\n",
    "# ---- Probe C summary ----\n",
    "print(f\"\\n4. PROBE C — DOC-DOC REDISTRIBUTION:\")\n",
    "for l in full_attn_layers:\n",
    "    o_kl = np.mean(probe_c_kl['oracle_trunc'][l]) if probe_c_kl['oracle_trunc'][l] else 0\n",
    "    r_kl = np.mean(probe_c_kl['random_matched_trunc'][l]) if probe_c_kl['random_matched_trunc'][l] else 0\n",
    "    print(f\"   Layer {l}: oracle KL={o_kl:.4f}, random KL={r_kl:.4f}, \"\n",
    "          f\"ratio={o_kl/r_kl:.2f}x\" if r_kl > 0 else f\"   Layer {l}: oracle KL={o_kl:.4f}\")\n",
    "\n",
    "# ---- Probe D summary ----\n",
    "print(f\"\\n5. PROBE D — SHIFT MAGNITUDE:\")\n",
    "last_l = HIDDEN_LAYERS[-1]\n",
    "for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "    if probe_d_shift[c][last_l]:\n",
    "        shift = np.mean(probe_d_shift[c][last_l])\n",
    "        print(f\"   Last layer ({last_l}) {c}: mean L2={shift:.4f}\")\n",
    "o_shift = np.mean(probe_d_shift['oracle_trunc'][last_l])\n",
    "r_shift = np.mean(probe_d_shift['random_matched_trunc'][last_l])\n",
    "if r_shift > 0:\n",
    "    print(f\"   Oracle/Random ratio: {o_shift/r_shift:.2f}x\")\n",
    "\n",
    "# ---- Probe E summary ----\n",
    "print(f\"\\n6. PROBE E — SHIFT DIRECTION (structural vs semantic):\")\n",
    "for l in HIDDEN_LAYERS:\n",
    "    cosines = []\n",
    "    for c in ['random_matched_trunc', 'repeat_the_trunc']:\n",
    "        if probe_e_cosine[c][l]:\n",
    "            cosines.append(np.mean(probe_e_cosine[c][l]))\n",
    "    if cosines:\n",
    "        avg = np.mean(cosines)\n",
    "        label = \"STRUCTURAL\" if avg > 0.7 else \"MIXED\" if avg > 0.3 else \"SEMANTIC\"\n",
    "        print(f\"   Layer {l}: mean cosine={avg:.4f} [{label}]\")\n",
    "\n",
    "# ---- Probe F summary ----\n",
    "print(f\"\\n7. PROBE F — ATTENTION SINKS:\")\n",
    "for l in full_attn_layers:\n",
    "    if (probe_f_received['bare'][l] and\n",
    "            probe_f_received['oracle_trunc'][l]):\n",
    "        bare_first = np.mean([d['first_pos_val']\n",
    "                              for d in probe_f_received['bare'][l]])\n",
    "        pref_prefix = np.mean([d['prefix_mean_recv']\n",
    "                               for d in probe_f_received['oracle_trunc'][l]])\n",
    "        print(f\"   Layer {l}: bare sink={bare_first:.4f}, \"\n",
    "              f\"prefix absorbs={pref_prefix:.4f}\")\n",
    "\n",
    "# ---- Overall interpretation ----\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"INTERPRETATION:\")\n",
    "\n",
    "# Determine dominant mechanism\n",
    "# Check if shifts are structural (probe E cosine > 0.7)\n",
    "mean_cosines = []\n",
    "for c in ['random_matched_trunc', 'repeat_the_trunc']:\n",
    "    for l in HIDDEN_LAYERS:\n",
    "        if probe_e_cosine[c][l]:\n",
    "            mean_cosines.append(np.mean(probe_e_cosine[c][l]))\n",
    "overall_cos = np.mean(mean_cosines) if mean_cosines else 0\n",
    "\n",
    "# Check if entropy increases or decreases\n",
    "ent_increases = 0\n",
    "ent_total = 0\n",
    "for l in full_attn_layers:\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        bare_ent = np.mean(probe_b_entropy['bare'][l])\n",
    "        cond_ent = np.mean(probe_b_entropy[c][l])\n",
    "        ent_total += 1\n",
    "        if cond_ent > bare_ent:\n",
    "            ent_increases += 1\n",
    "ent_direction = \"increases\" if ent_increases > ent_total / 2 else \"decreases\"\n",
    "\n",
    "# Check prefix attention mass\n",
    "mean_mass = []\n",
    "for l in full_attn_layers:\n",
    "    for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']:\n",
    "        if probe_a_mass[c][l]:\n",
    "            mean_mass.append(np.array(probe_a_mass[c][l]).mean())\n",
    "overall_mass = np.mean(mean_mass) if mean_mass else 0\n",
    "\n",
    "print(f\"\\n  Hypothesis 1 (Attention redistribution):\")\n",
    "print(f\"    Prefix absorbs {overall_mass:.1%} of doc token attention (full-attn layers)\")\n",
    "print(f\"    Entropy {ent_direction} -> {'dilution/regularization' if ent_direction == 'increases' else 'focusing'}\")\n",
    "\n",
    "print(f\"\\n  Hypothesis 2 (RoPE position shift):\")\n",
    "print(f\"    If dominant, shift magnitude would scale with prefix length\")\n",
    "print(f\"    and direction would differ by prefix type.\")\n",
    "print(f\"    Shift direction cosine: {overall_cos:.4f} \"\n",
    "      f\"({'consistent = not RoPE-driven' if overall_cos > 0.5 else 'divergent = possibly RoPE-driven'})\")\n",
    "\n",
    "print(f\"\\n  Hypothesis 3 (Representation regularization):\")\n",
    "o_last = np.mean(probe_d_shift['oracle_trunc'][last_l])\n",
    "r_last = np.mean(probe_d_shift['random_matched_trunc'][last_l])\n",
    "t_last = np.mean(probe_d_shift['repeat_the_trunc'][last_l])\n",
    "print(f\"    Shift magnitudes: oracle={o_last:.4f}, random={r_last:.4f}, \"\n",
    "      f\"repeat={t_last:.4f}\")\n",
    "if r_last > 0:\n",
    "    print(f\"    Oracle/Random: {o_last/r_last:.2f}x (1.0 = purely structural)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# Save results\n",
    "final_results = {\n",
    "    'experiment': 'exp03e_attention_probing',\n",
    "    'model': MODEL_NAME,\n",
    "    'dataset': 'neural-bridge/rag-dataset-12000',\n",
    "    'n_samples': N_SAMPLES,\n",
    "    'attn_implementation': 'eager',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'architecture': {\n",
    "        'n_layers': n_layers,\n",
    "        'full_attn_layers': full_attn_layers,\n",
    "        'attn_probe_layers': ATTN_LAYERS,\n",
    "        'hidden_probe_layers': HIDDEN_LAYERS,\n",
    "    },\n",
    "    'nll_crossref': {\n",
    "        'bare_nll': float(bare_nlls.mean()),\n",
    "        'oracle_nll': float(oracle_nlls.mean()),\n",
    "        'oracle_d': float(cohens_d(oracle_benefit)),\n",
    "    },\n",
    "    'probe_a_prefix_mass': {\n",
    "        c: {str(l): float(np.array(probe_a_mass[c][l]).mean())\n",
    "            for l in full_attn_layers if probe_a_mass[c][l]}\n",
    "        for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']\n",
    "    },\n",
    "    'probe_b_entropy': {\n",
    "        c: {str(l): float(np.mean(probe_b_entropy[c][l]))\n",
    "            for l in ATTN_LAYERS if probe_b_entropy[c][l]}\n",
    "        for c in COND_NAMES\n",
    "    },\n",
    "    'probe_c_kl': {\n",
    "        c: {str(l): float(np.mean(probe_c_kl[c][l]))\n",
    "            for l in ATTN_LAYERS if probe_c_kl[c][l]}\n",
    "        for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']\n",
    "    },\n",
    "    'probe_d_shift': {\n",
    "        c: {str(l): float(np.mean(probe_d_shift[c][l]))\n",
    "            for l in HIDDEN_LAYERS if probe_d_shift[c][l]}\n",
    "        for c in ['oracle_trunc', 'random_matched_trunc', 'repeat_the_trunc']\n",
    "    },\n",
    "    'probe_e_cosine': {\n",
    "        c: {str(l): float(np.mean(probe_e_cosine[c][l]))\n",
    "            for l in HIDDEN_LAYERS if probe_e_cosine[c][l]}\n",
    "        for c in ['random_matched_trunc', 'repeat_the_trunc']\n",
    "    },\n",
    "    'probe_e_overall_cosine': float(overall_cos),\n",
    "    'interpretation': {\n",
    "        'prefix_mass_pct': float(overall_mass),\n",
    "        'entropy_direction': ent_direction,\n",
    "        'shift_direction_cosine': float(overall_cos),\n",
    "        'shift_structural': bool(overall_cos > 0.7),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\nCleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, processor, tokenizer, encoder_text\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
