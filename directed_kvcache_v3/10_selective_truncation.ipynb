{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7e2cd1",
   "metadata": {},
   "source": [
    "# Experiment 10: Selective Truncation## Does letting the decoder see keyword tokens help beyond standard truncation?### MotivationExp 01 established that truncation (masking prefix from decoder cross-attention) isstrictly better than full visibility:- `oracle_full` (decoder sees query + doc): d=+0.345- `oracle_trunc` (decoder sees doc only): d=+0.408The decoder reading ALL prefix tokens creates noise/interference. But what aboutreading JUST the keyword? The encoder gets full structural + semantic enrichmentvia bidirectional attention, and the decoder gets targeted value access to thesingle most informative token.### Key idea: selective cross-attention masking```Encoder input:   [prefix tokens] [document tokens]Standard trunc:  [masked........] [visible........]Selective:       [masked.][KW][.] [visible........]                          ^^^^                    keyword unmasked```### Conditions (10)| # | Condition | Encoder prefix | Decoder sees | Purpose ||---|-----------|---------------|-------------|---------|| 1 | bare | (none) | doc only | lower bound || 2 | oracle\\_trunc | query | doc only | upper bound (Exp 01) || 3 | oracle\\_full | query | query + doc | Exp 01 comparison || 4 | oracle\\_kw\\_visible | query | top query keyword + doc | **KEY TEST** || 5 | template\\_trunc | \"What is [kw]?\" | doc only | Exp 02 best || 6 | template\\_kw\\_visible | \"What is [kw]?\" | [kw] + doc | **KEY TEST** || 7 | pad\\_kw\\_trunc | \"the the the [kw]\" | doc only | structural + vocab || 8 | pad\\_kw\\_kw\\_visible | \"the the the [kw]\" | [kw] + doc | **KEY TEST** || 9 | random\\_trunc | random text | doc only | structural control || 10 | keyword\\_only\\_visible | [kw] | [kw] + doc | minimal prefix + direct access |### Key comparisons- `oracle_trunc` vs `oracle_kw_visible`: does seeing 1 keyword help beyond truncation?- `template_trunc` vs `template_kw_visible`: same for doc-derived heuristic- `pad_kw_trunc` vs `pad_kw_kw_visible`: structural + vocab enrichment + direct access?- `oracle_trunc` vs `oracle_full`: replicates Exp 01 (trunc > full)### N=500 (same samples as Exp 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb783e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:31.481676Z",
     "iopub.status.busy": "2026-02-19T13:00:31.481072Z",
     "iopub.status.idle": "2026-02-19T13:00:35.988673Z",
     "shell.execute_reply": "2026-02-19T13:00:35.987764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 10: Selective Truncation\n",
      "Model: google/t5gemma-2-4b-4b\n",
      "N: 500\n",
      "Bonferroni comparisons: 9\n",
      "CUDA: NVIDIA A100-SXM4-40GB\n",
      "GPU memory: 42.3 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp10\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "N_SAMPLES = 500\n",
    "MODEL_NAME = \"google/t5gemma-2-4b-4b\"\n",
    "N_BONFERRONI = 9  # 9 non-bare conditions\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "print(f\"Exp 10: Selective Truncation\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"N: {N_SAMPLES}\")\n",
    "print(f\"Bonferroni comparisons: {N_BONFERRONI}\")\n",
    "print(f\"CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0553af27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:35.992657Z",
     "iopub.status.busy": "2026-02-19T13:00:35.991846Z",
     "iopub.status.idle": "2026-02-19T13:00:52.115255Z",
     "shell.execute_reply": "2026-02-19T13:00:52.114562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/t5gemma-2-4b-4b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a56b50c1bb4519bb8a4a621549abed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.bfloat16\n",
      "GPU memory used: 15.02 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load model\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "print(f\"Model loaded. dtype={next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory used: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ababdf98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:52.118695Z",
     "iopub.status.busy": "2026-02-19T13:00:52.118270Z",
     "iopub.status.idle": "2026-02-19T13:00:52.135748Z",
     "shell.execute_reply": "2026-02-19T13:00:52.135112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers defined.\n",
      "  score_nll_selective: supports visible_positions for keyword unmasking\n",
      "  find_keyword_positions: locates keyword tokens within prefix\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Scoring helpers with selective visibility\n",
    "\n",
    "def score_nll_selective(encoder_text, answer_text, prefix_token_count=0,\n",
    "                        truncate=False, visible_positions=None):\n",
    "    # Score NLL of answer tokens with optional truncation and selective visibility.\n",
    "    #\n",
    "    # Args:\n",
    "    #   encoder_text: Full text for encoder (e.g., \"[prefix]\\n[document]\")\n",
    "    #   answer_text: Answer text for decoder\n",
    "    #   prefix_token_count: Number of prefix tokens to potentially mask\n",
    "    #   truncate: If True, mask all prefix tokens from decoder cross-attention\n",
    "    #   visible_positions: List of prefix positions to UNMASK (override truncation).\n",
    "    #       Only used when truncate=True. These positions within the prefix\n",
    "    #       remain visible to the decoder.\n",
    "    enc_ids = tokenizer(encoder_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids.to(DEVICE)\n",
    "    total_enc_len = enc_ids.shape[1]\n",
    "\n",
    "    # Full mask for encoder (bidirectional, sees everything)\n",
    "    enc_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.get_encoder()(\n",
    "            input_ids=enc_ids, attention_mask=enc_mask\n",
    "        )\n",
    "\n",
    "    # Build cross-attention mask for decoder\n",
    "    if truncate and prefix_token_count > 0:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "        cross_attn_mask[:, :prefix_token_count] = 0\n",
    "        # Selectively unmask keyword positions\n",
    "        if visible_positions:\n",
    "            for pos in visible_positions:\n",
    "                if 0 <= pos < prefix_token_count:\n",
    "                    cross_attn_mask[:, pos] = 1\n",
    "    else:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    ans_ids = tokenizer(answer_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=False, truncation=True,\n",
    "                        max_length=256).input_ids.to(DEVICE)\n",
    "\n",
    "    if ans_ids.shape[1] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            attention_mask=cross_attn_mask,\n",
    "            labels=ans_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_log_probs = log_probs[0].gather(1, ans_ids[0].unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "\n",
    "    del encoder_outputs, outputs, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "\n",
    "def count_prefix_tokens(prefix_text, document_text):\n",
    "    # Count how many tokens the prefix occupies in [prefix + newline + document].\n",
    "    full_text = prefix_text + \"\\n\" + document_text\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True).input_ids\n",
    "    return len(full_ids) - len(doc_ids)\n",
    "\n",
    "\n",
    "def find_keyword_positions(full_text, keyword, document_text):\n",
    "    # Find the token positions of `keyword` within the prefix portion of full_text.\n",
    "    #\n",
    "    # Returns: (n_prefix, kw_positions)\n",
    "    #   n_prefix: number of prefix tokens\n",
    "    #   kw_positions: list of token indices within the prefix that correspond to keyword\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True).input_ids\n",
    "    n_prefix = len(full_ids) - len(doc_ids)\n",
    "\n",
    "    kw_ids = tokenizer(keyword, add_special_tokens=False).input_ids\n",
    "    prefix_ids = full_ids[:n_prefix]\n",
    "\n",
    "    positions = []\n",
    "    if len(kw_ids) == 0:\n",
    "        return n_prefix, positions\n",
    "\n",
    "    # Search for keyword token sequence within prefix\n",
    "    for i in range(len(prefix_ids) - len(kw_ids) + 1):\n",
    "        if prefix_ids[i:i + len(kw_ids)] == kw_ids:\n",
    "            positions = list(range(i, i + len(kw_ids)))\n",
    "            break\n",
    "\n",
    "    # Fallback: if exact match fails, try matching just the first kw token\n",
    "    if not positions and len(kw_ids) > 0:\n",
    "        for i in range(len(prefix_ids)):\n",
    "            if prefix_ids[i] == kw_ids[0]:\n",
    "                positions = [i]\n",
    "                break\n",
    "\n",
    "    return n_prefix, positions\n",
    "\n",
    "\n",
    "# === Surrogate generation ===\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text.lower()).split()\n",
    "    return [w for w in words if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "def get_top_keyword(text):\n",
    "    # Get the single most frequent content word from text.\n",
    "    content_words = extract_keywords(text)\n",
    "    if not content_words:\n",
    "        return \"information\"\n",
    "    counts = Counter(content_words)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "def make_surrogate_template(passage):\n",
    "    kw = get_top_keyword(passage)\n",
    "    return f\"What is {kw}?\", kw\n",
    "\n",
    "print(\"Helpers defined.\")\n",
    "print(\"  score_nll_selective: supports visible_positions for keyword unmasking\")\n",
    "print(\"  find_keyword_positions: locates keyword tokens within prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d0de16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:52.138558Z",
     "iopub.status.busy": "2026-02-19T13:00:52.138282Z",
     "iopub.status.idle": "2026-02-19T13:00:53.682903Z",
     "shell.execute_reply": "2026-02-19T13:00:53.682171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO v1.1 validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 02 alignment check: 20/20 queries match\n",
      "Selected 500 samples\n",
      "Mean words: 74\n",
      "Sample keywords: ['alveoli', 'wall', 'registered', 'oregon', 'degrees']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load MS MARCO data (same 500 as Exp 02) + precompute keywords\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading MS MARCO v1.1 validation...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "samples = []\n",
    "for item in ds:\n",
    "    if len(samples) >= N_SAMPLES * 3:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            samples.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc,\n",
    "            })\n",
    "            break\n",
    "\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(samples)\n",
    "samples = samples[:N_SAMPLES]\n",
    "del ds\n",
    "gc.collect()\n",
    "\n",
    "# Verify alignment with Exp 02\n",
    "EXP02_CHECKPOINT = Path(\"results/exp02/checkpoint.json\")\n",
    "if EXP02_CHECKPOINT.exists():\n",
    "    exp02_ckpt = json.loads(EXP02_CHECKPOINT.read_text())\n",
    "    exp02_results = exp02_ckpt.get('results', [])\n",
    "    matched = 0\n",
    "    for i in range(min(20, len(exp02_results))):\n",
    "        if samples[i]['query'] == exp02_results[i]['query']:\n",
    "            matched += 1\n",
    "    print(f\"Exp 02 alignment check: {matched}/20 queries match\")\n",
    "else:\n",
    "    print(\"Exp 02 checkpoint not found (alignment check skipped)\")\n",
    "\n",
    "# Precompute keywords and surrogates for each sample\n",
    "for i, s in enumerate(samples):\n",
    "    # Top query keyword\n",
    "    query_kws = extract_keywords(s['query'])\n",
    "    s['query_kw'] = query_kws[0] if query_kws else \"information\"\n",
    "\n",
    "    # Document keyword\n",
    "    s['doc_kw'] = get_top_keyword(s['passage'])\n",
    "\n",
    "    # Template surrogate (uses doc keyword)\n",
    "    s['surr_template'], s['template_kw'] = make_surrogate_template(s['passage'])\n",
    "\n",
    "    # Pad + keyword: \"the the the [kw]\"\n",
    "    s['pad_kw'] = \"the the the \" + s['doc_kw']\n",
    "\n",
    "    # Keyword only\n",
    "    s['keyword_only'] = s['doc_kw']\n",
    "\n",
    "    # Random surrogate (from another sample)\n",
    "    other_idx = (i + N_SAMPLES // 2) % len(samples)\n",
    "    other_passage = samples[other_idx]['passage']\n",
    "    s['surr_random'] = \" \".join(other_passage.split()[:20])\n",
    "\n",
    "print(f\"Selected {len(samples)} samples\")\n",
    "print(f\"Mean words: {np.mean([s['word_count'] for s in samples]):.0f}\")\n",
    "print(f\"Sample keywords: {[s['doc_kw'] for s in samples[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d135e114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:53.686324Z",
     "iopub.status.busy": "2026-02-19T13:00:53.685889Z",
     "iopub.status.idle": "2026-02-19T13:00:53.750151Z",
     "shell.execute_reply": "2026-02-19T13:00:53.749461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONDITION EXAMPLES + KEYWORD POSITION VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Query: what is the link between alveoli and capillaries\n",
      "Answer: Diffusion\n",
      "Passage: Gas exchange in the lungs takes place between the blood in the capillary network...\n",
      "Query keyword: 'link'\n",
      "Doc keyword: 'alveoli'\n",
      "  bare                    : enc=[Gas exchange in the lungs takes place between the blood]  dec=[doc only]\n",
      "  oracle_trunc            : enc=[what is the link between alveoli and capillaries | Gas ]  dec=[doc only (prefix masked)]\n",
      "  oracle_full             : enc=[what is the link between alveoli and capillaries | Gas ]  dec=[query + doc (all visible)]\n",
      "  oracle_kw_visible       : enc=[what is the link between alveoli and capillaries | Gas ]  dec=['link' + doc (keyword visible)]\n",
      "  template_trunc          : enc=[What is alveoli? | Gas exchange in the lungs takes plac]  dec=[doc only]\n",
      "  template_kw_visible     : enc=[What is alveoli? | Gas exchange in the lungs takes plac]  dec=['alveoli' + doc]\n",
      "  pad_kw_trunc            : enc=[the the the alveoli | Gas exchange in the lungs takes p]  dec=[doc only]\n",
      "  pad_kw_kw_visible       : enc=[the the the alveoli | Gas exchange in the lungs takes p]  dec=['alveoli' + doc]\n",
      "  random_trunc            : enc=[You are here Donair History. D... | Gas exchange in the]  dec=[doc only]\n",
      "  keyword_only_visible    : enc=[alveoli | Gas exchange in the lungs takes place be...]  dec=['alveoli' + doc (keyword visible)]\n",
      "\n",
      "--- Keyword position verification (first 20 samples) ---\n",
      "  Sample 0 oracle_kw: kw='link', n_prefix=10, positions=[]\n",
      "  Sample 0 template_kw: kw='alveoli', n_prefix=6, positions=[]\n",
      "  Sample 1 oracle_kw: kw='thick', n_prefix=10, positions=[]\n",
      "  Sample 1 template_kw: kw='wall', n_prefix=5, positions=[]\n",
      "  Sample 2 oracle_kw: kw='average', n_prefix=5, positions=[1]\n",
      "  Sample 2 template_kw: kw='registered', n_prefix=5, positions=[]\n",
      "\n",
      "Keyword hit rates (first 20 samples):\n",
      "  oracle_kw: 8/20 (40%)\n",
      "  template_kw: 1/20 (5%)\n",
      "  pad_kw: 1/20 (5%)\n",
      "  keyword_only: 20/20 (100%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Condition examples + keyword position verification\n",
    "print(\"=\" * 70)\n",
    "print(\"CONDITION EXAMPLES + KEYWORD POSITION VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "COND_NAMES = [\n",
    "    'bare', 'oracle_trunc', 'oracle_full', 'oracle_kw_visible',\n",
    "    'template_trunc', 'template_kw_visible',\n",
    "    'pad_kw_trunc', 'pad_kw_kw_visible',\n",
    "    'random_trunc', 'keyword_only_visible',\n",
    "]\n",
    "\n",
    "ex = samples[0]\n",
    "print(f\"\\nQuery: {ex['query'][:80]}\")\n",
    "print(f\"Answer: {ex['answer'][:80]}\")\n",
    "print(f\"Passage: {ex['passage'][:80]}...\")\n",
    "print(f\"Query keyword: '{ex['query_kw']}'\")\n",
    "print(f\"Doc keyword: '{ex['doc_kw']}'\")\n",
    "\n",
    "# Show each condition\n",
    "for cond in COND_NAMES:\n",
    "    if cond == 'bare':\n",
    "        enc = ex['passage'][:60] + \"...\"\n",
    "        dec = \"doc only\"\n",
    "    elif cond == 'oracle_trunc':\n",
    "        enc = ex['query'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = \"doc only (prefix masked)\"\n",
    "    elif cond == 'oracle_full':\n",
    "        enc = ex['query'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = \"query + doc (all visible)\"\n",
    "    elif cond == 'oracle_kw_visible':\n",
    "        enc = ex['query'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = f\"'{ex['query_kw']}' + doc (keyword visible)\"\n",
    "    elif cond == 'template_trunc':\n",
    "        enc = ex['surr_template'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = \"doc only\"\n",
    "    elif cond == 'template_kw_visible':\n",
    "        enc = ex['surr_template'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = f\"'{ex['template_kw']}' + doc\"\n",
    "    elif cond == 'pad_kw_trunc':\n",
    "        enc = ex['pad_kw'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = \"doc only\"\n",
    "    elif cond == 'pad_kw_kw_visible':\n",
    "        enc = ex['pad_kw'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = f\"'{ex['doc_kw']}' + doc\"\n",
    "    elif cond == 'random_trunc':\n",
    "        enc = ex['surr_random'][:30] + \"... | \" + ex['passage'][:30] + \"...\"\n",
    "        dec = \"doc only\"\n",
    "    elif cond == 'keyword_only_visible':\n",
    "        enc = ex['doc_kw'] + \" | \" + ex['passage'][:40] + \"...\"\n",
    "        dec = f\"'{ex['doc_kw']}' + doc (keyword visible)\"\n",
    "    print(f\"  {cond:<24s}: enc=[{enc[:55]}]  dec=[{dec}]\")\n",
    "\n",
    "# Keyword position verification on first 20 samples\n",
    "print(f\"\\n--- Keyword position verification (first 20 samples) ---\")\n",
    "hit_counts = {'oracle_kw': 0, 'template_kw': 0, 'pad_kw': 0, 'keyword_only': 0}\n",
    "total = 20\n",
    "\n",
    "for i in range(total):\n",
    "    s = samples[i]\n",
    "\n",
    "    # oracle_kw_visible: find query keyword in \"query\\npassage\"\n",
    "    full_text = s['query'] + \"\\n\" + s['passage']\n",
    "    n_pfx, positions = find_keyword_positions(full_text, s['query_kw'], s['passage'])\n",
    "    if positions:\n",
    "        hit_counts['oracle_kw'] += 1\n",
    "    if i < 3:\n",
    "        print(f\"  Sample {i} oracle_kw: kw='{s['query_kw']}', n_prefix={n_pfx}, \"\n",
    "              f\"positions={positions}\")\n",
    "\n",
    "    # template_kw_visible: find doc keyword in \"What is [kw]?\\npassage\"\n",
    "    full_text = s['surr_template'] + \"\\n\" + s['passage']\n",
    "    n_pfx, positions = find_keyword_positions(full_text, s['template_kw'], s['passage'])\n",
    "    if positions:\n",
    "        hit_counts['template_kw'] += 1\n",
    "    if i < 3:\n",
    "        print(f\"  Sample {i} template_kw: kw='{s['template_kw']}', n_prefix={n_pfx}, \"\n",
    "              f\"positions={positions}\")\n",
    "\n",
    "    # pad_kw: find doc keyword in \"the the the [kw]\\npassage\"\n",
    "    full_text = s['pad_kw'] + \"\\n\" + s['passage']\n",
    "    n_pfx, positions = find_keyword_positions(full_text, s['doc_kw'], s['passage'])\n",
    "    if positions:\n",
    "        hit_counts['pad_kw'] += 1\n",
    "\n",
    "    # keyword_only: find doc keyword in \"[kw]\\npassage\"\n",
    "    full_text = s['keyword_only'] + \"\\n\" + s['passage']\n",
    "    n_pfx, positions = find_keyword_positions(full_text, s['doc_kw'], s['passage'])\n",
    "    if positions:\n",
    "        hit_counts['keyword_only'] += 1\n",
    "\n",
    "print(f\"\\nKeyword hit rates (first {total} samples):\")\n",
    "for key, count in hit_counts.items():\n",
    "    print(f\"  {key}: {count}/{total} ({100*count/total:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa2f1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:00:53.753301Z",
     "iopub.status.busy": "2026-02-19T13:00:53.753049Z",
     "iopub.status.idle": "2026-02-19T13:18:10.660333Z",
     "shell.execute_reply": "2026-02-19T13:18:10.659655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RUNNING SELECTIVE TRUNCATION EXPERIMENT\n",
      "======================================================================\n",
      "Starting fresh: 10 conditions x 500 samples = 5000 scorings\n",
      "Estimated runtime: ~17 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b496d0bd090c4d0882847f9e9887f6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 20/500 | 0.7m | ETA 16.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 40/500 | 1.4m | ETA 16.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 60/500 | 2.1m | ETA 15.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 80/500 | 2.8m | ETA 14.5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/500 | 3.5m | ETA 13.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 120/500 | 4.1m | ETA 13.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 140/500 | 4.8m | ETA 12.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 160/500 | 5.5m | ETA 11.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 180/500 | 6.2m | ETA 11.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/500 | 6.9m | ETA 10.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 220/500 | 7.6m | ETA 9.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 240/500 | 8.3m | ETA 9.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 260/500 | 9.0m | ETA 8.3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 280/500 | 9.7m | ETA 7.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/500 | 10.4m | ETA 6.9m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 320/500 | 11.1m | ETA 6.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 340/500 | 11.8m | ETA 5.5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 360/500 | 12.4m | ETA 4.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 380/500 | 13.1m | ETA 4.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 400/500 | 13.8m | ETA 3.5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 420/500 | 14.5m | ETA 2.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 440/500 | 15.2m | ETA 2.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 460/500 | 15.9m | ETA 1.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 480/500 | 16.6m | ETA 0.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 500/500 | 17.3m | ETA 0.0m\n",
      "\n",
      "Scoring complete: 500 samples in 17.3 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Scoring loop (10 conditions x 500 samples)\n",
    "print(\"=\" * 70)\n",
    "print(\"RUNNING SELECTIVE TRUNCATION EXPERIMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def build_condition(cond_name, sample):\n",
    "    # Returns (encoder_text, prefix_token_count, truncate, visible_positions)\n",
    "    passage = sample['passage']\n",
    "\n",
    "    if cond_name == 'bare':\n",
    "        return passage, 0, False, None\n",
    "\n",
    "    elif cond_name == 'oracle_trunc':\n",
    "        surr = sample['query']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        ptoks = count_prefix_tokens(surr, passage)\n",
    "        return enc_text, ptoks, True, None\n",
    "\n",
    "    elif cond_name == 'oracle_full':\n",
    "        surr = sample['query']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        return enc_text, 0, False, None\n",
    "\n",
    "    elif cond_name == 'oracle_kw_visible':\n",
    "        surr = sample['query']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        n_pfx, kw_pos = find_keyword_positions(enc_text, sample['query_kw'], passage)\n",
    "        return enc_text, n_pfx, True, kw_pos if kw_pos else None\n",
    "\n",
    "    elif cond_name == 'template_trunc':\n",
    "        surr = sample['surr_template']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        ptoks = count_prefix_tokens(surr, passage)\n",
    "        return enc_text, ptoks, True, None\n",
    "\n",
    "    elif cond_name == 'template_kw_visible':\n",
    "        surr = sample['surr_template']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        n_pfx, kw_pos = find_keyword_positions(enc_text, sample['template_kw'], passage)\n",
    "        return enc_text, n_pfx, True, kw_pos if kw_pos else None\n",
    "\n",
    "    elif cond_name == 'pad_kw_trunc':\n",
    "        surr = sample['pad_kw']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        ptoks = count_prefix_tokens(surr, passage)\n",
    "        return enc_text, ptoks, True, None\n",
    "\n",
    "    elif cond_name == 'pad_kw_kw_visible':\n",
    "        surr = sample['pad_kw']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        n_pfx, kw_pos = find_keyword_positions(enc_text, sample['doc_kw'], passage)\n",
    "        return enc_text, n_pfx, True, kw_pos if kw_pos else None\n",
    "\n",
    "    elif cond_name == 'random_trunc':\n",
    "        surr = sample['surr_random']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        ptoks = count_prefix_tokens(surr, passage)\n",
    "        return enc_text, ptoks, True, None\n",
    "\n",
    "    elif cond_name == 'keyword_only_visible':\n",
    "        surr = sample['keyword_only']\n",
    "        enc_text = surr + \"\\n\" + passage\n",
    "        n_pfx, kw_pos = find_keyword_positions(enc_text, sample['doc_kw'], passage)\n",
    "        return enc_text, n_pfx, True, kw_pos if kw_pos else None\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown condition: {cond_name}\")\n",
    "\n",
    "\n",
    "# Resume from checkpoint\n",
    "all_results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    ckpt = json.loads(CHECKPOINT_PATH.read_text())\n",
    "    if ckpt.get('n_total') == N_SAMPLES and len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            all_results = ckpt['results']\n",
    "            start_idx = len(all_results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    total_calls = len(COND_NAMES) * N_SAMPLES\n",
    "    print(f\"Starting fresh: {len(COND_NAMES)} conditions x {N_SAMPLES} samples \"\n",
    "          f\"= {total_calls} scorings\")\n",
    "    print(f\"Estimated runtime: ~{total_calls * 0.2 / 60:.0f} min\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Scoring\"):\n",
    "    s = samples[i]\n",
    "    result = {\n",
    "        'query': s['query'],\n",
    "        'answer': s['answer'],\n",
    "        'passage_words': s['word_count'],\n",
    "        'query_kw': s['query_kw'],\n",
    "        'doc_kw': s['doc_kw'],\n",
    "    }\n",
    "\n",
    "    for cond_name in COND_NAMES:\n",
    "        enc_text, ptoks, trunc, vis_pos = build_condition(cond_name, s)\n",
    "        nll = score_nll_selective(enc_text, s['answer'], ptoks, trunc, vis_pos)\n",
    "        result[f'nll_{cond_name}'] = nll\n",
    "\n",
    "        # Track keyword hit for _kw_visible conditions\n",
    "        if vis_pos is not None:\n",
    "            result[f'kw_hit_{cond_name}'] = True\n",
    "            result[f'kw_ntoks_{cond_name}'] = len(vis_pos)\n",
    "        elif cond_name.endswith('_visible'):\n",
    "            result[f'kw_hit_{cond_name}'] = False\n",
    "            result[f'kw_ntoks_{cond_name}'] = 0\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "    if (i + 1) % 20 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'results': all_results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CHECKPOINT_PATH.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = i - start_idx + 1\n",
    "        eta = (N_SAMPLES - i - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {i+1}/{N_SAMPLES} | {elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nScoring complete: {len(all_results)} samples in {elapsed/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154b253a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.663821Z",
     "iopub.status.busy": "2026-02-19T13:18:10.663363Z",
     "iopub.status.idle": "2026-02-19T13:18:10.683051Z",
     "shell.execute_reply": "2026-02-19T13:18:10.682422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESULTS: All Conditions vs Bare (N=500)\n",
      "======================================================================\n",
      "\n",
      "Condition                  Mean NLL    vs Bare        d     Win%            p   sig\n",
      "----------------------------------------------------------------------------------\n",
      "bare                         3.6765         --       --       --           --    --\n",
      "oracle_trunc                 2.9929    +0.6836   +0.376    92.6%     4.79e-16   ***\n",
      "oracle_full                  3.3047    +0.3718   +0.338    82.2%     1.84e-13   ***\n",
      "oracle_kw_visible            3.0050    +0.6715   +0.369    92.4%     1.42e-15   ***\n",
      "template_trunc               3.1173    +0.5592   +0.336    90.8%     2.63e-13   ***\n",
      "template_kw_visible          3.1173    +0.5592   +0.336    90.8%     2.63e-13   ***\n",
      "pad_kw_trunc                 3.1628    +0.5136   +0.308    87.0%     1.66e-11   ***\n",
      "pad_kw_kw_visible            3.1629    +0.5136   +0.308    86.8%     1.67e-11   ***\n",
      "random_trunc                 3.1432    +0.5333   +0.303    87.6%     3.61e-11   ***\n",
      "keyword_only_visible         3.1955    +0.4810   +0.255    84.8%     2.04e-08   ***\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Main results table\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"RESULTS: All Conditions vs Bare (N={len(all_results)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "bare_nlls = np.array([r['nll_bare'] for r in all_results])\n",
    "\n",
    "print(f\"\\n{'Condition':<24} {'Mean NLL':>10} {'vs Bare':>10} {'d':>8} {'Win%':>8} \"\n",
    "      f\"{'p':>12} {'sig':>5}\")\n",
    "print(\"-\" * 82)\n",
    "\n",
    "analysis = {}\n",
    "\n",
    "for cond in COND_NAMES:\n",
    "    nlls = np.array([r[f'nll_{cond}'] for r in all_results])\n",
    "    mean_nll = nlls.mean()\n",
    "\n",
    "    if cond == 'bare':\n",
    "        print(f\"{cond:<24} {mean_nll:>10.4f} {'--':>10} {'--':>8} {'--':>8} \"\n",
    "              f\"{'--':>12} {'--':>5}\")\n",
    "        analysis[cond] = {'mean_nll': float(mean_nll)}\n",
    "    else:\n",
    "        diff = bare_nlls - nlls  # positive = condition is better\n",
    "        d = cohens_d(diff)\n",
    "        win_pct = 100 * np.mean(diff > 0)\n",
    "        t_stat, p_val = stats.ttest_1samp(diff, 0)\n",
    "        sig = ('***' if p_val < 0.001/N_BONFERRONI else\n",
    "               '**' if p_val < 0.01/N_BONFERRONI else\n",
    "               '*' if p_val < 0.05/N_BONFERRONI else 'ns')\n",
    "        print(f\"{cond:<24} {mean_nll:>10.4f} {diff.mean():>+10.4f} {d:>+8.3f} \"\n",
    "              f\"{win_pct:>7.1f}% {p_val:>12.2e} {sig:>5}\")\n",
    "        analysis[cond] = {\n",
    "            'mean_nll': float(mean_nll), 'delta': float(diff.mean()),\n",
    "            'd': float(d), 'win_pct': float(win_pct), 'p': float(p_val),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ec7542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.686023Z",
     "iopub.status.busy": "2026-02-19T13:18:10.685520Z",
     "iopub.status.idle": "2026-02-19T13:18:10.704517Z",
     "shell.execute_reply": "2026-02-19T13:18:10.703832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KEY PAIRWISE COMPARISONS\n",
      "======================================================================\n",
      "Does selective keyword visibility improve beyond standard truncation?\n",
      "\n",
      "  Oracle: does seeing query keyword help?\n",
      "    oracle_trunc vs oracle_kw_visible: d=-0.098, oracle_kw_visible wins 8.8%, p=2.89e-02 *\n",
      "    Winner: oracle_trunc\n",
      "\n",
      "  Template: does seeing doc keyword help?\n",
      "    template_trunc vs template_kw_visible: d=+0.000, template_kw_visible wins 0.0%, p=nan ns\n",
      "    Winner: template_trunc\n",
      "\n",
      "  Pad+KW: does seeing keyword help?\n",
      "    pad_kw_trunc vs pad_kw_kw_visible: d=-0.018, pad_kw_kw_visible wins 0.2%, p=6.81e-01 ns\n",
      "    Winner: pad_kw_trunc\n",
      "\n",
      "  Replication: trunc > full? (Exp 01)\n",
      "    oracle_trunc vs oracle_full: d=-0.360, oracle_full wins 13.2%, p=6.21e-15 ***\n",
      "    Winner: oracle_trunc\n",
      "\n",
      "  Selective vs full visibility?\n",
      "    oracle_kw_visible vs oracle_full: d=-0.346, oracle_full wins 13.6%, p=6.07e-14 ***\n",
      "    Winner: oracle_kw_visible\n",
      "\n",
      "  Keyword-only visible vs random trunc?\n",
      "    keyword_only_visible vs random_trunc: d=+0.063, random_trunc wins 58.8%, p=1.57e-01 ns\n",
      "    Winner: random_trunc\n",
      "\n",
      "  Keyword-only visible vs template trunc?\n",
      "    keyword_only_visible vs template_trunc: d=+0.089, template_trunc wins 66.0%, p=4.82e-02 *\n",
      "    Winner: template_trunc\n",
      "\n",
      "======================================================================\n",
      "HEADLINE:\n",
      "  oracle_trunc:      d=+0.376 (Exp 01 reference)\n",
      "  oracle_kw_visible: d=+0.369\n",
      "  oracle_full:       d=+0.338\n",
      "  >>> Selective visibility HURTS (-0.007)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Key pairwise comparisons\n",
    "print(\"=\" * 70)\n",
    "print(\"KEY PAIRWISE COMPARISONS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Does selective keyword visibility improve beyond standard truncation?\\n\")\n",
    "\n",
    "pairwise_tests = [\n",
    "    ('oracle_trunc', 'oracle_kw_visible',\n",
    "     \"Oracle: does seeing query keyword help?\"),\n",
    "    ('template_trunc', 'template_kw_visible',\n",
    "     \"Template: does seeing doc keyword help?\"),\n",
    "    ('pad_kw_trunc', 'pad_kw_kw_visible',\n",
    "     \"Pad+KW: does seeing keyword help?\"),\n",
    "    ('oracle_trunc', 'oracle_full',\n",
    "     \"Replication: trunc > full? (Exp 01)\"),\n",
    "    ('oracle_kw_visible', 'oracle_full',\n",
    "     \"Selective vs full visibility?\"),\n",
    "    ('keyword_only_visible', 'random_trunc',\n",
    "     \"Keyword-only visible vs random trunc?\"),\n",
    "    ('keyword_only_visible', 'template_trunc',\n",
    "     \"Keyword-only visible vs template trunc?\"),\n",
    "]\n",
    "\n",
    "pairwise_analysis = {}\n",
    "\n",
    "for cond_a, cond_b, question in pairwise_tests:\n",
    "    nlls_a = np.array([r[f'nll_{cond_a}'] for r in all_results])\n",
    "    nlls_b = np.array([r[f'nll_{cond_b}'] for r in all_results])\n",
    "    diff = nlls_a - nlls_b  # positive = B is better (lower NLL)\n",
    "    d = cohens_d(diff)\n",
    "    win_b = 100 * np.mean(diff > 0)\n",
    "    t_stat, p_val = stats.ttest_1samp(diff, 0)\n",
    "    sig = ('***' if p_val < 0.001 else '**' if p_val < 0.01 else\n",
    "           '*' if p_val < 0.05 else 'ns')\n",
    "    winner = cond_b if d > 0 else cond_a\n",
    "\n",
    "    print(f\"  {question}\")\n",
    "    print(f\"    {cond_a} vs {cond_b}: d={d:+.3f}, {cond_b} wins {win_b:.1f}%, \"\n",
    "          f\"p={p_val:.2e} {sig}\")\n",
    "    print(f\"    Winner: {winner}\")\n",
    "    print()\n",
    "\n",
    "    pairwise_analysis[f'{cond_a}_vs_{cond_b}'] = {\n",
    "        'd': float(d), 'win_b_pct': float(win_b),\n",
    "        'p': float(p_val), 'winner': winner,\n",
    "    }\n",
    "\n",
    "# Headline\n",
    "print(\"=\" * 70)\n",
    "oracle_trunc_d = analysis.get('oracle_trunc', {}).get('d', 0)\n",
    "oracle_kw_d = analysis.get('oracle_kw_visible', {}).get('d', 0)\n",
    "oracle_full_d = analysis.get('oracle_full', {}).get('d', 0)\n",
    "print(f\"HEADLINE:\")\n",
    "print(f\"  oracle_trunc:      d={oracle_trunc_d:+.3f} (Exp 01 reference)\")\n",
    "print(f\"  oracle_kw_visible: d={oracle_kw_d:+.3f}\")\n",
    "print(f\"  oracle_full:       d={oracle_full_d:+.3f}\")\n",
    "if oracle_kw_d > oracle_trunc_d:\n",
    "    print(f\"  >>> Selective visibility HELPS (+{oracle_kw_d - oracle_trunc_d:.3f})\")\n",
    "elif oracle_kw_d < oracle_trunc_d:\n",
    "    print(f\"  >>> Selective visibility HURTS ({oracle_kw_d - oracle_trunc_d:+.3f})\")\n",
    "else:\n",
    "    print(f\"  >>> Selective visibility has no effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2309e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.707484Z",
     "iopub.status.busy": "2026-02-19T13:18:10.707007Z",
     "iopub.status.idle": "2026-02-19T13:18:10.720777Z",
     "shell.execute_reply": "2026-02-19T13:18:10.720175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MECHANISM DECOMPOSITION CHAIN\n",
      "======================================================================\n",
      "bare -> random_trunc -> pad_kw_trunc -> pad_kw_kw_visible -> oracle_kw_visible\n",
      "\n",
      "Step                                                    NLL  Incremental        d            p   sig\n",
      "--------------------------------------------------------------------------------------------------\n",
      "  bare (baseline)                                    3.6765\n",
      "  + structure (random prefix)                        3.1432      +0.5333   +0.303     3.61e-11   ***\n",
      "  + vocabulary (keyword in prefix)                   3.1628      -0.0196   -0.026     5.62e-01    ns\n",
      "  + direct access (keyword visible to decoder)       3.1629      -0.0001   -0.018     6.81e-01    ns\n",
      "  + semantics (real query + keyword visible)         3.0050      +0.1579   +0.304     3.24e-11   ***\n",
      "\n",
      "--- Cumulative from bare ---\n",
      "  bare -> random_trunc                : d=+0.303 (82% of total chain)\n",
      "  bare -> pad_kw_trunc                : d=+0.308 (84% of total chain)\n",
      "  bare -> pad_kw_kw_visible           : d=+0.308 (84% of total chain)\n",
      "  bare -> oracle_kw_visible           : d=+0.369 (100% of total chain)\n",
      "\n",
      "  Reference: bare -> oracle_trunc: d=+0.376\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Mechanism decomposition chain\n",
    "print(\"=\" * 70)\n",
    "print(\"MECHANISM DECOMPOSITION CHAIN\")\n",
    "print(\"=\" * 70)\n",
    "print(\"bare -> random_trunc -> pad_kw_trunc -> pad_kw_kw_visible -> oracle_kw_visible\\n\")\n",
    "\n",
    "chain = ['bare', 'random_trunc', 'pad_kw_trunc', 'pad_kw_kw_visible', 'oracle_kw_visible']\n",
    "chain_labels = {\n",
    "    'bare': 'bare (baseline)',\n",
    "    'random_trunc': '+ structure (random prefix)',\n",
    "    'pad_kw_trunc': '+ vocabulary (keyword in prefix)',\n",
    "    'pad_kw_kw_visible': '+ direct access (keyword visible to decoder)',\n",
    "    'oracle_kw_visible': '+ semantics (real query + keyword visible)',\n",
    "}\n",
    "\n",
    "nlls_by_cond = {c: np.array([r[f'nll_{c}'] for r in all_results]) for c in chain}\n",
    "\n",
    "print(f\"{'Step':<50} {'NLL':>8} {'Incremental':>12} {'d':>8} {'p':>12} {'sig':>5}\")\n",
    "print(\"-\" * 98)\n",
    "\n",
    "prev_nlls = nlls_by_cond['bare']\n",
    "for cond in chain:\n",
    "    nlls = nlls_by_cond[cond]\n",
    "    label = chain_labels[cond]\n",
    "\n",
    "    if cond == 'bare':\n",
    "        print(f\"  {label:<48} {nlls.mean():>8.4f}\")\n",
    "    else:\n",
    "        increment = prev_nlls - nlls  # positive = improvement\n",
    "        d = cohens_d(increment)\n",
    "        t_stat, p_val = stats.ttest_1samp(increment, 0)\n",
    "        sig = ('***' if p_val < 0.001 else '**' if p_val < 0.01 else\n",
    "               '*' if p_val < 0.05 else 'ns')\n",
    "        print(f\"  {label:<48} {nlls.mean():>8.4f} {increment.mean():>+12.4f} \"\n",
    "              f\"{d:>+8.3f} {p_val:>12.2e} {sig:>5}\")\n",
    "    prev_nlls = nlls\n",
    "\n",
    "# Cumulative from bare\n",
    "print(f\"\\n--- Cumulative from bare ---\")\n",
    "total_benefit = nlls_by_cond['bare'] - nlls_by_cond['oracle_kw_visible']\n",
    "total_d = cohens_d(total_benefit)\n",
    "for cond in chain[1:]:\n",
    "    cum_benefit = nlls_by_cond['bare'] - nlls_by_cond[cond]\n",
    "    cum_d = cohens_d(cum_benefit)\n",
    "    pct = cum_d / total_d * 100 if total_d > 0 else 0\n",
    "    print(f\"  bare -> {cond:<28s}: d={cum_d:+.3f} ({pct:.0f}% of total chain)\")\n",
    "\n",
    "# Also show the oracle_trunc reference\n",
    "oracle_trunc_benefit = nlls_by_cond['bare'] - np.array([r['nll_oracle_trunc'] for r in all_results])\n",
    "oracle_trunc_d = cohens_d(oracle_trunc_benefit)\n",
    "print(f\"\\n  Reference: bare -> oracle_trunc: d={oracle_trunc_d:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea60388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.723779Z",
     "iopub.status.busy": "2026-02-19T13:18:10.723282Z",
     "iopub.status.idle": "2026-02-19T13:18:10.736883Z",
     "shell.execute_reply": "2026-02-19T13:18:10.736250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HARDNESS STRATIFICATION\n",
      "======================================================================\n",
      "Does keyword visibility help more for hard samples?\n",
      "\n",
      "Quintile        N     bare  orc_trunc d   orc_kw d    kw gain  tpl_trunc d   tpl_kw d    kw gain\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Q1 easy       100    0.487       +1.027     +1.005     -0.022       +1.161     +1.161     +0.000\n",
      "Q2             99    1.075       +1.213     +1.205     -0.008       +1.259     +1.259     +0.000\n",
      "Q3             98    1.905       +1.518     +1.406     -0.111       +1.359     +1.359     +0.000\n",
      "Q4            103    3.055       +1.219     +1.297     +0.079       +1.005     +1.005     +0.000\n",
      "Q5 hard       100   11.817       +0.674     +0.659     -0.015       +0.605     +0.605     +0.000\n",
      "\n",
      "Correlation: hardness vs oracle_kw_gain: r=-0.058 (p=1.93e-01)\n",
      "  --> Keyword visibility benefit is uniform across difficulty\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Hardness stratification\n",
    "print(\"=\" * 70)\n",
    "print(\"HARDNESS STRATIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Does keyword visibility help more for hard samples?\\n\")\n",
    "\n",
    "quintile_bounds = np.percentile(bare_nlls, [20, 40, 60, 80])\n",
    "quintiles = np.digitize(bare_nlls, quintile_bounds)\n",
    "quintile_labels = ['Q1 easy', 'Q2', 'Q3', 'Q4', 'Q5 hard']\n",
    "\n",
    "# Key comparison: oracle_trunc vs oracle_kw_visible by quintile\n",
    "oracle_trunc_nlls = np.array([r['nll_oracle_trunc'] for r in all_results])\n",
    "oracle_kw_nlls = np.array([r['nll_oracle_kw_visible'] for r in all_results])\n",
    "template_trunc_nlls = np.array([r['nll_template_trunc'] for r in all_results])\n",
    "template_kw_nlls = np.array([r['nll_template_kw_visible'] for r in all_results])\n",
    "\n",
    "print(f\"{'Quintile':<12} {'N':>4} {'bare':>8} \"\n",
    "      f\"{'orc_trunc d':>12} {'orc_kw d':>10} {'kw gain':>10} \"\n",
    "      f\"{'tpl_trunc d':>12} {'tpl_kw d':>10} {'kw gain':>10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "hardness_analysis = {}\n",
    "for q in range(5):\n",
    "    mask = quintiles == q\n",
    "    n_q = mask.sum()\n",
    "    bare_q = bare_nlls[mask].mean()\n",
    "\n",
    "    ot_d = cohens_d(bare_nlls[mask] - oracle_trunc_nlls[mask])\n",
    "    ok_d = cohens_d(bare_nlls[mask] - oracle_kw_nlls[mask])\n",
    "    ok_gain = ok_d - ot_d\n",
    "\n",
    "    tt_d = cohens_d(bare_nlls[mask] - template_trunc_nlls[mask])\n",
    "    tk_d = cohens_d(bare_nlls[mask] - template_kw_nlls[mask])\n",
    "    tk_gain = tk_d - tt_d\n",
    "\n",
    "    print(f\"{quintile_labels[q]:<12} {n_q:>4} {bare_q:>8.3f} \"\n",
    "          f\"{ot_d:>+12.3f} {ok_d:>+10.3f} {ok_gain:>+10.3f} \"\n",
    "          f\"{tt_d:>+12.3f} {tk_d:>+10.3f} {tk_gain:>+10.3f}\")\n",
    "\n",
    "    hardness_analysis[quintile_labels[q]] = {\n",
    "        'oracle_trunc_d': float(ot_d), 'oracle_kw_d': float(ok_d),\n",
    "        'oracle_kw_gain': float(ok_gain),\n",
    "        'template_trunc_d': float(tt_d), 'template_kw_d': float(tk_d),\n",
    "        'template_kw_gain': float(tk_gain),\n",
    "    }\n",
    "\n",
    "# Correlation: hardness vs keyword visibility gain\n",
    "oracle_kw_gain_per_sample = (bare_nlls - oracle_kw_nlls) - (bare_nlls - oracle_trunc_nlls)\n",
    "r, p = stats.pearsonr(bare_nlls, oracle_kw_gain_per_sample)\n",
    "print(f\"\\nCorrelation: hardness vs oracle_kw_gain: r={r:+.3f} (p={p:.2e})\")\n",
    "if r > 0.1:\n",
    "    print(\"  --> Keyword visibility helps MORE for harder samples\")\n",
    "elif r < -0.1:\n",
    "    print(\"  --> Keyword visibility helps MORE for easier samples\")\n",
    "else:\n",
    "    print(\"  --> Keyword visibility benefit is uniform across difficulty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4730b6c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.739773Z",
     "iopub.status.busy": "2026-02-19T13:18:10.739291Z",
     "iopub.status.idle": "2026-02-19T13:18:10.751719Z",
     "shell.execute_reply": "2026-02-19T13:18:10.751100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KEYWORD POSITION DIAGNOSTICS\n",
      "======================================================================\n",
      "\n",
      "  oracle_kw_visible:\n",
      "    Hit rate: 24.2% (121/500)\n",
      "    Mean keyword tokens (when found): 1.2\n",
      "    Hit d=+0.556 vs Miss d=+0.378 (gap=+0.177)\n",
      "\n",
      "  template_kw_visible:\n",
      "    Hit rate: 0.2% (1/500)\n",
      "    Mean keyword tokens (when found): 4.0\n",
      "    Not enough misses for comparison (499 misses)\n",
      "\n",
      "  pad_kw_kw_visible:\n",
      "    Hit rate: 0.4% (2/500)\n",
      "    Mean keyword tokens (when found): 2.5\n",
      "    Not enough misses for comparison (498 misses)\n",
      "\n",
      "  keyword_only_visible:\n",
      "    Hit rate: 100.0% (500/500)\n",
      "    Mean keyword tokens (when found): 1.5\n",
      "    Not enough misses for comparison (0 misses)\n",
      "\n",
      "--- Token count for keywords ---\n",
      "  query_kw='link' (1 toks), doc_kw='alveoli' (2 toks)\n",
      "  query_kw='thick' (1 toks), doc_kw='wall' (1 toks)\n",
      "  query_kw='average' (1 toks), doc_kw='registered' (1 toks)\n",
      "  query_kw='pharmacist' (2 toks), doc_kw='oregon' (2 toks)\n",
      "  query_kw='average' (1 toks), doc_kw='degrees' (1 toks)\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Keyword position diagnostics\n",
    "print(\"=\" * 70)\n",
    "print(\"KEYWORD POSITION DIAGNOSTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "kw_visible_conds = ['oracle_kw_visible', 'template_kw_visible',\n",
    "                    'pad_kw_kw_visible', 'keyword_only_visible']\n",
    "\n",
    "for cond in kw_visible_conds:\n",
    "    hits = [r.get(f'kw_hit_{cond}', False) for r in all_results]\n",
    "    ntoks = [r.get(f'kw_ntoks_{cond}', 0) for r in all_results]\n",
    "    hit_rate = 100 * np.mean(hits)\n",
    "    mean_toks = np.mean([n for n in ntoks if n > 0]) if any(n > 0 for n in ntoks) else 0\n",
    "\n",
    "    print(f\"\\n  {cond}:\")\n",
    "    print(f\"    Hit rate: {hit_rate:.1f}% ({sum(hits)}/{len(hits)})\")\n",
    "    print(f\"    Mean keyword tokens (when found): {mean_toks:.1f}\")\n",
    "\n",
    "    # Performance comparison: hit vs miss\n",
    "    hit_mask = np.array(hits)\n",
    "    if hit_mask.sum() > 10 and (~hit_mask).sum() > 10:\n",
    "        hit_nlls = np.array([r[f'nll_{cond}'] for r in all_results])[hit_mask]\n",
    "        miss_nlls = np.array([r[f'nll_{cond}'] for r in all_results])[~hit_mask]\n",
    "        hit_bare = bare_nlls[hit_mask]\n",
    "        miss_bare = bare_nlls[~hit_mask]\n",
    "        hit_d = cohens_d(hit_bare - hit_nlls)\n",
    "        miss_d = cohens_d(miss_bare - miss_nlls)\n",
    "        print(f\"    Hit d={hit_d:+.3f} vs Miss d={miss_d:+.3f} (gap={hit_d - miss_d:+.3f})\")\n",
    "    elif hit_mask.sum() > 0:\n",
    "        print(f\"    Not enough misses for comparison ({(~hit_mask).sum()} misses)\")\n",
    "\n",
    "# Keyword token distribution\n",
    "print(f\"\\n--- Token count for keywords ---\")\n",
    "for s in samples[:5]:\n",
    "    qk_toks = len(tokenizer(s['query_kw'], add_special_tokens=False).input_ids)\n",
    "    dk_toks = len(tokenizer(s['doc_kw'], add_special_tokens=False).input_ids)\n",
    "    print(f\"  query_kw='{s['query_kw']}' ({qk_toks} toks), \"\n",
    "          f\"doc_kw='{s['doc_kw']}' ({dk_toks} toks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b7c59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:18:10.754621Z",
     "iopub.status.busy": "2026-02-19T13:18:10.754383Z",
     "iopub.status.idle": "2026-02-19T13:18:11.244205Z",
     "shell.execute_reply": "2026-02-19T13:18:11.243487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERDICT -- Exp 10: Selective Truncation\n",
      "======================================================================\n",
      "\n",
      "Model: google/t5gemma-2-4b-4b\n",
      "N: 500 samples\n",
      "\n",
      "--- Effect sizes (d vs bare) ---\n",
      "  oracle_trunc            : d=+0.376 ***\n",
      "  oracle_full             : d=+0.338 ***\n",
      "  oracle_kw_visible       : d=+0.369 ***\n",
      "  template_trunc          : d=+0.336 ***\n",
      "  template_kw_visible     : d=+0.336 ***\n",
      "  pad_kw_trunc            : d=+0.308 ***\n",
      "  pad_kw_kw_visible       : d=+0.308 ***\n",
      "  random_trunc            : d=+0.303 ***\n",
      "  keyword_only_visible    : d=+0.255 ***\n",
      "\n",
      "--- KEY QUESTIONS ---\n",
      "\n",
      "Q1: Does selective keyword visibility help beyond truncation?\n",
      "  oracle_trunc: d=+0.376\n",
      "  oracle_kw_visible: d=+0.369\n",
      "  Pairwise: d=-0.098, p=2.89e-02\n",
      "  >>> NO significant difference: keyword visibility has minimal effect\n",
      "\n",
      "Q2: Does Exp 01 replicate (trunc > full)?\n",
      "  oracle_trunc: d=+0.376\n",
      "  oracle_full:  d=+0.338\n",
      "  >>> YES: truncation is better (replicates Exp 01)\n",
      "\n",
      "Q3: Is oracle_kw_visible a sweet spot?\n",
      "  >>> PARTIAL: selective > full but not > trunc\n",
      "\n",
      "Q4: Template keyword visibility?\n",
      "  template_trunc: d=+0.336\n",
      "  template_kw_visible: d=+0.336\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Results saved to results/exp10/results.json\n",
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 15.03 GB -> 0.01 GB\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Verdict + save + cleanup\n",
    "print(\"=\" * 70)\n",
    "print(\"VERDICT -- Exp 10: Selective Truncation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"N: {len(all_results)} samples\")\n",
    "\n",
    "# Key effect sizes\n",
    "print(f\"\\n--- Effect sizes (d vs bare) ---\")\n",
    "for cond in COND_NAMES[1:]:\n",
    "    a = analysis.get(cond, {})\n",
    "    d = a.get('d', 0)\n",
    "    p = a.get('p', 1)\n",
    "    sig = ('***' if p < 0.001/N_BONFERRONI else '**' if p < 0.01/N_BONFERRONI\n",
    "           else '*' if p < 0.05/N_BONFERRONI else 'ns')\n",
    "    print(f\"  {cond:<24s}: d={d:+.3f} {sig}\")\n",
    "\n",
    "# Key question answers\n",
    "print(f\"\\n--- KEY QUESTIONS ---\")\n",
    "\n",
    "# Q1: Does keyword visibility help?\n",
    "ot_d = analysis.get('oracle_trunc', {}).get('d', 0)\n",
    "ok_d = analysis.get('oracle_kw_visible', {}).get('d', 0)\n",
    "pw = pairwise_analysis.get('oracle_trunc_vs_oracle_kw_visible', {})\n",
    "print(f\"\\nQ1: Does selective keyword visibility help beyond truncation?\")\n",
    "print(f\"  oracle_trunc: d={ot_d:+.3f}\")\n",
    "print(f\"  oracle_kw_visible: d={ok_d:+.3f}\")\n",
    "print(f\"  Pairwise: d={pw.get('d', 0):+.3f}, p={pw.get('p', 1):.2e}\")\n",
    "if ok_d > ot_d + 0.02 and pw.get('p', 1) < 0.05:\n",
    "    print(f\"  >>> YES: keyword visibility provides additional benefit\")\n",
    "elif ok_d < ot_d - 0.02 and pw.get('p', 1) < 0.05:\n",
    "    print(f\"  >>> NO: keyword visibility HURTS (like full visibility)\")\n",
    "else:\n",
    "    print(f\"  >>> NO significant difference: keyword visibility has minimal effect\")\n",
    "\n",
    "# Q2: Does Exp 01 replicate?\n",
    "of_d = analysis.get('oracle_full', {}).get('d', 0)\n",
    "print(f\"\\nQ2: Does Exp 01 replicate (trunc > full)?\")\n",
    "print(f\"  oracle_trunc: d={ot_d:+.3f}\")\n",
    "print(f\"  oracle_full:  d={of_d:+.3f}\")\n",
    "if ot_d > of_d:\n",
    "    print(f\"  >>> YES: truncation is better (replicates Exp 01)\")\n",
    "else:\n",
    "    print(f\"  >>> NO: full visibility is better (contradicts Exp 01)\")\n",
    "\n",
    "# Q3: Is there a sweet spot between full and trunc?\n",
    "print(f\"\\nQ3: Is oracle_kw_visible a sweet spot?\")\n",
    "if ok_d > ot_d and ok_d > of_d:\n",
    "    print(f\"  >>> YES: selective > trunc ({ok_d:+.3f} > {ot_d:+.3f}) \"\n",
    "          f\"AND selective > full ({ok_d:+.3f} > {of_d:+.3f})\")\n",
    "elif ok_d > of_d:\n",
    "    print(f\"  >>> PARTIAL: selective > full but not > trunc\")\n",
    "else:\n",
    "    print(f\"  >>> NO: truncation remains optimal\")\n",
    "\n",
    "# Q4: Template keyword results\n",
    "tt_d = analysis.get('template_trunc', {}).get('d', 0)\n",
    "tk_d = analysis.get('template_kw_visible', {}).get('d', 0)\n",
    "print(f\"\\nQ4: Template keyword visibility?\")\n",
    "print(f\"  template_trunc: d={tt_d:+.3f}\")\n",
    "print(f\"  template_kw_visible: d={tk_d:+.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# Save results\n",
    "final_results = {\n",
    "    'experiment': 'exp10_selective_truncation',\n",
    "    'model': MODEL_NAME,\n",
    "    'n_samples': len(all_results),\n",
    "    'n_bonferroni': N_BONFERRONI,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'analysis': analysis,\n",
    "    'pairwise_analysis': pairwise_analysis,\n",
    "    'hardness_analysis': hardness_analysis,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "\n",
    "# Cleanup\n",
    "print(\"Cleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, processor, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00a428217ae54e9c92e26cde65183a7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0db27991091349ecaf571a41b6937bef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0fe5007e3f764b9ca333ac4f0f372b6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "18a56b50c1bb4519bb8a4a621549abed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_517e9e16bfeb4a2093cdbb08bb7ee7d5",
        "IPY_MODEL_fab937cf05ff4f3b82efd0ee571e7fc4",
        "IPY_MODEL_7499024ece10481f99cf0ef73f20551b"
       ],
       "layout": "IPY_MODEL_00a428217ae54e9c92e26cde65183a7c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "31b5d530a6c5429498061d85723a59f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "517e9e16bfeb4a2093cdbb08bb7ee7d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b48241ff5f8948fa839659edd4a02ee8",
       "placeholder": "​",
       "style": "IPY_MODEL_8bf2898fc2974e02ba808055fbb2381c",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     },
     "66588765a5c94bf590768903b65b8cfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66b48d53b86940faac25f445d487deea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6bcc9329b0c84d25a1e0a6db06d55114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7499024ece10481f99cf0ef73f20551b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_88df7cab23904288b2981fbf9ae81084",
       "placeholder": "​",
       "style": "IPY_MODEL_31b5d530a6c5429498061d85723a59f0",
       "tabbable": null,
       "tooltip": null,
       "value": " 1327/1327 [00:04&lt;00:00, 689.27it/s, Materializing param=model.encoder.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "88df7cab23904288b2981fbf9ae81084": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bf2898fc2974e02ba808055fbb2381c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9786d8c0b21b49fbb12e83cfe7bd1175": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a89487fd099d43d09c64381dcd6f0960": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_66588765a5c94bf590768903b65b8cfb",
       "placeholder": "​",
       "style": "IPY_MODEL_9786d8c0b21b49fbb12e83cfe7bd1175",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring: 100%"
      }
     },
     "af0fb03215e34c6dbb7849c2e7f719bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dc43502993ff400ab8e4a0dd99463b5d",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f6410dc6de924007ac37f337d2982bb1",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "b48241ff5f8948fa839659edd4a02ee8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b496d0bd090c4d0882847f9e9887f6de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a89487fd099d43d09c64381dcd6f0960",
        "IPY_MODEL_af0fb03215e34c6dbb7849c2e7f719bf",
        "IPY_MODEL_c0aba498beb14daab09390a70af4e6ff"
       ],
       "layout": "IPY_MODEL_c54d6f94b2334486b85f9fd0d10f3286",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c0aba498beb14daab09390a70af4e6ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6bcc9329b0c84d25a1e0a6db06d55114",
       "placeholder": "​",
       "style": "IPY_MODEL_0fe5007e3f764b9ca333ac4f0f372b6c",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [17:16&lt;00:00,  2.08s/it]"
      }
     },
     "c54d6f94b2334486b85f9fd0d10f3286": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc43502993ff400ab8e4a0dd99463b5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6410dc6de924007ac37f337d2982bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fab937cf05ff4f3b82efd0ee571e7fc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0db27991091349ecaf571a41b6937bef",
       "max": 1327.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_66b48d53b86940faac25f445d487deea",
       "tabbable": null,
       "tooltip": null,
       "value": 1327.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
