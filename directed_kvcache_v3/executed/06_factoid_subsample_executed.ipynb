{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75026afb",
   "metadata": {},
   "source": [
    "# Experiment 06: Factoid Subsample Validation\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The \"85% structural\" finding from Exp 2B is an aggregate that hides two distinct\n",
    "populations (discovered in post-hoc analysis of Exp 02/05 data):\n",
    "\n",
    "| Population | N (in Exp 02) | Structural % | Semantic % | Characteristic |\n",
    "|---|---|---|---|---|\n",
    "| Short factoid answers (<=9 words) | ~248 | ~37% | ~63% | Disambiguation required |\n",
    "| Long descriptive answers (>9 words) | ~252 | ~113% | ~-13% | Broad generation |\n",
    "| **Weighted average** | 500 | **85%** | **15%** | |\n",
    "\n",
    "For short precise answers, the model must select ONE specific fact from the passage.\n",
    "The query tells it which fact. A random prefix fixes the attention sink but cannot\n",
    "help with disambiguation. For long answers, broad representation suffices.\n",
    "\n",
    "This experiment validates the finding on a **fresh sample** of 500 MS MARCO examples\n",
    "filtered to short factoid answers (<=5 words), eliminating look-ahead bias from\n",
    "the post-hoc analysis.\n",
    "\n",
    "## Prediction\n",
    "\n",
    "If the two-population hypothesis is correct:\n",
    "- Structural% should drop from 85% to **~40-50%**\n",
    "- Vocabulary and semantics should contribute **~50-60%** combined\n",
    "- surr_template should significantly beat random (it couldn't on the mixed sample)\n",
    "- The \"directed\" in directed KV cache should finally matter\n",
    "\n",
    "## Conditions (8)\n",
    "\n",
    "| # | Condition | Prefix | Role |\n",
    "|---|-----------|--------|------|\n",
    "| 1 | `bare` | (none) | lower bound |\n",
    "| 2 | `oracle_x1_trunc` | query x 1 | upper bound |\n",
    "| 3 | `oracle_x4_trunc` | query x 4 | upper bound + rep |\n",
    "| 4 | `random_x1_trunc` | random_matched x 1 | structural control |\n",
    "| 5 | `random_x4_trunc` | random_matched x 4 | structural + rep |\n",
    "| 6 | `scrambled_oracle_trunc` | shuffled query x 1 | vocabulary control |\n",
    "| 7 | `surr_template_x1_trunc` | \"What is [kw]?\" x 1 | heuristic |\n",
    "| 8 | `surr_template_x4_trunc` | \"What is [kw]?\" x 4 | heuristic + rep |\n",
    "\n",
    "## Analysis\n",
    "\n",
    "1. Baseline characterization (verify short-answer distribution)\n",
    "2. 3-way decomposition (structure / vocabulary / semantics) — compare to Exp 2B\n",
    "3. Surrogate comparison: does template beat random for factoid QA?\n",
    "4. Hardness interaction: does semantic% vary by difficulty within factoid?\n",
    "5. Direct comparison with Exp 2B full-sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea576abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:47:56.490501Z",
     "iopub.status.busy": "2026-02-18T18:47:56.490038Z",
     "iopub.status.idle": "2026-02-18T18:47:58.630232Z",
     "shell.execute_reply": "2026-02-18T18:47:58.629198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 06: Factoid Subsample Validation\n",
      "N: 500, max answer words: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup\n",
    "import os\n",
    "os.umask(0o000)\n",
    "\n",
    "import sys, json, time, re, gc, random as pyrandom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "from lib.analysis import cohens_d\n",
    "\n",
    "SEED = 43  # Different seed from Exp 02 (42) for a fresh sample\n",
    "N_SAMPLES = 500\n",
    "MAX_ANSWER_WORDS = 5\n",
    "MODEL_NAME = \"google/t5gemma-2-4b-4b\"\n",
    "\n",
    "RESULTS_DIR = Path(\"results/exp06\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = RESULTS_DIR / \"checkpoint.json\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pyrandom.seed(SEED)\n",
    "\n",
    "print(\"Exp 06: Factoid Subsample Validation\")\n",
    "print(f\"N: {N_SAMPLES}, max answer words: {MAX_ANSWER_WORDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3a606e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:47:58.633918Z",
     "iopub.status.busy": "2026-02-18T18:47:58.633559Z",
     "iopub.status.idle": "2026-02-18T18:48:01.349372Z",
     "shell.execute_reply": "2026-02-18T18:48:01.348409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total short-answer candidates: 4061\n",
      "\n",
      "Sample statistics (N=500):\n",
      "  Answer length:  mean=2.2, median=2, range=[1, 5]\n",
      "  Answer distribution: 1w=222, 2w=102, 3w=73, 4w=57, 5w=46\n",
      "  Passage length: mean=71.8, median=70\n",
      "  Query length:   mean=6.5, median=6\n",
      "\n",
      "Example 0:\n",
      "  Q: are mastiffs dangerous\n",
      "  A (1w): No\n",
      "  P (55w): It is not clear what sparked the attack. Mastiff dogs are not considered a dangerous breed. “The chi...\n",
      "\n",
      "Example 1:\n",
      "  Q: liposculpture cost\n",
      "  A (1w): $2,500\n",
      "  P (73w): Liposuction – Liposculpture Cost. The cost for Liposuction by Dr. Marie DiLauro at Reflections start...\n",
      "\n",
      "Example 2:\n",
      "  Q: what is the average salary for a FIFA player\n",
      "  A (1w): $29,000.\n",
      "  P (49w): Average Fifa Player Salaries. The average salary for fifa player jobs is $29,000. Average fifa playe...\n",
      "\n",
      "Example 3:\n",
      "  Q: how much time after underwriting to closing\n",
      "  A (2w): 7-10 days\n",
      "  P (37w): Underwriting can take usually 3 days to a week, depending on how busy the underwriters are for that ...\n",
      "\n",
      "Example 4:\n",
      "  Q: cooking time for turkey\n",
      "  A (3w): 3 1/2 hours.\n",
      "  P (53w): Roast the turkey: The rule of thumb for cooking a turkey is 13 minutes per pound. So our 16-pound tu...\n",
      "\n",
      "--- Comparison with Exp 02 (mixed answers) ---\n",
      "  Exp 02: mean answer ~14w (range 1-96), mean passage ~74w\n",
      "  This:   mean answer 2.2w (range 1-5), mean passage 72w\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load MS MARCO and filter to short factoid answers\n",
    "from lib.data import count_words\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading MS MARCO...\")\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\", split=\"validation\")\n",
    "\n",
    "# Collect ALL eligible samples (not just 3*N), then filter to short answers\n",
    "all_candidates = []\n",
    "for item in ds:\n",
    "    if len(all_candidates) >= 20000:\n",
    "        break\n",
    "    passages = item.get('passages', {})\n",
    "    ptexts = passages.get('passage_text', [])\n",
    "    is_sel = passages.get('is_selected', [])\n",
    "    query = item.get('query', '')\n",
    "    answers = item.get('answers', [])\n",
    "    well_formed = item.get('wellFormedAnswers', [])\n",
    "    answer = None\n",
    "    if well_formed and len(well_formed) > 0 and well_formed[0] not in ('[]', ''):\n",
    "        answer = well_formed[0]\n",
    "    elif answers and len(answers) > 0 and answers[0] != 'No Answer Present.':\n",
    "        answer = answers[0]\n",
    "    if not answer:\n",
    "        continue\n",
    "    # Filter: answer must be short (factoid)\n",
    "    answer_words = count_words(answer)\n",
    "    if answer_words > MAX_ANSWER_WORDS:\n",
    "        continue\n",
    "    for pt, sel in zip(ptexts, is_sel):\n",
    "        wc = count_words(pt)\n",
    "        if sel == 1 and 30 <= wc <= 300:\n",
    "            all_candidates.append({\n",
    "                'passage': pt, 'query': query, 'answer': answer,\n",
    "                'word_count': wc, 'answer_words': answer_words,\n",
    "            })\n",
    "            break\n",
    "\n",
    "print(f\"Total short-answer candidates: {len(all_candidates)}\")\n",
    "\n",
    "# Shuffle with our seed and take N_SAMPLES\n",
    "np.random.seed(SEED)\n",
    "indices = np.random.permutation(len(all_candidates))\n",
    "samples = [all_candidates[i] for i in indices[:N_SAMPLES]]\n",
    "del ds, all_candidates\n",
    "gc.collect()\n",
    "\n",
    "# Dataset statistics\n",
    "passage_words = np.array([s['word_count'] for s in samples])\n",
    "answer_words = np.array([s['answer_words'] for s in samples])\n",
    "query_words = np.array([len(s['query'].split()) for s in samples])\n",
    "\n",
    "print(f\"\\nSample statistics (N={N_SAMPLES}):\")\n",
    "print(f\"  Answer length:  mean={answer_words.mean():.1f}, median={np.median(answer_words):.0f}, \"\n",
    "      f\"range=[{answer_words.min()}, {answer_words.max()}]\")\n",
    "print(f\"  Answer distribution: \" + \", \".join(\n",
    "    f\"{w}w={np.sum(answer_words==w)}\" for w in range(1, MAX_ANSWER_WORDS + 1)))\n",
    "print(f\"  Passage length: mean={passage_words.mean():.1f}, median={np.median(passage_words):.0f}\")\n",
    "print(f\"  Query length:   mean={query_words.mean():.1f}, median={np.median(query_words):.0f}\")\n",
    "\n",
    "# Show 5 examples\n",
    "for i in range(5):\n",
    "    s = samples[i]\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"  Q: {s['query']}\")\n",
    "    print(f\"  A ({s['answer_words']}w): {s['answer']}\")\n",
    "    print(f\"  P ({s['word_count']}w): {s['passage'][:100]}...\")\n",
    "\n",
    "# Compare with Exp 02 distribution\n",
    "print(f\"\\n--- Comparison with Exp 02 (mixed answers) ---\")\n",
    "print(f\"  Exp 02: mean answer ~14w (range 1-96), mean passage ~74w\")\n",
    "print(f\"  This:   mean answer {answer_words.mean():.1f}w (range {answer_words.min()}-{answer_words.max()}), \"\n",
    "      f\"mean passage {passage_words.mean():.0f}w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a72bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:48:01.352882Z",
     "iopub.status.busy": "2026-02-18T18:48:01.352484Z",
     "iopub.status.idle": "2026-02-18T18:48:20.124313Z",
     "shell.execute_reply": "2026-02-18T18:48:20.123471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/t5gemma-2-4b-4b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bf602f29eb49a68fa35a968988f989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. dtype=torch.bfloat16\n",
      "GPU memory: 15.02 GB\n",
      "Helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load model and define scoring helpers\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", torch_dtype=torch.bfloat16, token=HF_TOKEN,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "DEVICE = next(model.parameters()).device\n",
    "print(f\"Model loaded. dtype={next(model.parameters()).dtype}\")\n",
    "print(f\"GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "\n",
    "def score_nll(encoder_text, answer_text, prefix_token_count=0, truncate=False):\n",
    "    # Score NLL of answer given encoder text, with optional prefix truncation.\n",
    "    enc_ids = tokenizer(encoder_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids.to(DEVICE)\n",
    "    total_enc_len = enc_ids.shape[1]\n",
    "    enc_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.get_encoder()(\n",
    "            input_ids=enc_ids, attention_mask=enc_mask\n",
    "        )\n",
    "\n",
    "    if truncate and prefix_token_count > 0:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "        cross_attn_mask[:, :prefix_token_count] = 0\n",
    "    else:\n",
    "        cross_attn_mask = torch.ones(1, total_enc_len, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    ans_ids = tokenizer(answer_text, return_tensors=\"pt\",\n",
    "                        add_special_tokens=False, truncation=True,\n",
    "                        max_length=256).input_ids.to(DEVICE)\n",
    "    if ans_ids.shape[1] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            attention_mask=cross_attn_mask,\n",
    "            labels=ans_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    token_log_probs = log_probs[0].gather(1, ans_ids[0].unsqueeze(1)).squeeze(1)\n",
    "    mean_nll = -token_log_probs.mean().item()\n",
    "\n",
    "    del encoder_outputs, outputs, logits, log_probs\n",
    "    return mean_nll\n",
    "\n",
    "\n",
    "def count_prefix_tokens(prefix_text, document_text):\n",
    "    # Count how many tokens the prefix occupies in [prefix + newline + document].\n",
    "    full_text = prefix_text + \"\\n\" + document_text\n",
    "    full_ids = tokenizer(full_text, add_special_tokens=True, truncation=True,\n",
    "                         max_length=2048).input_ids\n",
    "    doc_ids = tokenizer(document_text, add_special_tokens=True, truncation=True,\n",
    "                        max_length=2048).input_ids\n",
    "    return len(full_ids) - len(doc_ids)\n",
    "\n",
    "\n",
    "STOP_WORDS = {\n",
    "    'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for',\n",
    "    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "    'before', 'after', 'above', 'below', 'between', 'and', 'but', 'or',\n",
    "    'not', 'no', 'if', 'then', 'than', 'so', 'up', 'out', 'about',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'it', 'its', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'he',\n",
    "    'him', 'his', 'she', 'her', 'they', 'them', 'their', 'how', 'when',\n",
    "    'where', 'why', 'much', 'many', 'some', 'any', 'all', 'each',\n",
    "    'does', 'also', 'just', 'more', 'most', 'very', 'too', 'only',\n",
    "}\n",
    "\n",
    "print(\"Helpers defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbe3b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:48:20.128299Z",
     "iopub.status.busy": "2026-02-18T18:48:20.127220Z",
     "iopub.status.idle": "2026-02-18T18:48:20.268758Z",
     "shell.execute_reply": "2026-02-18T18:48:20.267859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions (8):\n",
      "  bare\n",
      "  oracle_x1_trunc\n",
      "  oracle_x4_trunc\n",
      "  random_x1_trunc\n",
      "  random_x4_trunc\n",
      "  scrambled_oracle_trunc\n",
      "  surr_template_x1_trunc\n",
      "  surr_template_x4_trunc\n",
      "\n",
      "Example (sample 0):\n",
      "  Query: are mastiffs dangerous\n",
      "  Answer (1w): No\n",
      "  bare                          : [document only]\n",
      "  oracle_x1_trunc                (  5 toks): are mastiffs dangerous\n",
      "  oracle_x4_trunc                ( 17 toks): are mastiffs dangerous are mastiffs dangerous are masti\n",
      "  random_x1_trunc                (  4 toks): 1 Material and\n",
      "  random_x4_trunc                ( 16 toks): 1 Material and 1 Material and 1 Material and 1 Material\n",
      "  scrambled_oracle_trunc         (  5 toks): mastiffs dangerous are\n",
      "  surr_template_x1_trunc         (  6 toks): What is childs?\n",
      "  surr_template_x4_trunc         ( 21 toks): What is childs? What is childs? What is childs? What is\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Generate all 8 scoring conditions per sample\n",
    "\n",
    "for i, s in enumerate(samples):\n",
    "    query = s['query']\n",
    "    passage = s['passage']\n",
    "    query_words_list = query.split()\n",
    "\n",
    "    # Random text from unrelated passage\n",
    "    other_idx = (i + N_SAMPLES // 2) % len(samples)\n",
    "    other_words = samples[other_idx]['passage'].split()\n",
    "    random_matched = \" \".join(other_words[:len(query_words_list)])\n",
    "\n",
    "    # Scrambled oracle (same words, random order)\n",
    "    rng = np.random.RandomState(SEED + i)\n",
    "    shuffled = list(query_words_list)\n",
    "    rng.shuffle(shuffled)\n",
    "    scrambled = \" \".join(shuffled)\n",
    "\n",
    "    # Template surrogate: \"What is [keyword]?\"\n",
    "    doc_words_clean = re.sub(r'[^\\w\\s]', '', passage.lower()).split()\n",
    "    content = [w for w in doc_words_clean if w not in STOP_WORDS and len(w) > 2]\n",
    "    if content:\n",
    "        kw = Counter(content).most_common(1)[0][0]\n",
    "    else:\n",
    "        kw = \"information\"\n",
    "\n",
    "    s['oracle_x1'] = query\n",
    "    s['oracle_x4'] = \" \".join([query] * 4)\n",
    "    s['random_x1'] = random_matched\n",
    "    s['random_x4'] = \" \".join([random_matched] * 4)\n",
    "    s['scrambled_oracle'] = scrambled\n",
    "    s['surr_template_x1'] = f\"What is {kw}?\"\n",
    "    s['surr_template_x4'] = \" \".join([f\"What is {kw}?\"] * 4)\n",
    "\n",
    "COND_NAMES = [\n",
    "    'bare',\n",
    "    'oracle_x1_trunc',\n",
    "    'oracle_x4_trunc',\n",
    "    'random_x1_trunc',\n",
    "    'random_x4_trunc',\n",
    "    'scrambled_oracle_trunc',\n",
    "    'surr_template_x1_trunc',\n",
    "    'surr_template_x4_trunc',\n",
    "]\n",
    "\n",
    "print(f\"Conditions ({len(COND_NAMES)}):\")\n",
    "for c in COND_NAMES:\n",
    "    print(f\"  {c}\")\n",
    "\n",
    "# Show example\n",
    "ex = samples[0]\n",
    "print(f\"\\nExample (sample 0):\")\n",
    "print(f\"  Query: {ex['query']}\")\n",
    "print(f\"  Answer ({ex['answer_words']}w): {ex['answer']}\")\n",
    "for c in COND_NAMES:\n",
    "    if c == 'bare':\n",
    "        print(f\"  {c:<30}: [document only]\")\n",
    "    else:\n",
    "        key = c.replace('_trunc', '')\n",
    "        text = ex[key]\n",
    "        ptoks = count_prefix_tokens(text, ex['passage'])\n",
    "        print(f\"  {c:<30} ({ptoks:>3} toks): {str(text)[:55]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403e2565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T18:48:20.272397Z",
     "iopub.status.busy": "2026-02-18T18:48:20.271864Z",
     "iopub.status.idle": "2026-02-18T19:02:53.092926Z",
     "shell.execute_reply": "2026-02-18T19:02:53.092224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCORING ALL CONDITIONS\n",
      "======================================================================\n",
      "Starting fresh: 8 conditions x 500 samples = 4000 scorings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a316d4d7d4e7f9bab4cfd596ce830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 20/500 | 0.6m | ETA 14.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 40/500 | 1.2m | ETA 13.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 60/500 | 1.8m | ETA 13.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 80/500 | 2.4m | ETA 12.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 100/500 | 2.9m | ETA 11.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 120/500 | 3.5m | ETA 11.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 140/500 | 4.1m | ETA 10.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 160/500 | 4.7m | ETA 10.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 180/500 | 5.3m | ETA 9.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 200/500 | 5.9m | ETA 8.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 220/500 | 6.4m | ETA 8.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 240/500 | 7.0m | ETA 7.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 260/500 | 7.6m | ETA 7.0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 280/500 | 8.2m | ETA 6.4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 300/500 | 8.7m | ETA 5.8m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 320/500 | 9.3m | ETA 5.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 340/500 | 9.9m | ETA 4.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 360/500 | 10.5m | ETA 4.1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 380/500 | 11.1m | ETA 3.5m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 400/500 | 11.6m | ETA 2.9m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 420/500 | 12.2m | ETA 2.3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 440/500 | 12.8m | ETA 1.7m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 460/500 | 13.4m | ETA 1.2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 480/500 | 14.0m | ETA 0.6m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint 500/500 | 14.5m | ETA 0.0m\n",
      "\n",
      "Scoring complete: 500 samples, 8 conditions in 14.5 min\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Scoring loop with checkpointing\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SCORING ALL CONDITIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "start_idx = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    ckpt = json.loads(CHECKPOINT_PATH.read_text())\n",
    "    if ckpt.get('n_total') == N_SAMPLES and len(ckpt.get('results', [])) > 0:\n",
    "        saved_queries = [r['query'][:50] for r in ckpt['results']]\n",
    "        current_queries = [s['query'][:50] for s in samples[:len(saved_queries)]]\n",
    "        if saved_queries == current_queries:\n",
    "            results = ckpt['results']\n",
    "            start_idx = len(results)\n",
    "            print(f\"Resuming from checkpoint: {start_idx}/{N_SAMPLES}\")\n",
    "\n",
    "if start_idx == 0:\n",
    "    print(f\"Starting fresh: {len(COND_NAMES)} conditions x {N_SAMPLES} samples \"\n",
    "          f\"= {len(COND_NAMES) * N_SAMPLES} scorings\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in tqdm(range(start_idx, N_SAMPLES), initial=start_idx, total=N_SAMPLES,\n",
    "              desc=\"Scoring\"):\n",
    "    s = samples[i]\n",
    "    result = {\n",
    "        'query': s['query'],\n",
    "        'answer': s['answer'],\n",
    "        'passage_words': s['word_count'],\n",
    "        'answer_words': s['answer_words'],\n",
    "    }\n",
    "\n",
    "    for cond in COND_NAMES:\n",
    "        if cond == 'bare':\n",
    "            nll = score_nll(s['passage'], s['answer'])\n",
    "            result['nll_bare'] = nll\n",
    "        else:\n",
    "            key = cond.replace('_trunc', '')\n",
    "            prefix = s[key]\n",
    "            enc_text = prefix + \"\\n\" + s['passage']\n",
    "            ptoks = count_prefix_tokens(prefix, s['passage'])\n",
    "            nll = score_nll(enc_text, s['answer'], ptoks, truncate=True)\n",
    "            result[f'nll_{cond}'] = nll\n",
    "            result[f'ptoks_{cond}'] = ptoks\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    if (i + 1) % 20 == 0 or i == N_SAMPLES - 1:\n",
    "        ckpt = {\n",
    "            'n_total': N_SAMPLES,\n",
    "            'results': results,\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        }\n",
    "        CHECKPOINT_PATH.write_text(json.dumps(ckpt))\n",
    "        elapsed = time.time() - t0\n",
    "        done = i - start_idx + 1\n",
    "        eta = (N_SAMPLES - i - 1) * elapsed / done if done > 0 else 0\n",
    "        tqdm.write(f\"  Checkpoint {i+1}/{N_SAMPLES} | {elapsed/60:.1f}m | ETA {eta/60:.1f}m\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nScoring complete: {len(results)} samples, \"\n",
    "      f\"{len(COND_NAMES)} conditions in {elapsed/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb047d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T19:02:53.096580Z",
     "iopub.status.busy": "2026-02-18T19:02:53.095990Z",
     "iopub.status.idle": "2026-02-18T19:02:53.111420Z",
     "shell.execute_reply": "2026-02-18T19:02:53.110764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 1: BASELINE CHARACTERIZATION\n",
      "======================================================================\n",
      "\n",
      "Baseline (bare):  mean NLL = 6.7691, std = 5.7364\n",
      "Oracle (x1):      mean NLL = 5.5694\n",
      "Oracle headroom:  delta = +1.1997, d = +0.767\n",
      "Oracle win rate:  92.0% (p=3.50e-52)\n",
      "\n",
      "Answer distribution: 1w: 222 (44%), 2w: 102 (20%), 3w: 73 (15%), 4w: 57 (11%), 5w: 46 (9%)\n",
      "\n",
      "--- Comparison with Exp 02 (mixed answers) ---\n",
      "  Exp 02: bare NLL=3.68, oracle d=+0.376, headroom=+0.684\n",
      "  This:   bare NLL=6.77, oracle d=+0.767, headroom=+1.200\n",
      "\n",
      "Condition                           NLL    Delta        d    Win%   %Orc\n",
      "---------------------------------------------------------------------------\n",
      "  Oracle x1                      5.5694  +1.1997   +0.767   92.0%   100%\n",
      "  Oracle x4                      5.6582  +1.1109   +0.734   90.0%    96%\n",
      "  Scrambled oracle               5.6742  +1.0949   +0.722   90.8%    94%\n",
      "  Template x1                    5.8474  +0.9217   +0.685   88.4%    89%\n",
      "  Template x4                    5.8618  +0.9073   +0.639   86.4%    83%\n",
      "  Random x1                      5.8578  +0.9113   +0.578   85.8%    75%\n",
      "  Random x4                      5.9471  +0.8220   +0.514   81.2%    67%\n",
      "  bare (lower bound)             6.7691\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Part 1 — Baseline Characterization\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 1: BASELINE CHARACTERIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "bare_nlls = np.array([r['nll_bare'] for r in results])\n",
    "oracle_x1_nlls = np.array([r['nll_oracle_x1_trunc'] for r in results])\n",
    "oracle_benefit = bare_nlls - oracle_x1_nlls\n",
    "oracle_d = cohens_d(oracle_benefit)\n",
    "\n",
    "print(f\"\\nBaseline (bare):  mean NLL = {bare_nlls.mean():.4f}, std = {bare_nlls.std():.4f}\")\n",
    "print(f\"Oracle (x1):      mean NLL = {oracle_x1_nlls.mean():.4f}\")\n",
    "print(f\"Oracle headroom:  delta = {oracle_benefit.mean():+.4f}, d = {oracle_d:+.3f}\")\n",
    "\n",
    "_, p_oracle = stats.ttest_1samp(oracle_benefit, 0)\n",
    "win_rate = np.mean(oracle_benefit > 0) * 100\n",
    "print(f\"Oracle win rate:  {win_rate:.1f}% (p={p_oracle:.2e})\")\n",
    "\n",
    "# Answer length distribution\n",
    "aw = np.array([r['answer_words'] for r in results])\n",
    "print(f\"\\nAnswer distribution: \" + \", \".join(\n",
    "    f\"{w}w: {np.sum(aw==w)} ({np.sum(aw==w)/len(aw)*100:.0f}%)\" for w in range(1, MAX_ANSWER_WORDS + 1)))\n",
    "\n",
    "# Comparison with Exp 02\n",
    "print(f\"\\n--- Comparison with Exp 02 (mixed answers) ---\")\n",
    "print(f\"  Exp 02: bare NLL=3.68, oracle d=+0.376, headroom=+0.684\")\n",
    "print(f\"  This:   bare NLL={bare_nlls.mean():.2f}, oracle d={oracle_d:+.3f}, \"\n",
    "      f\"headroom={oracle_benefit.mean():+.3f}\")\n",
    "\n",
    "# All conditions overview\n",
    "print(f\"\\n{'Condition':<30} {'NLL':>8} {'Delta':>8} {'d':>8} {'Win%':>7} {'%Orc':>6}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "all_cond_pairs = [\n",
    "    ('oracle_x1_trunc', 'Oracle x1'),\n",
    "    ('oracle_x4_trunc', 'Oracle x4'),\n",
    "    ('scrambled_oracle_trunc', 'Scrambled oracle'),\n",
    "    ('surr_template_x1_trunc', 'Template x1'),\n",
    "    ('surr_template_x4_trunc', 'Template x4'),\n",
    "    ('random_x1_trunc', 'Random x1'),\n",
    "    ('random_x4_trunc', 'Random x4'),\n",
    "]\n",
    "\n",
    "for cond, desc in all_cond_pairs:\n",
    "    nlls = np.array([r[f'nll_{cond}'] for r in results])\n",
    "    benefit = bare_nlls - nlls\n",
    "    d = cohens_d(benefit)\n",
    "    delta = benefit.mean()\n",
    "    win = 100 * np.mean(benefit > 0)\n",
    "    pct = d / oracle_d * 100 if oracle_d > 0 else 0\n",
    "    print(f\"  {desc:<28} {nlls.mean():>8.4f} {delta:>+8.4f} {d:>+8.3f} {win:>6.1f}% {pct:>5.0f}%\")\n",
    "\n",
    "print(f\"  {'bare (lower bound)':<28} {bare_nlls.mean():>8.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0075958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T19:02:53.114374Z",
     "iopub.status.busy": "2026-02-18T19:02:53.114098Z",
     "iopub.status.idle": "2026-02-18T19:02:53.130248Z",
     "shell.execute_reply": "2026-02-18T19:02:53.129599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 2: 3-WAY DECOMPOSITION (the key test)\n",
      "======================================================================\n",
      "Decompose: bare -> random_x1 -> scrambled_oracle -> oracle_x1\n",
      "  Structure:  bare -> random_x1 (any prefix helps)\n",
      "  Vocabulary: random_x1 -> scrambled (right words, wrong order)\n",
      "  Semantics:  scrambled -> oracle (right word order)\n",
      "\n",
      "  Component                 Delta   %total        d            p   sig\n",
      "  -----------------------------------------------------------------\n",
      "  Structure               +0.9113    76.0%   +0.578     3.30e-33 ***\n",
      "  Vocabulary              +0.1835    15.3%   +0.164     2.77e-04 ***\n",
      "  Semantics               +0.1048     8.7%   +0.154     6.14e-04 ***\n",
      "  TOTAL                   +1.1997   100.0%\n",
      "\n",
      "  Decomposition residual: 0.000000\n",
      "\n",
      "======================================================================\n",
      "  KEY COMPARISON: Exp 2B (mixed) vs Exp 06 (factoid only)\n",
      "  Component           Exp 2B (mixed)     Exp 06 (factoid)     Change\n",
      "  -----------------------------------------------------------------\n",
      "  Structure                    84.7%                76.0%      -8.7pp\n",
      "  Vocabulary               5.5% (ns)                15.3%      +9.8pp\n",
      "  Semantics               9.7% (***)                 8.7%      -1.0pp\n",
      "======================================================================\n",
      "\n",
      "  --> PREDICTION FAILED: structural% is still 76%.\n",
      "      Even on factoid QA, the mechanism is primarily structural.\n",
      "\n",
      "  Per-sample structural% (N=460 with total>0.01):\n",
      "    Mean: 73.2%, Median: 71.9%\n",
      "    % samples with structural < 50%: 29.8%\n",
      "    % samples with structural < 0% (random hurts): 9.3%\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Part 2 — 3-Way Decomposition\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 2: 3-WAY DECOMPOSITION (the key test)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Decompose: bare -> random_x1 -> scrambled_oracle -> oracle_x1\")\n",
    "print(\"  Structure:  bare -> random_x1 (any prefix helps)\")\n",
    "print(\"  Vocabulary: random_x1 -> scrambled (right words, wrong order)\")\n",
    "print(\"  Semantics:  scrambled -> oracle (right word order)\\n\")\n",
    "\n",
    "random_x1_nlls = np.array([r['nll_random_x1_trunc'] for r in results])\n",
    "scrambled_nlls = np.array([r['nll_scrambled_oracle_trunc'] for r in results])\n",
    "\n",
    "struct_comp = bare_nlls - random_x1_nlls\n",
    "vocab_comp = random_x1_nlls - scrambled_nlls\n",
    "sem_comp = scrambled_nlls - oracle_x1_nlls\n",
    "total_comp = bare_nlls - oracle_x1_nlls\n",
    "\n",
    "total_mean = total_comp.mean()\n",
    "\n",
    "print(f\"  {'Component':<20} {'Delta':>10} {'%total':>8} {'d':>8} {'p':>12} {'sig':>5}\")\n",
    "print(f\"  {'-'*65}\")\n",
    "\n",
    "for label, comp in [('Structure', struct_comp), ('Vocabulary', vocab_comp),\n",
    "                    ('Semantics', sem_comp)]:\n",
    "    mu = comp.mean()\n",
    "    pct = mu / total_mean * 100 if total_mean != 0 else 0\n",
    "    d = cohens_d(comp)\n",
    "    _, p = stats.ttest_1samp(comp, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    print(f\"  {label:<20} {mu:>+10.4f} {pct:>7.1f}% {d:>+8.3f} {p:>12.2e} {sig}\")\n",
    "\n",
    "print(f\"  {'TOTAL':<20} {total_mean:>+10.4f} {'100.0%':>8}\")\n",
    "residual = total_mean - (struct_comp.mean() + vocab_comp.mean() + sem_comp.mean())\n",
    "print(f\"\\n  Decomposition residual: {residual:.6f}\")\n",
    "\n",
    "struct_pct = struct_comp.mean() / total_mean * 100 if total_mean != 0 else 0\n",
    "vocab_pct = vocab_comp.mean() / total_mean * 100 if total_mean != 0 else 0\n",
    "sem_pct = sem_comp.mean() / total_mean * 100 if total_mean != 0 else 0\n",
    "\n",
    "# THE KEY COMPARISON\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  KEY COMPARISON: Exp 2B (mixed) vs Exp 06 (factoid only)\")\n",
    "print(f\"  {'Component':<15} {'Exp 2B (mixed)':>18} {'Exp 06 (factoid)':>20} {'Change':>10}\")\n",
    "print(f\"  {'-'*65}\")\n",
    "print(f\"  {'Structure':<15} {'84.7%':>18} {struct_pct:>19.1f}% {struct_pct-84.7:>+9.1f}pp\")\n",
    "print(f\"  {'Vocabulary':<15} {'5.5% (ns)':>18} {vocab_pct:>19.1f}% {vocab_pct-5.5:>+9.1f}pp\")\n",
    "print(f\"  {'Semantics':<15} {'9.7% (***)':>18} {sem_pct:>19.1f}% {sem_pct-9.7:>+9.1f}pp\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if struct_pct < 60:\n",
    "    print(f\"\\n  --> PREDICTION CONFIRMED: structural% dropped to {struct_pct:.0f}%.\")\n",
    "    print(f\"      For short factoid answers, query content matters.\")\n",
    "    print(f\"      The 'directed' in directed KV cache IS valuable for this task type.\")\n",
    "elif struct_pct < 75:\n",
    "    print(f\"\\n  --> PARTIAL: structural% dropped to {struct_pct:.0f}% (from 85%).\")\n",
    "    print(f\"      Meaningful shift but structure still dominates.\")\n",
    "else:\n",
    "    print(f\"\\n  --> PREDICTION FAILED: structural% is still {struct_pct:.0f}%.\")\n",
    "    print(f\"      Even on factoid QA, the mechanism is primarily structural.\")\n",
    "\n",
    "# Per-sample structural% distribution\n",
    "per_sample_struct_pct = []\n",
    "for i in range(N_SAMPLES):\n",
    "    total_i = total_comp[i]\n",
    "    if total_i > 0.01:  # avoid division by near-zero\n",
    "        per_sample_struct_pct.append(struct_comp[i] / total_i * 100)\n",
    "per_sample_struct_pct = np.array(per_sample_struct_pct)\n",
    "print(f\"\\n  Per-sample structural% (N={len(per_sample_struct_pct)} with total>0.01):\")\n",
    "print(f\"    Mean: {per_sample_struct_pct.mean():.1f}%, Median: {np.median(per_sample_struct_pct):.1f}%\")\n",
    "print(f\"    % samples with structural < 50%: {np.mean(per_sample_struct_pct < 50)*100:.1f}%\")\n",
    "print(f\"    % samples with structural < 0% (random hurts): {np.mean(per_sample_struct_pct < 0)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de2db7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T19:02:53.133135Z",
     "iopub.status.busy": "2026-02-18T19:02:53.132597Z",
     "iopub.status.idle": "2026-02-18T19:02:53.145981Z",
     "shell.execute_reply": "2026-02-18T19:02:53.145317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 3: SURROGATE COMPARISON\n",
      "======================================================================\n",
      "Does 'What is [keyword]?' beat random for factoid QA?\n",
      "\n",
      "  Does oracle beat random? (semantic signal exists?)\n",
      "    oracle_x1 vs random_x1: d=+0.256, win=71.8%, p=1.78e-08 *** [oracle_x1]\n",
      "\n",
      "  Does template beat random? (heuristic captures semantics?)\n",
      "    surr_template_x1 vs random_x1: d=+0.012, win=51.2%, p=7.87e-01 ns [surr_template_x1]\n",
      "\n",
      "  Does oracle beat template? (room for improvement?)\n",
      "    oracle_x1 vs surr_template_x1: d=+0.376, win=69.2%, p=4.36e-16 *** [oracle_x1]\n",
      "\n",
      "  Does template x4 beat random x4? (amplified by repetition?)\n",
      "    surr_template_x4 vs random_x4: d=+0.096, win=59.4%, p=3.26e-02 * [surr_template_x4]\n",
      "\n",
      "  Does oracle x4 beat template x4?\n",
      "    oracle_x4 vs surr_template_x4: d=+0.289, win=68.6%, p=2.38e-10 *** [oracle_x4]\n",
      "\n",
      "--- Comparison with Exp 02 ---\n",
      "  Exp 02 oracle vs random: d=+0.080 (ns on mixed sample)\n",
      "  Exp 06 oracle vs random: d=+0.256 (factoid)\n",
      "  Exp 06 template vs random: d=+0.012 (factoid)\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Part 3 — Surrogate Comparison\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 3: SURROGATE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Does 'What is [keyword]?' beat random for factoid QA?\\n\")\n",
    "\n",
    "surr_x1_nlls = np.array([r['nll_surr_template_x1_trunc'] for r in results])\n",
    "surr_x4_nlls = np.array([r['nll_surr_template_x4_trunc'] for r in results])\n",
    "random_x4_nlls = np.array([r['nll_random_x4_trunc'] for r in results])\n",
    "oracle_x4_nlls = np.array([r['nll_oracle_x4_trunc'] for r in results])\n",
    "\n",
    "# Head-to-head comparisons\n",
    "pairs = [\n",
    "    ('oracle_x1', oracle_x1_nlls, 'random_x1', random_x1_nlls,\n",
    "     \"Does oracle beat random? (semantic signal exists?)\"),\n",
    "    ('surr_template_x1', surr_x1_nlls, 'random_x1', random_x1_nlls,\n",
    "     \"Does template beat random? (heuristic captures semantics?)\"),\n",
    "    ('oracle_x1', oracle_x1_nlls, 'surr_template_x1', surr_x1_nlls,\n",
    "     \"Does oracle beat template? (room for improvement?)\"),\n",
    "    ('surr_template_x4', surr_x4_nlls, 'random_x4', random_x4_nlls,\n",
    "     \"Does template x4 beat random x4? (amplified by repetition?)\"),\n",
    "    ('oracle_x4', oracle_x4_nlls, 'surr_template_x4', surr_x4_nlls,\n",
    "     \"Does oracle x4 beat template x4?\"),\n",
    "]\n",
    "\n",
    "for name_a, nlls_a, name_b, nlls_b, question in pairs:\n",
    "    diff = nlls_b - nlls_a  # positive = A is better\n",
    "    d = cohens_d(diff)\n",
    "    win = 100 * np.mean(diff > 0)\n",
    "    _, p = stats.ttest_1samp(diff, 0)\n",
    "    sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    winner = name_a if d > 0 else name_b\n",
    "    print(f\"  {question}\")\n",
    "    print(f\"    {name_a} vs {name_b}: d={d:+.3f}, win={win:.1f}%, p={p:.2e} {sig} [{winner}]\")\n",
    "    print()\n",
    "\n",
    "# Compare with Exp 02 (mixed sample)\n",
    "print(f\"--- Comparison with Exp 02 ---\")\n",
    "print(f\"  Exp 02 oracle vs random: d=+0.080 (ns on mixed sample)\")\n",
    "surr_rand_d = cohens_d(random_x1_nlls - surr_x1_nlls)\n",
    "oracle_rand_d = cohens_d(random_x1_nlls - oracle_x1_nlls)\n",
    "print(f\"  Exp 06 oracle vs random: d={oracle_rand_d:+.3f} (factoid)\")\n",
    "print(f\"  Exp 06 template vs random: d={surr_rand_d:+.3f} (factoid)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4b9713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T19:02:53.148728Z",
     "iopub.status.busy": "2026-02-18T19:02:53.148455Z",
     "iopub.status.idle": "2026-02-18T19:02:53.169485Z",
     "shell.execute_reply": "2026-02-18T19:02:53.168866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 4: HARDNESS INTERACTION (within factoid)\n",
      "======================================================================\n",
      "\n",
      "  Quintile        N   Bare NLL   Struct%   Vocab%    Sem%   Oracle d  Orc vs Rand\n",
      "  --------------------------------------------------------------------------------\n",
      "  Q1 easy       100      1.866     57.8%    31.0%   11.2%     +1.072   +0.435 ***\n",
      "  Q2            100      3.011     60.1%    27.6%   12.3%     +1.325   +0.561 ***\n",
      "  Q3             98      4.468     71.1%    24.9%    4.0%     +1.244   +0.425 ***\n",
      "  Q4            102      7.860     66.8%    20.0%   13.2%     +1.488   +0.663 ***\n",
      "  Q5 hard       100     16.572     83.5%     9.3%    7.2%     +1.667   +0.241 *\n",
      "\n",
      "--- Correlations ---\n",
      "  hardness vs structure:  r=+0.757 (p=3.16e-94)\n",
      "  hardness vs vocabulary: r=+0.039 (p=3.83e-01)\n",
      "  hardness vs semantics:  r=+0.074 (p=9.87e-02)\n",
      "\n",
      "--- By answer length ---\n",
      "  1 word (N=222): struct=77.3%, sem=9.5%, oracle d=+0.978\n",
      "  2-3 words (N=175): struct=71.8%, sem=5.5%, oracle d=+0.757\n",
      "  4-5 words (N=103): struct=77.4%, sem=12.2%, oracle d=+0.808\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Part 4 — Hardness Interaction\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 4: HARDNESS INTERACTION (within factoid)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "quintile_bounds = np.percentile(bare_nlls, [20, 40, 60, 80])\n",
    "quintiles = np.digitize(bare_nlls, quintile_bounds)\n",
    "q_labels = ['Q1 easy', 'Q2', 'Q3', 'Q4', 'Q5 hard']\n",
    "\n",
    "print(f\"\\n  {'Quintile':<12} {'N':>4} {'Bare NLL':>10} {'Struct%':>9} {'Vocab%':>8} \"\n",
    "      f\"{'Sem%':>7} {'Oracle d':>10} {'Orc vs Rand':>12}\")\n",
    "print(f\"  {'-'*80}\")\n",
    "\n",
    "for q in range(5):\n",
    "    mask = quintiles == q\n",
    "    n = mask.sum()\n",
    "    bare_q = bare_nlls[mask].mean()\n",
    "\n",
    "    s_comp = (bare_nlls[mask] - random_x1_nlls[mask]).mean()\n",
    "    v_comp = (random_x1_nlls[mask] - scrambled_nlls[mask]).mean()\n",
    "    sm_comp = (scrambled_nlls[mask] - oracle_x1_nlls[mask]).mean()\n",
    "    t_comp = (bare_nlls[mask] - oracle_x1_nlls[mask]).mean()\n",
    "\n",
    "    if t_comp > 0:\n",
    "        s_pct = s_comp / t_comp * 100\n",
    "        v_pct = v_comp / t_comp * 100\n",
    "        sm_pct = sm_comp / t_comp * 100\n",
    "    else:\n",
    "        s_pct = v_pct = sm_pct = 0\n",
    "\n",
    "    o_d = cohens_d(bare_nlls[mask] - oracle_x1_nlls[mask])\n",
    "\n",
    "    # Oracle vs random head-to-head\n",
    "    diff_q = random_x1_nlls[mask] - oracle_x1_nlls[mask]\n",
    "    or_d = cohens_d(diff_q)\n",
    "    _, or_p = stats.ttest_1samp(diff_q, 0)\n",
    "    or_sig = '***' if or_p < 0.001 else '**' if or_p < 0.01 else '*' if or_p < 0.05 else 'ns'\n",
    "\n",
    "    print(f\"  {q_labels[q]:<12} {n:>4} {bare_q:>10.3f} {s_pct:>8.1f}% {v_pct:>7.1f}% \"\n",
    "          f\"{sm_pct:>6.1f}% {o_d:>+10.3f} {or_d:>+8.3f} {or_sig}\")\n",
    "\n",
    "# Correlations\n",
    "print(f\"\\n--- Correlations ---\")\n",
    "r_s, p_s = stats.pearsonr(bare_nlls, struct_comp)\n",
    "r_v, p_v = stats.pearsonr(bare_nlls, vocab_comp)\n",
    "r_sm, p_sm = stats.pearsonr(bare_nlls, sem_comp)\n",
    "print(f\"  hardness vs structure:  r={r_s:+.3f} (p={p_s:.2e})\")\n",
    "print(f\"  hardness vs vocabulary: r={r_v:+.3f} (p={p_v:.2e})\")\n",
    "print(f\"  hardness vs semantics:  r={r_sm:+.3f} (p={p_sm:.2e})\")\n",
    "\n",
    "# By answer length (1w vs 2-3w vs 4-5w)\n",
    "print(f\"\\n--- By answer length ---\")\n",
    "for aw_label, aw_min, aw_max in [('1 word', 1, 1), ('2-3 words', 2, 3), ('4-5 words', 4, 5)]:\n",
    "    aw = np.array([r['answer_words'] for r in results])\n",
    "    mask = (aw >= aw_min) & (aw <= aw_max)\n",
    "    n = mask.sum()\n",
    "    if n < 10:\n",
    "        continue\n",
    "    t = (bare_nlls[mask] - oracle_x1_nlls[mask]).mean()\n",
    "    s = (bare_nlls[mask] - random_x1_nlls[mask]).mean()\n",
    "    if t > 0:\n",
    "        s_pct = s / t * 100\n",
    "        sm_pct = ((scrambled_nlls[mask] - oracle_x1_nlls[mask]).mean()) / t * 100\n",
    "    else:\n",
    "        s_pct = sm_pct = 0\n",
    "    o_d = cohens_d(bare_nlls[mask] - oracle_x1_nlls[mask])\n",
    "    print(f\"  {aw_label} (N={n}): struct={s_pct:.1f}%, sem={sm_pct:.1f}%, oracle d={o_d:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25647c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T19:02:53.172361Z",
     "iopub.status.busy": "2026-02-18T19:02:53.172118Z",
     "iopub.status.idle": "2026-02-18T19:02:53.676561Z",
     "shell.execute_reply": "2026-02-18T19:02:53.675897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SYNTHESIS: FACTOID SUBSAMPLE RESULTS\n",
      "======================================================================\n",
      "\n",
      "1. DATASET: MS MARCO v1.1, filtered to answer <= 5 words\n",
      "   N: 500, mean answer: 2.2 words\n",
      "   Oracle headroom: d=+0.767, delta=+1.200\n",
      "\n",
      "2. 3-WAY DECOMPOSITION:\n",
      "   Component           Exp 2B (mixed)     Exp 06 (factoid)\n",
      "   -------------------------------------------------------\n",
      "   Structure                    84.7%                76.0%\n",
      "   Vocabulary                    5.5%                15.3%\n",
      "   Semantics                     9.7%                 8.7%\n",
      "\n",
      "3. SURROGATE COMPARISON:\n",
      "   Oracle vs random:   d=+0.256 (***)\n",
      "   Template vs random: d=+0.012 (ns)\n",
      "\n",
      "======================================================================\n",
      "CONCLUSIONS:\n",
      "  1. PREDICTION FAILED: structural% is still 76% even for factoid QA.\n",
      "  2. Oracle beats random (d=+0.256) but template does not.\n",
      "     The semantic signal exists but the heuristic doesn't capture it.\n",
      "\n",
      "  Practical implication: the structural mechanism dominates even for factoid QA.\n",
      "======================================================================\n",
      "\n",
      "Results saved to results/exp06/results.json\n",
      "\n",
      "Cleaning up GPU memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 15.03 GB -> 0.01 GB\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Synthesis + Save\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SYNTHESIS: FACTOID SUBSAMPLE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summary numbers\n",
    "print(f\"\\n1. DATASET: MS MARCO v1.1, filtered to answer <= {MAX_ANSWER_WORDS} words\")\n",
    "print(f\"   N: {N_SAMPLES}, mean answer: {answer_words.mean():.1f} words\")\n",
    "print(f\"   Oracle headroom: d={oracle_d:+.3f}, delta={oracle_benefit.mean():+.3f}\")\n",
    "\n",
    "print(f\"\\n2. 3-WAY DECOMPOSITION:\")\n",
    "print(f\"   {'Component':<15} {'Exp 2B (mixed)':>18} {'Exp 06 (factoid)':>20}\")\n",
    "print(f\"   {'-'*55}\")\n",
    "print(f\"   {'Structure':<15} {'84.7%':>18} {struct_pct:>19.1f}%\")\n",
    "print(f\"   {'Vocabulary':<15} {'5.5%':>18} {vocab_pct:>19.1f}%\")\n",
    "print(f\"   {'Semantics':<15} {'9.7%':>18} {sem_pct:>19.1f}%\")\n",
    "\n",
    "print(f\"\\n3. SURROGATE COMPARISON:\")\n",
    "oracle_rand_d_val = cohens_d(random_x1_nlls - oracle_x1_nlls)\n",
    "surr_rand_d_val = cohens_d(random_x1_nlls - surr_x1_nlls)\n",
    "_, p_or = stats.ttest_1samp(random_x1_nlls - oracle_x1_nlls, 0)\n",
    "_, p_sr = stats.ttest_1samp(random_x1_nlls - surr_x1_nlls, 0)\n",
    "or_sig = '***' if p_or < 0.001 else '**' if p_or < 0.01 else '*' if p_or < 0.05 else 'ns'\n",
    "sr_sig = '***' if p_sr < 0.001 else '**' if p_sr < 0.01 else '*' if p_sr < 0.05 else 'ns'\n",
    "print(f\"   Oracle vs random:   d={oracle_rand_d_val:+.3f} ({or_sig})\")\n",
    "print(f\"   Template vs random: d={surr_rand_d_val:+.3f} ({sr_sig})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CONCLUSIONS:\")\n",
    "\n",
    "if struct_pct < 60:\n",
    "    mechanism = \"SEMANTIC_DOMINANT\"\n",
    "    print(f\"  1. PREDICTION CONFIRMED: factoid QA is {struct_pct:.0f}% structural / \"\n",
    "          f\"{100-struct_pct:.0f}% content.\")\n",
    "    print(f\"     The '85% structural' finding was an artifact of averaging over two populations.\")\n",
    "    print(f\"     For short factoid answers, the directed KV cache IS worth directing.\")\n",
    "elif struct_pct < 75:\n",
    "    mechanism = \"MIXED\"\n",
    "    print(f\"  1. PARTIAL CONFIRMATION: structural% dropped to {struct_pct:.0f}% (from 85%).\")\n",
    "    print(f\"     Content matters more for factoid QA but structure still dominates.\")\n",
    "else:\n",
    "    mechanism = \"STILL_STRUCTURAL\"\n",
    "    print(f\"  1. PREDICTION FAILED: structural% is still {struct_pct:.0f}% even for factoid QA.\")\n",
    "\n",
    "if surr_rand_d_val > 0.05 and p_sr < 0.05:\n",
    "    surrogate_value = \"POSITIVE\"\n",
    "    print(f\"  2. Template surrogate significantly beats random (d={surr_rand_d_val:+.3f}).\")\n",
    "    print(f\"     Heuristic surrogates have positive ROI for factoid QA.\")\n",
    "elif oracle_rand_d_val > 0.05 and p_or < 0.05:\n",
    "    surrogate_value = \"ORACLE_ONLY\"\n",
    "    print(f\"  2. Oracle beats random (d={oracle_rand_d_val:+.3f}) but template does not.\")\n",
    "    print(f\"     The semantic signal exists but the heuristic doesn't capture it.\")\n",
    "else:\n",
    "    surrogate_value = \"NONE\"\n",
    "    print(f\"  2. Even oracle barely beats random on factoid QA.\")\n",
    "\n",
    "print(f\"\\n  Practical implication: \", end=\"\")\n",
    "if mechanism == \"SEMANTIC_DOMINANT\" and surrogate_value == \"POSITIVE\":\n",
    "    print(\"for factoid extraction tasks, invest in content-aware surrogates.\")\n",
    "elif mechanism == \"SEMANTIC_DOMINANT\":\n",
    "    print(\"semantic content matters but better surrogates are needed to capture it.\")\n",
    "else:\n",
    "    print(\"the structural mechanism dominates even for factoid QA.\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Save results\n",
    "final_results = {\n",
    "    'experiment': 'exp06_factoid_subsample',\n",
    "    'model': MODEL_NAME,\n",
    "    'dataset': 'ms_marco_v1.1_short_answers',\n",
    "    'n_samples': N_SAMPLES,\n",
    "    'max_answer_words': MAX_ANSWER_WORDS,\n",
    "    'mean_answer_words': float(answer_words.mean()),\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'baseline': {\n",
    "        'bare_nll': float(bare_nlls.mean()),\n",
    "        'oracle_d': float(oracle_d),\n",
    "        'oracle_headroom': float(oracle_benefit.mean()),\n",
    "    },\n",
    "    'decomposition': {\n",
    "        'structure_pct': float(struct_pct),\n",
    "        'vocabulary_pct': float(vocab_pct),\n",
    "        'semantics_pct': float(sem_pct),\n",
    "        'structure_d': float(cohens_d(struct_comp)),\n",
    "        'vocabulary_d': float(cohens_d(vocab_comp)),\n",
    "        'semantics_d': float(cohens_d(sem_comp)),\n",
    "    },\n",
    "    'surrogate_comparison': {\n",
    "        'oracle_vs_random_d': float(oracle_rand_d_val),\n",
    "        'oracle_vs_random_p': float(p_or),\n",
    "        'template_vs_random_d': float(surr_rand_d_val),\n",
    "        'template_vs_random_p': float(p_sr),\n",
    "    },\n",
    "    'conditions': {},\n",
    "    'conclusion': {\n",
    "        'mechanism': mechanism,\n",
    "        'surrogate_value': surrogate_value,\n",
    "    },\n",
    "}\n",
    "\n",
    "for cond, desc in all_cond_pairs:\n",
    "    nlls = np.array([r[f'nll_{cond}'] for r in results])\n",
    "    benefit = bare_nlls - nlls\n",
    "    d = cohens_d(benefit)\n",
    "    _, p = stats.ttest_1samp(benefit, 0)\n",
    "    final_results['conditions'][cond] = {\n",
    "        'description': desc,\n",
    "        'd': float(d),\n",
    "        'mean_nll': float(nlls.mean()),\n",
    "        'mean_delta': float(benefit.mean()),\n",
    "        'pct_oracle': float(d / oracle_d * 100) if oracle_d > 0 else 0,\n",
    "        'p': float(p),\n",
    "    }\n",
    "\n",
    "with open(RESULTS_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\nResults saved to {RESULTS_DIR / 'results.json'}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\nCleaning up GPU memory...\")\n",
    "mem_before = torch.cuda.memory_allocated() / 1e9\n",
    "del model, processor, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "mem_after = torch.cuda.memory_allocated() / 1e9\n",
    "print(f\"GPU memory: {mem_before:.2f} GB -> {mem_after:.2f} GB\")\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06187d7b25e44b1aaacd62a19efc61a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1321d1c7c39d43d3b4873c1e15b75b3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "232a4389d89e4da6a77ec9e7d48e1d41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3c6a316d4d7d4e7f9bab4cfd596ce830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_754abeefc0104e31a4c186e9bf643587",
        "IPY_MODEL_db5c754b794f4bf6ae6268877ae2d946",
        "IPY_MODEL_4d7830da6da84659b98820feb83b5dfd"
       ],
       "layout": "IPY_MODEL_80249a971a934e19a2921c5afeda0dde",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3f9a945ae6cc41ac89157fc80fd7a41f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4d7830da6da84659b98820feb83b5dfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6f86b2745dd54bb1b289f0dea90837ed",
       "placeholder": "​",
       "style": "IPY_MODEL_4e5faa9f12ae4577b1fe74d9c2370551",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [14:32&lt;00:00,  1.75s/it]"
      }
     },
     "4e5faa9f12ae4577b1fe74d9c2370551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57690e2c02964143b80e3f805328ec20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9db2e6fbbd6c45f68dd059c8fb917122",
       "max": 1327.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1321d1c7c39d43d3b4873c1e15b75b3c",
       "tabbable": null,
       "tooltip": null,
       "value": 1327.0
      }
     },
     "657b591856f0439f998c8e0004e8edfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f86b2745dd54bb1b289f0dea90837ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "754abeefc0104e31a4c186e9bf643587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_657b591856f0439f998c8e0004e8edfa",
       "placeholder": "​",
       "style": "IPY_MODEL_3f9a945ae6cc41ac89157fc80fd7a41f",
       "tabbable": null,
       "tooltip": null,
       "value": "Scoring: 100%"
      }
     },
     "794e36097cb244d99acc13aaa7e1cfbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80249a971a934e19a2921c5afeda0dde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95087557da8d4808a93c14538b52299a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b6753d7355e45ae8c12d556ae0bbb3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9db2e6fbbd6c45f68dd059c8fb917122": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1bf602f29eb49a68fa35a968988f989": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fc793c21e1514f0ca754545852592deb",
        "IPY_MODEL_57690e2c02964143b80e3f805328ec20",
        "IPY_MODEL_cfaf82b3cd794109932ab112073e08a5"
       ],
       "layout": "IPY_MODEL_794e36097cb244d99acc13aaa7e1cfbf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cfaf82b3cd794109932ab112073e08a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b6753d7355e45ae8c12d556ae0bbb3b",
       "placeholder": "​",
       "style": "IPY_MODEL_232a4389d89e4da6a77ec9e7d48e1d41",
       "tabbable": null,
       "tooltip": null,
       "value": " 1327/1327 [00:04&lt;00:00, 724.05it/s, Materializing param=model.encoder.vision_tower.vision_model.post_layernorm.weight]"
      }
     },
     "d2436dec79754dddaf4ce4ddcd4b12ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d64b661da9be4c12926a2a16dbe7c4e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db5c754b794f4bf6ae6268877ae2d946": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_06187d7b25e44b1aaacd62a19efc61a7",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d2436dec79754dddaf4ce4ddcd4b12ea",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "fc793c21e1514f0ca754545852592deb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95087557da8d4808a93c14538b52299a",
       "placeholder": "​",
       "style": "IPY_MODEL_d64b661da9be4c12926a2a16dbe7c4e6",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading weights: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
